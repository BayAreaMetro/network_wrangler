{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Network Wrangler is a Python library for managing travel model network scenarios.</p>"},{"location":"#system-requirements","title":"System Requirements","text":"<p>Network Wrangler should be operating system agonistic and has been tested on Ubuntu and Mac OS.</p> <p>Network Wrangler does require Python 3.9+.  If you have a different version of Python installed (e.g. from ArcGIS), <code>conda</code> or a similar virtual environment manager can care of installing it for you in the installation instructions below.</p> <p>installing conda</p> <p>In order to assist in installation, its helpful to have miniconda or another virtual environment manager installed to make sure the network wrangler dependencies don\u2019t interfer with any other package requirements you have. If you don\u2019t have any of these already, we recommend starting with Miniconda as it has the smallest footprint. <code>conda</code> is the environment manager that is contained within both the Anaconda and mini-conda applications.</p> installing conda or Anaconda (the GUI version) for the first time on computer with Cube or ArcGIS?<p>For ArcGIS / Cube users - Recommend Install conda by leaving boxes unchecked for advanced options \u2013 system path and register anaconda. On some systems, checking these boxes will break Cube and ArcGis systems.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#create-and-activate-virtual-environment","title":"Create and Activate Virtual Environment","text":"<p>Create and/or activate the virtual environment where you want to install Network Wrangler.</p> <p>Option 1. Create a new conda environment for wrangler using conda</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.11 -n wrangler #if you don't already have a virtual environment\nconda activate wrangler\n</code></pre> <p>Option 2. Use pre-packaged conda-environment with all dependencies</p> <p>Network wrangler comes packaged with a conda environment that already has all the required dependencies.  This can be helpful if you are having trouble with different versions of requirements since <code>conda</code> can be better at sorting through them than <code>pip</code>.</p> <pre><code>conda config --add channels conda-forge\nconda env create -f environments/conda/environment.yml\nconda activate wrangler\n</code></pre>"},{"location":"#step-2-consider-which-dependencies-you-want","title":"Step 2. Consider which Dependencies you want","text":"<p>The core requirements for network wrangler are specified in <code>pyproject.toml</code> and will be automatically checked and installed when you install network wrangler.</p> <p>Additional, optional libraries are specified in separate requirements files to reduce the bloat of the minimum installation.</p> File pip Option Code Purpose <code>requirements.viz.txt</code> <code>viz</code> Requirements for running visualizations. <code>requirements.docs.txt</code> <code>docs</code> Requirements for building documentation. <code>requirements.tests.txt</code> <code>tests</code> Requirements for running tests. <p>If you want to view your networks or use jupyter notebooks, will likely want to install at least the visualization dependencies, which you can always do later as follows:</p> <pre><code>conda activate wrangler\npip install -r requirements.viz.txt\n</code></pre> <p>install additional dependencies using pip</p> <p>You don\u2019t have to separately install these dependencies. You can also install them when you install network wrangler itself using command like follows using the respective pip option code or a list of them:</p> <pre><code>conda activate wrangler\npip install network-wrangler[viz]\n</code></pre> <p>tricky dependencies</p> <p><code>rtree</code>, <code>geopandas</code> and <code>osmnx</code> can have some tricky co-dependencies.  If don\u2019t already have an up-to-date installation of them, we\u2019ve had the best success installing them using conda (as opposed to pip).</p> <pre><code>conda install rtree geopandas osmnx\n</code></pre>"},{"location":"#step-3-install-wrangler","title":"Step 3. Install Wrangler","text":"Latest ReleaseFrom GitHub <pre><code>pip install network-wrangler\n</code></pre> <p>Only necessary if you want to test features before they have released as official versions.</p> <pre><code>pip install git+https://github.com/wsp-sag/network_wrangler.git@develop#egg=network_wrangler\n</code></pre> <p>Tip</p> <p>If you wanted to install from a specific tag/version number or branch, replace <code>@develop</code> with <code>@&lt;branchname&gt;</code>  or <code>@tag</code></p>"},{"location":"#common-installation-issues","title":"Common Installation Issues","text":"libstdc++ is deprecated <p>clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]`</p> <p>If you are using MacOS, you might need to update your xcode command line tools and headers</p> libspatialindex_c or Missing GEOS module <p>\u201cOSError: Could not find libspatialindex_c library file</p> <p>or</p> <p>Shapely, a pre-requisite, doesn\u2019t install propertly because it is missing GEOS module</p> <p>Try installing them using conda.</p> <pre><code>conda uninstall geopandas rtree shapely\nconda install rtree shapely geopandas\n</code></pre> Conda is unable to install a library or to update to a specific library version<p>Add libraries from conda-forge</p> <pre><code>conda install -c conda-forge *library*\n</code></pre> User does not have permission to install in directories<p>Try running Anaconda as an administrator, even if you are an admin on your machine.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>To get a feel for the API and using project cards, please refer to the \u201cWrangler Quickstart\u201d jupyter notebook.</p> <p>To start the notebook, open a command line in the network_wrangler top-level directory and type:</p> <p><code>jupyter notebook</code></p>"},{"location":"#usage","title":"Usage","text":"<pre><code>import network_wrangler\n\n##todo this is just an example for now\n\nnetwork_wrangler.setup_logging()\n\n## Network Manipulation\nmy_network = network_wrangler.read_roadway_network(...) # returns\nmy_network.apply_project_card(...) # returns\nmy_network.write_roadway_network(...) # returns\n\n## Scenario Building\nmy_scenario = network_wrangler.create_scenario(\n        base_scenario=my_base_scenario,\n        card_search_dir=project_card_directory,\n        tags = [\"baseline-2050\"]\n        )\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/baseline\", \"baseline-2050\")\nmy_scenario.summarize(outfile=\"scenario_summary_baseline.txt\")\n\nmy_scenario.add_projects_from_files(list_of_build_project_card_files)\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\nmy_scenario.write(\"my_project/build\", \"baseline\")\n</code></pre>"},{"location":"#attribution","title":"Attribution","text":"<p>NetworkWrangler was developed using resources from the Metropolitan Transportation Commission, Metropolitan Council MN, and in-kind time from UrbanLabs LLC and WSP.  It is currently maintained using in-kind time\u2026so please be patient.</p> <p>This project is built upon the ideas and concepts implemented in the network wrangler project by the San Francisco County Transportation Authority and expanded upon by the Metropolitan Transportation Commission.</p> <p>While Network Wrangler as written here is based on these concepts, the code is distinct and builds upon other packages such as <code>geopandas</code> and <code>pydantic</code> which hadn\u2019t been implemented when networkwrangler 1.0 was developed.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome. Please review contributing guidelines and instructions.</p>"},{"location":"#companion-software","title":"Companion Software","text":"<p>ProjectCard: Initially part of NetworkWrangler, the functionality for reading, writing and validating ProjectCard objects was pulled out into a separate project so that it could be used by other entities without necessitating NetworkWrangler.</p>"},{"location":"#having-an-issue","title":"Having an issue?","text":"<p>\ud83e\udeb2 NetworkWrangler may contain bugs.</p> <p>\ud83e\udd14 Also, since it has primarily been used by its developers, the documentation may contain some omissions or not be entirely clear.</p> <p>But we\u2019d love to make it better! Please report bugs or incorrect/unclear/missing documentation with a GitHub Issue -  or fix them yourself with a pull request!</p>"},{"location":"#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"#release-history","title":"Release History","text":""},{"location":"#changelog","title":"Changelog","text":"<p>Notable changes and version history.</p> Version Date Comment v1.0-beta-2 20204-10-15 Bug fixes in scenario loading, projectcard API and compatibility of transit net with roadway deletions. Some additional performance improvements. v1.0-beta-1 20204-10-9 Feature-complete for 1.0 v1.0-alpha-2 2024-10-8 Testing for Met Council v1.0-alpha-1 2024-07-17 Full refactor v0.2.0-alpha 2020-09-16 - v0.1.0-alpha 2020-09-09 - 0.0.2 2020-02-05 -"},{"location":"api/","title":"API Documentation","text":""},{"location":"api/#core-classes","title":"Core Classes","text":"<p>The fundamental classes that form the backbone of Network Wrangler:</p> <p>Scenario objects manage how a collection of projects is applied to the networks.</p> <p>Scenarios are built from a base scenario and a list of project cards.</p> <p>A project card is a YAML file (or similar) that describes a change to the network. The project card can contain multiple changes, each of which is applied to the network in sequence.</p> <p>Roadway Network class and functions for Network Wrangler.</p> <p>Used to represent a roadway network and perform operations on it.</p> <p>Usage:</p> <pre><code>from network_wrangler import load_roadway_from_dir, write_roadway\n\nnet = load_roadway_from_dir(\"my_dir\")\nnet.get_selection({\"links\": [{\"name\": [\"I 35E\"]}]})\nnet.apply(\"my_project_card.yml\")\n\nwrite_roadway(net, \"my_out_prefix\", \"my_dir\", file_format=\"parquet\")\n</code></pre> <p>TransitNetwork class for representing a transit network.</p> <p>Transit Networks are represented as a Wrangler-flavored GTFS Feed and optionally mapped to a RoadwayNetwork object. The TransitNetwork object is the primary object for managing transit networks in Wrangler.</p> <p>Usage:</p> <pre><code>```python\nimport network_wrangler as wr\n\nt = wr.load_transit(stpaul_gtfs)\nt.road_net = wr.load_roadway(stpaul_roadway)\nt = t.apply(project_card)\nwrite_transit(t, \"output_dir\")\n```\n</code></pre>"},{"location":"api/#network_wrangler.scenario--create-a-scenario","title":"Create a Scenario","text":"<p>Instantiate a scenario by seeding it with a base scenario and optionally some project cards.</p> <pre><code>from network_wrangler import create_scenario\n\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags=[\"baseline2050\"],\n)\n</code></pre> <p>A <code>base_year_scenario</code> is a dictionary representation of key components of a scenario:</p> <ul> <li><code>road_net</code>: RoadwayNetwork instance</li> <li><code>transit_net</code>: TransitNetwork instance</li> <li><code>applied_projects</code>: list of projects that have been applied to the base scenario so that the     scenario knows if there will be conflicts with future projects or if a future project\u2019s     pre-requisite is satisfied.</li> <li><code>conflicts</code>: dictionary of conflicts for project that have been applied to the base scenario so     that the scenario knows if there will be conflicts with future projects.</li> </ul> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_from_roadway_dir(STPAUL_DIR),\n    \"transit_net\": load_transit(STPAUL_DIR),\n    \"applied_projects\": [],\n    \"conflicts\": {},\n}\n</code></pre>"},{"location":"api/#network_wrangler.scenario--add-projects-to-a-scenario","title":"Add Projects to a Scenario","text":"<p>In addition to adding projects when you create the scenario, project cards can be added to a scenario using the <code>add_project_cards</code> method.</p> <pre><code>from projectcard import read_cards\n\nproject_card_dict = read_cards(card_location, filter_tags=[\"Baseline2030\"], recursive=True)\nmy_scenario.add_project_cards(project_card_dict.values())\n</code></pre> <p>Where <code>card_location</code> can be a single path, list of paths, a directory, or a glob pattern.</p>"},{"location":"api/#network_wrangler.scenario--apply-projects-to-a-scenario","title":"Apply Projects to a Scenario","text":"<p>Projects can be applied to a scenario using the <code>apply_all_projects</code> method. Before applying projects, the scenario will check that all pre-requisites are satisfied, that there are no conflicts, and that the projects are in the planned projects list.</p> <p>If you want to check the order of projects before applying them, you can use the <code>queued_projects</code> prooperty.</p> <pre><code>my_scenario.queued_projects\nmy_scenario.apply_all_projects()\n</code></pre> <p>You can review the resulting scenario, roadway network, and transit networks.</p> <pre><code>my_scenario.applied_projects\nmy_scenario.road_net.links_gdf.explore()\nmy_scenario.transit_net.feed.shapes_gdf.explore()\n</code></pre>"},{"location":"api/#network_wrangler.scenario--write-a-scenario-to-disk","title":"Write a Scenario to Disk","text":"<p>Scenarios (and their networks) can be written to disk using the <code>write</code> method which in addition to writing out roadway and transit networks, will serialize the scenario to a yaml-like file and can also write out the project cards that have been applied.</p> <pre><code>my_scenario.write(\n    \"output_dir\",\n    \"scenario_name_to_use\",\n    overwrite=True,\n    projects_write=True,\n    file_format=\"parquet\",\n)\n</code></pre> Example Serialized Scenario File<pre><code>applied_projects: &amp;id001\n- project a\n- project b\nbase_scenario:\napplied_projects: *id001\nroadway:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\n    file_format: geojson\ntransit:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\nconfig:\nCPU:\n    EST_PD_READ_SPEED:\n    csv: 0.03\n    geojson: 0.03\n    json: 0.15\n    parquet: 0.005\n    txt: 0.04\nIDS:\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: &amp;id002 !!python/tuple\n    - 950000\n    - 999999\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: *id002\n    ML_NODE_ID_SCALAR: 15000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\nMODEL_ROADWAY:\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\n    ML_OFFSET_METERS: -10\nconflicts: {}\ncorequisites: {}\nname: first_scenario\nprerequisites: {}\nroadway:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/roadway\nfile_format: parquet\ntransit:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/transit\nfile_format: txt\n</code></pre>"},{"location":"api/#network_wrangler.scenario--load-a-scenario-from-disk","title":"Load a scenario from disk","text":"<p>And if you want to reload scenario that you \u201cwrote\u201d, you can use the <code>load_scenario</code> function.</p> <pre><code>from network_wrangler import load_scenario\n\nmy_scenario = load_scenario(\"output_dir/scenario_name_to_use_scenario.yml\")\n</code></pre>"},{"location":"api/#network_wrangler.scenario.BASE_SCENARIO_SUGGESTED_PROPS","title":"network_wrangler.scenario.BASE_SCENARIO_SUGGESTED_PROPS  <code>module-attribute</code>","text":"<pre><code>BASE_SCENARIO_SUGGESTED_PROPS = ['road_net', 'transit_net', 'applied_projects', 'conflicts']\n</code></pre> <p>List of card types that that will be applied to the transit network.</p>"},{"location":"api/#network_wrangler.scenario.ROADWAY_CARD_TYPES","title":"network_wrangler.scenario.ROADWAY_CARD_TYPES  <code>module-attribute</code>","text":"<pre><code>ROADWAY_CARD_TYPES = ['roadway_property_change', 'roadway_deletion', 'roadway_addition', 'pycode']\n</code></pre> <p>List of card types that that will be applied to the transit network AFTER being applied to the roadway network.</p>"},{"location":"api/#network_wrangler.scenario.TRANSIT_CARD_TYPES","title":"network_wrangler.scenario.TRANSIT_CARD_TYPES  <code>module-attribute</code>","text":"<pre><code>TRANSIT_CARD_TYPES = ['transit_property_change', 'transit_routing_change', 'transit_route_addition', 'transit_service_deletion']\n</code></pre> <p>List of card types that that will be applied to the roadway network.</p>"},{"location":"api/#network_wrangler.scenario.Scenario","title":"network_wrangler.scenario.Scenario","text":"<p>Holds information about a scenario.</p> <p>Typical usage example:</p> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_roadway(\n        links_file=STPAUL_LINK_FILE,\n        nodes_file=STPAUL_NODE_FILE,\n        shapes_file=STPAUL_SHAPE_FILE,\n    ),\n    \"transit_net\": load_transit(STPAUL_DIR),\n}\n\n# create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\nproject_card_directory = Path(STPAUL_DIR) / \"project_cards\"\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags=[\"baseline2050\"],\n)\n\n# check project card queue and then apply the projects\nmy_scenario.queued_projects\nmy_scenario.apply_all_projects()\n\n# check applied projects, write it out, and create a summary report.\nmy_scenario.applied_projects\nmy_scenario.write(\"baseline\")\nmy_scenario.summary\n\n# Add some projects to create a build scenario based on a list of files.\nbuild_card_filenames = [\n    \"3_multiple_roadway_attribute_change.yml\",\n    \"road.prop_changes.segment.yml\",\n    \"4_simple_managed_lane.yml\",\n]\nmy_scenario.add_projects_from_files(build_card_filenames)\nmy_scenario.write(\"build2050\")\nmy_scenario.summary\n</code></pre> <p>Attributes:</p> <ul> <li> <code>base_scenario</code>               (<code>dict</code>)           \u2013            <p>dictionary representation of a scenario</p> </li> <li> <code>road_net</code>               (<code>Optional[RoadwayNetwork]</code>)           \u2013            <p>instance of RoadwayNetwork for the scenario</p> </li> <li> <code>transit_net</code>               (<code>Optional[TransitNetwork]</code>)           \u2013            <p>instance of TransitNetwork for the scenario</p> </li> <li> <code>project_cards</code>               (<code>dict[str, ProjectCard]</code>)           \u2013            <p>Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.</p> </li> <li> <code>queued_projects</code>           \u2013            <p>Projects which are \u201cshovel ready\u201d - have had pre-requisits checked and done any required re-ordering. Similar to a git staging, project cards aren\u2019t recognized in this collecton once they are moved to applied.</p> </li> <li> <code>applied_projects</code>               (<code>list[str]</code>)           \u2013            <p>list of project names that have been applied</p> </li> <li> <code>projects</code>           \u2013            <p>list of all projects either planned, queued, or applied</p> </li> <li> <code>prerequisites</code>               (<code>dict[str, list[str]]</code>)           \u2013            <p>dictionary storing prerequiste info as <code>projectA: [prereqs-for-projectA]</code></p> </li> <li> <code>corequisites</code>               (<code>dict[str, list[str]]</code>)           \u2013            <p>dictionary storing corequisite info as<code>projectA: [coreqs-for-projectA]</code></p> </li> <li> <code>conflicts</code>               (<code>dict[str, list[str]]</code>)           \u2013            <p>dictionary storing conflict info as <code>projectA: [conflicts-for-projectA]</code></p> </li> <li> <code>config</code>           \u2013            <p>WranglerConfig instance.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>class Scenario:\n    \"\"\"Holds information about a scenario.\n\n    Typical usage example:\n\n    ```python\n    my_base_year_scenario = {\n        \"road_net\": load_roadway(\n            links_file=STPAUL_LINK_FILE,\n            nodes_file=STPAUL_NODE_FILE,\n            shapes_file=STPAUL_SHAPE_FILE,\n        ),\n        \"transit_net\": load_transit(STPAUL_DIR),\n    }\n\n    # create a future baseline scenario from base by searching for all cards in dir w/ baseline tag\n    project_card_directory = Path(STPAUL_DIR) / \"project_cards\"\n    my_scenario = create_scenario(\n        base_scenario=my_base_year_scenario,\n        card_search_dir=project_card_directory,\n        filter_tags=[\"baseline2050\"],\n    )\n\n    # check project card queue and then apply the projects\n    my_scenario.queued_projects\n    my_scenario.apply_all_projects()\n\n    # check applied projects, write it out, and create a summary report.\n    my_scenario.applied_projects\n    my_scenario.write(\"baseline\")\n    my_scenario.summary\n\n    # Add some projects to create a build scenario based on a list of files.\n    build_card_filenames = [\n        \"3_multiple_roadway_attribute_change.yml\",\n        \"road.prop_changes.segment.yml\",\n        \"4_simple_managed_lane.yml\",\n    ]\n    my_scenario.add_projects_from_files(build_card_filenames)\n    my_scenario.write(\"build2050\")\n    my_scenario.summary\n    ```\n\n    Attributes:\n        base_scenario: dictionary representation of a scenario\n        road_net: instance of RoadwayNetwork for the scenario\n        transit_net: instance of TransitNetwork for the scenario\n        project_cards: Mapping[ProjectCard.name,ProjectCard] Storage of all project cards by name.\n        queued_projects: Projects which are \"shovel ready\" - have had pre-requisits checked and\n            done any required re-ordering. Similar to a git staging, project cards aren't\n            recognized in this collecton once they are moved to applied.\n        applied_projects: list of project names that have been applied\n        projects: list of all projects either planned, queued, or applied\n        prerequisites:  dictionary storing prerequiste info as `projectA: [prereqs-for-projectA]`\n        corequisites:  dictionary storing corequisite info as`projectA: [coreqs-for-projectA]`\n        conflicts: dictionary storing conflict info as `projectA: [conflicts-for-projectA]`\n        config: WranglerConfig instance.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_scenario: Union[Scenario, dict],\n        project_card_list: Optional[list[ProjectCard]] = None,\n        config: Optional[Union[WranglerConfig, dict, Path, list[Path]]] = None,\n        name: str = \"\",\n    ):\n        \"\"\"Constructor.\n\n        Args:\n            base_scenario: A base scenario object to base this isntance off of, or a dict which\n                describes the scenario attributes including applied projects and respective\n                conflicts. `{\"applied_projects\": [],\"conflicts\":{...}}`\n            project_card_list: Optional list of ProjectCard instances to add to planned projects.\n                Defaults to None.\n            config: WranglerConfig instance or a dictionary of configuration settings or a path to\n                one or more configuration files. Configurations that are not explicity set will\n                default to the values in the default configuration in\n                `/configs/wrangler/default.yml`.\n            name: Optional name for the scenario.\n        \"\"\"\n        WranglerLogger.info(\"Creating Scenario\")\n        self.config = load_wrangler_config(config)\n\n        if project_card_list is None:\n            project_card_list = []\n\n        if isinstance(base_scenario, Scenario):\n            base_scenario = base_scenario.__dict__\n\n        self.base_scenario: dict = extract_base_scenario_metadata(base_scenario)\n\n        if not set(BASE_SCENARIO_SUGGESTED_PROPS) &lt;= set(base_scenario.keys()):\n            WranglerLogger.warning(\n                f\"Base_scenario doesn't contain {BASE_SCENARIO_SUGGESTED_PROPS}\"\n            )\n        self.name: str = name\n        # if the base scenario had roadway or transit networks, use them as the basis.\n        self.road_net: Optional[RoadwayNetwork] = copy.deepcopy(\n            base_scenario.pop(\"road_net\", None)\n        )\n\n        self.transit_net: Optional[TransitNetwork] = copy.deepcopy(\n            base_scenario.pop(\"transit_net\", None)\n        )\n        if self.road_net and self.transit_net:\n            self.transit_net.road_net = self.road_net\n\n        # Set configs for networks to be the same as scenario.\n        if isinstance(self.road_net, RoadwayNetwork):\n            self.road_net.config = self.config\n        if isinstance(self.transit_net, TransitNetwork):\n            self.transit_net.config = self.config\n\n        self.project_cards: dict[str, ProjectCard] = {}\n        self._planned_projects: list[str] = []\n        self._queued_projects = None\n        self.applied_projects: list[str] = base_scenario.pop(\"applied_projects\", [])\n\n        self.prerequisites: dict[str, list[str]] = base_scenario.pop(\"prerequisites\", {})\n        self.corequisites: dict[str, list[str]] = base_scenario.pop(\"corequisites\", {})\n        self.conflicts: dict[str, list[str]] = base_scenario.pop(\"conflicts\", {})\n\n        for p in project_card_list:\n            self._add_project(p)\n\n    @property\n    def projects(self):\n        \"\"\"Returns a list of all projects in the scenario: applied and planned.\"\"\"\n        return self.applied_projects + self._planned_projects\n\n    @property\n    def queued_projects(self):\n        \"\"\"Returns a list version of _queued_projects queue.\n\n        Queued projects are thos that have been planned, have all pre-requisites satisfied, and\n        have been ordered based on pre-requisites.\n\n        If no queued projects, will dynamically generate from planned projects based on\n        pre-requisites and return the queue.\n        \"\"\"\n        if not self._queued_projects:\n            self._check_projects_requirements_satisfied(self._planned_projects)\n            self._queued_projects = self.order_projects(self._planned_projects)\n        return list(self._queued_projects)\n\n    def __str__(self):\n        \"\"\"String representation of the Scenario object.\"\"\"\n        s = [f\"{key}: {value}\" for key, value in self.__dict__.items()]\n        return \"\\n\".join(s)\n\n    def _add_dependencies(self, project_name, dependencies: dict) -&gt; None:\n        \"\"\"Add dependencies from a project card to relevant scenario variables.\n\n        Updates existing \"prerequisites\", \"corequisites\" and \"conflicts\".\n        Lowercases everything to enable string matching.\n\n        Args:\n            project_name: name of project you are adding dependencies for.\n            dependencies: Dictionary of depndencies by dependency type and list of associated\n                projects.\n        \"\"\"\n        project_name = project_name.lower()\n\n        for d, v in dependencies.items():\n            _dep = list(map(str.lower, v))\n            WranglerLogger.debug(f\"Adding {_dep} to {project_name} dependency table.\")\n            self.__dict__[d].update({project_name: _dep})\n\n    def _add_project(\n        self,\n        project_card: ProjectCard,\n        validate: bool = True,\n        filter_tags: Optional[list[str]] = None,\n    ) -&gt; None:\n        \"\"\"Adds a single ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Resets scenario queued_projects.\n\n        Args:\n            project_card (ProjectCard): ProjectCard instance to add to scenario.\n            validate (bool, optional): If True, will validate the projectcard before\n                being adding it to the scenario. Defaults to True.\n            filter_tags: If used, will only add the project card if\n                its tags match one or more of these filter_tags. Defaults to []\n                which means no tag-filtering will occur.\n\n        \"\"\"\n        filter_tags = filter_tags or []\n        project_name = project_card.project.lower()\n        filter_tags = list(map(str.lower, filter_tags))\n\n        if project_name in self.projects:\n            msg = f\"Names not unique from existing scenario projects: {project_card.project}\"\n            raise ProjectCardError(msg)\n\n        if filter_tags and set(project_card.tags).isdisjoint(set(filter_tags)):\n            WranglerLogger.debug(\n                f\"Skipping {project_name} - no overlapping tags with {filter_tags}.\"\n            )\n            return\n\n        if validate:\n            project_card.validate()\n\n        WranglerLogger.info(f\"Adding {project_name} to scenario.\")\n        self.project_cards[project_name] = project_card\n        self._planned_projects.append(project_name)\n        self._queued_projects = None\n        self._add_dependencies(project_name, project_card.dependencies)\n\n    def add_project_cards(\n        self,\n        project_card_list: list[ProjectCard],\n        validate: bool = True,\n        filter_tags: Optional[list[str]] = None,\n    ) -&gt; None:\n        \"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n        Checks that a project of same name is not already in scenario.\n        If selected, will validate ProjectCard before adding.\n        If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n        Args:\n            project_card_list: List of ProjectCard instances to add to\n                scenario.\n            validate (bool, optional): If True, will require each ProjectCard is validated before\n                being added to scenario. Defaults to True.\n            filter_tags: If used, will filter ProjectCard instances\n                and only add those whose tags match one or more of these filter_tags.\n                Defaults to [] - which means no tag-filtering will occur.\n        \"\"\"\n        filter_tags = filter_tags or []\n        for p in project_card_list:\n            self._add_project(p, validate=validate, filter_tags=filter_tags)\n\n    def _check_projects_requirements_satisfied(self, project_list: list[str]):\n        \"\"\"Checks all requirements are satisified to apply this specific set of projects.\n\n        Including:\n        1. has an associaed project card\n        2. is in scenario's planned projects\n        3. pre-requisites satisfied\n        4. co-requisies satisfied by applied or co-applied projects\n        5. no conflicing applied or co-applied projects\n\n        Args:\n            project_list: list of projects to check requirements for.\n        \"\"\"\n        self._check_projects_planned(project_list)\n        self._check_projects_have_project_cards(project_list)\n        self._check_projects_prerequisites(project_list)\n        self._check_projects_corequisites(project_list)\n        self._check_projects_conflicts(project_list)\n\n    def _check_projects_planned(self, project_names: list[str]) -&gt; None:\n        \"\"\"Checks that a list of projects are in the scenario's planned projects.\"\"\"\n        _missing_ps = [p for p in project_names if p not in self._planned_projects]\n        if _missing_ps:\n            msg = f\"Projects are not in planned projects: \\n {_missing_ps}. \\\n                Add them by using add_project_cards().\"\n            WranglerLogger.debug(msg)\n            raise ValueError(msg)\n\n    def _check_projects_have_project_cards(self, project_list: list[str]) -&gt; bool:\n        \"\"\"Checks that a list of projects has an associated project card in the scenario.\"\"\"\n        _missing = [p for p in project_list if p not in self.project_cards]\n        if _missing:\n            WranglerLogger.error(\n                f\"Projects referenced which are missing project cards: {_missing}\"\n            )\n            return False\n        return True\n\n    def _check_projects_prerequisites(self, project_names: list[str]) -&gt; None:\n        \"\"\"Check a list of projects' pre-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.prerequisites.keys())):\n            return\n        _prereqs = []\n        for p in project_names:\n            _prereqs += self.prerequisites.get(p, [])\n        _projects_applied = self.applied_projects + project_names\n        _missing = list(set(_prereqs) - set(_projects_applied))\n        if _missing:\n            WranglerLogger.debug(\n                f\"project_names: {project_names}\\nprojects_have_or_will_be_applied: \\\n                    {_projects_applied}\\nmissing: {_missing}\"\n            )\n            msg = f\"Missing {len(_missing)} pre-requisites.\"\n            raise ScenarioPrerequisiteError(msg)\n\n    def _check_projects_corequisites(self, project_names: list[str]) -&gt; None:\n        \"\"\"Check a list of projects' co-requisites have been or will be applied to scenario.\"\"\"\n        if set(project_names).isdisjoint(set(self.corequisites.keys())):\n            return\n        _coreqs = []\n        for p in project_names:\n            _coreqs += self.corequisites.get(p, [])\n        _projects_applied = self.applied_projects + project_names\n        _missing = list(set(_coreqs) - set(_projects_applied))\n        if _missing:\n            WranglerLogger.debug(\n                f\"project_names: {project_names}\\nprojects_have_or_will_be_applied: \\\n                    {_projects_applied}\\nmissing: {_missing}\"\n            )\n            msg = f\"Missing {len(_missing)} corequisites.\"\n            raise ScenarioCorequisiteError(msg)\n\n    def _check_projects_conflicts(self, project_names: list[str]) -&gt; None:\n        \"\"\"Checks that list of projects' conflicts have not been or will be applied to scenario.\"\"\"\n        # WranglerLogger.debug(\"Checking Conflicts...\")\n        projects_to_check = project_names + self.applied_projects\n        # WranglerLogger.debug(f\"\\nprojects_to_check:{projects_to_check}\\nprojects_with_conflicts:{set(self.conflicts.keys())}\")\n        if set(projects_to_check).isdisjoint(set(self.conflicts.keys())):\n            # WranglerLogger.debug(\"Projects have no conflicts to check\")\n            return\n        _conflicts = []\n        for p in project_names:\n            _conflicts += self.conflicts.get(p, [])\n        _conflict_problems = [p for p in _conflicts if p in projects_to_check]\n        if _conflict_problems:\n            WranglerLogger.warning(f\"Conflict Problems: \\n{_conflict_problems}\")\n            _conf_dict = {\n                k: v\n                for k, v in self.conflicts.items()\n                if k in projects_to_check and not set(v).isdisjoint(set(_conflict_problems))\n            }\n            WranglerLogger.debug(f\"Problematic Conflicts: \\n{_conf_dict}\")\n            msg = f\"Found {len(_conflict_problems)} conflicts: {_conflict_problems}\"\n            raise ScenarioConflictError(msg)\n\n    def order_projects(self, project_list: list[str]) -&gt; deque:\n        \"\"\"Orders a list of projects based on moving up pre-requisites into a deque.\n\n        Args:\n            project_list: list of projects to order\n\n        Returns: deque for applying projects.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n        assert self._check_projects_have_project_cards(project_list)\n\n        # build prereq (adjacency) list for topological sort\n        adjacency_list: dict[str, list] = defaultdict(list)\n        visited_list: dict[str, bool] = defaultdict(bool)\n\n        for project in project_list:\n            visited_list[project] = False\n            if not self.prerequisites.get(project):\n                continue\n            for prereq in self.prerequisites[project]:\n                # this will always be true, else would have been flagged in missing \\\n                # prerequsite check, but just in case\n                if prereq.lower() in project_list:\n                    if adjacency_list.get(prereq.lower()):\n                        adjacency_list[prereq.lower()].append(project)\n                    else:\n                        adjacency_list[prereq.lower()] = [project]\n\n        # sorted_project_names is topological sorted project card names (based on prerequsiite)\n        _ordered_projects = topological_sort(\n            adjacency_list=adjacency_list, visited_list=visited_list\n        )\n\n        if set(_ordered_projects) != set(project_list):\n            _missing = list(set(project_list) - set(_ordered_projects))\n            msg = f\"Project sort resulted in missing projects: {_missing}\"\n            raise ValueError(msg)\n\n        project_deque = deque(_ordered_projects)\n\n        WranglerLogger.debug(f\"Ordered Projects: \\n{project_deque}\")\n\n        return project_deque\n\n    def apply_all_projects(self):\n        \"\"\"Applies all planned projects in the queue.\"\"\"\n        # Call this to make sure projects are appropriately queued in hidden variable.\n        self.queued_projects  # noqa: B018\n\n        # Use hidden variable.\n        while self._queued_projects:\n            self._apply_project(self._queued_projects.popleft())\n\n        # set this so it will trigger re-queuing any more projects.\n        self._queued_projects = None\n\n    def _apply_change(self, change: Union[ProjectCard, SubProject]) -&gt; None:\n        \"\"\"Applies a specific change specified in a project card.\n\n        Change type must be in at least one of:\n        - ROADWAY_CARD_TYPES\n        - TRANSIT_CARD_TYPES\n\n        Args:\n            change: a project card or subproject card\n        \"\"\"\n        if change.change_type in ROADWAY_CARD_TYPES:\n            if not self.road_net:\n                msg = \"Missing Roadway Network\"\n                raise ValueError(msg)\n            if change.change_type in SECONDARY_TRANSIT_CARD_TYPES and self.transit_net:\n                self.road_net.apply(change, transit_net=self.transit_net)\n            else:\n                self.road_net.apply(change)\n        if change.change_type in TRANSIT_CARD_TYPES:\n            if not self.transit_net:\n                msg = \"Missing Transit Network\"\n                raise ValueError(msg)\n            self.transit_net.apply(change)\n\n        if change.change_type not in ROADWAY_CARD_TYPES + TRANSIT_CARD_TYPES:\n            msg = f\"Project {change.project}: Don't understand project cat: {change.change_type}\"\n            raise ProjectCardError(msg)\n\n    def _apply_project(self, project_name: str) -&gt; None:\n        \"\"\"Applies project card to scenario.\n\n        If a list of changes is specified in referenced project card, iterates through each change.\n\n        Args:\n            project_name (str): name of project to be applied.\n        \"\"\"\n        project_name = project_name.lower()\n\n        WranglerLogger.info(\n            f\"Applying {project_name} from file:\\\n                            {self.project_cards[project_name].file}\"\n        )\n\n        p = self.project_cards[project_name]\n        WranglerLogger.debug(f\"types: {p.change_types}\")\n        WranglerLogger.debug(f\"type: {p.change_type}\")\n        if p._sub_projects:\n            for sp in p._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp)\n\n        else:\n            self._apply_change(p)\n\n        self._planned_projects.remove(project_name)\n        self.applied_projects.append(project_name)\n\n    def apply_projects(self, project_list: list[str]):\n        \"\"\"Applies a specific list of projects from the planned project queue.\n\n        Will order the list of projects based on pre-requisites.\n\n        NOTE: does not check co-requisites b/c that isn't possible when applying a single project.\n\n        Args:\n            project_list: List of projects to be applied. All need to be in the planned project\n                queue.\n        \"\"\"\n        project_list = [p.lower() for p in project_list]\n\n        self._check_projects_requirements_satisfied(project_list)\n        ordered_project_queue = self.order_projects(project_list)\n\n        while ordered_project_queue:\n            self._apply_project(ordered_project_queue.popleft())\n\n        # Set so that when called again it will retrigger queueing from planned projects.\n        self._ordered_projects = None\n\n    def write(\n        self,\n        path: Path,\n        name: str,\n        overwrite: bool = True,\n        roadway_write: bool = True,\n        transit_write: bool = True,\n        projects_write: bool = True,\n        roadway_convert_complex_link_properties_to_single_field: bool = False,\n        roadway_out_dir: Optional[Path] = None,\n        roadway_prefix: Optional[str] = None,\n        roadway_file_format: RoadwayFileTypes = \"parquet\",\n        roadway_true_shape: bool = False,\n        transit_out_dir: Optional[Path] = None,\n        transit_prefix: Optional[str] = None,\n        transit_file_format: TransitFileTypes = \"txt\",\n        projects_out_dir: Optional[Path] = None,\n    ) -&gt; Path:\n        \"\"\"Writes scenario networks and summary to disk and returns path to scenario file.\n\n        Args:\n            path: Path to write scenario networks and scenario summary to.\n            name: Name to use.\n            overwrite: If True, will overwrite the files if they already exist.\n            roadway_write: If True, will write out the roadway network.\n            transit_write: If True, will write out the transit network.\n            projects_write: If True, will write out the project cards.\n            roadway_convert_complex_link_properties_to_single_field: If True, will convert complex\n                link properties to a single field.\n            roadway_out_dir: Path to write the roadway network files to.\n            roadway_prefix: Prefix to add to the file name.\n            roadway_file_format: File format to write the roadway network to\n            roadway_true_shape: If True, will write the true shape of the roadway network\n            transit_out_dir: Path to write the transit network files to.\n            transit_prefix: Prefix to add to the file name.\n            transit_file_format: File format to write the transit network to\n            projects_out_dir: Path to write the project cards to.\n        \"\"\"\n        path = Path(path)\n        path.mkdir(parents=True, exist_ok=True)\n\n        if self.road_net and roadway_write:\n            if roadway_out_dir is None:\n                roadway_out_dir = path / \"roadway\"\n            roadway_out_dir.mkdir(parents=True, exist_ok=True)\n\n            write_roadway(\n                net=self.road_net,\n                out_dir=roadway_out_dir,\n                prefix=roadway_prefix or name,\n                convert_complex_link_properties_to_single_field=roadway_convert_complex_link_properties_to_single_field,\n                file_format=roadway_file_format,\n                true_shape=roadway_true_shape,\n                overwrite=overwrite,\n            )\n        if self.transit_net and transit_write:\n            if transit_out_dir is None:\n                transit_out_dir = path / \"transit\"\n            transit_out_dir.mkdir(parents=True, exist_ok=True)\n            write_transit(\n                self.transit_net,\n                out_dir=transit_out_dir,\n                prefix=transit_prefix or name,\n                file_format=transit_file_format,\n                overwrite=overwrite,\n            )\n        if projects_write:\n            if projects_out_dir is None:\n                projects_out_dir = path / \"projects\"\n            write_applied_projects(\n                self,\n                out_dir=projects_out_dir,\n                overwrite=overwrite,\n            )\n\n        scenario_data = self.summary\n        if transit_write:\n            scenario_data[\"transit\"] = {\n                \"dir\": str(transit_out_dir),\n                \"file_format\": transit_file_format,\n            }\n        if roadway_write:\n            scenario_data[\"roadway\"] = {\n                \"dir\": str(roadway_out_dir),\n                \"file_format\": roadway_file_format,\n            }\n        if projects_write:\n            scenario_data[\"project_cards\"] = {\"dir\": str(projects_out_dir)}\n        scenario_file_path = Path(path) / f\"{name}_scenario.yml\"\n        with scenario_file_path.open(\"w\") as f:\n            yaml.dump(scenario_data, f, default_flow_style=False, allow_unicode=True)\n        return scenario_file_path\n\n    @property\n    def summary(self) -&gt; dict:\n        \"\"\"A high level summary of the created scenario and public attributes.\"\"\"\n        skip = [\"road_net\", \"base_scenario\", \"transit_net\", \"project_cards\", \"config\"]\n        summary_dict = {\n            k: v for k, v in self.__dict__.items() if not k.startswith(\"_\") and k not in skip\n        }\n        summary_dict[\"config\"] = self.config.to_dict()\n\n        \"\"\"\n        # Handle nested dictionary for \"base_scenario\"\n        skip_base = [\"project_cards\"]\n        if \"base_scenario\" in self.__dict__:\n            base_summary_dict = {\n                k: v\n                for k, v in self.base_scenario.items()\n                if not k.startswith(\"_\") and k not in skip_base\n            }\n            summary_dict[\"base_scenario\"] = base_summary_dict\n        \"\"\"\n\n        return summary_dict\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.projects","title":"network_wrangler.scenario.Scenario.projects  <code>property</code>","text":"<pre><code>projects\n</code></pre> <p>Returns a list of all projects in the scenario: applied and planned.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.queued_projects","title":"network_wrangler.scenario.Scenario.queued_projects  <code>property</code>","text":"<pre><code>queued_projects\n</code></pre> <p>Returns a list version of _queued_projects queue.</p> <p>Queued projects are thos that have been planned, have all pre-requisites satisfied, and have been ordered based on pre-requisites.</p> <p>If no queued projects, will dynamically generate from planned projects based on pre-requisites and return the queue.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.summary","title":"network_wrangler.scenario.Scenario.summary  <code>property</code>","text":"<pre><code>summary\n</code></pre> <p>A high level summary of the created scenario and public attributes.</p>"},{"location":"api/#network_wrangler.scenario.Scenario.__init__","title":"network_wrangler.scenario.Scenario.__init__","text":"<pre><code>__init__(base_scenario, project_card_list=None, config=None, name='')\n</code></pre> <p>Constructor.</p> <p>Parameters:</p> <ul> <li> <code>base_scenario</code>               (<code>Union[Scenario, dict]</code>)           \u2013            <p>A base scenario object to base this isntance off of, or a dict which describes the scenario attributes including applied projects and respective conflicts. <code>{\"applied_projects\": [],\"conflicts\":{...}}</code></p> </li> <li> <code>project_card_list</code>               (<code>Optional[list[ProjectCard]]</code>, default:                   <code>None</code> )           \u2013            <p>Optional list of ProjectCard instances to add to planned projects. Defaults to None.</p> </li> <li> <code>config</code>               (<code>Optional[Union[WranglerConfig, dict, Path, list[Path]]]</code>, default:                   <code>None</code> )           \u2013            <p>WranglerConfig instance or a dictionary of configuration settings or a path to one or more configuration files. Configurations that are not explicity set will default to the values in the default configuration in <code>/configs/wrangler/default.yml</code>.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>Optional name for the scenario.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __init__(\n    self,\n    base_scenario: Union[Scenario, dict],\n    project_card_list: Optional[list[ProjectCard]] = None,\n    config: Optional[Union[WranglerConfig, dict, Path, list[Path]]] = None,\n    name: str = \"\",\n):\n    \"\"\"Constructor.\n\n    Args:\n        base_scenario: A base scenario object to base this isntance off of, or a dict which\n            describes the scenario attributes including applied projects and respective\n            conflicts. `{\"applied_projects\": [],\"conflicts\":{...}}`\n        project_card_list: Optional list of ProjectCard instances to add to planned projects.\n            Defaults to None.\n        config: WranglerConfig instance or a dictionary of configuration settings or a path to\n            one or more configuration files. Configurations that are not explicity set will\n            default to the values in the default configuration in\n            `/configs/wrangler/default.yml`.\n        name: Optional name for the scenario.\n    \"\"\"\n    WranglerLogger.info(\"Creating Scenario\")\n    self.config = load_wrangler_config(config)\n\n    if project_card_list is None:\n        project_card_list = []\n\n    if isinstance(base_scenario, Scenario):\n        base_scenario = base_scenario.__dict__\n\n    self.base_scenario: dict = extract_base_scenario_metadata(base_scenario)\n\n    if not set(BASE_SCENARIO_SUGGESTED_PROPS) &lt;= set(base_scenario.keys()):\n        WranglerLogger.warning(\n            f\"Base_scenario doesn't contain {BASE_SCENARIO_SUGGESTED_PROPS}\"\n        )\n    self.name: str = name\n    # if the base scenario had roadway or transit networks, use them as the basis.\n    self.road_net: Optional[RoadwayNetwork] = copy.deepcopy(\n        base_scenario.pop(\"road_net\", None)\n    )\n\n    self.transit_net: Optional[TransitNetwork] = copy.deepcopy(\n        base_scenario.pop(\"transit_net\", None)\n    )\n    if self.road_net and self.transit_net:\n        self.transit_net.road_net = self.road_net\n\n    # Set configs for networks to be the same as scenario.\n    if isinstance(self.road_net, RoadwayNetwork):\n        self.road_net.config = self.config\n    if isinstance(self.transit_net, TransitNetwork):\n        self.transit_net.config = self.config\n\n    self.project_cards: dict[str, ProjectCard] = {}\n    self._planned_projects: list[str] = []\n    self._queued_projects = None\n    self.applied_projects: list[str] = base_scenario.pop(\"applied_projects\", [])\n\n    self.prerequisites: dict[str, list[str]] = base_scenario.pop(\"prerequisites\", {})\n    self.corequisites: dict[str, list[str]] = base_scenario.pop(\"corequisites\", {})\n    self.conflicts: dict[str, list[str]] = base_scenario.pop(\"conflicts\", {})\n\n    for p in project_card_list:\n        self._add_project(p)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.__str__","title":"network_wrangler.scenario.Scenario.__str__","text":"<pre><code>__str__()\n</code></pre> <p>String representation of the Scenario object.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def __str__(self):\n    \"\"\"String representation of the Scenario object.\"\"\"\n    s = [f\"{key}: {value}\" for key, value in self.__dict__.items()]\n    return \"\\n\".join(s)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.add_project_cards","title":"network_wrangler.scenario.Scenario.add_project_cards","text":"<pre><code>add_project_cards(project_card_list, validate=True, filter_tags=None)\n</code></pre> <p>Adds a list of ProjectCard instances to the Scenario.</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> <ul> <li> <code>project_card_list</code>               (<code>list[ProjectCard]</code>)           \u2013            <p>List of ProjectCard instances to add to scenario.</p> </li> <li> <code>validate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will require each ProjectCard is validated before being added to scenario. Defaults to True.</p> </li> <li> <code>filter_tags</code>               (<code>Optional[list[str]]</code>, default:                   <code>None</code> )           \u2013            <p>If used, will filter ProjectCard instances and only add those whose tags match one or more of these filter_tags. Defaults to [] - which means no tag-filtering will occur.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def add_project_cards(\n    self,\n    project_card_list: list[ProjectCard],\n    validate: bool = True,\n    filter_tags: Optional[list[str]] = None,\n) -&gt; None:\n    \"\"\"Adds a list of ProjectCard instances to the Scenario.\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        project_card_list: List of ProjectCard instances to add to\n            scenario.\n        validate (bool, optional): If True, will require each ProjectCard is validated before\n            being added to scenario. Defaults to True.\n        filter_tags: If used, will filter ProjectCard instances\n            and only add those whose tags match one or more of these filter_tags.\n            Defaults to [] - which means no tag-filtering will occur.\n    \"\"\"\n    filter_tags = filter_tags or []\n    for p in project_card_list:\n        self._add_project(p, validate=validate, filter_tags=filter_tags)\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_all_projects","title":"network_wrangler.scenario.Scenario.apply_all_projects","text":"<pre><code>apply_all_projects()\n</code></pre> <p>Applies all planned projects in the queue.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_all_projects(self):\n    \"\"\"Applies all planned projects in the queue.\"\"\"\n    # Call this to make sure projects are appropriately queued in hidden variable.\n    self.queued_projects  # noqa: B018\n\n    # Use hidden variable.\n    while self._queued_projects:\n        self._apply_project(self._queued_projects.popleft())\n\n    # set this so it will trigger re-queuing any more projects.\n    self._queued_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.apply_projects","title":"network_wrangler.scenario.Scenario.apply_projects","text":"<pre><code>apply_projects(project_list)\n</code></pre> <p>Applies a specific list of projects from the planned project queue.</p> <p>Will order the list of projects based on pre-requisites.</p> <p>NOTE: does not check co-requisites b/c that isn\u2019t possible when applying a single project.</p> <p>Parameters:</p> <ul> <li> <code>project_list</code>               (<code>list[str]</code>)           \u2013            <p>List of projects to be applied. All need to be in the planned project queue.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def apply_projects(self, project_list: list[str]):\n    \"\"\"Applies a specific list of projects from the planned project queue.\n\n    Will order the list of projects based on pre-requisites.\n\n    NOTE: does not check co-requisites b/c that isn't possible when applying a single project.\n\n    Args:\n        project_list: List of projects to be applied. All need to be in the planned project\n            queue.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n\n    self._check_projects_requirements_satisfied(project_list)\n    ordered_project_queue = self.order_projects(project_list)\n\n    while ordered_project_queue:\n        self._apply_project(ordered_project_queue.popleft())\n\n    # Set so that when called again it will retrigger queueing from planned projects.\n    self._ordered_projects = None\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.order_projects","title":"network_wrangler.scenario.Scenario.order_projects","text":"<pre><code>order_projects(project_list)\n</code></pre> <p>Orders a list of projects based on moving up pre-requisites into a deque.</p> <p>Parameters:</p> <ul> <li> <code>project_list</code>               (<code>list[str]</code>)           \u2013            <p>list of projects to order</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def order_projects(self, project_list: list[str]) -&gt; deque:\n    \"\"\"Orders a list of projects based on moving up pre-requisites into a deque.\n\n    Args:\n        project_list: list of projects to order\n\n    Returns: deque for applying projects.\n    \"\"\"\n    project_list = [p.lower() for p in project_list]\n    assert self._check_projects_have_project_cards(project_list)\n\n    # build prereq (adjacency) list for topological sort\n    adjacency_list: dict[str, list] = defaultdict(list)\n    visited_list: dict[str, bool] = defaultdict(bool)\n\n    for project in project_list:\n        visited_list[project] = False\n        if not self.prerequisites.get(project):\n            continue\n        for prereq in self.prerequisites[project]:\n            # this will always be true, else would have been flagged in missing \\\n            # prerequsite check, but just in case\n            if prereq.lower() in project_list:\n                if adjacency_list.get(prereq.lower()):\n                    adjacency_list[prereq.lower()].append(project)\n                else:\n                    adjacency_list[prereq.lower()] = [project]\n\n    # sorted_project_names is topological sorted project card names (based on prerequsiite)\n    _ordered_projects = topological_sort(\n        adjacency_list=adjacency_list, visited_list=visited_list\n    )\n\n    if set(_ordered_projects) != set(project_list):\n        _missing = list(set(project_list) - set(_ordered_projects))\n        msg = f\"Project sort resulted in missing projects: {_missing}\"\n        raise ValueError(msg)\n\n    project_deque = deque(_ordered_projects)\n\n    WranglerLogger.debug(f\"Ordered Projects: \\n{project_deque}\")\n\n    return project_deque\n</code></pre>"},{"location":"api/#network_wrangler.scenario.Scenario.write","title":"network_wrangler.scenario.Scenario.write","text":"<pre><code>write(path, name, overwrite=True, roadway_write=True, transit_write=True, projects_write=True, roadway_convert_complex_link_properties_to_single_field=False, roadway_out_dir=None, roadway_prefix=None, roadway_file_format='parquet', roadway_true_shape=False, transit_out_dir=None, transit_prefix=None, transit_file_format='txt', projects_out_dir=None)\n</code></pre> <p>Writes scenario networks and summary to disk and returns path to scenario file.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>Path</code>)           \u2013            <p>Path to write scenario networks and scenario summary to.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name to use.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will overwrite the files if they already exist.</p> </li> <li> <code>roadway_write</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will write out the roadway network.</p> </li> <li> <code>transit_write</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will write out the transit network.</p> </li> <li> <code>projects_write</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will write out the project cards.</p> </li> <li> <code>roadway_convert_complex_link_properties_to_single_field</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will convert complex link properties to a single field.</p> </li> <li> <code>roadway_out_dir</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>Path to write the roadway network files to.</p> </li> <li> <code>roadway_prefix</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Prefix to add to the file name.</p> </li> <li> <code>roadway_file_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'parquet'</code> )           \u2013            <p>File format to write the roadway network to</p> </li> <li> <code>roadway_true_shape</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will write the true shape of the roadway network</p> </li> <li> <code>transit_out_dir</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>Path to write the transit network files to.</p> </li> <li> <code>transit_prefix</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Prefix to add to the file name.</p> </li> <li> <code>transit_file_format</code>               (<code>TransitFileTypes</code>, default:                   <code>'txt'</code> )           \u2013            <p>File format to write the transit network to</p> </li> <li> <code>projects_out_dir</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>Path to write the project cards to.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def write(\n    self,\n    path: Path,\n    name: str,\n    overwrite: bool = True,\n    roadway_write: bool = True,\n    transit_write: bool = True,\n    projects_write: bool = True,\n    roadway_convert_complex_link_properties_to_single_field: bool = False,\n    roadway_out_dir: Optional[Path] = None,\n    roadway_prefix: Optional[str] = None,\n    roadway_file_format: RoadwayFileTypes = \"parquet\",\n    roadway_true_shape: bool = False,\n    transit_out_dir: Optional[Path] = None,\n    transit_prefix: Optional[str] = None,\n    transit_file_format: TransitFileTypes = \"txt\",\n    projects_out_dir: Optional[Path] = None,\n) -&gt; Path:\n    \"\"\"Writes scenario networks and summary to disk and returns path to scenario file.\n\n    Args:\n        path: Path to write scenario networks and scenario summary to.\n        name: Name to use.\n        overwrite: If True, will overwrite the files if they already exist.\n        roadway_write: If True, will write out the roadway network.\n        transit_write: If True, will write out the transit network.\n        projects_write: If True, will write out the project cards.\n        roadway_convert_complex_link_properties_to_single_field: If True, will convert complex\n            link properties to a single field.\n        roadway_out_dir: Path to write the roadway network files to.\n        roadway_prefix: Prefix to add to the file name.\n        roadway_file_format: File format to write the roadway network to\n        roadway_true_shape: If True, will write the true shape of the roadway network\n        transit_out_dir: Path to write the transit network files to.\n        transit_prefix: Prefix to add to the file name.\n        transit_file_format: File format to write the transit network to\n        projects_out_dir: Path to write the project cards to.\n    \"\"\"\n    path = Path(path)\n    path.mkdir(parents=True, exist_ok=True)\n\n    if self.road_net and roadway_write:\n        if roadway_out_dir is None:\n            roadway_out_dir = path / \"roadway\"\n        roadway_out_dir.mkdir(parents=True, exist_ok=True)\n\n        write_roadway(\n            net=self.road_net,\n            out_dir=roadway_out_dir,\n            prefix=roadway_prefix or name,\n            convert_complex_link_properties_to_single_field=roadway_convert_complex_link_properties_to_single_field,\n            file_format=roadway_file_format,\n            true_shape=roadway_true_shape,\n            overwrite=overwrite,\n        )\n    if self.transit_net and transit_write:\n        if transit_out_dir is None:\n            transit_out_dir = path / \"transit\"\n        transit_out_dir.mkdir(parents=True, exist_ok=True)\n        write_transit(\n            self.transit_net,\n            out_dir=transit_out_dir,\n            prefix=transit_prefix or name,\n            file_format=transit_file_format,\n            overwrite=overwrite,\n        )\n    if projects_write:\n        if projects_out_dir is None:\n            projects_out_dir = path / \"projects\"\n        write_applied_projects(\n            self,\n            out_dir=projects_out_dir,\n            overwrite=overwrite,\n        )\n\n    scenario_data = self.summary\n    if transit_write:\n        scenario_data[\"transit\"] = {\n            \"dir\": str(transit_out_dir),\n            \"file_format\": transit_file_format,\n        }\n    if roadway_write:\n        scenario_data[\"roadway\"] = {\n            \"dir\": str(roadway_out_dir),\n            \"file_format\": roadway_file_format,\n        }\n    if projects_write:\n        scenario_data[\"project_cards\"] = {\"dir\": str(projects_out_dir)}\n    scenario_file_path = Path(path) / f\"{name}_scenario.yml\"\n    with scenario_file_path.open(\"w\") as f:\n        yaml.dump(scenario_data, f, default_flow_style=False, allow_unicode=True)\n    return scenario_file_path\n</code></pre>"},{"location":"api/#network_wrangler.scenario.build_scenario_from_config","title":"network_wrangler.scenario.build_scenario_from_config","text":"<pre><code>build_scenario_from_config(scenario_config)\n</code></pre> <p>Builds a scenario from a dictionary configuration.</p> <p>Parameters:</p> <ul> <li> <code>scenario_config</code>               (<code>Union[Path, list[Path], ScenarioConfig, dict]</code>)           \u2013            <p>Path to a configuration file, list of paths, or a dictionary of configuration.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def build_scenario_from_config(\n    scenario_config: Union[Path, list[Path], ScenarioConfig, dict],\n) -&gt; Scenario:\n    \"\"\"Builds a scenario from a dictionary configuration.\n\n    Args:\n        scenario_config: Path to a configuration file, list of paths, or a dictionary of\n            configuration.\n    \"\"\"\n    WranglerLogger.info(f\"Building Scenario from Configuration: {scenario_config}\")\n    scenario_config = load_scenario_config(scenario_config)\n    WranglerLogger.debug(f\"{pprint.pformat(scenario_config)}\")\n\n    base_scenario = create_base_scenario(\n        **scenario_config.base_scenario.to_dict(), config=scenario_config.wrangler_config\n    )\n\n    my_scenario = create_scenario(\n        base_scenario=base_scenario,\n        config=scenario_config.wrangler_config,\n        **scenario_config.projects.to_dict(),\n    )\n\n    my_scenario.apply_all_projects()\n\n    write_args = _scenario_output_config_to_scenario_write(scenario_config.output_scenario)\n    my_scenario.write(**write_args, name=scenario_config.name)\n    return my_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.create_base_scenario","title":"network_wrangler.scenario.create_base_scenario","text":"<pre><code>create_base_scenario(roadway=None, transit=None, applied_projects=None, conflicts=None, config=DefaultConfig)\n</code></pre> <p>Creates a base scenario dictionary from roadway and transit network files.</p> <p>Parameters:</p> <ul> <li> <code>roadway</code>               (<code>Optional[dict]</code>, default:                   <code>None</code> )           \u2013            <p>kwargs for load_roadway_from_dir</p> </li> <li> <code>transit</code>               (<code>Optional[dict]</code>, default:                   <code>None</code> )           \u2013            <p>kwargs for load_transit from dir</p> </li> <li> <code>applied_projects</code>               (<code>Optional[list]</code>, default:                   <code>None</code> )           \u2013            <p>list of projects that have been applied to the base scenario.</p> </li> <li> <code>conflicts</code>               (<code>Optional[dict]</code>, default:                   <code>None</code> )           \u2013            <p>dictionary of conflicts that have been identified in the base scenario. Takes the format of <code>{\"projectA\": [\"projectB\", \"projectC\"]}</code> showing that projectA, which has been applied, conflicts with projectB and projectC and so they shouldn\u2019t be applied in the future.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def create_base_scenario(\n    roadway: Optional[dict] = None,\n    transit: Optional[dict] = None,\n    applied_projects: Optional[list] = None,\n    conflicts: Optional[dict] = None,\n    config: WranglerConfig = DefaultConfig,\n) -&gt; dict:\n    \"\"\"Creates a base scenario dictionary from roadway and transit network files.\n\n    Args:\n        roadway: kwargs for load_roadway_from_dir\n        transit: kwargs for load_transit from dir\n        applied_projects: list of projects that have been applied to the base scenario.\n        conflicts: dictionary of conflicts that have been identified in the base scenario.\n            Takes the format of `{\"projectA\": [\"projectB\", \"projectC\"]}` showing that projectA,\n            which has been applied, conflicts with projectB and projectC and so they shouldn't be\n            applied in the future.\n        config: WranglerConfig instance.\n    \"\"\"\n    applied_projects = applied_projects or []\n    conflicts = conflicts or {}\n    if roadway:\n        road_net = load_roadway_from_dir(**roadway, config=config)\n    else:\n        road_net = None\n        WranglerLogger.info(\n            \"No roadway directory specified, base scenario will have empty roadway network.\"\n        )\n\n    if transit:\n        transit_net = load_transit(**transit, config=config)\n        if roadway:\n            transit_net.road_net = road_net\n    else:\n        transit_net = None\n        WranglerLogger.info(\n            \"No transit directory specified, base scenario will have empty transit network.\"\n        )\n\n    base_scenario = {\n        \"road_net\": road_net,\n        \"transit_net\": transit_net,\n        \"applied_projects\": applied_projects,\n        \"conflicts\": conflicts,\n    }\n\n    return base_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.create_scenario","title":"network_wrangler.scenario.create_scenario","text":"<pre><code>create_scenario(base_scenario=None, name=datetime.now().strftime('%Y%m%d%H%M%S'), project_card_list=None, project_card_filepath=None, filter_tags=None, config=None)\n</code></pre> <p>Creates scenario from a base scenario and adds project cards.</p> <p>Project cards can be added using any/all of the following methods: 1. List of ProjectCard instances 2. List of ProjectCard files 3. Directory and optional glob search to find project card files in</p> <p>Checks that a project of same name is not already in scenario. If selected, will validate ProjectCard before adding. If provided, will only add ProjectCard if it matches at least one filter_tags.</p> <p>Parameters:</p> <ul> <li> <code>base_scenario</code>               (<code>Optional[Union[Scenario, dict]]</code>, default:                   <code>None</code> )           \u2013            <p>base Scenario scenario instances of dictionary of attributes.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>strftime('%Y%m%d%H%M%S')</code> )           \u2013            <p>Optional name for the scenario. Defaults to current datetime.</p> </li> <li> <code>project_card_list</code>           \u2013            <p>List of ProjectCard instances to create Scenario from. Defaults to [].</p> </li> <li> <code>project_card_filepath</code>               (<code>Optional[Union[list[Path], Path]]</code>, default:                   <code>None</code> )           \u2013            <p>where the project card is.  A single path, list of paths,</p> </li> <li> <code>filter_tags</code>               (<code>Optional[list[str]]</code>, default:                   <code>None</code> )           \u2013            <p>If used, will only add the project card if its tags match one or more of these filter_tags. Defaults to [] which means no tag-filtering will occur.</p> </li> <li> <code>config</code>               (<code>Optional[Union[dict, Path, list[Path], WranglerConfig]]</code>, default:                   <code>None</code> )           \u2013            <p>Optional wrangler configuration file or dictionary or instance. Defaults to default config.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def create_scenario(\n    base_scenario: Optional[Union[Scenario, dict]] = None,\n    name: str = datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n    project_card_list=None,\n    project_card_filepath: Optional[Union[list[Path], Path]] = None,\n    filter_tags: Optional[list[str]] = None,\n    config: Optional[Union[dict, Path, list[Path], WranglerConfig]] = None,\n) -&gt; Scenario:\n    \"\"\"Creates scenario from a base scenario and adds project cards.\n\n    Project cards can be added using any/all of the following methods:\n    1. List of ProjectCard instances\n    2. List of ProjectCard files\n    3. Directory and optional glob search to find project card files in\n\n    Checks that a project of same name is not already in scenario.\n    If selected, will validate ProjectCard before adding.\n    If provided, will only add ProjectCard if it matches at least one filter_tags.\n\n    Args:\n        base_scenario: base Scenario scenario instances of dictionary of attributes.\n        name: Optional name for the scenario. Defaults to current datetime.\n        project_card_list: List of ProjectCard instances to create Scenario from. Defaults\n            to [].\n        project_card_filepath: where the project card is.  A single path, list of paths,\n        a directory, or a glob pattern. Defaults to None.\n        filter_tags: If used, will only add the project card if\n            its tags match one or more of these filter_tags. Defaults to []\n            which means no tag-filtering will occur.\n        config: Optional wrangler configuration file or dictionary or instance. Defaults to\n            default config.\n    \"\"\"\n    base_scenario = base_scenario or {}\n    project_card_list = project_card_list or []\n    filter_tags = filter_tags or []\n\n    scenario = Scenario(base_scenario, config=config, name=name)\n\n    if project_card_filepath:\n        project_card_list += list(\n            read_cards(project_card_filepath, filter_tags=filter_tags).values()\n        )\n\n    if project_card_list:\n        scenario.add_project_cards(project_card_list, filter_tags=filter_tags)\n\n    return scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.extract_base_scenario_metadata","title":"network_wrangler.scenario.extract_base_scenario_metadata","text":"<pre><code>extract_base_scenario_metadata(base_scenario)\n</code></pre> <p>Extract metadata from base scenario rather than keeping all of big files.</p> <p>Useful for summarizing a scenario.</p> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def extract_base_scenario_metadata(base_scenario: dict) -&gt; dict:\n    \"\"\"Extract metadata from base scenario rather than keeping all of big files.\n\n    Useful for summarizing a scenario.\n    \"\"\"\n    _skip_copy = [\"road_net\", \"transit_net\", \"config\"]\n    out_dict = {k: v for k, v in base_scenario.items() if k not in _skip_copy}\n    if isinstance(base_scenario.get(\"road_net\"), RoadwayNetwork):\n        nodes_file_path = base_scenario[\"road_net\"].nodes_df.attrs.get(\"source_file\", None)\n        if nodes_file_path is not None:\n            out_dict[\"roadway\"] = {\n                \"dir\": str(Path(nodes_file_path).parent),\n                \"file_format\": str(nodes_file_path.suffix).lstrip(\".\"),\n            }\n    if isinstance(base_scenario.get(\"transit_net\"), TransitNetwork):\n        feed_path = base_scenario[\"transit_net\"].feed.feed_path\n        if feed_path is not None:\n            out_dict[\"transit\"] = {\"dir\": str(feed_path)}\n    return out_dict\n</code></pre>"},{"location":"api/#network_wrangler.scenario.load_scenario","title":"network_wrangler.scenario.load_scenario","text":"<pre><code>load_scenario(scenario_data, name=datetime.now().strftime('%Y%m%d%H%M%S'))\n</code></pre> <p>Loads a scenario from a file written by Scenario.write() as the base scenario.</p> <p>Parameters:</p> <ul> <li> <code>scenario_data</code>               (<code>Union[dict, Path]</code>)           \u2013            <p>Scenario data as a dict or path to scenario data file</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>strftime('%Y%m%d%H%M%S')</code> )           \u2013            <p>Optional name for the scenario. Defaults to current datetime.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def load_scenario(\n    scenario_data: Union[dict, Path],\n    name: str = datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n) -&gt; Scenario:\n    \"\"\"Loads a scenario from a file written by Scenario.write() as the base scenario.\n\n    Args:\n        scenario_data: Scenario data as a dict or path to scenario data file\n        name: Optional name for the scenario. Defaults to current datetime.\n    \"\"\"\n    if not isinstance(scenario_data, dict):\n        WranglerLogger.debug(f\"Loading Scenario from file: {scenario_data}\")\n        scenario_data = load_dict(scenario_data)\n    else:\n        WranglerLogger.debug(\"Loading Scenario from dict.\")\n\n    base_scenario_data = {\n        \"roadway\": scenario_data.get(\"roadway\"),\n        \"transit\": scenario_data.get(\"transit\"),\n        \"applied_projects\": scenario_data.get(\"applied_projects\", []),\n        \"conflicts\": scenario_data.get(\"conflicts\", {}),\n    }\n    base_scenario = _load_base_scenario_from_config(\n        base_scenario_data, config=scenario_data[\"config\"]\n    )\n    my_scenario = create_scenario(\n        base_scenario=base_scenario, name=name, config=scenario_data[\"config\"]\n    )\n    return my_scenario\n</code></pre>"},{"location":"api/#network_wrangler.scenario.write_applied_projects","title":"network_wrangler.scenario.write_applied_projects","text":"<pre><code>write_applied_projects(scenario, out_dir, overwrite=True)\n</code></pre> <p>Summarizes all projects in a scenario to folder.</p> <p>Parameters:</p> <ul> <li> <code>scenario</code>               (<code>Scenario</code>)           \u2013            <p>Scenario instance to summarize.</p> </li> <li> <code>out_dir</code>               (<code>Path</code>)           \u2013            <p>Path to write the project cards.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will overwrite the files if they already exist.</p> </li> </ul> Source code in <code>network_wrangler/scenario.py</code> <pre><code>def write_applied_projects(scenario: Scenario, out_dir: Path, overwrite: bool = True) -&gt; None:\n    \"\"\"Summarizes all projects in a scenario to folder.\n\n    Args:\n        scenario: Scenario instance to summarize.\n        out_dir: Path to write the project cards.\n        overwrite: If True, will overwrite the files if they already exist.\n    \"\"\"\n    outdir = Path(out_dir)\n    prep_dir(out_dir, overwrite=overwrite)\n\n    for p in scenario.applied_projects:\n        if p in scenario.project_cards:\n            card = scenario.project_cards[p]\n        elif p in scenario.base_scenario[\"project_cards\"]:\n            card = scenario.base_scenario[\"project_cards\"][p]\n        else:\n            continue\n        filename = Path(card.__dict__.get(\"file\", f\"{p}.yml\")).name\n        outpath = outdir / filename\n        write_card(card, outpath)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork","title":"network_wrangler.roadway.network.RoadwayNetwork","text":"<p>               Bases: <code>BaseModel</code></p> <p>Representation of a Roadway Network.</p> <p>Typical usage example:</p> <pre><code>net = load_roadway(\n    links_file=MY_LINK_FILE,\n    nodes_file=MY_NODE_FILE,\n    shapes_file=MY_SHAPE_FILE,\n)\nmy_selection = {\n    \"link\": [{\"name\": [\"I 35E\"]}],\n    \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n    \"B\": {\"osm_node_id\": \"2564047368\"},\n}\nnet.get_selection(my_selection)\n\nmy_change = [\n    {\n        'property': 'lanes',\n        'existing': 1,\n        'set': 2,\n    },\n    {\n        'property': 'drive_access',\n        'set': 0,\n    },\n]\n\nmy_net.apply_roadway_feature_change(\n    my_net.get_selection(my_selection),\n    my_change\n)\n\n    net.model_net\n    net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n    _, disconnected_nodes = net.assess_connectivity(\n        mode=\"walk\",\n        ignore_end_nodes=True,\n        nodes=self.m_nodes_df,\n        links=self.m_links_df\n    )\n    write_roadway(net,filename=my_out_prefix, path=my_dir, for_model = True)\n</code></pre> <p>Attributes:</p> <ul> <li> <code>nodes_df</code>               (<code>RoadNodesTable</code>)           \u2013            <p>dataframe of of node records.</p> </li> <li> <code>links_df</code>               (<code>RoadLinksTable</code>)           \u2013            <p>dataframe of link records and associated properties.</p> </li> <li> <code>shapes_df</code>               (<code>RoadShapesTable</code>)           \u2013            <p>dataframe of detailed shape records  This is lazily created iff it is called because shapes files can be expensive to read.</p> </li> <li> <code>_selections</code>               (<code>dict</code>)           \u2013            <p>dictionary of stored roadway selection objects, mapped by <code>RoadwayLinkSelection.sel_key</code> or <code>RoadwayNodeSelection.sel_key</code> in case they are     made repeatedly.</p> </li> <li> <code>network_hash</code>               (<code>str</code>)           \u2013            <p>dynamic property of the hashed value of links_df and nodes_df. Used for quickly identifying if a network has changed since various expensive operations have taken place (i.e. generating a ModelRoadwayNetwork or a network graph)</p> </li> <li> <code>model_net</code>               (<code>ModelRoadwayNetwork</code>)           \u2013            <p>referenced <code>ModelRoadwayNetwork</code> object which will be lazily created if None or if the <code>network_hash</code> has changed.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>)           \u2013            <p>wrangler configuration object</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>class RoadwayNetwork(BaseModel):\n    \"\"\"Representation of a Roadway Network.\n\n    Typical usage example:\n\n    ```py\n    net = load_roadway(\n        links_file=MY_LINK_FILE,\n        nodes_file=MY_NODE_FILE,\n        shapes_file=MY_SHAPE_FILE,\n    )\n    my_selection = {\n        \"link\": [{\"name\": [\"I 35E\"]}],\n        \"A\": {\"osm_node_id\": \"961117623\"},  # start searching for segments at A\n        \"B\": {\"osm_node_id\": \"2564047368\"},\n    }\n    net.get_selection(my_selection)\n\n    my_change = [\n        {\n            'property': 'lanes',\n            'existing': 1,\n            'set': 2,\n        },\n        {\n            'property': 'drive_access',\n            'set': 0,\n        },\n    ]\n\n    my_net.apply_roadway_feature_change(\n        my_net.get_selection(my_selection),\n        my_change\n    )\n\n        net.model_net\n        net.is_network_connected(mode=\"drive\", nodes=self.m_nodes_df, links=self.m_links_df)\n        _, disconnected_nodes = net.assess_connectivity(\n            mode=\"walk\",\n            ignore_end_nodes=True,\n            nodes=self.m_nodes_df,\n            links=self.m_links_df\n        )\n        write_roadway(net,filename=my_out_prefix, path=my_dir, for_model = True)\n    ```\n\n    Attributes:\n        nodes_df (RoadNodesTable): dataframe of of node records.\n        links_df (RoadLinksTable): dataframe of link records and associated properties.\n        shapes_df (RoadShapesTable): dataframe of detailed shape records  This is lazily\n            created iff it is called because shapes files can be expensive to read.\n        _selections (dict): dictionary of stored roadway selection objects, mapped by\n            `RoadwayLinkSelection.sel_key` or `RoadwayNodeSelection.sel_key` in case they are\n                made repeatedly.\n        network_hash: dynamic property of the hashed value of links_df and nodes_df. Used for\n            quickly identifying if a network has changed since various expensive operations have\n            taken place (i.e. generating a ModelRoadwayNetwork or a network graph)\n        model_net (ModelRoadwayNetwork): referenced `ModelRoadwayNetwork` object which will be\n            lazily created if None or if the `network_hash` has changed.\n        config (WranglerConfig): wrangler configuration object\n    \"\"\"\n\n    model_config = {\"arbitrary_types_allowed\": True}\n\n    nodes_df: pd.DataFrame\n    links_df: pd.DataFrame\n    _shapes_df: Optional[pd.DataFrame] = None\n\n    _links_file: Optional[Path] = None\n    _nodes_file: Optional[Path] = None\n    _shapes_file: Optional[Path] = None\n\n    config: WranglerConfig = DefaultConfig\n\n    _model_net: Optional[ModelRoadwayNetwork] = None\n    _selections: dict[str, Selections] = {}\n    _modal_graphs: dict[str, dict] = defaultdict(lambda: {\"graph\": None, \"hash\": None})\n\n    @field_validator(\"config\")\n    def validate_config(cls, v):\n        \"\"\"Validate config.\"\"\"\n        return load_wrangler_config(v)\n\n    @field_validator(\"nodes_df\", \"links_df\")\n    def coerce_crs(cls, v):\n        \"\"\"Coerce crs of nodes_df and links_df to LAT_LON_CRS.\"\"\"\n        if v.crs != LAT_LON_CRS:\n            WranglerLogger.warning(\n                f\"CRS of links_df ({v.crs}) doesn't match network crs {LAT_LON_CRS}. \\\n                    Changing to network crs.\"\n            )\n            v.to_crs(LAT_LON_CRS)\n        return v\n\n    @property\n    def shapes_df(self) -&gt; pd.DataFrame:\n        \"\"\"Load and return RoadShapesTable.\n\n        If not already loaded, will read from shapes_file and return. If shapes_file is None,\n        will return an empty dataframe with the right schema. If shapes_df is already set, will\n        return that.\n        \"\"\"\n        if (self._shapes_df is None or self._shapes_df.empty) and self._shapes_file is not None:\n            self._shapes_df = read_shapes(\n                self._shapes_file,\n                filter_to_shape_ids=self.links_df.shape_id.to_list(),\n                config=self.config,\n            )\n        # if there is NONE, then at least create an empty dataframe with right schema\n        elif self._shapes_df is None:\n            self._shapes_df = empty_df_from_datamodel(RoadShapesTable)\n            self._shapes_df.set_index(\"shape_id_idx\", inplace=True)\n\n        return self._shapes_df\n\n    @shapes_df.setter\n    def shapes_df(self, value):\n        self._shapes_df = df_to_shapes_df(value, config=self.config)\n\n    @property\n    def network_hash(self) -&gt; str:\n        \"\"\"Hash of the links and nodes dataframes.\"\"\"\n        _value = str.encode(self.links_df.df_hash() + \"-\" + self.nodes_df.df_hash())\n\n        _hash = hashlib.sha256(_value).hexdigest()\n        return _hash\n\n    @property\n    def model_net(self) -&gt; ModelRoadwayNetwork:\n        \"\"\"Return a ModelRoadwayNetwork object for this network.\"\"\"\n        if self._model_net is None or self._model_net._net_hash != self.network_hash:\n            self._model_net = ModelRoadwayNetwork(self)\n        return self._model_net\n\n    @property\n    def summary(self) -&gt; dict:\n        \"\"\"Quick summary dictionary of number of links, nodes.\"\"\"\n        d = {\n            \"links\": len(self.links_df),\n            \"nodes\": len(self.nodes_df),\n        }\n        return d\n\n    @property\n    def link_shapes_df(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Add shape geometry to links if available.\n\n        returns: shapes merged to links dataframe\n        \"\"\"\n        _links_df = copy.deepcopy(self.links_df)\n        link_shapes_df = _links_df.merge(\n            self.shapes_df,\n            left_on=\"shape_id\",\n            right_on=\"shape_id\",\n            how=\"left\",\n        )\n        link_shapes_df[\"geometry\"] = link_shapes_df[\"geometry_y\"].combine_first(\n            link_shapes_df[\"geometry_x\"]\n        )\n        link_shapes_df = link_shapes_df.drop(columns=[\"geometry_x\", \"geometry_y\"])\n        link_shapes_df = link_shapes_df.set_geometry(\"geometry\")\n        return link_shapes_df\n\n    def get_property_by_timespan_and_group(\n        self,\n        link_property: str,\n        category: Optional[Union[str, int]] = DEFAULT_CATEGORY,\n        timespan: Optional[TimespanString] = DEFAULT_TIMESPAN,\n        strict_timespan_match: bool = False,\n        min_overlap_minutes: int = 60,\n    ) -&gt; Any:\n        \"\"\"Returns a new dataframe with model_link_id and link property by category and timespan.\n\n        Convenience method for backward compatability.\n\n        Args:\n            link_property: link property to query\n            category: category to query or a list of categories. Defaults to DEFAULT_CATEGORY.\n            timespan: timespan to query in the form of [\"HH:MM\",\"HH:MM\"].\n                Defaults to DEFAULT_TIMESPAN.\n            strict_timespan_match: If True, will only return links that match the timespan exactly.\n                Defaults to False.\n            min_overlap_minutes: If strict_timespan_match is False, will return links that overlap\n                with the timespan by at least this many minutes. Defaults to 60.\n        \"\"\"\n        from .links.scopes import prop_for_scope  # noqa: PLC0415\n\n        return prop_for_scope(\n            self.links_df,\n            link_property,\n            timespan=timespan,\n            category=category,\n            strict_timespan_match=strict_timespan_match,\n            min_overlap_minutes=min_overlap_minutes,\n        )\n\n    def get_selection(\n        self,\n        selection_dict: Union[dict, SelectFacility],\n        overwrite: bool = False,\n    ) -&gt; Union[RoadwayNodeSelection, RoadwayLinkSelection]:\n        \"\"\"Return selection if it already exists, otherwise performs selection.\n\n        Args:\n            selection_dict (dict): SelectFacility dictionary.\n            overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n        \"\"\"\n        key = _create_selection_key(selection_dict)\n        if (key in self._selections) and not overwrite:\n            WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n            return self._selections[key]\n\n        if isinstance(selection_dict, SelectFacility):\n            selection_data = selection_dict\n        elif isinstance(selection_dict, SelectLinksDict):\n            selection_data = SelectFacility(links=selection_dict)\n        elif isinstance(selection_dict, SelectNodesDict):\n            selection_data = SelectFacility(nodes=selection_dict)\n        elif isinstance(selection_dict, dict):\n            selection_data = SelectFacility(**selection_dict)\n        else:\n            msg = \"selection_dict arg must be a dictionary or SelectFacility model.\"\n            WranglerLogger.error(\n                msg + f\" Received: {selection_dict} of type {type(selection_dict)}\"\n            )\n            raise SelectionError(msg)\n\n        WranglerLogger.debug(f\"Getting selection from key: {key}\")\n        if \"links\" in selection_data.fields:\n            return RoadwayLinkSelection(self, selection_dict)\n        if \"nodes\" in selection_data.fields:\n            return RoadwayNodeSelection(self, selection_dict)\n        msg = \"Selection data should have either 'links' or 'nodes'.\"\n        WranglerLogger.error(msg + f\" Received: {selection_dict}\")\n        raise SelectionError(msg)\n\n    def modal_graph_hash(self, mode) -&gt; str:\n        \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n        _value = str.encode(self.links_df.df_hash() + \"-\" + mode)\n        _hash = hashlib.sha256(_value).hexdigest()\n\n        return _hash\n\n    def get_modal_graph(self, mode) -&gt; MultiDiGraph:\n        \"\"\"Return a networkx graph of the network for a specific mode.\n\n        Args:\n            mode: mode of the network, one of `drive`,`transit`,`walk`, `bike`\n        \"\"\"\n        from .graph import net_to_graph  # noqa: PLC0415\n\n        if self._modal_graphs[mode][\"hash\"] != self.modal_graph_hash(mode):\n            self._modal_graphs[mode][\"graph\"] = net_to_graph(self, mode)\n\n        return self._modal_graphs[mode][\"graph\"]\n\n    def apply(\n        self,\n        project_card: Union[ProjectCard, dict],\n        transit_net: Optional[TransitNetwork] = None,\n        **kwargs,\n    ) -&gt; RoadwayNetwork:\n        \"\"\"Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n        Args:\n            project_card: either a dictionary of the project card object or ProjectCard instance\n            transit_net: optional transit network which will be used to if project requires as\n                noted in `SECONDARY_TRANSIT_CARD_TYPES`.  If no transit network is provided, will\n                skip anything related to transit network.\n            **kwargs: keyword arguments to pass to project application\n        \"\"\"\n        if not (isinstance(project_card, (ProjectCard, SubProject))):\n            project_card = ProjectCard(project_card)\n\n        # project_card.validate()\n        if not project_card.valid:\n            msg = f\"Project card {project_card.project} not valid.\"\n            WranglerLogger.error(msg)\n            raise ProjectCardError(msg)\n\n        if project_card._sub_projects:\n            for sp in project_card._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp, transit_net=transit_net, **kwargs)\n            return self\n        return self._apply_change(project_card, transit_net=transit_net, **kwargs)\n\n    def _apply_change(\n        self,\n        change: Union[ProjectCard, SubProject],\n        transit_net: Optional[TransitNetwork] = None,\n    ) -&gt; RoadwayNetwork:\n        \"\"\"Apply a single change: a single-project project or a sub-project.\"\"\"\n        if not isinstance(change, SubProject):\n            WranglerLogger.info(f\"Applying Project to Roadway Network: {change.project}\")\n\n        if change.change_type == \"roadway_property_change\":\n            return apply_roadway_property_change(\n                self,\n                self.get_selection(change.roadway_property_change[\"facility\"]),\n                change.roadway_property_change[\"property_changes\"],\n                project_name=change.project,\n            )\n\n        if change.change_type == \"roadway_addition\":\n            return apply_new_roadway(\n                self,\n                change.roadway_addition,\n                project_name=change.project,\n            )\n\n        if change.change_type == \"roadway_deletion\":\n            return apply_roadway_deletion(\n                self,\n                change.roadway_deletion,\n                transit_net=transit_net,\n            )\n\n        if change.change_type == \"pycode\":\n            return apply_calculated_roadway(self, change.pycode)\n        WranglerLogger.error(f\"Couldn't find project in: \\n{change.__dict__}\")\n        msg = f\"Invalid Project Card Category: {change.change_type}\"\n        raise ProjectCardError(msg)\n\n    def links_with_link_ids(self, link_ids: list[int]) -&gt; pd.DataFrame:\n        \"\"\"Return subset of links_df based on link_ids list.\"\"\"\n        return filter_links_to_ids(self.links_df, link_ids)\n\n    def links_with_nodes(self, node_ids: list[int]) -&gt; pd.DataFrame:\n        \"\"\"Return subset of links_df based on node_ids list.\"\"\"\n        return filter_links_to_node_ids(self.links_df, node_ids)\n\n    def nodes_in_links(self) -&gt; pd.DataFrame:\n        \"\"\"Returns subset of self.nodes_df that are in self.links_df.\"\"\"\n        return filter_nodes_to_links(self.links_df, self.nodes_df)\n\n    def node_coords(self, model_node_id: int) -&gt; tuple:\n        \"\"\"Return coordinates (x, y) of a node based on model_node_id.\"\"\"\n        try:\n            node = self.nodes_df[self.nodes_df.model_node_id == model_node_id]\n        except ValueError as err:\n            msg = f\"Node with model_node_id {model_node_id} not found.\"\n            WranglerLogger.error(msg)\n            raise NodeNotFoundError(msg) from err\n        return node.geometry.x.values[0], node.geometry.y.values[0]\n\n    def add_links(\n        self,\n        add_links_df: pd.DataFrame,\n        in_crs: int = LAT_LON_CRS,\n    ):\n        \"\"\"Validate combined links_df with LinksSchema before adding to self.links_df.\n\n        Args:\n            add_links_df: Dataframe of additional links to add.\n            in_crs: crs of input data. Defaults to LAT_LON_CRS.\n        \"\"\"\n        dupe_recs = self.links_df.model_link_id.isin(add_links_df.model_link_id)\n\n        if dupe_recs.any():\n            dupe_ids = self.links_df.loc[dupe_recs, \"model_link_id\"]\n            WranglerLogger.error(\n                f\"Cannot add links with model_link_id already in network: {dupe_ids}\"\n            )\n            msg = \"Cannot add links with model_link_id already in network.\"\n            raise LinkAddError(msg)\n\n        if add_links_df.attrs.get(\"name\") != \"road_links\":\n            add_links_df = data_to_links_df(add_links_df, nodes_df=self.nodes_df, in_crs=in_crs)\n        self.links_df = validate_df_to_model(\n            concat_with_attr([self.links_df, add_links_df], axis=0), RoadLinksTable\n        )\n\n    def add_nodes(\n        self,\n        add_nodes_df: pd.DataFrame,\n        in_crs: int = LAT_LON_CRS,\n    ):\n        \"\"\"Validate combined nodes_df with NodesSchema before adding to self.nodes_df.\n\n        Args:\n            add_nodes_df: Dataframe of additional nodes to add.\n            in_crs: crs of input data. Defaults to LAT_LON_CRS.\n        \"\"\"\n        dupe_ids = self.nodes_df.model_node_id.isin(add_nodes_df.model_node_id)\n        if dupe_ids.any():\n            WranglerLogger.error(\n                f\"Cannot add nodes with model_node_id already in network: {dupe_ids}\"\n            )\n            msg = \"Cannot add nodes with model_node_id already in network.\"\n            raise NodeAddError(msg)\n\n        if add_nodes_df.attrs.get(\"name\") != \"road_nodes\":\n            add_nodes_df = data_to_nodes_df(add_nodes_df, in_crs=in_crs, config=self.config)\n        self.nodes_df = validate_df_to_model(\n            concat_with_attr([self.nodes_df, add_nodes_df], axis=0), RoadNodesTable\n        )\n        if self.nodes_df.attrs.get(\"name\") != \"road_nodes\":\n            msg = f\"Expected nodes_df to have name 'road_nodes', got {self.nodes_df.attrs.get('name')}\"\n            raise NotNodesError(msg)\n\n    def add_shapes(\n        self,\n        add_shapes_df: pd.DataFrame,\n        in_crs: int = LAT_LON_CRS,\n    ):\n        \"\"\"Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.\n\n        Args:\n            add_shapes_df: Dataframe of additional shapes to add.\n            in_crs: crs of input data. Defaults to LAT_LON_CRS.\n        \"\"\"\n        dupe_ids = self.shapes_df.shape_id.isin(add_shapes_df.shape_id)\n        if dupe_ids.any():\n            msg = \"Cannot add shapes with shape_id already in network.\"\n            WranglerLogger.error(msg + f\"\\nDuplicates: {dupe_ids}\")\n            raise ShapeAddError(msg)\n\n        if add_shapes_df.attrs.get(\"name\") != \"road_shapes\":\n            add_shapes_df = df_to_shapes_df(add_shapes_df, in_crs=in_crs, config=self.config)\n\n        WranglerLogger.debug(f\"add_shapes_df: \\n{add_shapes_df}\")\n        WranglerLogger.debug(f\"self.shapes_df: \\n{self.shapes_df}\")\n\n        self.shapes_df = validate_df_to_model(\n            concat_with_attr([self.shapes_df, add_shapes_df], axis=0), RoadShapesTable\n        )\n\n    def delete_links(\n        self,\n        selection_dict: Union[dict, SelectLinksDict],\n        clean_nodes: bool = False,\n        clean_shapes: bool = False,\n        transit_net: Optional[TransitNetwork] = None,\n    ):\n        \"\"\"Deletes links based on selection dictionary and optionally associated nodes and shapes.\n\n        Args:\n            selection_dict (SelectLinks): Dictionary describing link selections as follows:\n                `all`: Optional[bool] = False. If true, will select all.\n                `name`: Optional[list[str]]\n                `ref`: Optional[list[str]]\n                `osm_link_id`:Optional[list[str]]\n                `model_link_id`: Optional[list[int]]\n                `modes`: Optional[list[str]]. Defaults to \"any\"\n                `ignore_missing`: if true, will not error when defaults to True.\n                ...plus any other link property to select on top of these.\n            clean_nodes (bool, optional): If True, will clean nodes uniquely associated with\n                deleted links. Defaults to False.\n            clean_shapes (bool, optional): If True, will clean nodes uniquely associated with\n                deleted links. Defaults to False.\n            transit_net (TransitNetwork, optional): If provided, will check TransitNetwork and\n                warn if deletion breaks transit shapes. Defaults to None.\n        \"\"\"\n        if not isinstance(selection_dict, SelectLinksDict):\n            selection_dict = SelectLinksDict(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        selection = self.get_selection({\"links\": selection_dict})\n        if isinstance(selection, RoadwayNodeSelection):\n            msg = \"Selection should be for links, but got nodes.\"\n            raise SelectionError(msg)\n        if clean_nodes:\n            node_ids_to_delete = node_ids_unique_to_link_ids(\n                selection.selected_links, selection.selected_links_df, self.nodes_df\n            )\n            WranglerLogger.debug(\n                f\"Dropping nodes associated with dropped links: \\n{node_ids_to_delete}\"\n            )\n            self.nodes_df = delete_nodes_by_ids(self.nodes_df, del_node_ids=node_ids_to_delete)\n\n        if clean_shapes:\n            shape_ids_to_delete = shape_ids_unique_to_link_ids(\n                selection.selected_links, selection.selected_links_df, self.shapes_df\n            )\n            WranglerLogger.debug(\n                f\"Dropping shapes associated with dropped links: \\n{shape_ids_to_delete}\"\n            )\n            self.shapes_df = delete_shapes_by_ids(\n                self.shapes_df, del_shape_ids=shape_ids_to_delete\n            )\n\n        self.links_df = delete_links_by_ids(\n            self.links_df,\n            selection.selected_links,\n            ignore_missing=selection.ignore_missing,\n            transit_net=transit_net,\n        )\n\n    def delete_nodes(\n        self,\n        selection_dict: Union[dict, SelectNodesDict],\n        remove_links: bool = False,\n    ) -&gt; None:\n        \"\"\"Deletes nodes from roadway network. Wont delete nodes used by links in network.\n\n        Args:\n            selection_dict: dictionary of node selection criteria in the form of a SelectNodesDict.\n            remove_links: if True, will remove any links that are associated with the nodes.\n                If False, will only remove nodes if they are not associated with any links.\n                Defaults to False.\n\n        Raises:\n            NodeDeletionError: If not ignore_missing and selected nodes to delete aren't in network\n        \"\"\"\n        if not isinstance(selection_dict, SelectNodesDict):\n            selection_dict = SelectNodesDict(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        _selection = self.get_selection({\"nodes\": selection_dict})\n        assert isinstance(_selection, RoadwayNodeSelection)  # for mypy\n        selection: RoadwayNodeSelection = _selection\n        if remove_links:\n            del_node_ids = selection.selected_nodes\n            link_ids = self.links_with_nodes(selection.selected_nodes).model_link_id.to_list()\n            WranglerLogger.info(f\"Removing {len(link_ids)} links associated with nodes.\")\n            self.delete_links({\"model_link_id\": link_ids})\n        else:\n            unused_node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n            del_node_ids = list(set(selection.selected_nodes).intersection(unused_node_ids))\n\n        self.nodes_df = delete_nodes_by_ids(\n            self.nodes_df, del_node_ids, ignore_missing=selection.ignore_missing\n        )\n\n    def clean_unused_shapes(self):\n        \"\"\"Removes any unused shapes from network that aren't referenced by links_df.\"\"\"\n        from .shapes.shapes import shape_ids_without_links  # noqa: PLC0415\n\n        del_shape_ids = shape_ids_without_links(self.shapes_df, self.links_df)\n        self.shapes_df = self.shapes_df.drop(del_shape_ids)\n\n    def clean_unused_nodes(self):\n        \"\"\"Removes any unused nodes from network that aren't referenced by links_df.\n\n        NOTE: does not check if these nodes are used by transit, so use with caution.\n        \"\"\"\n        from .nodes.nodes import node_ids_without_links  # noqa: PLC0415\n\n        node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n        self.nodes_df = self.nodes_df.drop(node_ids)\n\n    def move_nodes(\n        self,\n        node_geometry_change_table: pd.DataFrame,\n    ):\n        \"\"\"Moves nodes based on updated geometry along with associated links and shape geometry.\n\n        Args:\n            node_geometry_change_table: a table with model_node_id, X, Y, and CRS.\n        \"\"\"\n        node_geometry_change_table = NodeGeometryChangeTable(node_geometry_change_table)\n        node_ids = node_geometry_change_table.model_node_id.to_list()\n        WranglerLogger.debug(f\"Moving nodes: {node_ids}\")\n        self.nodes_df = edit_node_geometry(self.nodes_df, node_geometry_change_table)\n        self.links_df = edit_link_geometry_from_nodes(self.links_df, self.nodes_df, node_ids)\n        self.shapes_df = edit_shape_geometry_from_nodes(\n            self.shapes_df, self.links_df, self.nodes_df, node_ids\n        )\n\n    def has_node(self, model_node_id: int) -&gt; bool:\n        \"\"\"Queries if network has node based on model_node_id.\n\n        Args:\n            model_node_id: model_node_id to check for.\n        \"\"\"\n        has_node = self.nodes_df[self.nodes_df.model_node_id].isin([model_node_id]).any()\n\n        return has_node\n\n    def has_link(self, ab: tuple) -&gt; bool:\n        \"\"\"Returns true if network has links with AB values.\n\n        Args:\n            ab: Tuple of values corresponding with A and B.\n        \"\"\"\n        sel_a, sel_b = ab\n        has_link = (\n            self.links_df[self.links_df[[\"A\", \"B\"]]].isin_dict({\"A\": sel_a, \"B\": sel_b}).any()\n        )\n        return has_link\n\n    def is_connected(self, mode: str) -&gt; bool:\n        \"\"\"Determines if the network graph is \"strongly\" connected.\n\n        A graph is strongly connected if each vertex is reachable from every other vertex.\n\n        Args:\n            mode:  mode of the network, one of `drive`,`transit`,`walk`, `bike`\n        \"\"\"\n        is_connected = nx.is_strongly_connected(self.get_modal_graph(mode))\n\n        return is_connected\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.link_shapes_df","title":"network_wrangler.roadway.network.RoadwayNetwork.link_shapes_df  <code>property</code>","text":"<pre><code>link_shapes_df\n</code></pre> <p>Add shape geometry to links if available.</p> <p>returns: shapes merged to links dataframe</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.model_net","title":"network_wrangler.roadway.network.RoadwayNetwork.model_net  <code>property</code>","text":"<pre><code>model_net\n</code></pre> <p>Return a ModelRoadwayNetwork object for this network.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.network_hash","title":"network_wrangler.roadway.network.RoadwayNetwork.network_hash  <code>property</code>","text":"<pre><code>network_hash\n</code></pre> <p>Hash of the links and nodes dataframes.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.shapes_df","title":"network_wrangler.roadway.network.RoadwayNetwork.shapes_df  <code>property</code> <code>writable</code>","text":"<pre><code>shapes_df\n</code></pre> <p>Load and return RoadShapesTable.</p> <p>If not already loaded, will read from shapes_file and return. If shapes_file is None, will return an empty dataframe with the right schema. If shapes_df is already set, will return that.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.summary","title":"network_wrangler.roadway.network.RoadwayNetwork.summary  <code>property</code>","text":"<pre><code>summary\n</code></pre> <p>Quick summary dictionary of number of links, nodes.</p>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_links","title":"network_wrangler.roadway.network.RoadwayNetwork.add_links","text":"<pre><code>add_links(add_links_df, in_crs=LAT_LON_CRS)\n</code></pre> <p>Validate combined links_df with LinksSchema before adding to self.links_df.</p> <p>Parameters:</p> <ul> <li> <code>add_links_df</code>               (<code>DataFrame</code>)           \u2013            <p>Dataframe of additional links to add.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>crs of input data. Defaults to LAT_LON_CRS.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_links(\n    self,\n    add_links_df: pd.DataFrame,\n    in_crs: int = LAT_LON_CRS,\n):\n    \"\"\"Validate combined links_df with LinksSchema before adding to self.links_df.\n\n    Args:\n        add_links_df: Dataframe of additional links to add.\n        in_crs: crs of input data. Defaults to LAT_LON_CRS.\n    \"\"\"\n    dupe_recs = self.links_df.model_link_id.isin(add_links_df.model_link_id)\n\n    if dupe_recs.any():\n        dupe_ids = self.links_df.loc[dupe_recs, \"model_link_id\"]\n        WranglerLogger.error(\n            f\"Cannot add links with model_link_id already in network: {dupe_ids}\"\n        )\n        msg = \"Cannot add links with model_link_id already in network.\"\n        raise LinkAddError(msg)\n\n    if add_links_df.attrs.get(\"name\") != \"road_links\":\n        add_links_df = data_to_links_df(add_links_df, nodes_df=self.nodes_df, in_crs=in_crs)\n    self.links_df = validate_df_to_model(\n        concat_with_attr([self.links_df, add_links_df], axis=0), RoadLinksTable\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_nodes","title":"network_wrangler.roadway.network.RoadwayNetwork.add_nodes","text":"<pre><code>add_nodes(add_nodes_df, in_crs=LAT_LON_CRS)\n</code></pre> <p>Validate combined nodes_df with NodesSchema before adding to self.nodes_df.</p> <p>Parameters:</p> <ul> <li> <code>add_nodes_df</code>               (<code>DataFrame</code>)           \u2013            <p>Dataframe of additional nodes to add.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>crs of input data. Defaults to LAT_LON_CRS.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_nodes(\n    self,\n    add_nodes_df: pd.DataFrame,\n    in_crs: int = LAT_LON_CRS,\n):\n    \"\"\"Validate combined nodes_df with NodesSchema before adding to self.nodes_df.\n\n    Args:\n        add_nodes_df: Dataframe of additional nodes to add.\n        in_crs: crs of input data. Defaults to LAT_LON_CRS.\n    \"\"\"\n    dupe_ids = self.nodes_df.model_node_id.isin(add_nodes_df.model_node_id)\n    if dupe_ids.any():\n        WranglerLogger.error(\n            f\"Cannot add nodes with model_node_id already in network: {dupe_ids}\"\n        )\n        msg = \"Cannot add nodes with model_node_id already in network.\"\n        raise NodeAddError(msg)\n\n    if add_nodes_df.attrs.get(\"name\") != \"road_nodes\":\n        add_nodes_df = data_to_nodes_df(add_nodes_df, in_crs=in_crs, config=self.config)\n    self.nodes_df = validate_df_to_model(\n        concat_with_attr([self.nodes_df, add_nodes_df], axis=0), RoadNodesTable\n    )\n    if self.nodes_df.attrs.get(\"name\") != \"road_nodes\":\n        msg = f\"Expected nodes_df to have name 'road_nodes', got {self.nodes_df.attrs.get('name')}\"\n        raise NotNodesError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.add_shapes","title":"network_wrangler.roadway.network.RoadwayNetwork.add_shapes","text":"<pre><code>add_shapes(add_shapes_df, in_crs=LAT_LON_CRS)\n</code></pre> <p>Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.</p> <p>Parameters:</p> <ul> <li> <code>add_shapes_df</code>               (<code>DataFrame</code>)           \u2013            <p>Dataframe of additional shapes to add.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>crs of input data. Defaults to LAT_LON_CRS.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_shapes(\n    self,\n    add_shapes_df: pd.DataFrame,\n    in_crs: int = LAT_LON_CRS,\n):\n    \"\"\"Validate combined shapes_df with RoadShapesTable efore adding to self.shapes_df.\n\n    Args:\n        add_shapes_df: Dataframe of additional shapes to add.\n        in_crs: crs of input data. Defaults to LAT_LON_CRS.\n    \"\"\"\n    dupe_ids = self.shapes_df.shape_id.isin(add_shapes_df.shape_id)\n    if dupe_ids.any():\n        msg = \"Cannot add shapes with shape_id already in network.\"\n        WranglerLogger.error(msg + f\"\\nDuplicates: {dupe_ids}\")\n        raise ShapeAddError(msg)\n\n    if add_shapes_df.attrs.get(\"name\") != \"road_shapes\":\n        add_shapes_df = df_to_shapes_df(add_shapes_df, in_crs=in_crs, config=self.config)\n\n    WranglerLogger.debug(f\"add_shapes_df: \\n{add_shapes_df}\")\n    WranglerLogger.debug(f\"self.shapes_df: \\n{self.shapes_df}\")\n\n    self.shapes_df = validate_df_to_model(\n        concat_with_attr([self.shapes_df, add_shapes_df], axis=0), RoadShapesTable\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.apply","title":"network_wrangler.roadway.network.RoadwayNetwork.apply","text":"<pre><code>apply(project_card, transit_net=None, **kwargs)\n</code></pre> <p>Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.</p> <p>Parameters:</p> <ul> <li> <code>project_card</code>               (<code>Union[ProjectCard, dict]</code>)           \u2013            <p>either a dictionary of the project card object or ProjectCard instance</p> </li> <li> <code>transit_net</code>               (<code>Optional[TransitNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>optional transit network which will be used to if project requires as noted in <code>SECONDARY_TRANSIT_CARD_TYPES</code>.  If no transit network is provided, will skip anything related to transit network.</p> </li> <li> <code>**kwargs</code>           \u2013            <p>keyword arguments to pass to project application</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def apply(\n    self,\n    project_card: Union[ProjectCard, dict],\n    transit_net: Optional[TransitNetwork] = None,\n    **kwargs,\n) -&gt; RoadwayNetwork:\n    \"\"\"Wrapper method to apply a roadway project, returning a new RoadwayNetwork instance.\n\n    Args:\n        project_card: either a dictionary of the project card object or ProjectCard instance\n        transit_net: optional transit network which will be used to if project requires as\n            noted in `SECONDARY_TRANSIT_CARD_TYPES`.  If no transit network is provided, will\n            skip anything related to transit network.\n        **kwargs: keyword arguments to pass to project application\n    \"\"\"\n    if not (isinstance(project_card, (ProjectCard, SubProject))):\n        project_card = ProjectCard(project_card)\n\n    # project_card.validate()\n    if not project_card.valid:\n        msg = f\"Project card {project_card.project} not valid.\"\n        WranglerLogger.error(msg)\n        raise ProjectCardError(msg)\n\n    if project_card._sub_projects:\n        for sp in project_card._sub_projects:\n            WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n            self._apply_change(sp, transit_net=transit_net, **kwargs)\n        return self\n    return self._apply_change(project_card, transit_net=transit_net, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.clean_unused_nodes","title":"network_wrangler.roadway.network.RoadwayNetwork.clean_unused_nodes","text":"<pre><code>clean_unused_nodes()\n</code></pre> <p>Removes any unused nodes from network that aren\u2019t referenced by links_df.</p> <p>NOTE: does not check if these nodes are used by transit, so use with caution.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def clean_unused_nodes(self):\n    \"\"\"Removes any unused nodes from network that aren't referenced by links_df.\n\n    NOTE: does not check if these nodes are used by transit, so use with caution.\n    \"\"\"\n    from .nodes.nodes import node_ids_without_links  # noqa: PLC0415\n\n    node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n    self.nodes_df = self.nodes_df.drop(node_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.clean_unused_shapes","title":"network_wrangler.roadway.network.RoadwayNetwork.clean_unused_shapes","text":"<pre><code>clean_unused_shapes()\n</code></pre> <p>Removes any unused shapes from network that aren\u2019t referenced by links_df.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def clean_unused_shapes(self):\n    \"\"\"Removes any unused shapes from network that aren't referenced by links_df.\"\"\"\n    from .shapes.shapes import shape_ids_without_links  # noqa: PLC0415\n\n    del_shape_ids = shape_ids_without_links(self.shapes_df, self.links_df)\n    self.shapes_df = self.shapes_df.drop(del_shape_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.coerce_crs","title":"network_wrangler.roadway.network.RoadwayNetwork.coerce_crs","text":"<pre><code>coerce_crs(v)\n</code></pre> <p>Coerce crs of nodes_df and links_df to LAT_LON_CRS.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>@field_validator(\"nodes_df\", \"links_df\")\ndef coerce_crs(cls, v):\n    \"\"\"Coerce crs of nodes_df and links_df to LAT_LON_CRS.\"\"\"\n    if v.crs != LAT_LON_CRS:\n        WranglerLogger.warning(\n            f\"CRS of links_df ({v.crs}) doesn't match network crs {LAT_LON_CRS}. \\\n                Changing to network crs.\"\n        )\n        v.to_crs(LAT_LON_CRS)\n    return v\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.delete_links","title":"network_wrangler.roadway.network.RoadwayNetwork.delete_links","text":"<pre><code>delete_links(selection_dict, clean_nodes=False, clean_shapes=False, transit_net=None)\n</code></pre> <p>Deletes links based on selection dictionary and optionally associated nodes and shapes.</p> <p>Parameters:</p> <ul> <li> <code>selection_dict</code>               (<code>SelectLinks</code>)           \u2013            <p>Dictionary describing link selections as follows: <code>all</code>: Optional[bool] = False. If true, will select all. <code>name</code>: Optional[list[str]] <code>ref</code>: Optional[list[str]] <code>osm_link_id</code>:Optional[list[str]] <code>model_link_id</code>: Optional[list[int]] <code>modes</code>: Optional[list[str]]. Defaults to \u201cany\u201d <code>ignore_missing</code>: if true, will not error when defaults to True. \u2026plus any other link property to select on top of these.</p> </li> <li> <code>clean_nodes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will clean nodes uniquely associated with deleted links. Defaults to False.</p> </li> <li> <code>clean_shapes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will clean nodes uniquely associated with deleted links. Defaults to False.</p> </li> <li> <code>transit_net</code>               (<code>TransitNetwork</code>, default:                   <code>None</code> )           \u2013            <p>If provided, will check TransitNetwork and warn if deletion breaks transit shapes. Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def delete_links(\n    self,\n    selection_dict: Union[dict, SelectLinksDict],\n    clean_nodes: bool = False,\n    clean_shapes: bool = False,\n    transit_net: Optional[TransitNetwork] = None,\n):\n    \"\"\"Deletes links based on selection dictionary and optionally associated nodes and shapes.\n\n    Args:\n        selection_dict (SelectLinks): Dictionary describing link selections as follows:\n            `all`: Optional[bool] = False. If true, will select all.\n            `name`: Optional[list[str]]\n            `ref`: Optional[list[str]]\n            `osm_link_id`:Optional[list[str]]\n            `model_link_id`: Optional[list[int]]\n            `modes`: Optional[list[str]]. Defaults to \"any\"\n            `ignore_missing`: if true, will not error when defaults to True.\n            ...plus any other link property to select on top of these.\n        clean_nodes (bool, optional): If True, will clean nodes uniquely associated with\n            deleted links. Defaults to False.\n        clean_shapes (bool, optional): If True, will clean nodes uniquely associated with\n            deleted links. Defaults to False.\n        transit_net (TransitNetwork, optional): If provided, will check TransitNetwork and\n            warn if deletion breaks transit shapes. Defaults to None.\n    \"\"\"\n    if not isinstance(selection_dict, SelectLinksDict):\n        selection_dict = SelectLinksDict(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    selection = self.get_selection({\"links\": selection_dict})\n    if isinstance(selection, RoadwayNodeSelection):\n        msg = \"Selection should be for links, but got nodes.\"\n        raise SelectionError(msg)\n    if clean_nodes:\n        node_ids_to_delete = node_ids_unique_to_link_ids(\n            selection.selected_links, selection.selected_links_df, self.nodes_df\n        )\n        WranglerLogger.debug(\n            f\"Dropping nodes associated with dropped links: \\n{node_ids_to_delete}\"\n        )\n        self.nodes_df = delete_nodes_by_ids(self.nodes_df, del_node_ids=node_ids_to_delete)\n\n    if clean_shapes:\n        shape_ids_to_delete = shape_ids_unique_to_link_ids(\n            selection.selected_links, selection.selected_links_df, self.shapes_df\n        )\n        WranglerLogger.debug(\n            f\"Dropping shapes associated with dropped links: \\n{shape_ids_to_delete}\"\n        )\n        self.shapes_df = delete_shapes_by_ids(\n            self.shapes_df, del_shape_ids=shape_ids_to_delete\n        )\n\n    self.links_df = delete_links_by_ids(\n        self.links_df,\n        selection.selected_links,\n        ignore_missing=selection.ignore_missing,\n        transit_net=transit_net,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.delete_nodes","title":"network_wrangler.roadway.network.RoadwayNetwork.delete_nodes","text":"<pre><code>delete_nodes(selection_dict, remove_links=False)\n</code></pre> <p>Deletes nodes from roadway network. Wont delete nodes used by links in network.</p> <p>Parameters:</p> <ul> <li> <code>selection_dict</code>               (<code>Union[dict, SelectNodesDict]</code>)           \u2013            <p>dictionary of node selection criteria in the form of a SelectNodesDict.</p> </li> <li> <code>remove_links</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will remove any links that are associated with the nodes. If False, will only remove nodes if they are not associated with any links. Defaults to False.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>NodeDeletionError</code>             \u2013            <p>If not ignore_missing and selected nodes to delete aren\u2019t in network</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def delete_nodes(\n    self,\n    selection_dict: Union[dict, SelectNodesDict],\n    remove_links: bool = False,\n) -&gt; None:\n    \"\"\"Deletes nodes from roadway network. Wont delete nodes used by links in network.\n\n    Args:\n        selection_dict: dictionary of node selection criteria in the form of a SelectNodesDict.\n        remove_links: if True, will remove any links that are associated with the nodes.\n            If False, will only remove nodes if they are not associated with any links.\n            Defaults to False.\n\n    Raises:\n        NodeDeletionError: If not ignore_missing and selected nodes to delete aren't in network\n    \"\"\"\n    if not isinstance(selection_dict, SelectNodesDict):\n        selection_dict = SelectNodesDict(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    _selection = self.get_selection({\"nodes\": selection_dict})\n    assert isinstance(_selection, RoadwayNodeSelection)  # for mypy\n    selection: RoadwayNodeSelection = _selection\n    if remove_links:\n        del_node_ids = selection.selected_nodes\n        link_ids = self.links_with_nodes(selection.selected_nodes).model_link_id.to_list()\n        WranglerLogger.info(f\"Removing {len(link_ids)} links associated with nodes.\")\n        self.delete_links({\"model_link_id\": link_ids})\n    else:\n        unused_node_ids = node_ids_without_links(self.nodes_df, self.links_df)\n        del_node_ids = list(set(selection.selected_nodes).intersection(unused_node_ids))\n\n    self.nodes_df = delete_nodes_by_ids(\n        self.nodes_df, del_node_ids, ignore_missing=selection.ignore_missing\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_modal_graph","title":"network_wrangler.roadway.network.RoadwayNetwork.get_modal_graph","text":"<pre><code>get_modal_graph(mode)\n</code></pre> <p>Return a networkx graph of the network for a specific mode.</p> <p>Parameters:</p> <ul> <li> <code>mode</code>           \u2013            <p>mode of the network, one of <code>drive</code>,<code>transit</code>,<code>walk</code>, <code>bike</code></p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_modal_graph(self, mode) -&gt; MultiDiGraph:\n    \"\"\"Return a networkx graph of the network for a specific mode.\n\n    Args:\n        mode: mode of the network, one of `drive`,`transit`,`walk`, `bike`\n    \"\"\"\n    from .graph import net_to_graph  # noqa: PLC0415\n\n    if self._modal_graphs[mode][\"hash\"] != self.modal_graph_hash(mode):\n        self._modal_graphs[mode][\"graph\"] = net_to_graph(self, mode)\n\n    return self._modal_graphs[mode][\"graph\"]\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_property_by_timespan_and_group","title":"network_wrangler.roadway.network.RoadwayNetwork.get_property_by_timespan_and_group","text":"<pre><code>get_property_by_timespan_and_group(link_property, category=DEFAULT_CATEGORY, timespan=DEFAULT_TIMESPAN, strict_timespan_match=False, min_overlap_minutes=60)\n</code></pre> <p>Returns a new dataframe with model_link_id and link property by category and timespan.</p> <p>Convenience method for backward compatability.</p> <p>Parameters:</p> <ul> <li> <code>link_property</code>               (<code>str</code>)           \u2013            <p>link property to query</p> </li> <li> <code>category</code>               (<code>Optional[Union[str, int]]</code>, default:                   <code>DEFAULT_CATEGORY</code> )           \u2013            <p>category to query or a list of categories. Defaults to DEFAULT_CATEGORY.</p> </li> <li> <code>timespan</code>               (<code>Optional[TimespanString]</code>, default:                   <code>DEFAULT_TIMESPAN</code> )           \u2013            <p>timespan to query in the form of [\u201cHH:MM\u201d,\u201dHH:MM\u201d]. Defaults to DEFAULT_TIMESPAN.</p> </li> <li> <code>strict_timespan_match</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will only return links that match the timespan exactly. Defaults to False.</p> </li> <li> <code>min_overlap_minutes</code>               (<code>int</code>, default:                   <code>60</code> )           \u2013            <p>If strict_timespan_match is False, will return links that overlap with the timespan by at least this many minutes. Defaults to 60.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_property_by_timespan_and_group(\n    self,\n    link_property: str,\n    category: Optional[Union[str, int]] = DEFAULT_CATEGORY,\n    timespan: Optional[TimespanString] = DEFAULT_TIMESPAN,\n    strict_timespan_match: bool = False,\n    min_overlap_minutes: int = 60,\n) -&gt; Any:\n    \"\"\"Returns a new dataframe with model_link_id and link property by category and timespan.\n\n    Convenience method for backward compatability.\n\n    Args:\n        link_property: link property to query\n        category: category to query or a list of categories. Defaults to DEFAULT_CATEGORY.\n        timespan: timespan to query in the form of [\"HH:MM\",\"HH:MM\"].\n            Defaults to DEFAULT_TIMESPAN.\n        strict_timespan_match: If True, will only return links that match the timespan exactly.\n            Defaults to False.\n        min_overlap_minutes: If strict_timespan_match is False, will return links that overlap\n            with the timespan by at least this many minutes. Defaults to 60.\n    \"\"\"\n    from .links.scopes import prop_for_scope  # noqa: PLC0415\n\n    return prop_for_scope(\n        self.links_df,\n        link_property,\n        timespan=timespan,\n        category=category,\n        strict_timespan_match=strict_timespan_match,\n        min_overlap_minutes=min_overlap_minutes,\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.get_selection","title":"network_wrangler.roadway.network.RoadwayNetwork.get_selection","text":"<pre><code>get_selection(selection_dict, overwrite=False)\n</code></pre> <p>Return selection if it already exists, otherwise performs selection.</p> <p>Parameters:</p> <ul> <li> <code>selection_dict</code>               (<code>dict</code>)           \u2013            <p>SelectFacility dictionary.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will overwrite any previously cached searches. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def get_selection(\n    self,\n    selection_dict: Union[dict, SelectFacility],\n    overwrite: bool = False,\n) -&gt; Union[RoadwayNodeSelection, RoadwayLinkSelection]:\n    \"\"\"Return selection if it already exists, otherwise performs selection.\n\n    Args:\n        selection_dict (dict): SelectFacility dictionary.\n        overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n    \"\"\"\n    key = _create_selection_key(selection_dict)\n    if (key in self._selections) and not overwrite:\n        WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n        return self._selections[key]\n\n    if isinstance(selection_dict, SelectFacility):\n        selection_data = selection_dict\n    elif isinstance(selection_dict, SelectLinksDict):\n        selection_data = SelectFacility(links=selection_dict)\n    elif isinstance(selection_dict, SelectNodesDict):\n        selection_data = SelectFacility(nodes=selection_dict)\n    elif isinstance(selection_dict, dict):\n        selection_data = SelectFacility(**selection_dict)\n    else:\n        msg = \"selection_dict arg must be a dictionary or SelectFacility model.\"\n        WranglerLogger.error(\n            msg + f\" Received: {selection_dict} of type {type(selection_dict)}\"\n        )\n        raise SelectionError(msg)\n\n    WranglerLogger.debug(f\"Getting selection from key: {key}\")\n    if \"links\" in selection_data.fields:\n        return RoadwayLinkSelection(self, selection_dict)\n    if \"nodes\" in selection_data.fields:\n        return RoadwayNodeSelection(self, selection_dict)\n    msg = \"Selection data should have either 'links' or 'nodes'.\"\n    WranglerLogger.error(msg + f\" Received: {selection_dict}\")\n    raise SelectionError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.has_link","title":"network_wrangler.roadway.network.RoadwayNetwork.has_link","text":"<pre><code>has_link(ab)\n</code></pre> <p>Returns true if network has links with AB values.</p> <p>Parameters:</p> <ul> <li> <code>ab</code>               (<code>tuple</code>)           \u2013            <p>Tuple of values corresponding with A and B.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def has_link(self, ab: tuple) -&gt; bool:\n    \"\"\"Returns true if network has links with AB values.\n\n    Args:\n        ab: Tuple of values corresponding with A and B.\n    \"\"\"\n    sel_a, sel_b = ab\n    has_link = (\n        self.links_df[self.links_df[[\"A\", \"B\"]]].isin_dict({\"A\": sel_a, \"B\": sel_b}).any()\n    )\n    return has_link\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.has_node","title":"network_wrangler.roadway.network.RoadwayNetwork.has_node","text":"<pre><code>has_node(model_node_id)\n</code></pre> <p>Queries if network has node based on model_node_id.</p> <p>Parameters:</p> <ul> <li> <code>model_node_id</code>               (<code>int</code>)           \u2013            <p>model_node_id to check for.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def has_node(self, model_node_id: int) -&gt; bool:\n    \"\"\"Queries if network has node based on model_node_id.\n\n    Args:\n        model_node_id: model_node_id to check for.\n    \"\"\"\n    has_node = self.nodes_df[self.nodes_df.model_node_id].isin([model_node_id]).any()\n\n    return has_node\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.is_connected","title":"network_wrangler.roadway.network.RoadwayNetwork.is_connected","text":"<pre><code>is_connected(mode)\n</code></pre> <p>Determines if the network graph is \u201cstrongly\u201d connected.</p> <p>A graph is strongly connected if each vertex is reachable from every other vertex.</p> <p>Parameters:</p> <ul> <li> <code>mode</code>               (<code>str</code>)           \u2013            <p>mode of the network, one of <code>drive</code>,<code>transit</code>,<code>walk</code>, <code>bike</code></p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def is_connected(self, mode: str) -&gt; bool:\n    \"\"\"Determines if the network graph is \"strongly\" connected.\n\n    A graph is strongly connected if each vertex is reachable from every other vertex.\n\n    Args:\n        mode:  mode of the network, one of `drive`,`transit`,`walk`, `bike`\n    \"\"\"\n    is_connected = nx.is_strongly_connected(self.get_modal_graph(mode))\n\n    return is_connected\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.links_with_link_ids","title":"network_wrangler.roadway.network.RoadwayNetwork.links_with_link_ids","text":"<pre><code>links_with_link_ids(link_ids)\n</code></pre> <p>Return subset of links_df based on link_ids list.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def links_with_link_ids(self, link_ids: list[int]) -&gt; pd.DataFrame:\n    \"\"\"Return subset of links_df based on link_ids list.\"\"\"\n    return filter_links_to_ids(self.links_df, link_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.links_with_nodes","title":"network_wrangler.roadway.network.RoadwayNetwork.links_with_nodes","text":"<pre><code>links_with_nodes(node_ids)\n</code></pre> <p>Return subset of links_df based on node_ids list.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def links_with_nodes(self, node_ids: list[int]) -&gt; pd.DataFrame:\n    \"\"\"Return subset of links_df based on node_ids list.\"\"\"\n    return filter_links_to_node_ids(self.links_df, node_ids)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.modal_graph_hash","title":"network_wrangler.roadway.network.RoadwayNetwork.modal_graph_hash","text":"<pre><code>modal_graph_hash(mode)\n</code></pre> <p>Hash of the links in order to detect a network change from when graph created.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def modal_graph_hash(self, mode) -&gt; str:\n    \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n    _value = str.encode(self.links_df.df_hash() + \"-\" + mode)\n    _hash = hashlib.sha256(_value).hexdigest()\n\n    return _hash\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.move_nodes","title":"network_wrangler.roadway.network.RoadwayNetwork.move_nodes","text":"<pre><code>move_nodes(node_geometry_change_table)\n</code></pre> <p>Moves nodes based on updated geometry along with associated links and shape geometry.</p> <p>Parameters:</p> <ul> <li> <code>node_geometry_change_table</code>               (<code>DataFrame</code>)           \u2013            <p>a table with model_node_id, X, Y, and CRS.</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def move_nodes(\n    self,\n    node_geometry_change_table: pd.DataFrame,\n):\n    \"\"\"Moves nodes based on updated geometry along with associated links and shape geometry.\n\n    Args:\n        node_geometry_change_table: a table with model_node_id, X, Y, and CRS.\n    \"\"\"\n    node_geometry_change_table = NodeGeometryChangeTable(node_geometry_change_table)\n    node_ids = node_geometry_change_table.model_node_id.to_list()\n    WranglerLogger.debug(f\"Moving nodes: {node_ids}\")\n    self.nodes_df = edit_node_geometry(self.nodes_df, node_geometry_change_table)\n    self.links_df = edit_link_geometry_from_nodes(self.links_df, self.nodes_df, node_ids)\n    self.shapes_df = edit_shape_geometry_from_nodes(\n        self.shapes_df, self.links_df, self.nodes_df, node_ids\n    )\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.node_coords","title":"network_wrangler.roadway.network.RoadwayNetwork.node_coords","text":"<pre><code>node_coords(model_node_id)\n</code></pre> <p>Return coordinates (x, y) of a node based on model_node_id.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def node_coords(self, model_node_id: int) -&gt; tuple:\n    \"\"\"Return coordinates (x, y) of a node based on model_node_id.\"\"\"\n    try:\n        node = self.nodes_df[self.nodes_df.model_node_id == model_node_id]\n    except ValueError as err:\n        msg = f\"Node with model_node_id {model_node_id} not found.\"\n        WranglerLogger.error(msg)\n        raise NodeNotFoundError(msg) from err\n    return node.geometry.x.values[0], node.geometry.y.values[0]\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.nodes_in_links","title":"network_wrangler.roadway.network.RoadwayNetwork.nodes_in_links","text":"<pre><code>nodes_in_links()\n</code></pre> <p>Returns subset of self.nodes_df that are in self.links_df.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def nodes_in_links(self) -&gt; pd.DataFrame:\n    \"\"\"Returns subset of self.nodes_df that are in self.links_df.\"\"\"\n    return filter_nodes_to_links(self.links_df, self.nodes_df)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.RoadwayNetwork.validate_config","title":"network_wrangler.roadway.network.RoadwayNetwork.validate_config","text":"<pre><code>validate_config(v)\n</code></pre> <p>Validate config.</p> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>@field_validator(\"config\")\ndef validate_config(cls, v):\n    \"\"\"Validate config.\"\"\"\n    return load_wrangler_config(v)\n</code></pre>"},{"location":"api/#network_wrangler.roadway.network.add_incident_link_data_to_nodes","title":"network_wrangler.roadway.network.add_incident_link_data_to_nodes","text":"<pre><code>add_incident_link_data_to_nodes(links_df, nodes_df, link_variables=None)\n</code></pre> <p>Add data from links going to/from nodes to node.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame</code>)           \u2013            <p>Will assess connectivity of this links list</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame</code>)           \u2013            <p>Will assess connectivity of this nodes list</p> </li> <li> <code>link_variables</code>               (<code>Optional[list]</code>, default:                   <code>None</code> )           \u2013            <p>list of columns in links dataframe to add to incident nodes</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>nodes DataFrame with link data where length is N*number of links going in/out</p> </li> </ul> Source code in <code>network_wrangler/roadway/network.py</code> <pre><code>def add_incident_link_data_to_nodes(\n    links_df: pd.DataFrame,\n    nodes_df: pd.DataFrame,\n    link_variables: Optional[list] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Add data from links going to/from nodes to node.\n\n    Args:\n        links_df: Will assess connectivity of this links list\n        nodes_df: Will assess connectivity of this nodes list\n        link_variables: list of columns in links dataframe to add to incident nodes\n\n    Returns:\n        nodes DataFrame with link data where length is N*number of links going in/out\n    \"\"\"\n    WranglerLogger.debug(\"Adding following link data to nodes: \".format())\n    link_variables = link_variables or []\n\n    _link_vals_to_nodes = [x for x in link_variables if x in links_df.columns]\n    if link_variables not in _link_vals_to_nodes:\n        WranglerLogger.warning(\n            f\"Following columns not in links_df and wont be added to nodes: {list(set(link_variables) - set(_link_vals_to_nodes))} \"\n        )\n\n    _nodes_from_links_A = nodes_df.merge(\n        links_df[[links_df.A, *_link_vals_to_nodes]],\n        how=\"outer\",\n        left_on=nodes_df.model_node_id,\n        right_on=links_df.A,\n    )\n    _nodes_from_links_B = nodes_df.merge(\n        links_df[[links_df.B, *_link_vals_to_nodes]],\n        how=\"outer\",\n        left_on=nodes_df.model_node_id,\n        right_on=links_df.B,\n    )\n    _nodes_from_links_ab = concat_with_attr([_nodes_from_links_A, _nodes_from_links_B])\n\n    return _nodes_from_links_ab\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork","title":"network_wrangler.transit.network.TransitNetwork","text":"<p>Representation of a Transit Network.</p> <p>Typical usage example: <pre><code>import network_wrangler as wr\n\ntc = wr.load_transit(stpaul_gtfs)\n</code></pre></p> <p>Attributes:</p> <ul> <li> <code>feed</code>           \u2013            <p>gtfs feed object with interlinked tables.</p> </li> <li> <code>road_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>Associated roadway network object.</p> </li> <li> <code>graph</code>               (<code>MultiDiGraph</code>)           \u2013            <p>Graph for associated roadway network object.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>)           \u2013            <p>Configuration object for the transit network.</p> </li> <li> <code>feed_path</code>               (<code>str</code>)           \u2013            <p>Where the feed was read in from.</p> </li> <li> <code>validated_frequencies</code>               (<code>bool</code>)           \u2013            <p>The frequencies have been validated.</p> </li> <li> <code>validated_road_network_consistency</code>           \u2013            <p>The network has been validated against the road network.</p> </li> </ul> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>class TransitNetwork:\n    \"\"\"Representation of a Transit Network.\n\n    Typical usage example:\n    ``` py\n    import network_wrangler as wr\n\n    tc = wr.load_transit(stpaul_gtfs)\n    ```\n\n    Attributes:\n        feed: gtfs feed object with interlinked tables.\n        road_net (RoadwayNetwork): Associated roadway network object.\n        graph (nx.MultiDiGraph): Graph for associated roadway network object.\n        config (WranglerConfig): Configuration object for the transit network.\n        feed_path (str): Where the feed was read in from.\n        validated_frequencies (bool): The frequencies have been validated.\n        validated_road_network_consistency (): The network has been validated against\n            the road network.\n    \"\"\"\n\n    TIME_COLS: ClassVar = [\"arrival_time\", \"departure_time\", \"start_time\", \"end_time\"]\n\n    def __init__(self, feed: Feed, config: WranglerConfig = DefaultConfig) -&gt; None:\n        \"\"\"Constructor for TransitNetwork.\n\n        Args:\n            feed: Feed object representing the transit network gtfs tables\n            config: WranglerConfig object. Defaults to DefaultConfig.\n        \"\"\"\n        WranglerLogger.debug(\"Creating new TransitNetwork.\")\n\n        self._road_net: Optional[RoadwayNetwork] = None\n        self.feed: Feed = feed\n        self.graph: nx.MultiDiGraph = None\n        self.config: WranglerConfig = config\n        # initialize\n        self._consistent_with_road_net = False\n\n        # cached selections\n        self._selections: dict[str, TransitSelection] = {}\n\n    @property\n    def feed_path(self):\n        \"\"\"Pass through property from Feed.\"\"\"\n        return self.feed.feed_path\n\n    @property\n    def applied_projects(self) -&gt; list[str]:\n        \"\"\"List of projects applied to the network.\n\n        Note: This may or may not return a full accurate account of all the applied projects.\n        For better project accounting, please leverage the scenario object.\n        \"\"\"\n        return _get_applied_projects_from_tables(self.feed)\n\n    @property\n    def feed(self):\n        \"\"\"Feed associated with the transit network.\"\"\"\n        return self._feed\n\n    @feed.setter\n    def feed(self, feed: Feed):\n        if not isinstance(feed, Feed):\n            msg = f\"TransitNetwork's feed value must be a valid Feed instance. \\\n                             This is a {type(feed)}.\"\n            WranglerLogger.error(msg)\n            raise TransitValidationError(msg)\n        if self._road_net is None or transit_road_net_consistency(feed, self._road_net):\n            self._feed = feed\n            self._stored_feed_hash = copy.deepcopy(feed.hash)\n        else:\n            msg = \"Can't assign Feed inconsistent with set Roadway Network.\"\n            WranglerLogger.error(msg)\n            raise TransitRoadwayConsistencyError(msg)\n\n    @property\n    def road_net(self) -&gt; Union[None, RoadwayNetwork]:\n        \"\"\"Roadway network associated with the transit network.\"\"\"\n        return self._road_net\n\n    @road_net.setter\n    def road_net(self, road_net_in: RoadwayNetwork):\n        if road_net_in is None or road_net_in.__class__.__name__ != \"RoadwayNetwork\":\n            msg = f\"TransitNetwork's road_net: value must be a valid RoadwayNetwork instance. \\\n                             This is a {type(road_net_in)}.\"\n            WranglerLogger.error(msg)\n            raise TransitValidationError(msg)\n        if transit_road_net_consistency(self.feed, road_net_in):\n            self._road_net = road_net_in\n            self._stored_road_net_hash = copy.deepcopy(road_net_in.network_hash)\n            self._consistent_with_road_net = True\n        else:\n            msg = \"Can't assign inconsistent RoadwayNetwork - Roadway Network not \\\n                   set, but can be referenced separately.\"\n            WranglerLogger.error(msg)\n            raise TransitRoadwayConsistencyError(msg)\n\n    @property\n    def feed_hash(self):\n        \"\"\"Return the hash of the feed.\"\"\"\n        return self.feed.hash\n\n    @property\n    def consistent_with_road_net(self) -&gt; bool:\n        \"\"\"Indicate if road_net is consistent with transit network.\n\n        Will return True if road_net is None, but provide a warning.\n\n        Checks the network hash of when consistency was last evaluated. If transit network or\n        roadway network has changed, will re-evaluate consistency and return the updated value and\n        update self._stored_road_net_hash.\n\n        Returns:\n            Boolean indicating if road_net is consistent with transit network.\n        \"\"\"\n        if self.road_net is None:\n            WranglerLogger.warning(\"Roadway Network not set, cannot accurately check consistency.\")\n            return True\n        updated_road = self.road_net.network_hash != self._stored_road_net_hash\n        updated_feed = self.feed_hash != self._stored_feed_hash\n\n        if updated_road or updated_feed:\n            self._consistent_with_road_net = transit_road_net_consistency(self.feed, self.road_net)\n            self._stored_road_net_hash = copy.deepcopy(self.road_net.network_hash)\n            self._stored_feed_hash = copy.deepcopy(self.feed_hash)\n        return self._consistent_with_road_net\n\n    def __deepcopy__(self, memo):\n        \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n        COPY_REF_NOT_VALUE = [\"_road_net\"]\n        # Create a new, empty instance\n        copied_net = self.__class__.__new__(self.__class__)\n        # Return the new TransitNetwork instance\n        attribute_dict = vars(self)\n\n        # Copy the attributes to the new instance\n        for attr_name, attr_value in attribute_dict.items():\n            # WranglerLogger.debug(f\"Copying {attr_name}\")\n            if attr_name in COPY_REF_NOT_VALUE:\n                # If the attribute is in the COPY_REF_NOT_VALUE list, assign the reference\n                setattr(copied_net, attr_name, attr_value)\n            else:\n                # WranglerLogger.debug(f\"making deep copy: {attr_name}\")\n                # For other attributes, perform a deep copy\n                setattr(copied_net, attr_name, copy.deepcopy(attr_value, memo))\n\n        return copied_net\n\n    def deepcopy(self):\n        \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n        return copy.deepcopy(self)\n\n    @property\n    def stops_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stops as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return to_points_gdf(self.feed.stops, ref_nodes_df=ref_nodes)\n\n    @property\n    def shapes_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return aggregated shapes as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return shapes_to_trip_shapes_gdf(self.feed.shapes, ref_nodes_df=ref_nodes)\n\n    @property\n    def shape_links_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return shape-links as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return shapes_to_shape_links_gdf(self.feed.shapes, ref_nodes_df=ref_nodes)\n\n    @property\n    def stop_time_links_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stop-time-links as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n        return stop_times_to_stop_time_links_gdf(\n            self.feed.stop_times, self.feed.stops, ref_nodes_df=ref_nodes\n        )\n\n    @property\n    def stop_times_points_gdf(self) -&gt; gpd.GeoDataFrame:\n        \"\"\"Return stop-time-points as a GeoDataFrame using set roadway geometry.\"\"\"\n        ref_nodes = self.road_net.nodes_df if self.road_net is not None else None\n\n        return stop_times_to_stop_time_points_gdf(\n            self.feed.stop_times, self.feed.stops, ref_nodes_df=ref_nodes\n        )\n\n    def get_selection(\n        self,\n        selection_dict: dict,\n        overwrite: bool = False,\n    ) -&gt; TransitSelection:\n        \"\"\"Return selection if it already exists, otherwise performs selection.\n\n        Will raise an error if no trips found.\n\n        Args:\n            selection_dict (dict): _description_\n            overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n\n        Returns:\n            Selection: Selection object\n        \"\"\"\n        key = dict_to_hexkey(selection_dict)\n\n        if (key not in self._selections) or overwrite:\n            WranglerLogger.debug(f\"Performing selection from key: {key}\")\n            self._selections[key] = TransitSelection(self, selection_dict)\n        else:\n            WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n\n        if not self._selections[key]:\n            msg = f\"No links or nodes found for selection dict: \\n {selection_dict}\"\n            WranglerLogger.error(msg)\n            raise TransitSelectionEmptyError(msg)\n        return self._selections[key]\n\n    def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; TransitNetwork:\n        \"\"\"Wrapper method to apply a roadway project, returning a new TransitNetwork instance.\n\n        Args:\n            project_card: either a dictionary of the project card object or ProjectCard instance\n            **kwargs: keyword arguments to pass to project application\n        \"\"\"\n        if not (isinstance(project_card, (ProjectCard, SubProject))):\n            project_card = ProjectCard(project_card)\n\n        if not project_card.valid:\n            msg = f\"Project card {project_card.project} not valid.\"\n            WranglerLogger.error(msg)\n            raise ProjectCardError(msg)\n\n        if project_card._sub_projects:\n            for sp in project_card._sub_projects:\n                WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n                self._apply_change(sp, **kwargs)\n            return self\n        return self._apply_change(project_card, **kwargs)\n\n    def _apply_change(\n        self,\n        change: Union[ProjectCard, SubProject],\n        reference_road_net: Optional[RoadwayNetwork] = None,\n    ) -&gt; TransitNetwork:\n        \"\"\"Apply a single change: a single-project project or a sub-project.\"\"\"\n        if not isinstance(change, SubProject):\n            WranglerLogger.info(f\"Applying Project to Transit Network: {change.project}\")\n\n        if change.change_type == \"transit_property_change\":\n            return apply_transit_property_change(\n                self,\n                self.get_selection(change.transit_property_change[\"service\"]),\n                change.transit_property_change[\"property_changes\"],\n                project_name=change.project,\n            )\n\n        if change.change_type == \"transit_routing_change\":\n            return apply_transit_routing_change(\n                self,\n                self.get_selection(change.transit_routing_change[\"service\"]),\n                change.transit_routing_change[\"routing\"],\n                reference_road_net=reference_road_net,\n                project_name=change.project,\n            )\n\n        if change.change_type == \"pycode\":\n            return apply_calculated_transit(self, change.pycode)\n\n        if change.change_type == \"transit_route_addition\":\n            return apply_transit_route_addition(\n                self,\n                change.transit_route_addition,\n                reference_road_net=reference_road_net,\n            )\n        if change.change_type == \"transit_service_deletion\":\n            return apply_transit_service_deletion(\n                self,\n                self.get_selection(change.transit_service_deletion[\"service\"]),\n                clean_shapes=change.transit_service_deletion.get(\"clean_shapes\"),\n                clean_routes=change.transit_service_deletion.get(\"clean_routes\"),\n            )\n        msg = f\"Not a currently valid transit project: {change}.\"\n        WranglerLogger.error(msg)\n        raise NotImplementedError(msg)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.applied_projects","title":"network_wrangler.transit.network.TransitNetwork.applied_projects  <code>property</code>","text":"<pre><code>applied_projects\n</code></pre> <p>List of projects applied to the network.</p> <p>Note: This may or may not return a full accurate account of all the applied projects. For better project accounting, please leverage the scenario object.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.consistent_with_road_net","title":"network_wrangler.transit.network.TransitNetwork.consistent_with_road_net  <code>property</code>","text":"<pre><code>consistent_with_road_net\n</code></pre> <p>Indicate if road_net is consistent with transit network.</p> <p>Will return True if road_net is None, but provide a warning.</p> <p>Checks the network hash of when consistency was last evaluated. If transit network or roadway network has changed, will re-evaluate consistency and return the updated value and update self._stored_road_net_hash.</p> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>Boolean indicating if road_net is consistent with transit network.</p> </li> </ul>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed","title":"network_wrangler.transit.network.TransitNetwork.feed  <code>property</code> <code>writable</code>","text":"<pre><code>feed\n</code></pre> <p>Feed associated with the transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed_hash","title":"network_wrangler.transit.network.TransitNetwork.feed_hash  <code>property</code>","text":"<pre><code>feed_hash\n</code></pre> <p>Return the hash of the feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.feed_path","title":"network_wrangler.transit.network.TransitNetwork.feed_path  <code>property</code>","text":"<pre><code>feed_path\n</code></pre> <p>Pass through property from Feed.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.road_net","title":"network_wrangler.transit.network.TransitNetwork.road_net  <code>property</code> <code>writable</code>","text":"<pre><code>road_net\n</code></pre> <p>Roadway network associated with the transit network.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.shape_links_gdf","title":"network_wrangler.transit.network.TransitNetwork.shape_links_gdf  <code>property</code>","text":"<pre><code>shape_links_gdf\n</code></pre> <p>Return shape-links as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.shapes_gdf","title":"network_wrangler.transit.network.TransitNetwork.shapes_gdf  <code>property</code>","text":"<pre><code>shapes_gdf\n</code></pre> <p>Return aggregated shapes as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stop_time_links_gdf","title":"network_wrangler.transit.network.TransitNetwork.stop_time_links_gdf  <code>property</code>","text":"<pre><code>stop_time_links_gdf\n</code></pre> <p>Return stop-time-links as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stop_times_points_gdf","title":"network_wrangler.transit.network.TransitNetwork.stop_times_points_gdf  <code>property</code>","text":"<pre><code>stop_times_points_gdf\n</code></pre> <p>Return stop-time-points as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.stops_gdf","title":"network_wrangler.transit.network.TransitNetwork.stops_gdf  <code>property</code>","text":"<pre><code>stops_gdf\n</code></pre> <p>Return stops as a GeoDataFrame using set roadway geometry.</p>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.__deepcopy__","title":"network_wrangler.transit.network.TransitNetwork.__deepcopy__","text":"<pre><code>__deepcopy__(memo)\n</code></pre> <p>Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n    COPY_REF_NOT_VALUE = [\"_road_net\"]\n    # Create a new, empty instance\n    copied_net = self.__class__.__new__(self.__class__)\n    # Return the new TransitNetwork instance\n    attribute_dict = vars(self)\n\n    # Copy the attributes to the new instance\n    for attr_name, attr_value in attribute_dict.items():\n        # WranglerLogger.debug(f\"Copying {attr_name}\")\n        if attr_name in COPY_REF_NOT_VALUE:\n            # If the attribute is in the COPY_REF_NOT_VALUE list, assign the reference\n            setattr(copied_net, attr_name, attr_value)\n        else:\n            # WranglerLogger.debug(f\"making deep copy: {attr_name}\")\n            # For other attributes, perform a deep copy\n            setattr(copied_net, attr_name, copy.deepcopy(attr_value, memo))\n\n    return copied_net\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.__init__","title":"network_wrangler.transit.network.TransitNetwork.__init__","text":"<pre><code>__init__(feed, config=DefaultConfig)\n</code></pre> <p>Constructor for TransitNetwork.</p> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Feed</code>)           \u2013            <p>Feed object representing the transit network gtfs tables</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig object. Defaults to DefaultConfig.</p> </li> </ul> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def __init__(self, feed: Feed, config: WranglerConfig = DefaultConfig) -&gt; None:\n    \"\"\"Constructor for TransitNetwork.\n\n    Args:\n        feed: Feed object representing the transit network gtfs tables\n        config: WranglerConfig object. Defaults to DefaultConfig.\n    \"\"\"\n    WranglerLogger.debug(\"Creating new TransitNetwork.\")\n\n    self._road_net: Optional[RoadwayNetwork] = None\n    self.feed: Feed = feed\n    self.graph: nx.MultiDiGraph = None\n    self.config: WranglerConfig = config\n    # initialize\n    self._consistent_with_road_net = False\n\n    # cached selections\n    self._selections: dict[str, TransitSelection] = {}\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.apply","title":"network_wrangler.transit.network.TransitNetwork.apply","text":"<pre><code>apply(project_card, **kwargs)\n</code></pre> <p>Wrapper method to apply a roadway project, returning a new TransitNetwork instance.</p> <p>Parameters:</p> <ul> <li> <code>project_card</code>               (<code>Union[ProjectCard, dict]</code>)           \u2013            <p>either a dictionary of the project card object or ProjectCard instance</p> </li> <li> <code>**kwargs</code>           \u2013            <p>keyword arguments to pass to project application</p> </li> </ul> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def apply(self, project_card: Union[ProjectCard, dict], **kwargs) -&gt; TransitNetwork:\n    \"\"\"Wrapper method to apply a roadway project, returning a new TransitNetwork instance.\n\n    Args:\n        project_card: either a dictionary of the project card object or ProjectCard instance\n        **kwargs: keyword arguments to pass to project application\n    \"\"\"\n    if not (isinstance(project_card, (ProjectCard, SubProject))):\n        project_card = ProjectCard(project_card)\n\n    if not project_card.valid:\n        msg = f\"Project card {project_card.project} not valid.\"\n        WranglerLogger.error(msg)\n        raise ProjectCardError(msg)\n\n    if project_card._sub_projects:\n        for sp in project_card._sub_projects:\n            WranglerLogger.debug(f\"- applying subproject: {sp.change_type}\")\n            self._apply_change(sp, **kwargs)\n        return self\n    return self._apply_change(project_card, **kwargs)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.deepcopy","title":"network_wrangler.transit.network.TransitNetwork.deepcopy","text":"<pre><code>deepcopy()\n</code></pre> <p>Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.</p> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def deepcopy(self):\n    \"\"\"Returns copied TransitNetwork instance with deep copy of Feed but not roadway net.\"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"api/#network_wrangler.transit.network.TransitNetwork.get_selection","title":"network_wrangler.transit.network.TransitNetwork.get_selection","text":"<pre><code>get_selection(selection_dict, overwrite=False)\n</code></pre> <p>Return selection if it already exists, otherwise performs selection.</p> <p>Will raise an error if no trips found.</p> <p>Parameters:</p> <ul> <li> <code>selection_dict</code>               (<code>dict</code>)           \u2013            <p>description</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will overwrite any previously cached searches. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Selection</code> (              <code>TransitSelection</code> )          \u2013            <p>Selection object</p> </li> </ul> Source code in <code>network_wrangler/transit/network.py</code> <pre><code>def get_selection(\n    self,\n    selection_dict: dict,\n    overwrite: bool = False,\n) -&gt; TransitSelection:\n    \"\"\"Return selection if it already exists, otherwise performs selection.\n\n    Will raise an error if no trips found.\n\n    Args:\n        selection_dict (dict): _description_\n        overwrite: if True, will overwrite any previously cached searches. Defaults to False.\n\n    Returns:\n        Selection: Selection object\n    \"\"\"\n    key = dict_to_hexkey(selection_dict)\n\n    if (key not in self._selections) or overwrite:\n        WranglerLogger.debug(f\"Performing selection from key: {key}\")\n        self._selections[key] = TransitSelection(self, selection_dict)\n    else:\n        WranglerLogger.debug(f\"Using cached selection from key: {key}\")\n\n    if not self._selections[key]:\n        msg = f\"No links or nodes found for selection dict: \\n {selection_dict}\"\n        WranglerLogger.error(msg)\n        raise TransitSelectionEmptyError(msg)\n    return self._selections[key]\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DbForeignKeys","title":"network_wrangler.models._base.db.DbForeignKeys  <code>module-attribute</code>","text":"<pre><code>DbForeignKeys = dict[str, TableForeignKeys]\n</code></pre> <p>Mapping of tables that have fields that other tables use as fks.</p> <p><code>{ &lt;table&gt;:{&lt;field&gt;:[(&lt;table using FK&gt;,&lt;field using fk&gt;)]} }</code></p> Example <p>{\u201cstops\u201d:     {\u201cstop_id\u201d: [         (\u201cstops\u201d, \u201cparent_station\u201d),         (\u201cstop_times\u201d, \u201cstop_id\u201d)         ]} }</p>"},{"location":"api/#network_wrangler.models._base.db.TableForeignKeys","title":"network_wrangler.models._base.db.TableForeignKeys  <code>module-attribute</code>","text":"<pre><code>TableForeignKeys = dict[str, tuple[str, str]]\n</code></pre> <p>Dict of each table\u2019s foreign keys.</p> <p><code>{ &lt;table&gt;:{&lt;field&gt;:[&lt;fk_table&gt;,&lt;fk_field&gt;]} }</code></p> Example <p>{\u201cstops\u201d:     {\u201cparent_station\u201d: (\u201cstops\u201d, \u201cstop_id\u201d)} \u201cstop_times\u201d:     {\u201cstop_id\u201d: (\u201cstops\u201d, \u201cstop_id\u201d)}     {\u201ctrip_id\u201d: (\u201ctrips\u201d, \u201ctrip_id\u201d)} }</p>"},{"location":"api/#network_wrangler.models._base.db.TablePrimaryKeys","title":"network_wrangler.models._base.db.TablePrimaryKeys  <code>module-attribute</code>","text":"<pre><code>TablePrimaryKeys = list[str]\n</code></pre> <p>TableForeignKeys is a dictionary of foreign keys for a single table.</p> Uses the form <p>{:[,]} Example <p>{\u201cparent_station\u201d: (\u201cstops\u201d, \u201cstop_id\u201d)}</p>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin","title":"network_wrangler.models._base.db.DBModelMixin","text":"<p>An mixin class for interrelated pandera DataFrameModel tables.</p> <p>Contains a bunch of convenience methods and overrides the dunder methods     deepcopy and eq.</p> <p>Methods:</p> <ul> <li> <code>hash</code>             \u2013              <p>hash of tables</p> </li> <li> <code>deepcopy</code>             \u2013              <p>deepcopy of tables which references a custom deepcopy</p> </li> <li> <code>get_table</code>             \u2013              <p>retrieve table by name</p> </li> <li> <code>table_names_with_field</code>             \u2013              <p>returns tables in <code>table_names</code> with field name</p> </li> </ul> Attr <p>Where metadata variable _fk = {:[,]} <p>e.g.: <code>_fk = {\"parent_station\": [\"stops\", \"stop_id\"]}</code></p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>class DBModelMixin:\n    \"\"\"An mixin class for interrelated pandera DataFrameModel tables.\n\n    Contains a bunch of convenience methods and overrides the dunder methods\n        __deepcopy__ and __eq__.\n\n    Methods:\n        hash: hash of tables\n        deepcopy: deepcopy of tables which references a custom __deepcopy__\n        get_table: retrieve table by name\n        table_names_with_field: returns tables in `table_names` with field name\n\n    Attr:\n        table_names: list of dataframe table names that are required as part of this \"db\"\n            schema.\n        optional_table_names: list of optional table names that will be added to `table_names` iff\n            they are found.\n        hash: creates a hash of tables found in `table_names` to track if they change.\n        tables: dataframes corresponding to each table_name in `table_names`\n        tables_dict: mapping of `&lt;table_name&gt;:&lt;table&gt;` dataframe\n        _table_models: mapping of `&lt;table_name&gt;:&lt;DataFrameModel&gt;` to use for validation when\n            `__setattr__` is called.\n        _converters: mapping of `&lt;table_name&gt;:&lt;converter_method&gt;` where converter method should\n            have a function signature of `(&lt;table&gt;, self.**kwargs)` .  Called on `__setattr__` if\n            initial validation fails.\n\n    Where metadata variable _fk = {&lt;table_field&gt;:[&lt;fk table&gt;,&lt;fk field&gt;]}\n\n    e.g.: `_fk = {\"parent_station\": [\"stops\", \"stop_id\"]}`\n\n    \"\"\"\n\n    # list of optional tables which are added to table_names if they are found.\n    optional_table_names: ClassVar[list[str]] = []\n\n    # list of interrelated tables.\n    table_names: ClassVar[list[str]] = []\n\n    # mapping of which Pandera DataFrameModel to validate the table to.\n    _table_models: ClassVar[dict[str, DataFrameModel]] = {}\n\n    # mapping of &lt;table_name&gt;:&lt;conversion method&gt; to use iff df validation fails.\n    _converters: ClassVar[dict[str, Callable]] = {}\n\n    def __setattr__(self, key, value):\n        \"\"\"Override the default setattr behavior to handle DataFrame validation.\n\n        Note: this is NOT called when a dataframe is mutated in place!\n\n        Args:\n            key (str): The attribute name.\n            value: The value to be assigned to the attribute.\n\n        Raises:\n            SchemaErrors: If the DataFrame does not conform to the schema.\n            ForeignKeyError: If doesn't validate to foreign key.\n        \"\"\"\n        if isinstance(value, pd.DataFrame):\n            WranglerLogger.debug(f\"Validating + coercing value to {key}\")\n            df = self.validate_coerce_table(key, value)\n            super().__setattr__(key, df)\n        else:\n            super().__setattr__(key, value)\n\n    def validate_coerce_table(self, table_name: str, table: pd.DataFrame) -&gt; pd.DataFrame:\n        if table_name not in self._table_models:\n            return table\n        table_model = self._table_models[table_name]\n        converter = self._converters.get(table_name)\n        try:\n            validated_df = validate_df_to_model(table, table_model)\n        except SchemaErrors as e:\n            if not converter:\n                raise e\n            WranglerLogger.debug(\n                f\"Initial validation failed as {table_name}. \\\n                                Attempting to convert using: {converter}\"\n            )\n            # Note that some converters may have dependency on other attributes being set first\n            converted_df = converter(table, **self.__dict__)\n            validated_df = validate_df_to_model(converted_df, table_model)\n\n        # Do this in both directions so that ordering of tables being added doesn't matter.\n        self.check_table_fks(table_name, table=validated_df)\n        self.check_referenced_fks(table_name, table=validated_df)\n        return validated_df\n\n    def initialize_tables(self, **kwargs):\n        \"\"\"Initializes the tables for the database.\n\n        Args:\n            **kwargs: Keyword arguments representing the tables to be initialized.\n\n        Raises:\n            RequiredTableError: If any required tables are missing in the initialization.\n        \"\"\"\n        # Flag missing required tables\n        _missing_tables = [t for t in self.table_names if t not in kwargs]\n        if _missing_tables:\n            msg = f\"Missing required tables: {_missing_tables}\"\n            raise RequiredTableError(msg)\n\n        # Add provided optional tables\n        _opt_tables = [k for k in kwargs if k in self.optional_table_names]\n        self.table_names += _opt_tables\n\n        # Set tables in order\n        for table in self.table_names:\n            WranglerLogger.info(f\"Initializing {table}\")\n            self.__setattr__(table, kwargs[table])\n\n    @classmethod\n    def fks(cls) -&gt; DbForeignKeys:\n        \"\"\"Return the fk field constraints as `{ &lt;table&gt;:{&lt;field&gt;:[&lt;fk_table&gt;,&lt;fk_field&gt;]} }`.\"\"\"\n        fk_fields = {}\n        for table_name, table_model in cls._table_models.items():\n            config = table_model.Config\n            if not hasattr(config, \"_fk\"):\n                continue\n            fk_fields[table_name] = config._fk\n        return fk_fields\n\n    @classmethod\n    def fields_as_fks(cls) -&gt; DbForeignKeyUsage:\n        \"\"\"Returns mapping of tables that have fields that other tables use as fks.\n\n        `{ &lt;table&gt;:{&lt;field&gt;:[(&lt;table using FK&gt;,&lt;field using fk&gt;)]} }`\n\n        Useful for knowing if you should check FK validation when changing a field value.\n        \"\"\"\n        pks_as_fks: defaultdict = defaultdict(lambda: defaultdict(list))\n        for t, field_fk in cls.fks().items():\n            for f, fk in field_fk.items():\n                fk_table, fk_field = fk\n                pks_as_fks[fk_table][fk_field].append((t, f))\n        return {k: dict(v) for k, v in pks_as_fks.items()}\n\n    def check_referenced_fk(\n        self, pk_table_name: str, pk_field: str, pk_table: Optional[pd.DataFrame] = None\n    ) -&gt; bool:\n        \"\"\"True if table.field has the values referenced in any table referencing fields as fk.\n\n        For example. If routes.route_id is referenced in trips table, we need to check that\n        if a route_id is deleted, it isn't referenced in trips.route_id.\n        \"\"\"\n        msg = f\"Checking tables which referenced {pk_table_name}.{pk_field} as an FK\"\n        # WranglerLogger.debug(msg)\n        if pk_table is None:\n            pk_table = self.get_table(pk_table_name)\n\n        if pk_field not in pk_table:\n            WranglerLogger.warning(\n                f\"Foreign key value {pk_field} not in {pk_table_name} - \\\n                 skipping fk validation\"\n            )\n            return True\n\n        fields_as_fks: DbForeignKeyUsage = self.fields_as_fks()\n\n        if pk_table_name not in fields_as_fks:\n            return True\n        if pk_field not in fields_as_fks[pk_table_name]:\n            return True\n\n        all_valid = True\n\n        for ref_table_name, ref_field in fields_as_fks[pk_table_name][pk_field]:\n            if ref_table_name not in self.table_names:\n                WranglerLogger.debug(\n                    f\"Referencing table {ref_table_name} not in self.table_names - \\\n                    skipping fk validation.\"\n                )\n                continue\n\n            try:\n                ref_table = self.get_table(ref_table_name)\n            except RequiredTableError:\n                WranglerLogger.debug(\n                    f\"Referencing table {ref_table_name} not yet set in \\\n                     {type(self)} - skipping fk validation.\"\n                )\n                continue\n\n            if ref_field not in ref_table:\n                WranglerLogger.debug(\n                    f\"Referencing field {ref_field} not in {ref_table_name} - \\\n                    skipping fk validation.\"\n                )\n                continue\n\n            valid, _missing = fk_in_pk(pk_table[pk_field], ref_table[ref_field])\n            all_valid = all_valid and valid\n            if _missing:\n                WranglerLogger.error(\n                    f\"Following values missing from {pk_table_name}.{pk_field} that \\\n                      are referenced by {ref_table}: \\n{_missing}\"\n                )\n        return all_valid\n\n    def check_referenced_fks(self, table_name: str, table: Optional[pd.DataFrame] = None) -&gt; bool:\n        \"\"\"True if this table has the values referenced in any table referencing fields as fk.\n\n        For example. If routes.route_id is referenced in trips table, we need to check that\n        if a route_id is deleted, it isn't referenced in trips.route_id.\n        \"\"\"\n        # WranglerLogger.debug(f\"Checking referenced foreign keys for {table_name}\")\n        all_valid = True\n        if table is None:\n            table = self.get_table(table_name)\n        all_valid = True\n        for field in self.fields_as_fks().get(table_name, {}):\n            valid = self.check_referenced_fk(table_name, field, pk_table=table)\n            all_valid = valid and all_valid\n        return all_valid\n\n    def check_table_fks(\n        self, table_name: str, table: Optional[pd.DataFrame] = None, raise_error: bool = True\n    ) -&gt; bool:\n        \"\"\"Return True if the foreign key fields in table have valid references.\n\n        Note: will return true and give a warning if the specified foreign key table doesn't exist.\n        \"\"\"\n        # WranglerLogger.debug(f\"Checking foreign keys for {table_name}\")\n        fks = self.fks()\n        if table_name not in fks:\n            return True\n        if table is None:\n            table = self.get_table(table_name)\n        all_valid = True\n        for field, fk in fks[table_name].items():\n            # WranglerLogger.debug(f\"Checking {table_name}.{field} foreign key\")\n            pkref_table_name, pkref_field = fk\n            # WranglerLogger.debug(f\"Looking for PK in {pkref_table_name}.{pkref_field}.\")\n            if field not in table:\n                WranglerLogger.warning(\n                    f\"Foreign key value {field} not in {table_name} -\\\n                    skipping validation\"\n                )\n                continue\n\n            if pkref_table_name not in self.table_names:\n                WranglerLogger.debug(\n                    f\"PK table {pkref_table_name} for specified FK \\\n                    {table_name}.{field} not in table list - skipping validation.\"\n                )\n                continue\n            try:\n                pkref_table = self.get_table(pkref_table_name)\n            except RequiredTableError:\n                WranglerLogger.debug(\n                    f\"PK table {pkref_table_name} for specified FK \\\n                    {table_name}.{field} not in {type(self)}-  \\\n                    skipping validation.\"\n                )\n                continue\n            if pkref_field not in pkref_table:\n                WranglerLogger.error(\n                    f\"!!! {pkref_table_name} missing {pkref_field} field used as FK\\\n                                    ref in {table_name}.{field}.\"\n                )\n                all_valid = False\n                continue\n            if len(pkref_table) &lt; SMALL_RECS:\n                pass\n                # WranglerLogger.debug(f\"PK values:\\n{pkref_table[pkref_field]}.\")\n            # WranglerLogger.debug(f\"Checking {table_name}.{field} foreign key\")\n            valid, missing = fk_in_pk(pkref_table[pkref_field], table[field])\n            if missing:\n                WranglerLogger.error(\n                    f\"!!! {pkref_table_name}.{pkref_field} missing values used as FK\\\n                      in {table_name}.{field}: \\n_missing\"\n                )\n            all_valid = valid and all_valid\n\n        if not all_valid:\n            if raise_error:\n                msg = f\"FK fields/ values referenced in {table_name} missing.\"\n                raise ForeignKeyValueError(msg)\n            return False\n        return True\n\n    def check_fks(self) -&gt; bool:\n        \"\"\"Check all FKs in set of tables.\"\"\"\n        all_valid = True\n        for table_name in self.table_names:\n            valid = self.check_table_fks(\n                table_name, self.tables_dict[table_name], raise_error=False\n            )\n            all_valid = valid and all_valid\n        return all_valid\n\n    @property\n    def tables(self) -&gt; list[DataFrameModel]:\n        return [self.__dict__[t] for t in self.table_names]\n\n    @property\n    def tables_dict(self) -&gt; dict[str, DataFrameModel]:\n        num_records = [len(self.get_table(t)) for t in self.table_names]\n        return pd.DataFrame({\"Table\": self.table_names, \"Records\": num_records})\n\n    @property\n    def describe_df(self) -&gt; pd.DataFrame:\n        return pd.DataFrame({t: len(self.get_table(t)) for t in self.table_names})\n\n    def get_table(self, table_name: str) -&gt; pd.DataFrame:\n        \"\"\"Get table by name.\"\"\"\n        if table_name not in self.table_names:\n            msg = f\"{table_name} table not in db.\"\n            raise ValueError(msg)\n        if table_name not in self.__dict__:\n            msg = f\"Required table not set yet: {table_name}\"\n            raise RequiredTableError(msg)\n        return self.__dict__[table_name]\n\n    def table_names_with_field(self, field: str) -&gt; list[str]:\n        \"\"\"Returns tables in the class instance which contain the field.\"\"\"\n        return [t for t in self.table_names if field in self.get_table(t).columns]\n\n    @property\n    def hash(self) -&gt; str:\n        \"\"\"A hash representing the contents of the tables in self.table_names.\"\"\"\n        _table_hashes = [self.get_table(t).df_hash() for t in self.table_names]\n        _value = str.encode(\"-\".join(_table_hashes))\n\n        _hash = hashlib.sha256(_value).hexdigest()\n        return _hash\n\n    def __eq__(self, other):\n        \"\"\"Override the default Equals behavior.\"\"\"\n        if isinstance(other, self.__class__):\n            return self.hash == other.hash\n        return False\n\n    def __deepcopy__(self, memo):\n        \"\"\"Custom implementation of __deepcopy__ method.\n\n        This method is called by copy.deepcopy() to create a deep copy of the object.\n\n        Args:\n            memo (dict): Dictionary to track objects already copied during deepcopy.\n\n        Returns:\n            Feed: A deep copy of the db object.\n        \"\"\"\n        # Create a new, empty instance of the Feed class\n        new_instance = self.__class__.__new__(self.__class__)\n\n        # Copy all attributes to the new instance\n        for attr_name, attr_value in self.__dict__.items():\n            # Handle pandera DataFrameModel objects specially\n            if (\n                hasattr(attr_value, \"__class__\")\n                and hasattr(attr_value.__class__, \"__name__\")\n                and \"DataFrameModel\" in attr_value.__class__.__name__\n            ):\n                # For pandera DataFrameModel objects, copy the underlying DataFrame and recreate the model\n                # This avoids the timestamp corruption issue with copy.deepcopy()\n                try:\n                    # Get the underlying DataFrame\n                    if hasattr(attr_value, \"_obj\"):\n                        df_copy = attr_value._obj.copy(deep=True)\n                    elif hasattr(attr_value, \"data\"):\n                        df_copy = attr_value.data.copy(deep=True)\n                    else:\n                        # For newer pandera versions, try direct access\n                        df_copy = attr_value.copy(deep=True)\n\n                    # Recreate the DataFrameModel object with the copied DataFrame\n                    new_table = attr_value.__class__(df_copy)\n\n                    setattr(new_instance, attr_name, new_table)\n                except Exception as e:\n                    # Fallback to regular deep copy if the above fails\n                    setattr(new_instance, attr_name, copy.deepcopy(attr_value, memo))\n            elif isinstance(attr_value, pd.DataFrame):\n                # For plain pandas DataFrames, use deep copy\n                setattr(new_instance, attr_name, attr_value.copy(deep=True))\n            else:\n                # For all other objects, use regular deep copy\n                setattr(new_instance, attr_name, copy.deepcopy(attr_value, memo))\n\n        return new_instance\n\n    def deepcopy(self):\n        \"\"\"Convenience method to exceute deep copy of instance.\"\"\"\n        return copy.deepcopy(self)\n\n    def __hash__(self):\n        \"\"\"Hash based on the hashes of the tables in table_names.\"\"\"\n        return hash(tuple((name, self.get_table(name).to_csv()) for name in self.table_names))\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.hash","title":"network_wrangler.models._base.db.DBModelMixin.hash  <code>property</code>","text":"<pre><code>hash\n</code></pre> <p>A hash representing the contents of the tables in self.table_names.</p>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.__deepcopy__","title":"network_wrangler.models._base.db.DBModelMixin.__deepcopy__","text":"<pre><code>__deepcopy__(memo)\n</code></pre> <p>Custom implementation of deepcopy method.</p> <p>This method is called by copy.deepcopy() to create a deep copy of the object.</p> <p>Parameters:</p> <ul> <li> <code>memo</code>               (<code>dict</code>)           \u2013            <p>Dictionary to track objects already copied during deepcopy.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Feed</code>          \u2013            <p>A deep copy of the db object.</p> </li> </ul> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Custom implementation of __deepcopy__ method.\n\n    This method is called by copy.deepcopy() to create a deep copy of the object.\n\n    Args:\n        memo (dict): Dictionary to track objects already copied during deepcopy.\n\n    Returns:\n        Feed: A deep copy of the db object.\n    \"\"\"\n    # Create a new, empty instance of the Feed class\n    new_instance = self.__class__.__new__(self.__class__)\n\n    # Copy all attributes to the new instance\n    for attr_name, attr_value in self.__dict__.items():\n        # Handle pandera DataFrameModel objects specially\n        if (\n            hasattr(attr_value, \"__class__\")\n            and hasattr(attr_value.__class__, \"__name__\")\n            and \"DataFrameModel\" in attr_value.__class__.__name__\n        ):\n            # For pandera DataFrameModel objects, copy the underlying DataFrame and recreate the model\n            # This avoids the timestamp corruption issue with copy.deepcopy()\n            try:\n                # Get the underlying DataFrame\n                if hasattr(attr_value, \"_obj\"):\n                    df_copy = attr_value._obj.copy(deep=True)\n                elif hasattr(attr_value, \"data\"):\n                    df_copy = attr_value.data.copy(deep=True)\n                else:\n                    # For newer pandera versions, try direct access\n                    df_copy = attr_value.copy(deep=True)\n\n                # Recreate the DataFrameModel object with the copied DataFrame\n                new_table = attr_value.__class__(df_copy)\n\n                setattr(new_instance, attr_name, new_table)\n            except Exception as e:\n                # Fallback to regular deep copy if the above fails\n                setattr(new_instance, attr_name, copy.deepcopy(attr_value, memo))\n        elif isinstance(attr_value, pd.DataFrame):\n            # For plain pandas DataFrames, use deep copy\n            setattr(new_instance, attr_name, attr_value.copy(deep=True))\n        else:\n            # For all other objects, use regular deep copy\n            setattr(new_instance, attr_name, copy.deepcopy(attr_value, memo))\n\n    return new_instance\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.__eq__","title":"network_wrangler.models._base.db.DBModelMixin.__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Override the default Equals behavior.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"Override the default Equals behavior.\"\"\"\n    if isinstance(other, self.__class__):\n        return self.hash == other.hash\n    return False\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.__hash__","title":"network_wrangler.models._base.db.DBModelMixin.__hash__","text":"<pre><code>__hash__()\n</code></pre> <p>Hash based on the hashes of the tables in table_names.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def __hash__(self):\n    \"\"\"Hash based on the hashes of the tables in table_names.\"\"\"\n    return hash(tuple((name, self.get_table(name).to_csv()) for name in self.table_names))\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.__setattr__","title":"network_wrangler.models._base.db.DBModelMixin.__setattr__","text":"<pre><code>__setattr__(key, value)\n</code></pre> <p>Override the default setattr behavior to handle DataFrame validation.</p> <p>Note: this is NOT called when a dataframe is mutated in place!</p> <p>Parameters:</p> <ul> <li> <code>key</code>               (<code>str</code>)           \u2013            <p>The attribute name.</p> </li> <li> <code>value</code>           \u2013            <p>The value to be assigned to the attribute.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>SchemaErrors</code>             \u2013            <p>If the DataFrame does not conform to the schema.</p> </li> <li> <code>ForeignKeyError</code>             \u2013            <p>If doesn\u2019t validate to foreign key.</p> </li> </ul> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def __setattr__(self, key, value):\n    \"\"\"Override the default setattr behavior to handle DataFrame validation.\n\n    Note: this is NOT called when a dataframe is mutated in place!\n\n    Args:\n        key (str): The attribute name.\n        value: The value to be assigned to the attribute.\n\n    Raises:\n        SchemaErrors: If the DataFrame does not conform to the schema.\n        ForeignKeyError: If doesn't validate to foreign key.\n    \"\"\"\n    if isinstance(value, pd.DataFrame):\n        WranglerLogger.debug(f\"Validating + coercing value to {key}\")\n        df = self.validate_coerce_table(key, value)\n        super().__setattr__(key, df)\n    else:\n        super().__setattr__(key, value)\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.check_fks","title":"network_wrangler.models._base.db.DBModelMixin.check_fks","text":"<pre><code>check_fks()\n</code></pre> <p>Check all FKs in set of tables.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def check_fks(self) -&gt; bool:\n    \"\"\"Check all FKs in set of tables.\"\"\"\n    all_valid = True\n    for table_name in self.table_names:\n        valid = self.check_table_fks(\n            table_name, self.tables_dict[table_name], raise_error=False\n        )\n        all_valid = valid and all_valid\n    return all_valid\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.check_referenced_fk","title":"network_wrangler.models._base.db.DBModelMixin.check_referenced_fk","text":"<pre><code>check_referenced_fk(pk_table_name, pk_field, pk_table=None)\n</code></pre> <p>True if table.field has the values referenced in any table referencing fields as fk.</p> <p>For example. If routes.route_id is referenced in trips table, we need to check that if a route_id is deleted, it isn\u2019t referenced in trips.route_id.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def check_referenced_fk(\n    self, pk_table_name: str, pk_field: str, pk_table: Optional[pd.DataFrame] = None\n) -&gt; bool:\n    \"\"\"True if table.field has the values referenced in any table referencing fields as fk.\n\n    For example. If routes.route_id is referenced in trips table, we need to check that\n    if a route_id is deleted, it isn't referenced in trips.route_id.\n    \"\"\"\n    msg = f\"Checking tables which referenced {pk_table_name}.{pk_field} as an FK\"\n    # WranglerLogger.debug(msg)\n    if pk_table is None:\n        pk_table = self.get_table(pk_table_name)\n\n    if pk_field not in pk_table:\n        WranglerLogger.warning(\n            f\"Foreign key value {pk_field} not in {pk_table_name} - \\\n             skipping fk validation\"\n        )\n        return True\n\n    fields_as_fks: DbForeignKeyUsage = self.fields_as_fks()\n\n    if pk_table_name not in fields_as_fks:\n        return True\n    if pk_field not in fields_as_fks[pk_table_name]:\n        return True\n\n    all_valid = True\n\n    for ref_table_name, ref_field in fields_as_fks[pk_table_name][pk_field]:\n        if ref_table_name not in self.table_names:\n            WranglerLogger.debug(\n                f\"Referencing table {ref_table_name} not in self.table_names - \\\n                skipping fk validation.\"\n            )\n            continue\n\n        try:\n            ref_table = self.get_table(ref_table_name)\n        except RequiredTableError:\n            WranglerLogger.debug(\n                f\"Referencing table {ref_table_name} not yet set in \\\n                 {type(self)} - skipping fk validation.\"\n            )\n            continue\n\n        if ref_field not in ref_table:\n            WranglerLogger.debug(\n                f\"Referencing field {ref_field} not in {ref_table_name} - \\\n                skipping fk validation.\"\n            )\n            continue\n\n        valid, _missing = fk_in_pk(pk_table[pk_field], ref_table[ref_field])\n        all_valid = all_valid and valid\n        if _missing:\n            WranglerLogger.error(\n                f\"Following values missing from {pk_table_name}.{pk_field} that \\\n                  are referenced by {ref_table}: \\n{_missing}\"\n            )\n    return all_valid\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.check_referenced_fks","title":"network_wrangler.models._base.db.DBModelMixin.check_referenced_fks","text":"<pre><code>check_referenced_fks(table_name, table=None)\n</code></pre> <p>True if this table has the values referenced in any table referencing fields as fk.</p> <p>For example. If routes.route_id is referenced in trips table, we need to check that if a route_id is deleted, it isn\u2019t referenced in trips.route_id.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def check_referenced_fks(self, table_name: str, table: Optional[pd.DataFrame] = None) -&gt; bool:\n    \"\"\"True if this table has the values referenced in any table referencing fields as fk.\n\n    For example. If routes.route_id is referenced in trips table, we need to check that\n    if a route_id is deleted, it isn't referenced in trips.route_id.\n    \"\"\"\n    # WranglerLogger.debug(f\"Checking referenced foreign keys for {table_name}\")\n    all_valid = True\n    if table is None:\n        table = self.get_table(table_name)\n    all_valid = True\n    for field in self.fields_as_fks().get(table_name, {}):\n        valid = self.check_referenced_fk(table_name, field, pk_table=table)\n        all_valid = valid and all_valid\n    return all_valid\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.check_table_fks","title":"network_wrangler.models._base.db.DBModelMixin.check_table_fks","text":"<pre><code>check_table_fks(table_name, table=None, raise_error=True)\n</code></pre> <p>Return True if the foreign key fields in table have valid references.</p> <p>Note: will return true and give a warning if the specified foreign key table doesn\u2019t exist.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def check_table_fks(\n    self, table_name: str, table: Optional[pd.DataFrame] = None, raise_error: bool = True\n) -&gt; bool:\n    \"\"\"Return True if the foreign key fields in table have valid references.\n\n    Note: will return true and give a warning if the specified foreign key table doesn't exist.\n    \"\"\"\n    # WranglerLogger.debug(f\"Checking foreign keys for {table_name}\")\n    fks = self.fks()\n    if table_name not in fks:\n        return True\n    if table is None:\n        table = self.get_table(table_name)\n    all_valid = True\n    for field, fk in fks[table_name].items():\n        # WranglerLogger.debug(f\"Checking {table_name}.{field} foreign key\")\n        pkref_table_name, pkref_field = fk\n        # WranglerLogger.debug(f\"Looking for PK in {pkref_table_name}.{pkref_field}.\")\n        if field not in table:\n            WranglerLogger.warning(\n                f\"Foreign key value {field} not in {table_name} -\\\n                skipping validation\"\n            )\n            continue\n\n        if pkref_table_name not in self.table_names:\n            WranglerLogger.debug(\n                f\"PK table {pkref_table_name} for specified FK \\\n                {table_name}.{field} not in table list - skipping validation.\"\n            )\n            continue\n        try:\n            pkref_table = self.get_table(pkref_table_name)\n        except RequiredTableError:\n            WranglerLogger.debug(\n                f\"PK table {pkref_table_name} for specified FK \\\n                {table_name}.{field} not in {type(self)}-  \\\n                skipping validation.\"\n            )\n            continue\n        if pkref_field not in pkref_table:\n            WranglerLogger.error(\n                f\"!!! {pkref_table_name} missing {pkref_field} field used as FK\\\n                                ref in {table_name}.{field}.\"\n            )\n            all_valid = False\n            continue\n        if len(pkref_table) &lt; SMALL_RECS:\n            pass\n            # WranglerLogger.debug(f\"PK values:\\n{pkref_table[pkref_field]}.\")\n        # WranglerLogger.debug(f\"Checking {table_name}.{field} foreign key\")\n        valid, missing = fk_in_pk(pkref_table[pkref_field], table[field])\n        if missing:\n            WranglerLogger.error(\n                f\"!!! {pkref_table_name}.{pkref_field} missing values used as FK\\\n                  in {table_name}.{field}: \\n_missing\"\n            )\n        all_valid = valid and all_valid\n\n    if not all_valid:\n        if raise_error:\n            msg = f\"FK fields/ values referenced in {table_name} missing.\"\n            raise ForeignKeyValueError(msg)\n        return False\n    return True\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.deepcopy","title":"network_wrangler.models._base.db.DBModelMixin.deepcopy","text":"<pre><code>deepcopy()\n</code></pre> <p>Convenience method to exceute deep copy of instance.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def deepcopy(self):\n    \"\"\"Convenience method to exceute deep copy of instance.\"\"\"\n    return copy.deepcopy(self)\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.fields_as_fks","title":"network_wrangler.models._base.db.DBModelMixin.fields_as_fks  <code>classmethod</code>","text":"<pre><code>fields_as_fks()\n</code></pre> <p>Returns mapping of tables that have fields that other tables use as fks.</p> <p><code>{ &lt;table&gt;:{&lt;field&gt;:[(&lt;table using FK&gt;,&lt;field using fk&gt;)]} }</code></p> <p>Useful for knowing if you should check FK validation when changing a field value.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>@classmethod\ndef fields_as_fks(cls) -&gt; DbForeignKeyUsage:\n    \"\"\"Returns mapping of tables that have fields that other tables use as fks.\n\n    `{ &lt;table&gt;:{&lt;field&gt;:[(&lt;table using FK&gt;,&lt;field using fk&gt;)]} }`\n\n    Useful for knowing if you should check FK validation when changing a field value.\n    \"\"\"\n    pks_as_fks: defaultdict = defaultdict(lambda: defaultdict(list))\n    for t, field_fk in cls.fks().items():\n        for f, fk in field_fk.items():\n            fk_table, fk_field = fk\n            pks_as_fks[fk_table][fk_field].append((t, f))\n    return {k: dict(v) for k, v in pks_as_fks.items()}\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.fks","title":"network_wrangler.models._base.db.DBModelMixin.fks  <code>classmethod</code>","text":"<pre><code>fks()\n</code></pre> <p>Return the fk field constraints as <code>{ &lt;table&gt;:{&lt;field&gt;:[&lt;fk_table&gt;,&lt;fk_field&gt;]} }</code>.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>@classmethod\ndef fks(cls) -&gt; DbForeignKeys:\n    \"\"\"Return the fk field constraints as `{ &lt;table&gt;:{&lt;field&gt;:[&lt;fk_table&gt;,&lt;fk_field&gt;]} }`.\"\"\"\n    fk_fields = {}\n    for table_name, table_model in cls._table_models.items():\n        config = table_model.Config\n        if not hasattr(config, \"_fk\"):\n            continue\n        fk_fields[table_name] = config._fk\n    return fk_fields\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.get_table","title":"network_wrangler.models._base.db.DBModelMixin.get_table","text":"<pre><code>get_table(table_name)\n</code></pre> <p>Get table by name.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def get_table(self, table_name: str) -&gt; pd.DataFrame:\n    \"\"\"Get table by name.\"\"\"\n    if table_name not in self.table_names:\n        msg = f\"{table_name} table not in db.\"\n        raise ValueError(msg)\n    if table_name not in self.__dict__:\n        msg = f\"Required table not set yet: {table_name}\"\n        raise RequiredTableError(msg)\n    return self.__dict__[table_name]\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.initialize_tables","title":"network_wrangler.models._base.db.DBModelMixin.initialize_tables","text":"<pre><code>initialize_tables(**kwargs)\n</code></pre> <p>Initializes the tables for the database.</p> <p>Parameters:</p> <ul> <li> <code>**kwargs</code>           \u2013            <p>Keyword arguments representing the tables to be initialized.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>RequiredTableError</code>             \u2013            <p>If any required tables are missing in the initialization.</p> </li> </ul> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def initialize_tables(self, **kwargs):\n    \"\"\"Initializes the tables for the database.\n\n    Args:\n        **kwargs: Keyword arguments representing the tables to be initialized.\n\n    Raises:\n        RequiredTableError: If any required tables are missing in the initialization.\n    \"\"\"\n    # Flag missing required tables\n    _missing_tables = [t for t in self.table_names if t not in kwargs]\n    if _missing_tables:\n        msg = f\"Missing required tables: {_missing_tables}\"\n        raise RequiredTableError(msg)\n\n    # Add provided optional tables\n    _opt_tables = [k for k in kwargs if k in self.optional_table_names]\n    self.table_names += _opt_tables\n\n    # Set tables in order\n    for table in self.table_names:\n        WranglerLogger.info(f\"Initializing {table}\")\n        self.__setattr__(table, kwargs[table])\n</code></pre>"},{"location":"api/#network_wrangler.models._base.db.DBModelMixin.table_names_with_field","title":"network_wrangler.models._base.db.DBModelMixin.table_names_with_field","text":"<pre><code>table_names_with_field(field)\n</code></pre> <p>Returns tables in the class instance which contain the field.</p> Source code in <code>network_wrangler/models/_base/db.py</code> <pre><code>def table_names_with_field(self, field: str) -&gt; list[str]:\n    \"\"\"Returns tables in the class instance which contain the field.\"\"\"\n    return [t for t in self.table_names if field in self.get_table(t).columns]\n</code></pre>"},{"location":"api/#configuration","title":"Configuration","text":"<p>Classes and utilities for configuring Network Wrangler behavior:</p> <p>Configuration for parameters for Network Wrangler.</p> <p>Users can change a handful of parameters which control the way Wrangler runs.  These parameters can be saved as a wrangler config file which can be read in repeatedly to make sure the same parameters are used each time.</p> Usage <p>At runtime, you can specify configurable parameters at the scenario level which will then also be assigned and accessible to the roadway and transit networks.</p> <pre><code>create_scenario(...config = myconfig)\n</code></pre> <p>Or if you are not using Scenario functionality, you can specify the config when you read in a RoadwayNetwork.</p> <pre><code>load_roadway_from_dir(**roadway, config=myconfig)\nload_transit(**transit, config=myconfig)\n</code></pre> <p><code>my_config</code> can be a:</p> <ul> <li>Path to a config file in yaml/toml/json (recommended),</li> <li>List of paths to config files (in case you want to split up various sub-configurations)</li> <li>Dictionary which is in the same structure of a config file, or</li> <li>A <code>WranglerConfig()</code>  instance.</li> </ul> <p>If not provided, Wrangler will use reasonable defaults.</p> <p>Default Wrangler Configuration Values</p> <p>If not explicitly provided, the following default values are used:</p> <pre><code>IDS:\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: (950000, 999999)\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: (950000, 999999)\n    ML_NODE_ID_SCALAR: 15000\nEDITS:\n    EXISTING_VALUE_CONFLIC: warn\n    OVERWRITE_SCOPED: conflicting\nMODEL_ROADWAY:\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\nCPU:\n    EST_PD_READ_SPEED:\n        csv: 0.03\n        parquet: 0.005\n        geojson: 0.03\n        json: 0.15\n        txt: 0.04\n</code></pre> Extended usage <p>Load the default configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n</code></pre> <p>Access the configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS\n&gt;&gt; -10\n</code></pre> <p>Modify the default configuration in-line:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS = 20\n</code></pre> <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_wrangler_config\n\nconfig = load_wrangler_config(\"path/to/config.yaml\")\n</code></pre> <p>Set a configuration value:</p> <pre><code>config.MODEL_ROADWAY.ML_OFFSET_METERS = 10\n</code></pre> <p>Scenario configuration for Network Wrangler.</p> <p>You can build a scenario and write out the output from a scenario configuration file using the code below.  This is very useful when you are running a specific scenario with minor variations over again because you can enter your config file into version control.  In addition to the completed roadway and transit files, the output will provide a record of how the scenario was run.</p> Usage <pre><code>    from scenario import build_scenario_from_config\n    my_scenario = build_scenario_from_config(my_scenario_config)\n</code></pre> <p>Where <code>my_scenario_config</code> can be a:</p> <ul> <li>Path to a scenario config file in yaml/toml/json (recommended),</li> <li>Dictionary which is in the same structure of a scenario config file, or</li> <li>A <code>ScenarioConfig()</code>  instance.</li> </ul> <p>Notes on relative paths in scenario configs</p> <ul> <li>Relative paths are recognized by a preceeding \u201c.\u201d.</li> <li>Relative paths within <code>output_scenario</code> for <code>roadway</code>, <code>transit</code>, and <code>project_cards</code> are interpreted to be relative to <code>output_scenario.path</code>.</li> <li>All other relative paths are interpreted to be relative to directory of the scenario config file. (Or if scenario config is provided as a dictionary, relative paths will be interpreted as relative to the current working directory.)</li> </ul> Example Scenario Config<pre><code>name: \"my_scenario\"\nbase_scenario:\n    roadway:\n        dir: \"path/to/roadway_network\"\n        file_format: \"geojson\"\n        read_in_shapes: True\n    transit:\n        dir: \"path/to/transit_network\"\n        file_format: \"txt\"\n    applied_projects:\n        - \"project1\"\n        - \"project2\"\n    conflicts:\n        \"project3\": [\"project1\", \"project2\"]\n        \"project4\": [\"project1\"]\nprojects:\n    project_card_filepath:\n        - \"path/to/projectA.yaml\"\n        - \"path/to/projectB.yaml\"\n    filter_tags:\n        - \"tag1\"\noutput_scenario:\n    overwrite: True\n    roadway:\n        out_dir: \"path/to/output/roadway\"\n        prefix: \"my_scenario\"\n        file_format: \"geojson\"\n        true_shape: False\n    transit:\n        out_dir: \"path/to/output/transit\"\n        prefix: \"my_scenario\"\n        file_format: \"txt\"\n    project_cards:\n        out_dir: \"path/to/output/project_cards\"\n\nwrangler_config: \"path/to/wrangler_config.yaml\"\n</code></pre> Extended Usage <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_scenario_config\n\nmy_scenario_config = load_scenario_config(\"path/to/config.yaml\")\n</code></pre> <p>Access the configuration:</p> <pre><code>my_scenario_config.base_transit_network.path\n&gt;&gt; path/to/transit_network\n</code></pre> <p>Configuration utilities.</p>"},{"location":"api/#network_wrangler.configs.wrangler.CpuConfig","title":"network_wrangler.configs.wrangler.CpuConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>CPU Configuration -  Will not change any outcomes.</p> <p>Attributes:</p> <ul> <li> <code>EST_PD_READ_SPEED</code>               (<code>dict[str, float]</code>)           \u2013            <p>Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER</p> </li> </ul> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass CpuConfig(ConfigItem):\n    \"\"\"CPU Configuration -  Will not change any outcomes.\n\n    Attributes:\n        EST_PD_READ_SPEED: Read sec / MB - WILL DEPEND ON SPECIFIC COMPUTER\n    \"\"\"\n\n    EST_PD_READ_SPEED: dict[str, float] = Field(\n        default_factory=lambda: {\n            \"csv\": 0.03,\n            \"parquet\": 0.005,\n            \"geojson\": 0.03,\n            \"json\": 0.15,\n            \"txt\": 0.04,\n        }\n    )\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.EditsConfig","title":"network_wrangler.configs.wrangler.EditsConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for Edits.</p> <p>Attributes:</p> <ul> <li> <code>EXISTING_VALUE_CONFLICT</code>               (<code>Literal['warn', 'error', 'skip']</code>)           \u2013            <p>Only used if \u2018existing\u2019 provided in project card and <code>existing</code> doesn\u2019t match the existing network value. One of <code>error</code>, <code>warn</code>, or <code>skip</code>. <code>error</code> will raise an error, <code>warn</code> will warn the user, and <code>skip</code> will skip the change for that specific property (note it will still apply any remaining property changes). Defaults to <code>warn</code>. Can be overridden by setting <code>existing_value_conflict</code> in a <code>roadway_property_change</code> project card.</p> </li> <li> <code>OVERWRITE_SCOPED</code>               (<code>Literal['conflicting', 'all', 'error']</code>)           \u2013            <p>How to handle conflicts with existing values. Should be one of \u201cconflicting\u201d, \u201call\u201d, or False. \u201cconflicting\u201d will only overwrite values where the scope only partially overlaps with the existing value. \u201call\u201d will overwrite all the scoped values. \u201cerror\u201d will error if there is any overlap. Default is \u201cconflicting\u201d. Can be changed at the project-level by setting <code>overwrite_scoped</code> in a <code>roadway_property_change</code> project card.</p> </li> </ul> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass EditsConfig(ConfigItem):\n    \"\"\"Configuration for Edits.\n\n    Attributes:\n        EXISTING_VALUE_CONFLICT: Only used if 'existing' provided in project card and\n            `existing` doesn't match the existing network value. One of `error`, `warn`, or `skip`.\n            `error` will raise an error, `warn` will warn the user, and `skip` will skip the change\n            for that specific property (note it will still apply any remaining property changes).\n            Defaults to `warn`. Can be overridden by setting `existing_value_conflict` in\n            a `roadway_property_change` project card.\n\n        OVERWRITE_SCOPED: How to handle conflicts with existing values.\n            Should be one of \"conflicting\", \"all\", or False.\n            \"conflicting\" will only overwrite values where the scope only partially overlaps with\n            the existing value. \"all\" will overwrite all the scoped values. \"error\" will error if\n            there is any overlap. Default is \"conflicting\". Can be changed at the project-level\n            by setting `overwrite_scoped` in a `roadway_property_change` project card.\n    \"\"\"\n\n    EXISTING_VALUE_CONFLICT: Literal[\"warn\", \"error\", \"skip\"] = \"warn\"\n    OVERWRITE_SCOPED: Literal[\"conflicting\", \"all\", \"error\"] = \"conflicting\"\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.IdGenerationConfig","title":"network_wrangler.configs.wrangler.IdGenerationConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> <ul> <li> <code>TRANSIT_SHAPE_ID_METHOD</code>               (<code>Literal['scalar']</code>)           \u2013            <p>method for creating a shape_id for a transit shape. Should be \u201cscalar\u201d.</p> </li> <li> <code>TRANSIT_SHAPE_ID_SCALAR</code>               (<code>int</code>)           \u2013            <p>scalar value to add to general purpose lane to create a shape_id for a transit shape.</p> </li> <li> <code>ROAD_SHAPE_ID_METHOD</code>               (<code>Literal['scalar']</code>)           \u2013            <p>method for creating a shape_id for a roadway shape. Should be \u201cscalar\u201d.</p> </li> <li> <code>ROAD_SHAPE_ID_SCALAR</code>               (<code>int</code>)           \u2013            <p>scalar value to add to general purpose lane to create a shape_id for a roadway shape.</p> </li> <li> <code>ML_LINK_ID_METHOD</code>               (<code>Literal['range', 'scalar']</code>)           \u2013            <p>method for creating a model_link_id for an associated link for a parallel managed lane.</p> </li> <li> <code>ML_LINK_ID_RANGE</code>               (<code>tuple[int, int]</code>)           \u2013            <p>range of model_link_ids to use when creating an associated link for a parallel managed lane.</p> </li> <li> <code>ML_LINK_ID_SCALAR</code>               (<code>int</code>)           \u2013            <p>scalar value to add to general purpose lane to create a model_link_id when creating an associated link for a parallel managed lane.</p> </li> <li> <code>ML_NODE_ID_METHOD</code>               (<code>Literal['range', 'scalar']</code>)           \u2013            <p>method for creating a model_node_id for an associated node for a parallel managed lane.</p> </li> <li> <code>ML_NODE_ID_RANGE</code>               (<code>tuple[int, int]</code>)           \u2013            <p>range of model_node_ids to use when creating an associated node for a parallel managed lane.</p> </li> <li> <code>ML_NODE_ID_SCALAR</code>               (<code>int</code>)           \u2013            <p>scalar value to add to general purpose lane node ides create a model_node_id when creating an associated nodes for parallel managed lane.</p> </li> </ul> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass IdGenerationConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        TRANSIT_SHAPE_ID_METHOD: method for creating a shape_id for a transit shape.\n            Should be \"scalar\".\n        TRANSIT_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a transit shape.\n        ROAD_SHAPE_ID_METHOD: method for creating a shape_id for a roadway shape.\n            Should be \"scalar\".\n        ROAD_SHAPE_ID_SCALAR: scalar value to add to general purpose lane to create a\n            shape_id for a roadway shape.\n        ML_LINK_ID_METHOD: method for creating a model_link_id for an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_RANGE: range of model_link_ids to use when creating an associated\n            link for a parallel managed lane.\n        ML_LINK_ID_SCALAR: scalar value to add to general purpose lane to create a\n            model_link_id when creating an associated link for a parallel managed lane.\n        ML_NODE_ID_METHOD: method for creating a model_node_id for an associated node\n            for a parallel managed lane.\n        ML_NODE_ID_RANGE: range of model_node_ids to use when creating an associated\n            node for a parallel managed lane.\n        ML_NODE_ID_SCALAR: scalar value to add to general purpose lane node ides create\n            a model_node_id when creating an associated nodes for parallel managed lane.\n    \"\"\"\n\n    TRANSIT_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    TRANSIT_SHAPE_ID_SCALAR: int = 1000000\n    ROAD_SHAPE_ID_METHOD: Literal[\"scalar\"] = \"scalar\"\n    ROAD_SHAPE_ID_SCALAR: int = 1000\n    ML_LINK_ID_METHOD: Literal[\"range\", \"scalar\"] = \"scalar\"\n    ML_LINK_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_LINK_ID_SCALAR: int = 3000000\n    ML_NODE_ID_METHOD: Literal[\"range\", \"scalar\"] = \"range\"\n    ML_NODE_ID_RANGE: tuple[int, int] = (950000, 999999)\n    ML_NODE_ID_SCALAR: int = 15000\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.ModelRoadwayConfig","title":"network_wrangler.configs.wrangler.ModelRoadwayConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Model Roadway Configuration.</p> <p>Attributes:</p> <ul> <li> <code>ML_OFFSET_METERS</code>               (<code>int</code>)           \u2013            <p>Offset in meters for managed lanes.</p> </li> <li> <code>ADDITIONAL_COPY_FROM_GP_TO_ML</code>               (<code>list[str]</code>)           \u2013            <p>Additional fields to copy from general purpose to managed lanes.</p> </li> <li> <code>ADDITIONAL_COPY_TO_ACCESS_EGRESS</code>               (<code>list[str]</code>)           \u2013            <p>Additional fields to copy to access and egress links.</p> </li> </ul> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass ModelRoadwayConfig(ConfigItem):\n    \"\"\"Model Roadway Configuration.\n\n    Attributes:\n        ML_OFFSET_METERS: Offset in meters for managed lanes.\n        ADDITIONAL_COPY_FROM_GP_TO_ML: Additional fields to copy from general purpose to managed\n            lanes.\n        ADDITIONAL_COPY_TO_ACCESS_EGRESS: Additional fields to copy to access and egress links.\n    \"\"\"\n\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: list[str] = Field(default_factory=list)\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: list[str] = Field(default_factory=list)\n</code></pre>"},{"location":"api/#network_wrangler.configs.wrangler.WranglerConfig","title":"network_wrangler.configs.wrangler.WranglerConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for Network Wrangler.</p> <p>Attributes:</p> <ul> <li> <code>IDS</code>               (<code>IdGenerationConfig</code>)           \u2013            <p>Parameteters governing how new ids are generated.</p> </li> <li> <code>MODEL_ROADWAY</code>               (<code>ModelRoadwayConfig</code>)           \u2013            <p>Parameters governing how the model roadway is created.</p> </li> <li> <code>CPU</code>               (<code>CpuConfig</code>)           \u2013            <p>Parameters for accessing CPU information. Will not change any outcomes.</p> </li> <li> <code>EDITS</code>               (<code>EditsConfig</code>)           \u2013            <p>Parameters governing how edits are handled.</p> </li> </ul> Source code in <code>network_wrangler/configs/wrangler.py</code> <pre><code>@dataclass\nclass WranglerConfig(ConfigItem):\n    \"\"\"Configuration for Network Wrangler.\n\n    Attributes:\n        IDS: Parameteters governing how new ids are generated.\n        MODEL_ROADWAY: Parameters governing how the model roadway is created.\n        CPU: Parameters for accessing CPU information. Will not change any outcomes.\n        EDITS: Parameters governing how edits are handled.\n    \"\"\"\n\n    IDS: IdGenerationConfig = IdGenerationConfig()\n    MODEL_ROADWAY: ModelRoadwayConfig = ModelRoadwayConfig()\n    CPU: CpuConfig = CpuConfig()\n    EDITS: EditsConfig = EditsConfig()\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ProjectCardOutputConfig","title":"network_wrangler.configs.scenario.ProjectCardOutputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for outputing project cards in a scenario.</p> <p>Attributes:</p> <ul> <li> <code>out_dir</code>           \u2013            <p>Path to write the project card files to if you don\u2019t want to use the default.</p> </li> <li> <code>write</code>           \u2013            <p>If True, will write the project cards. Defaults to True.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ProjectCardOutputConfig(ConfigItem):\n    \"\"\"Configuration for outputing project cards in a scenario.\n\n    Attributes:\n        out_dir: Path to write the project card files to if you don't want to use the default.\n        write: If True, will write the project cards. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        out_dir: Path = DEFAULT_PROJECT_OUT_DIR,\n        write: bool = DEFAULT_PROJECT_WRITE,\n    ):\n        \"\"\"Constructor for ProjectCardOutputConfig.\"\"\"\n        if out_dir is not None and not Path(out_dir).is_absolute():\n            self.out_dir = (base_path / Path(out_dir)).resolve()\n        else:\n            self.out_dir = Path(out_dir)\n        self.write = write\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ProjectsConfig","title":"network_wrangler.configs.scenario.ProjectsConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for projects in a scenario.</p> <p>Attributes:</p> <ul> <li> <code>project_card_filepath</code>           \u2013            <p>where the project card is.  A single path, list of paths, a directory, or a glob pattern. Defaults to None.</p> </li> <li> <code>filter_tags</code>           \u2013            <p>List of tags to filter the project cards by.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ProjectsConfig(ConfigItem):\n    \"\"\"Configuration for projects in a scenario.\n\n    Attributes:\n        project_card_filepath: where the project card is.  A single path, list of paths,\n            a directory, or a glob pattern. Defaults to None.\n        filter_tags: List of tags to filter the project cards by.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        project_card_filepath: ProjectCardFilepaths = DEFAULT_PROJECT_IN_PATHS,\n        filter_tags: list[str] = DEFAULT_PROJECT_TAGS,\n    ):\n        \"\"\"Constructor for ProjectsConfig.\"\"\"\n        self.project_card_filepath = _resolve_rel_paths(project_card_filepath, base_path=base_path)\n        self.filter_tags = filter_tags\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.RoadwayNetworkInputConfig","title":"network_wrangler.configs.scenario.RoadwayNetworkInputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the road network in a scenario.</p> <p>Attributes:</p> <ul> <li> <code>dir</code>           \u2013            <p>Path to directory with roadway network files.</p> </li> <li> <code>file_format</code>           \u2013            <p>File format for the roadway network files. Should be one of RoadwayFileTypes. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>read_in_shapes</code>           \u2013            <p>If True, will read in the shapes of the roadway network. Defaults to False.</p> </li> <li> <code>boundary_geocode</code>           \u2013            <p>Geocode of the boundary. Will use this to filter the roadway network.</p> </li> <li> <code>boundary_file</code>           \u2013            <p>Path to the boundary file. If provided and both boundary_gdf and boundary_geocode are not provided, will use this to filter the roadway network.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class RoadwayNetworkInputConfig(ConfigItem):\n    \"\"\"Configuration for the road network in a scenario.\n\n    Attributes:\n        dir: Path to directory with roadway network files.\n        file_format: File format for the roadway network files. Should be one of RoadwayFileTypes.\n            Defaults to \"geojson\".\n        read_in_shapes: If True, will read in the shapes of the roadway network. Defaults to False.\n        boundary_geocode: Geocode of the boundary. Will use this to filter the roadway network.\n        boundary_file: Path to the boundary file. If provided and both boundary_gdf and\n            boundary_geocode are not provided, will use this to filter the roadway network.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        dir: Path = DEFAULT_ROADWAY_IN_DIR,\n        file_format: RoadwayFileTypes = DEFAULT_ROADWAY_IN_FORMAT,\n        read_in_shapes: bool = DEFAULT_ROADWAY_SHAPE_READ,\n        boundary_geocode: Optional[str] = None,\n        boundary_file: Optional[Path] = None,\n    ):\n        \"\"\"Constructor for RoadwayNetworkInputConfig.\"\"\"\n        if dir is not None and not Path(dir).is_absolute():\n            self.dir = (base_path / Path(dir)).resolve()\n        else:\n            self.dir = Path(dir)\n        self.file_format = file_format\n        self.read_in_shapes = read_in_shapes\n        self.boundary_geocode = boundary_geocode\n        self.boundary_file = boundary_file\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.RoadwayNetworkOutputConfig","title":"network_wrangler.configs.scenario.RoadwayNetworkOutputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for writing out the resulting roadway network for a scenario.</p> <p>Attributes:</p> <ul> <li> <code>out_dir</code>           \u2013            <p>Path to write the roadway network files to if you don\u2019t want to use the default.</p> </li> <li> <code>prefix</code>           \u2013            <p>Prefix to add to the file name. If not provided will use the scenario name.</p> </li> <li> <code>file_format</code>           \u2013            <p>File format to write the roadway network to. Should be one of RoadwayFileTypes. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>true_shape</code>           \u2013            <p>If True, will write the true shape of the roadway network. Defaults to False.</p> </li> <li> <code>write</code>           \u2013            <p>If True, will write the roadway network. Defaults to True.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class RoadwayNetworkOutputConfig(ConfigItem):\n    \"\"\"Configuration for writing out the resulting roadway network for a scenario.\n\n    Attributes:\n        out_dir: Path to write the roadway network files to if you don't want to use the default.\n        prefix: Prefix to add to the file name. If not provided will use the scenario name.\n        file_format: File format to write the roadway network to. Should be one of\n            RoadwayFileTypes. Defaults to \"geojson\".\n        true_shape: If True, will write the true shape of the roadway network. Defaults to False.\n        write: If True, will write the roadway network. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        out_dir: Path = DEFAULT_ROADWAY_OUT_DIR,\n        base_path: Path = DEFAULT_BASE_DIR,\n        convert_complex_link_properties_to_single_field: bool = False,\n        prefix: Optional[str] = None,\n        file_format: RoadwayFileTypes = DEFAULT_ROADWAY_OUT_FORMAT,\n        true_shape: bool = False,\n        write: bool = DEFAULT_ROADWAY_WRITE,\n    ):\n        \"\"\"Constructor for RoadwayNetworkOutputConfig.\"\"\"\n        if out_dir is not None and not Path(out_dir).is_absolute():\n            self.out_dir = (base_path / Path(out_dir)).resolve()\n        else:\n            self.out_dir = Path(out_dir)\n\n        self.convert_complex_link_properties_to_single_field = (\n            convert_complex_link_properties_to_single_field\n        )\n        self.prefix = prefix\n        self.file_format = file_format\n        self.true_shape = true_shape\n        self.write = write\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioConfig","title":"network_wrangler.configs.scenario.ScenarioConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Scenario configuration for Network Wrangler.</p> <p>Attributes:</p> <ul> <li> <code>base_path</code>           \u2013            <p>base path of the scenario. Defaults to cwd.</p> </li> <li> <code>name</code>           \u2013            <p>Name of the scenario.</p> </li> <li> <code>base_scenario</code>           \u2013            <p>information about the base scenario</p> </li> <li> <code>projects</code>           \u2013            <p>information about the projects to apply on top of the base scenario</p> </li> <li> <code>output_scenario</code>           \u2013            <p>information about how to output the scenario</p> </li> <li> <code>wrangler_config</code>           \u2013            <p>wrangler configuration to use</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ScenarioConfig(ConfigItem):\n    \"\"\"Scenario configuration for Network Wrangler.\n\n    Attributes:\n        base_path: base path of the scenario. Defaults to cwd.\n        name: Name of the scenario.\n        base_scenario: information about the base scenario\n        projects: information about the projects to apply on top of the base scenario\n        output_scenario: information about how to output the scenario\n        wrangler_config: wrangler configuration to use\n    \"\"\"\n\n    def __init__(\n        self,\n        base_scenario: dict,\n        projects: dict,\n        output_scenario: dict,\n        base_path: Path = DEFAULT_BASE_DIR,\n        name: str = DEFAULT_SCENARIO_NAME,\n        wrangler_config=DefaultConfig,\n    ):\n        \"\"\"Constructor for ScenarioConfig.\"\"\"\n        self.base_path = Path(base_path) if base_path is not None else Path.cwd()\n        self.name = name\n        self.base_scenario = ScenarioInputConfig(**base_scenario, base_path=base_path)\n        self.projects = ProjectsConfig(**projects, base_path=base_path)\n        self.output_scenario = ScenarioOutputConfig(**output_scenario, base_path=base_path)\n        self.wrangler_config = wrangler_config\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioInputConfig","title":"network_wrangler.configs.scenario.ScenarioInputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the writing the output of a scenario.</p> <p>Attributes:</p> <ul> <li> <code>roadway</code>               (<code>Optional[RoadwayNetworkInputConfig]</code>)           \u2013            <p>Configuration for writing out the roadway network.</p> </li> <li> <code>transit</code>               (<code>Optional[TransitNetworkInputConfig]</code>)           \u2013            <p>Configuration for writing out the transit network.</p> </li> <li> <code>applied_projects</code>           \u2013            <p>List of projects to apply to the base scenario.</p> </li> <li> <code>conflicts</code>           \u2013            <p>Dict of projects that conflict with the applied_projects.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ScenarioInputConfig(ConfigItem):\n    \"\"\"Configuration for the writing the output of a scenario.\n\n    Attributes:\n        roadway: Configuration for writing out the roadway network.\n        transit: Configuration for writing out the transit network.\n        applied_projects: List of projects to apply to the base scenario.\n        conflicts: Dict of projects that conflict with the applied_projects.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        roadway: Optional[dict] = None,\n        transit: Optional[dict] = None,\n        applied_projects: Optional[list[str]] = None,\n        conflicts: Optional[dict] = None,\n    ):\n        \"\"\"Constructor for ScenarioInputConfig.\"\"\"\n        if roadway is not None:\n            self.roadway: Optional[RoadwayNetworkInputConfig] = RoadwayNetworkInputConfig(\n                **roadway, base_path=base_path\n            )\n        else:\n            self.roadway = None\n\n        if transit is not None:\n            self.transit: Optional[TransitNetworkInputConfig] = TransitNetworkInputConfig(\n                **transit, base_path=base_path\n            )\n        else:\n            self.transit = None\n\n        self.applied_projects = applied_projects if applied_projects is not None else []\n        self.conflicts = conflicts if conflicts is not None else {}\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.ScenarioOutputConfig","title":"network_wrangler.configs.scenario.ScenarioOutputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the writing the output of a scenario.</p> <p>Attributes:</p> <ul> <li> <code>roadway</code>           \u2013            <p>Configuration for writing out the roadway network.</p> </li> <li> <code>transit</code>           \u2013            <p>Configuration for writing out the transit network.</p> </li> <li> <code>project_cards</code>               (<code>Optional[ProjectCardOutputConfig]</code>)           \u2013            <p>Configuration for writing out the project cards.</p> </li> <li> <code>overwrite</code>           \u2013            <p>If True, will overwrite the files if they already exist. Defaults to True</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class ScenarioOutputConfig(ConfigItem):\n    \"\"\"Configuration for the writing the output of a scenario.\n\n    Attributes:\n        roadway: Configuration for writing out the roadway network.\n        transit: Configuration for writing out the transit network.\n        project_cards: Configuration for writing out the project cards.\n        overwrite: If True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Path = DEFAULT_OUTPUT_DIR,\n        base_path: Path = DEFAULT_BASE_DIR,\n        roadway: Optional[dict] = None,\n        transit: Optional[dict] = None,\n        project_cards: Optional[dict] = None,\n        overwrite: bool = True,\n    ):\n        \"\"\"Constructor for ScenarioOutputConfig.\"\"\"\n        if not Path(path).is_absolute():\n            self.path = (base_path / Path(path)).resolve()\n        else:\n            self.path = Path(path)\n\n        roadway = roadway if roadway else RoadwayNetworkOutputConfig().to_dict()\n        transit = transit if transit else TransitNetworkOutputConfig().to_dict()\n        self.roadway = RoadwayNetworkOutputConfig(**roadway, base_path=self.path)\n        self.transit = TransitNetworkOutputConfig(**transit, base_path=self.path)\n\n        if project_cards is not None:\n            self.project_cards: Optional[ProjectCardOutputConfig] = ProjectCardOutputConfig(\n                **project_cards, base_path=self.path\n            )\n        else:\n            self.project_cards = None\n\n        self.overwrite = overwrite\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.TransitNetworkInputConfig","title":"network_wrangler.configs.scenario.TransitNetworkInputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the transit network in a scenario.</p> <p>Attributes:</p> <ul> <li> <code>dir</code>           \u2013            <p>Path to the transit network files. Defaults to \u201c.\u201d.</p> </li> <li> <code>file_format</code>           \u2013            <p>File format for the transit network files. Should be one of TransitFileTypes. Defaults to \u201ctxt\u201d.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class TransitNetworkInputConfig(ConfigItem):\n    \"\"\"Configuration for the transit network in a scenario.\n\n    Attributes:\n        dir: Path to the transit network files. Defaults to \".\".\n        file_format: File format for the transit network files. Should be one of TransitFileTypes.\n            Defaults to \"txt\".\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        dir: Path = DEFAULT_TRANSIT_IN_DIR,\n        file_format: TransitFileTypes = DEFAULT_TRANSIT_IN_FORMAT,\n    ):\n        \"\"\"Constructor for TransitNetworkInputConfig.\"\"\"\n        if dir is not None and not Path(dir).is_absolute():\n            self.feed = (base_path / Path(dir)).resolve()\n        else:\n            self.feed = Path(dir)\n        self.file_format = file_format\n</code></pre>"},{"location":"api/#network_wrangler.configs.scenario.TransitNetworkOutputConfig","title":"network_wrangler.configs.scenario.TransitNetworkOutputConfig","text":"<p>               Bases: <code>ConfigItem</code></p> <p>Configuration for the transit network in a scenario.</p> <p>Attributes:</p> <ul> <li> <code>out_dir</code>           \u2013            <p>Path to write the transit network files to if you don\u2019t want to use the default.</p> </li> <li> <code>prefix</code>           \u2013            <p>Prefix to add to the file name. If not provided will use the scenario name.</p> </li> <li> <code>file_format</code>           \u2013            <p>File format to write the transit network to. Should be one of TransitFileTypes. Defaults to \u201ctxt\u201d.</p> </li> <li> <code>write</code>           \u2013            <p>If True, will write the transit network. Defaults to True.</p> </li> </ul> Source code in <code>network_wrangler/configs/scenario.py</code> <pre><code>class TransitNetworkOutputConfig(ConfigItem):\n    \"\"\"Configuration for the transit network in a scenario.\n\n    Attributes:\n        out_dir: Path to write the transit network files to if you don't want to use the default.\n        prefix: Prefix to add to the file name. If not provided will use the scenario name.\n        file_format: File format to write the transit network to. Should be one of\n            TransitFileTypes. Defaults to \"txt\".\n        write: If True, will write the transit network. Defaults to True.\n    \"\"\"\n\n    def __init__(\n        self,\n        base_path: Path = DEFAULT_BASE_DIR,\n        out_dir: Path = DEFAULT_TRANSIT_OUT_DIR,\n        prefix: Optional[str] = None,\n        file_format: TransitFileTypes = DEFAULT_TRANSIT_OUT_FORMAT,\n        write: bool = DEFAULT_TRANSIT_WRITE,\n    ):\n        \"\"\"Constructor for TransitNetworkOutputCOnfig.\"\"\"\n        if out_dir is not None and not Path(out_dir).is_absolute():\n            self.out_dir = (base_path / Path(out_dir)).resolve()\n        else:\n            self.out_dir = Path(out_dir)\n        self.write = write\n        self.prefix = prefix\n        self.file_format = file_format\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem","title":"network_wrangler.configs.utils.ConfigItem","text":"<p>Base class to add partial dict-like interface to  configuration.</p> <p>Allow use of .items() [\u201cX\u201d] and .get(\u201cX\u201d) .to_dict() from configuration.</p> <p>Not to be constructed directly. To be used a mixin for dataclasses representing config schema. Do not use \u201cget\u201d \u201cto_dict\u201d, or \u201citems\u201d for key names.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>class ConfigItem:\n    \"\"\"Base class to add partial dict-like interface to  configuration.\n\n    Allow use of .items() [\"X\"] and .get(\"X\") .to_dict() from configuration.\n\n    Not to be constructed directly. To be used a mixin for dataclasses\n    representing config schema.\n    Do not use \"get\" \"to_dict\", or \"items\" for key names.\n    \"\"\"\n\n    base_path: Optional[Path] = None\n\n    def __getitem__(self, key):\n        \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n        return getattr(self, key)\n\n    def items(self):\n        \"\"\"A set-like object providing a view on D's items.\"\"\"\n        return self.__dict__.items()\n\n    def to_dict(self):\n        \"\"\"Convert the configuration to a dictionary.\"\"\"\n        result = {}\n        for key, value in self.__dict__.items():\n            if isinstance(value, ConfigItem):\n                result[key] = value.to_dict()\n            else:\n                result[key] = value\n        return result\n\n    def get(self, key, default=None):\n        \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n        return self.__dict__.get(key, default)\n\n    def update(self, data: Union[Path, list[Path], dict]):\n        \"\"\"Update the configuration with a dictionary of new values.\"\"\"\n        if not isinstance(data, dict):\n            WranglerLogger.info(f\"Updating configuration with {data}.\")\n            data = load_merge_dict(data)\n\n        self.__dict__.update(data)\n        return self\n\n    def resolve_paths(self, base_path):\n        \"\"\"Resolve relative paths in the configuration.\"\"\"\n        base_path = Path(base_path)\n        for key, value in self.__dict__.items():\n            if isinstance(value, ConfigItem):\n                value.resolve_paths(base_path)\n            elif isinstance(value, str) and value.startswith(\".\"):\n                resolved_path = (base_path / value).resolve()\n                setattr(self, key, str(resolved_path))\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.__getitem__","title":"network_wrangler.configs.utils.ConfigItem.__getitem__","text":"<pre><code>__getitem__(key)\n</code></pre> <p>Return the value for key if key is in the dictionary, else default.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n    return getattr(self, key)\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.get","title":"network_wrangler.configs.utils.ConfigItem.get","text":"<pre><code>get(key, default=None)\n</code></pre> <p>Return the value for key if key is in the dictionary, else default.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def get(self, key, default=None):\n    \"\"\"Return the value for key if key is in the dictionary, else default.\"\"\"\n    return self.__dict__.get(key, default)\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.items","title":"network_wrangler.configs.utils.ConfigItem.items","text":"<pre><code>items()\n</code></pre> <p>A set-like object providing a view on D\u2019s items.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def items(self):\n    \"\"\"A set-like object providing a view on D's items.\"\"\"\n    return self.__dict__.items()\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.resolve_paths","title":"network_wrangler.configs.utils.ConfigItem.resolve_paths","text":"<pre><code>resolve_paths(base_path)\n</code></pre> <p>Resolve relative paths in the configuration.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def resolve_paths(self, base_path):\n    \"\"\"Resolve relative paths in the configuration.\"\"\"\n    base_path = Path(base_path)\n    for key, value in self.__dict__.items():\n        if isinstance(value, ConfigItem):\n            value.resolve_paths(base_path)\n        elif isinstance(value, str) and value.startswith(\".\"):\n            resolved_path = (base_path / value).resolve()\n            setattr(self, key, str(resolved_path))\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.to_dict","title":"network_wrangler.configs.utils.ConfigItem.to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Convert the configuration to a dictionary.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def to_dict(self):\n    \"\"\"Convert the configuration to a dictionary.\"\"\"\n    result = {}\n    for key, value in self.__dict__.items():\n        if isinstance(value, ConfigItem):\n            result[key] = value.to_dict()\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.ConfigItem.update","title":"network_wrangler.configs.utils.ConfigItem.update","text":"<pre><code>update(data)\n</code></pre> <p>Update the configuration with a dictionary of new values.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def update(self, data: Union[Path, list[Path], dict]):\n    \"\"\"Update the configuration with a dictionary of new values.\"\"\"\n    if not isinstance(data, dict):\n        WranglerLogger.info(f\"Updating configuration with {data}.\")\n        data = load_merge_dict(data)\n\n    self.__dict__.update(data)\n    return self\n</code></pre>"},{"location":"api/#network_wrangler.configs.utils.find_configs_in_dir","title":"network_wrangler.configs.utils.find_configs_in_dir","text":"<pre><code>find_configs_in_dir(dir, config_type)\n</code></pre> <p>Find configuration files in the directory that match <code>*config&lt;ext&gt;</code>.</p> Source code in <code>network_wrangler/configs/utils.py</code> <pre><code>def find_configs_in_dir(dir: Union[Path, list[Path]], config_type) -&gt; list[Path]:\n    \"\"\"Find configuration files in the directory that match `*config&lt;ext&gt;`.\"\"\"\n    config_files: list[Path] = []\n    if isinstance(dir, list):\n        for d in dir:\n            config_files.extend(find_configs_in_dir(d, config_type))\n    elif dir.is_dir():\n        dir = Path(dir)\n        for ext in SUPPORTED_CONFIG_EXTENSIONS:\n            config_like_files = list(dir.glob(f\"*config{ext}\"))\n            config_files.extend(find_configs_in_dir(config_like_files, config_type))\n    elif dir.is_file():\n        try:\n            config_type(load_dict(dir))\n        except ValidationError:\n            return config_files\n        config_files.append(dir)\n\n    if config_files:\n        return [Path(config_file) for config_file in config_files]\n    return []\n</code></pre>"},{"location":"api_projects/","title":"Projects","text":"<p>Projects are how you manipulate the networks. Each project type is defined in a module in the <code>projects</code> folder and accepts a RoadwayNetwork and or TransitNetwork as an input and returns the same objects (manipulated) as an output.</p>"},{"location":"api_projects/#project-models","title":"Project Models","text":"<p>Data models for roadway changes.</p> <p>Data models for selecting roadway facilities in a project card.</p> <p>Data Models for selecting transit trips, nodes, links, and routes.</p>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem","title":"network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem","text":"<p>               Bases: <code>BaseModel</code></p> <p>Value for setting property value for a single time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class GroupedScopedPropertySetItem(BaseModel):\n    \"\"\"Value for setting property value for a single time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    category: Optional[Union[str, int]] = None\n    timespan: Optional[TimespanString] = None\n    categories: Optional[list[Any]] = []\n    timespans: Optional[list[TimespanString]] = []\n    set: Optional[Any] = None\n    overwrite_conflicts: Optional[bool] = False\n    existing: Optional[Any] = None\n    change: Optional[Union[int, float]] = None\n    _examples = [\n        {\"category\": \"hov3\", \"timespan\": [\"6:00\", \"9:00\"], \"set\": 2.0},\n        {\"category\": \"hov2\", \"set\": 2.0},\n        {\"timespan\": [\"12:00\", \"2:00\"], \"change\": -1},\n    ]\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_set_or_change(cls, data: dict):\n        \"\"\"Validate that each item has a set or change value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        if \"set\" in data and \"change\" in data:\n            WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n            data[\"change\"] = None\n        return data\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_categories_or_timespans(cls, data: Any) -&gt; Any:\n        \"\"\"Validate that each item has a category or timespan value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        require_any_of = [\"category\", \"timespan\", \"categories\", \"timespans\"]\n        if not any(attr in data for attr in require_any_of):\n            msg = f\"Require at least one of {require_any_of}\"\n            raise ValidationError(msg)\n        return data\n\n    @field_validator(\"timespan\")\n    @classmethod\n    def validate_timespan(cls, v):\n        \"\"\"Validate the timespan field.\"\"\"\n        if v is not None:\n            return validate_timespan_string(v)\n        return v\n\n    @field_validator(\"timespans\", mode=\"before\")\n    @classmethod\n    def validate_timespans(cls, v):\n        \"\"\"Validate the timespans field.\"\"\"\n        if v is not None:\n            return [validate_timespan_string(ts) for ts in v]\n        return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.check_categories_or_timespans","title":"network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.check_categories_or_timespans  <code>classmethod</code>","text":"<pre><code>check_categories_or_timespans(data)\n</code></pre> <p>Validate that each item has a category or timespan value.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_categories_or_timespans(cls, data: Any) -&gt; Any:\n    \"\"\"Validate that each item has a category or timespan value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    require_any_of = [\"category\", \"timespan\", \"categories\", \"timespans\"]\n    if not any(attr in data for attr in require_any_of):\n        msg = f\"Require at least one of {require_any_of}\"\n        raise ValidationError(msg)\n    return data\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.check_set_or_change","title":"network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.check_set_or_change  <code>classmethod</code>","text":"<pre><code>check_set_or_change(data)\n</code></pre> <p>Validate that each item has a set or change value.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_set_or_change(cls, data: dict):\n    \"\"\"Validate that each item has a set or change value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    if \"set\" in data and \"change\" in data:\n        WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n        data[\"change\"] = None\n    return data\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.validate_timespan","title":"network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.validate_timespan  <code>classmethod</code>","text":"<pre><code>validate_timespan(v)\n</code></pre> <p>Validate the timespan field.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@field_validator(\"timespan\")\n@classmethod\ndef validate_timespan(cls, v):\n    \"\"\"Validate the timespan field.\"\"\"\n    if v is not None:\n        return validate_timespan_string(v)\n    return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.validate_timespans","title":"network_wrangler.models.projects.roadway_changes.GroupedScopedPropertySetItem.validate_timespans  <code>classmethod</code>","text":"<pre><code>validate_timespans(v)\n</code></pre> <p>Validate the timespans field.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@field_validator(\"timespans\", mode=\"before\")\n@classmethod\ndef validate_timespans(cls, v):\n    \"\"\"Validate the timespans field.\"\"\"\n    if v is not None:\n        return [validate_timespan_string(ts) for ts in v]\n    return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem","title":"network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem","text":"<p>               Bases: <code>BaseModel</code></p> <p>Value for setting property value for a single time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class IndivScopedPropertySetItem(BaseModel):\n    \"\"\"Value for setting property value for a single time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    category: Optional[Union[str, int]] = DEFAULT_CATEGORY\n    timespan: Optional[TimespanString] = DEFAULT_TIMESPAN\n    set: Optional[Any] = None\n    existing: Optional[Any] = None\n    overwrite_conflicts: Optional[bool] = False\n    change: Optional[Union[int, float]] = None\n    _examples = [\n        {\"category\": \"hov3\", \"timespan\": [\"6:00\", \"9:00\"], \"set\": 2.0},\n        {\"category\": \"hov2\", \"set\": 2.0},\n        {\"timespan\": [\"12:00\", \"2:00\"], \"change\": -1},\n    ]\n\n    @property\n    def timespan_dt(self) -&gt; list[list[datetime]]:\n        \"\"\"Convert timespan to list of datetime objects.\"\"\"\n        return str_to_time_list(self.timespan)\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_set_or_change(cls, data: dict):\n        \"\"\"Validate that each item has a set or change value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        if data.get(\"set\") and data.get(\"change\"):\n            WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n            data[\"change\"] = None\n\n        WranglerLogger.debug(f\"Data: {data}\")\n        if data.get(\"set\") is None and data.get(\"change\") is None:\n            msg = f\"Require at least one of 'set' or'change' in IndivScopedPropertySetItem\"\n            WranglerLogger.debug(msg=f\"   Found: {data}\")\n            raise ValueError(msg)\n        return data\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_categories_or_timespans(cls, data: Any) -&gt; Any:\n        \"\"\"Validate that each item has a category or timespan value.\"\"\"\n        if not isinstance(data, dict):\n            return data\n        require_any_of = [\"category\", \"timespan\"]\n        if not any(attr in data for attr in require_any_of):\n            msg = f\"Require at least one of {require_any_of}\"\n            raise ValidationError(msg)\n        return data\n\n    @field_validator(\"timespan\")\n    @classmethod\n    def validate_timespan(cls, v):\n        \"\"\"Validate the timespan field.\"\"\"\n        if v is not None:\n            return validate_timespan_string(v)\n        return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.timespan_dt","title":"network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.timespan_dt  <code>property</code>","text":"<pre><code>timespan_dt\n</code></pre> <p>Convert timespan to list of datetime objects.</p>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.check_categories_or_timespans","title":"network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.check_categories_or_timespans  <code>classmethod</code>","text":"<pre><code>check_categories_or_timespans(data)\n</code></pre> <p>Validate that each item has a category or timespan value.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_categories_or_timespans(cls, data: Any) -&gt; Any:\n    \"\"\"Validate that each item has a category or timespan value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    require_any_of = [\"category\", \"timespan\"]\n    if not any(attr in data for attr in require_any_of):\n        msg = f\"Require at least one of {require_any_of}\"\n        raise ValidationError(msg)\n    return data\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.check_set_or_change","title":"network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.check_set_or_change  <code>classmethod</code>","text":"<pre><code>check_set_or_change(data)\n</code></pre> <p>Validate that each item has a set or change value.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_set_or_change(cls, data: dict):\n    \"\"\"Validate that each item has a set or change value.\"\"\"\n    if not isinstance(data, dict):\n        return data\n    if data.get(\"set\") and data.get(\"change\"):\n        WranglerLogger.warning(\"Both set and change are set. Ignoring change.\")\n        data[\"change\"] = None\n\n    WranglerLogger.debug(f\"Data: {data}\")\n    if data.get(\"set\") is None and data.get(\"change\") is None:\n        msg = f\"Require at least one of 'set' or'change' in IndivScopedPropertySetItem\"\n        WranglerLogger.debug(msg=f\"   Found: {data}\")\n        raise ValueError(msg)\n    return data\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.validate_timespan","title":"network_wrangler.models.projects.roadway_changes.IndivScopedPropertySetItem.validate_timespan  <code>classmethod</code>","text":"<pre><code>validate_timespan(v)\n</code></pre> <p>Validate the timespan field.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@field_validator(\"timespan\")\n@classmethod\ndef validate_timespan(cls, v):\n    \"\"\"Validate the timespan field.\"\"\"\n    if v is not None:\n        return validate_timespan_string(v)\n    return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.RoadPropertyChange","title":"network_wrangler.models.projects.roadway_changes.RoadPropertyChange","text":"<p>               Bases: <code>RecordModel</code></p> <p>Value for setting property value for a time of day and category.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class RoadPropertyChange(RecordModel):\n    \"\"\"Value for setting property value for a time of day and category.\"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\", exclude_none=True)\n\n    existing: Optional[Any] = None\n    change: Optional[Union[int, float]] = None\n    set: Optional[Any] = None\n    scoped: Optional[Union[None, ScopedPropertySetList]] = None\n    overwrite_scoped: Optional[Literal[\"conflicting\", \"all\", \"error\"]] = None\n    existing_value_conflict: Optional[Literal[\"error\", \"warn\", \"skip\"]] = None\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"change\", \"set\"],\n    ]\n\n    _examples: ClassVar[list] = [\n        {\"set\": 1},\n        {\"existing\": 2, \"change\": -1},\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\"timespan\": [\"6:00\", \"9:00\"], \"value\": 2.0},\n                {\"timespan\": [\"9:00\", \"15:00\"], \"value\": 4.0},\n            ],\n        },\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\n                    \"categories\": [\"hov3\", \"hov2\"],\n                    \"timespan\": [\"6:00\", \"9:00\"],\n                    \"value\": 2.0,\n                },\n                {\"category\": \"truck\", \"timespan\": [\"6:00\", \"9:00\"], \"value\": 4.0},\n            ],\n        },\n        {\n            \"set\": 0,\n            \"scoped\": [\n                {\"categories\": [\"hov3\", \"hov2\"], \"value\": 2.0},\n                {\"category\": \"truck\", \"value\": 4.0},\n            ],\n        },\n    ]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.RoadwayDeletion","title":"network_wrangler.models.projects.roadway_changes.RoadwayDeletion","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing roadway deletion project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class RoadwayDeletion(RecordModel):\n    \"\"\"Requirements for describing roadway deletion project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"links\", \"nodes\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    links: Optional[SelectLinksDict] = None\n    nodes: Optional[SelectNodesDict] = None\n    clean_shapes: bool = False\n    clean_nodes: bool = False\n\n    @field_validator(\"links\")\n    @classmethod\n    def set_to_all_modes(cls, links: Optional[SelectLinksDict] = None):\n        \"\"\"Set the search mode to 'any' if not specified explicitly.\"\"\"\n        if links is not None and links.modes == DEFAULT_SEARCH_MODES:\n            links.modes = DEFAULT_DELETE_MODES\n        return links\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.RoadwayDeletion.set_to_all_modes","title":"network_wrangler.models.projects.roadway_changes.RoadwayDeletion.set_to_all_modes  <code>classmethod</code>","text":"<pre><code>set_to_all_modes(links=None)\n</code></pre> <p>Set the search mode to \u2018any\u2019 if not specified explicitly.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@field_validator(\"links\")\n@classmethod\ndef set_to_all_modes(cls, links: Optional[SelectLinksDict] = None):\n    \"\"\"Set the search mode to 'any' if not specified explicitly.\"\"\"\n    if links is not None and links.modes == DEFAULT_SEARCH_MODES:\n        links.modes = DEFAULT_DELETE_MODES\n    return links\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.ScopedPropertySetList","title":"network_wrangler.models.projects.roadway_changes.ScopedPropertySetList","text":"<p>               Bases: <code>RootListMixin</code>, <code>RootModel</code></p> <p>List of ScopedPropertySetItems used to evaluate and apply changes to roadway properties.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>class ScopedPropertySetList(RootListMixin, RootModel):\n    \"\"\"List of ScopedPropertySetItems used to evaluate and apply changes to roadway properties.\"\"\"\n\n    root: list[IndivScopedPropertySetItem]\n\n    @model_validator(mode=\"before\")\n    @classmethod\n    def check_set_or_change(cls, data: list):\n        \"\"\"Validate that each item has a set or change value.\"\"\"\n        data = _grouped_to_indiv_list_of_scopedpropsetitem(data)\n        return data\n\n    @model_validator(mode=\"after\")\n    def check_conflicting_scopes(self):\n        \"\"\"Check for conflicting scopes in the list of ScopedPropertySetItem.\"\"\"\n        conflicts = []\n        for i in self:\n            if i.timespan == DEFAULT_TIMESPAN:\n                continue\n            overlapping_ts_i = self.overlapping_timespans(i.timespan)\n            for j in overlapping_ts_i:\n                if j == i:\n                    continue\n                if j.category == i.category:\n                    conflicts.append((i, j))\n        if conflicts:\n            msg = \"Conflicting scopes in ScopedPropertySetList\"\n            WranglerLogger.error(msg + f\"\\n    Conflicts: {conflicts}\")\n            raise ScopeConflictError(msg)\n\n        return self\n\n    def overlapping_timespans(self, timespan: TimespanString) -&gt; list[IndivScopedPropertySetItem]:\n        \"\"\"Return a list of items that overlap with the given timespan.\"\"\"\n        timespan_dt = str_to_time_list(timespan)\n        return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n\n    @property\n    def change_items(self) -&gt; list[IndivScopedPropertySetItem]:\n        \"\"\"Filter out items that do not have a change value.\"\"\"\n        WranglerLogger.debug(f\"self.root[0]: {self.root[0]}\")\n        return [i for i in self if i.change is not None]\n\n    @property\n    def set_items(self):\n        \"\"\"Filter out items that do not have a set value.\"\"\"\n        return [i for i in self if i.set is not None]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.change_items","title":"network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.change_items  <code>property</code>","text":"<pre><code>change_items\n</code></pre> <p>Filter out items that do not have a change value.</p>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.set_items","title":"network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.set_items  <code>property</code>","text":"<pre><code>set_items\n</code></pre> <p>Filter out items that do not have a set value.</p>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.check_conflicting_scopes","title":"network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.check_conflicting_scopes","text":"<pre><code>check_conflicting_scopes()\n</code></pre> <p>Check for conflicting scopes in the list of ScopedPropertySetItem.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_conflicting_scopes(self):\n    \"\"\"Check for conflicting scopes in the list of ScopedPropertySetItem.\"\"\"\n    conflicts = []\n    for i in self:\n        if i.timespan == DEFAULT_TIMESPAN:\n            continue\n        overlapping_ts_i = self.overlapping_timespans(i.timespan)\n        for j in overlapping_ts_i:\n            if j == i:\n                continue\n            if j.category == i.category:\n                conflicts.append((i, j))\n    if conflicts:\n        msg = \"Conflicting scopes in ScopedPropertySetList\"\n        WranglerLogger.error(msg + f\"\\n    Conflicts: {conflicts}\")\n        raise ScopeConflictError(msg)\n\n    return self\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.check_set_or_change","title":"network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.check_set_or_change  <code>classmethod</code>","text":"<pre><code>check_set_or_change(data)\n</code></pre> <p>Validate that each item has a set or change value.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef check_set_or_change(cls, data: list):\n    \"\"\"Validate that each item has a set or change value.\"\"\"\n    data = _grouped_to_indiv_list_of_scopedpropsetitem(data)\n    return data\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.overlapping_timespans","title":"network_wrangler.models.projects.roadway_changes.ScopedPropertySetList.overlapping_timespans","text":"<pre><code>overlapping_timespans(timespan)\n</code></pre> <p>Return a list of items that overlap with the given timespan.</p> Source code in <code>network_wrangler/models/projects/roadway_changes.py</code> <pre><code>def overlapping_timespans(self, timespan: TimespanString) -&gt; list[IndivScopedPropertySetItem]:\n    \"\"\"Return a list of items that overlap with the given timespan.\"\"\"\n    timespan_dt = str_to_time_list(timespan)\n    return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_selection.RoadwaySelectionFormatError","title":"network_wrangler.models.projects.roadway_selection.RoadwaySelectionFormatError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with the format of a selection.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class RoadwaySelectionFormatError(Exception):\n    \"\"\"Raised when there is an issue with the format of a selection.\"\"\"\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_selection.SelectFacility","title":"network_wrangler.models.projects.roadway_selection.SelectFacility","text":"<p>               Bases: <code>RecordModel</code></p> <p>Roadway Facility Selection.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectFacility(RecordModel):\n    \"\"\"Roadway Facility Selection.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"links\", \"nodes\", [\"links\", \"from\", \"to\"]],\n    ]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    links: Optional[SelectLinksDict] = None\n    nodes: Optional[SelectNodesDict] = None\n    from_: Annotated[Optional[SelectNodeDict], Field(None, alias=\"from\")]\n    to: Optional[SelectNodeDict] = None\n\n    _examples: ClassVar[list[dict]] = [\n        {\n            \"links\": {\"name\": [\"Main Street\"]},\n            \"from\": {\"model_node_id\": 1},\n            \"to\": {\"model_node_id\": 2},\n        },\n        {\"nodes\": {\"osm_node_id\": [\"1\", \"2\", \"3\"]}},\n        {\"nodes\": {\"model_node_id\": [1, 2, 3]}},\n        {\"links\": {\"model_link_id\": [1, 2, 3]}},\n    ]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_selection.SelectLinksDict","title":"network_wrangler.models.projects.roadway_selection.SelectLinksDict","text":"<p>               Bases: <code>RecordModel</code></p> <p>requirements for describing links in the <code>facility</code> section of a project card.</p> <p>Examples:</p> <pre><code>    {'name': ['Main St'], 'modes': ['drive']}\n    {'osm_link_id': ['123456789']}\n    {'model_link_id': [123456789], 'modes': ['walk']}\n    {'all': 'True', 'modes': ['transit']}\n    {'all': 'True', name': ['Main St']}\n</code></pre> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectLinksDict(RecordModel):\n    \"\"\"requirements for describing links in the `facility` section of a project card.\n\n    Examples:\n    ```python\n        {'name': ['Main St'], 'modes': ['drive']}\n        {'osm_link_id': ['123456789']}\n        {'model_link_id': [123456789], 'modes': ['walk']}\n        {'all': 'True', 'modes': ['transit']}\n        {'all': 'True', name': ['Main St']}\n    ```\n\n    \"\"\"\n\n    require_conflicts: ClassVar[ConflictsWith] = [\n        [\"all\", \"osm_link_id\"],\n        [\"all\", \"model_link_id\"],\n        [\"all\", \"name\"],\n        [\"all\", \"ref\"],\n        [\"osm_link_id\", \"model_link_id\"],\n        [\"osm_link_id\", \"name\"],\n        [\"model_link_id\", \"name\"],\n    ]\n    require_any_of: ClassVar[AnyOf] = [[\"name\", \"ref\", \"osm_link_id\", \"model_link_id\", \"all\"]]\n\n    model_config = ConfigDict(extra=\"allow\")\n\n    all: Optional[bool] = False\n    name: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    ref: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    osm_link_id: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    model_link_id: Annotated[Optional[list[int]], Field(None, min_length=1)]\n    modes: list[str] = DEFAULT_SEARCH_MODES\n    ignore_missing: Optional[bool] = True\n\n    _examples: ClassVar[list[dict]] = [\n        {\"name\": [\"Main St\"], \"modes\": [\"drive\"]},\n        {\"osm_link_id\": [\"123456789\"]},\n        {\"model_link_id\": [123456789], \"modes\": [\"walk\"]},\n        {\"all\": \"True\", \"modes\": [\"transit\"]},\n    ]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_selection.SelectNodeDict","title":"network_wrangler.models.projects.roadway_selection.SelectNodeDict","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection of a single roadway node in the <code>facility</code> section of a project card.</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectNodeDict(RecordModel):\n    \"\"\"Selection of a single roadway node in the `facility` section of a project card.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [[\"osm_node_id\", \"model_node_id\"]]\n    model_config = ConfigDict(extra=\"allow\")\n\n    osm_node_id: Optional[str] = None\n    model_node_id: Optional[int] = None\n\n    _examples: ClassVar[list[dict]] = [{\"osm_node_id\": \"12345\"}, {\"model_node_id\": 67890}]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.roadway_selection.SelectNodesDict","title":"network_wrangler.models.projects.roadway_selection.SelectNodesDict","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple nodes of a project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/roadway_selection.py</code> <pre><code>class SelectNodesDict(RecordModel):\n    \"\"\"Requirements for describing multiple nodes of a project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"osm_node_id\", \"model_node_id\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n\n    all: Optional[bool] = False\n    osm_node_id: Annotated[Optional[list[str]], Field(None, min_length=1)]\n    model_node_id: Annotated[Optional[list[int]], Field(min_length=1)]\n    ignore_missing: Optional[bool] = True\n\n    _examples: ClassVar[list[dict]] = [\n        {\"osm_node_id\": [\"12345\", \"67890\"], \"model_node_id\": [12345, 67890]},\n        {\"osm_node_id\": [\"12345\", \"67890\"]},\n        {\"model_node_id\": [12345, 67890]},\n    ]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.SelectRouteProperties","title":"network_wrangler.models.projects.transit_selection.SelectRouteProperties","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit routes.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectRouteProperties(RecordModel):\n    \"\"\"Selection properties for transit routes.\"\"\"\n\n    route_short_name: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    route_long_name: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    agency_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    route_type: Annotated[Optional[list[int]], Field(None, min_length=1)]\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.SelectTransitLinks","title":"network_wrangler.models.projects.transit_selection.SelectTransitLinks","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple transit links of a project card.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitLinks(RecordModel):\n    \"\"\"Requirements for describing multiple transit links of a project card.\"\"\"\n\n    require_one_of: ClassVar[OneOf] = [\n        [\"ab_nodes\", \"model_link_id\"],\n    ]\n\n    model_link_id: Annotated[Optional[list[int]], Field(min_length=1)] = None\n    ab_nodes: Annotated[Optional[list[TransitABNodesModel]], Field(min_length=1)] = None\n    require: Optional[SelectionRequire] = \"any\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n    _examples: ClassVar[list[dict]] = [\n        {\n            \"ab_nodes\": [{\"A\": \"75520\", \"B\": \"66380\"}, {\"A\": \"66380\", \"B\": \"75520\"}],\n            \"type\": \"any\",\n        },\n        {\n            \"model_link_id\": [123, 321],\n            \"type\": \"all\",\n        },\n    ]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.SelectTransitNodes","title":"network_wrangler.models.projects.transit_selection.SelectTransitNodes","text":"<p>               Bases: <code>RecordModel</code></p> <p>Requirements for describing multiple transit nodes of a project card (e.g. to delete).</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitNodes(RecordModel):\n    \"\"\"Requirements for describing multiple transit nodes of a project card (e.g. to delete).\"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [\n        [\n            \"model_node_id\",\n            # \"gtfs_stop_id\", TODO Not implemented\n        ]\n    ]\n\n    # gtfs_stop_id: Annotated[Optional[List[ForcedStr]], Field(None, min_length=1)] TODO Not implemented\n    model_node_id: Annotated[list[int], Field(min_length=1)]\n    require: Optional[SelectionRequire] = \"any\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n\n    _examples: ClassVar[list[dict]] = [\n        # {\"gtfstop_id\": [\"stop1\", \"stop2\"], \"require\": \"any\"},  TODO Not implemented\n        {\"model_node_id\": [1, 2], \"require\": \"all\"},\n    ]\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.SelectTransitTrips","title":"network_wrangler.models.projects.transit_selection.SelectTransitTrips","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit trips.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTransitTrips(RecordModel):\n    \"\"\"Selection properties for transit trips.\"\"\"\n\n    trip_properties: Optional[SelectTripProperties] = None\n    route_properties: Optional[SelectRouteProperties] = None\n    timespans: Annotated[Optional[list[TimespanString]], Field(None, min_length=1)]\n    nodes: Optional[SelectTransitNodes] = None\n    links: Optional[SelectTransitLinks] = None\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n\n    @field_validator(\"timespans\", mode=\"before\")\n    @classmethod\n    def validate_timespans(cls, v):\n        \"\"\"Validate the timespans field.\"\"\"\n        if v is not None:\n            return [validate_timespan_string(ts) for ts in v]\n        return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.SelectTransitTrips.validate_timespans","title":"network_wrangler.models.projects.transit_selection.SelectTransitTrips.validate_timespans  <code>classmethod</code>","text":"<pre><code>validate_timespans(v)\n</code></pre> <p>Validate the timespans field.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>@field_validator(\"timespans\", mode=\"before\")\n@classmethod\ndef validate_timespans(cls, v):\n    \"\"\"Validate the timespans field.\"\"\"\n    if v is not None:\n        return [validate_timespan_string(ts) for ts in v]\n    return v\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.SelectTripProperties","title":"network_wrangler.models.projects.transit_selection.SelectTripProperties","text":"<p>               Bases: <code>RecordModel</code></p> <p>Selection properties for transit trips.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class SelectTripProperties(RecordModel):\n    \"\"\"Selection properties for transit trips.\"\"\"\n\n    trip_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    shape_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    direction_id: Annotated[Optional[int], Field(None)]\n    service_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    route_id: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n    trip_short_name: Annotated[Optional[list[ForcedStr]], Field(None, min_length=1)]\n\n    model_config = ConfigDict(\n        extra=\"allow\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"api_projects/#network_wrangler.models.projects.transit_selection.TransitABNodesModel","title":"network_wrangler.models.projects.transit_selection.TransitABNodesModel","text":"<p>               Bases: <code>RecordModel</code></p> <p>Single transit link model.</p> Source code in <code>network_wrangler/models/projects/transit_selection.py</code> <pre><code>class TransitABNodesModel(RecordModel):\n    \"\"\"Single transit link model.\"\"\"\n\n    A: Optional[int] = None  # model_node_id\n    B: Optional[int] = None  # model_node_id\n\n    model_config = ConfigDict(\n        extra=\"forbid\",\n        validate_assignment=True,\n        exclude_none=True,\n        protected_namespaces=(),\n    )\n</code></pre>"},{"location":"api_roadway/","title":"Roadway","text":"<p>The roadway module contains submodules which define and extend the links, nodes, and shapes dataframe objects which within a RoadwayNetwork object as well as other classes and methods which support and extend the RoadwayNetwork class.</p>"},{"location":"api_roadway/#roadway-network-objects","title":"Roadway Network Objects","text":"<p>Submodules which define and extend the links, nodes, and shapes dataframe objects which within a RoadwayNetwork object.  Includes classes which define:</p> <ul> <li>dataframe schemas to be used for dataframe validation using <code>pandera</code></li> <li>methods which extend the dataframes</li> </ul>"},{"location":"api_roadway/#tables","title":"Tables","text":"<p>Datamodels for Roadway Network Tables.</p> <p>This module contains the datamodels used to validate the format and types of Roadway Network tables.</p> <p>Includes:</p> <ul> <li>RoadLinksTable</li> <li>RoadNodesTable</li> <li>RoadShapesTable</li> <li>ExplodedScopedLinkPropertyTable</li> </ul> <p>Complex roadway types defined using Pydantic models to facilitation validation.</p>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable","title":"network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate an exploded links_df by scope.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class ExplodedScopedLinkPropertyTable(DataFrameModel):\n    \"\"\"Datamodel used to validate an exploded links_df by scope.\"\"\"\n\n    model_link_id: Series[int]\n    category: Series[Any]\n    timespan: Series[list[str]]\n    start_time: Series[dt.datetime]\n    end_time: Series[dt.datetime]\n    scoped: Series[Any] = Field(default=None, nullable=True)\n\n    class Config:\n        \"\"\"Config for ExplodedScopedLinkPropertySchema.\"\"\"\n\n        name = \"ExplodedScopedLinkPropertySchema\"\n        coerce = True\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable","title":"network_wrangler.models.roadway.tables.RoadLinksTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if links_df is of correct format and types.</p> <p>Attributes:</p> <ul> <li> <code>model_link_id</code>               (<code>int</code>)           \u2013            <p>Unique identifier for the link.</p> </li> <li> <code>A</code>               (<code>int</code>)           \u2013            <p><code>model_node_id</code> of the link\u2019s start node. Foreign key to <code>road_nodes</code>.</p> </li> <li> <code>B</code>               (<code>int</code>)           \u2013            <p><code>model_node_id</code> of the link\u2019s end node. Foreign key to <code>road_nodes</code>.</p> </li> <li> <code>geometry</code>               (<code>GeoSeries</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Simple A\u2192B geometry of the link.</p> </li> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>Name of the link.</p> </li> <li> <code>rail_only</code>               (<code>bool</code>)           \u2013            <p>If the link is only for rail. Default is False.</p> </li> <li> <code>bus_only</code>               (<code>bool</code>)           \u2013            <p>If the link is only for buses. Default is False.</p> </li> <li> <code>drive_access</code>               (<code>bool</code>)           \u2013            <p>If the link allows driving. Default is True.</p> </li> <li> <code>bike_access</code>               (<code>bool</code>)           \u2013            <p>If the link allows biking. Default is True.</p> </li> <li> <code>walk_access</code>               (<code>bool</code>)           \u2013            <p>If the link allows walking. Default is True.</p> </li> <li> <code>truck_access</code>               (<code>bool</code>)           \u2013            <p>If the link allows trucks. Default is True.</p> </li> <li> <code>distance</code>               (<code>float</code>)           \u2013            <p>Length of the link.</p> </li> <li> <code>roadway</code>               (<code>str</code>)           \u2013            <p>Type of roadway per OSM definitions. Default is \u201croad\u201d.</p> </li> <li> <code>projects</code>               (<code>str</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Comma-separated list of project names applied to the link. Default is \u201c\u201d.</p> </li> <li> <code>managed</code>               (<code>int</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Indicator for the type of managed lane facility. Values can be:</p> <ul> <li>0 indicating no managed lane on this link.</li> <li>1 indicates that there is a managed lane on the link (std network) or that the link is a     managed lane (model network).</li> <li>-1 indicates that there is a parallel managed lane derived from this link (model network).</li> </ul> </li> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>Identifier referencing the primary key of the shapes table. Default is None.</p> </li> <li> <code>lanes</code>               (<code>int</code>)           \u2013            <p>Default number of lanes on the link. Default is 1.</p> </li> <li> <code>sc_lanes</code>               (<code>Optional[list[dict]]</code>)           \u2013            <p>List of scoped link values for the number of lanes. Default is None. Example: <code>[{'timespan':['12:00':'15:00'], 'value': 3},{'timespan':['15:00':'19:00'], 'value': 2}]</code>.</p> </li> <li> <code>price</code>               (<code>float</code>)           \u2013            <p>Default price to use the link. Default is 0.</p> </li> <li> <code>sc_price</code>               (<code>Optional[list[dict]]</code>)           \u2013            <p>List of scoped link values for the price. Default is None. Example: <code>[{'timespan':['15:00':'19:00'],'category': 'sov', 'value': 2.5}]</code>.</p> </li> <li> <code>ref</code>               (<code>Optional[str]</code>)           \u2013            <p>Reference numbers for link referring to a route or exit number per the OSM definition. Default is None.</p> </li> <li> <code>access</code>               (<code>Optional[Any]</code>)           \u2013            <p>User-defined method to note access restrictions for the link. Default is None.</p> </li> <li> <code>ML_projects</code>               (<code>Optional[str]</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Comma-separated list of project names applied to the managed lane. Default is \u201c\u201d.</p> </li> <li> <code>ML_lanes</code>               (<code>Optional[int]</code>)           \u2013            <p>Default number of lanes on the managed lane. Default is None.</p> </li> <li> <code>ML_price</code>               (<code>Optional[float]</code>)           \u2013            <p>Default price to use the managed lane. Default is 0.</p> </li> <li> <code>ML_access</code>               (<code>Optional[Any]</code>)           \u2013            <p>User-defined method to note access restrictions for the managed lane. Default is None.</p> </li> <li> <code>ML_access_point</code>               (<code>Optional[bool]</code>)           \u2013            <p>If the link is an access point for the managed lane. Default is False.</p> </li> <li> <code>ML_egress_point</code>               (<code>Optional[bool]</code>)           \u2013            <p>If the link is an egress point for the managed lane. Default is False.</p> </li> <li> <code>sc_ML_lanes</code>               (<code>Optional[list[dict]]</code>)           \u2013            <p>List of scoped link values for the number of lanes on the managed lane. Default is None.</p> </li> <li> <code>sc_ML_price</code>               (<code>Optional[list[dict]]</code>)           \u2013            <p>List of scoped link values for the price of the managed lane. Default is None.</p> </li> <li> <code>sc_ML_access</code>               (<code>Optional[list[dict]]</code>)           \u2013            <p>List of scoped link values for the access restrictions of the managed lane. Default is None.</p> </li> <li> <code>ML_geometry</code>               (<code>Optional[GeoSeries]</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Simple A\u2192B geometry of the managed lane. Default is None.</p> </li> <li> <code>ML_shape_id</code>               (<code>Optional[str]</code>)           \u2013            <p>Identifier referencing the primary key of the shapes table for the managed lane. Default is None.</p> </li> <li> <code>osm_link_id</code>               (<code>Optional[str]</code>)           \u2013            <p>Identifier referencing the OSM link ID. Default is \u201c\u201d.</p> </li> <li> <code>GP_A</code>               (<code>Optional[int]</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Identifier referencing the primary key of the associated general purpose link start node for a managed lane link in a model network. Default is None.</p> </li> <li> <code>GP_B</code>               (<code>Optional[int]</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Identifier referencing the primary key of the associated general purpose link end node for a managed lane link in a model network. Default is None.</p> </li> </ul> <p>User Defined Properties</p> <p>Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they have overlapping property names.</p>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable--properties-for-parallel-managed-lanes","title":"Properties for parallel managed lanes","text":"<p>Properties for parallel managed lanes are prefixed with <code>ML_</code>. (Almost) any property, including an ad-hoc one, can be made to apply to a parallel managed lane by applying the prefix <code>ML_</code>, e.g. <code>ML_lanes</code></p> <p>Warning</p> <p>The following properties should not be assigned an <code>ML_</code> prefix by the user because they are assigned one within networkwrangler:</p> <ul> <li><code>name</code></li> <li><code>A</code></li> <li><code>B</code></li> <li><code>model_link_id</code></li> </ul>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable--time-or-category-dependent-properties","title":"Time- or category-dependent properties","text":"<p>The following properties can be time-dependent, category-dependent, or both by adding <code>sc_</code>. The \u201cplain\u201d property without the prefix becomes the default when no scoped property applies.</p> Property # of Lanes Price Default value <code>lanes</code> <code>price</code> Time- and/or category-dependent value <code>sc_lanes</code> <code>sc_price</code> Default value for managed lane <code>ML_lanes</code> <code>ML_price</code> Time- and/or category-dependent value for managed lane <code>sc_ML_lanes</code> <code>sc_ML_price</code> <p>previous format for scoped properties</p> <p>Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:</p> <ul> <li><code>load_roadway_from_dir()</code>, <code>read_links()</code>, and associated functions will \u201csniff\u201d the network for the old format and apply the converter function <code>translate_links_df_v0_to_v1()</code></li> <li><code>write_links()</code> has an boolean attribute to <code>convert_complex_properties_to_single_field</code> which can also be invoked from <code>write_roadway()</code> as <code>convert_complex_link_properties_to_single_field</code>.</li> </ul>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable--defining-time-dependent-properties","title":"Defining time-dependent properties","text":"<p>Time-dependent properties are defined as a list of dictionaries with timespans and values.</p> <ul> <li>Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: <code>('06:00':'09:00')</code>.</li> <li>Timespans must not intersect.</li> </ul> <p>Time-dependent property</p> <p>$3 peak-period pricing</p> <pre><code># default price\n'price' = 0\n'sc_price':\n[\n    {\n        'time':['06:00':'09:00'],\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'value': 3,\n    }\n]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable--defining-time-and-category-dependent-properties","title":"Defining time- and category-dependent properties","text":"<p>Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.</p> <p>time- and category-dependent property</p> <p>A pricing strategy which only applies in peak period for trucks and sovs:</p> <pre><code># default price\n\"price\": 0\n# price scoped by time of day\n\"sc_price\":\n[\n    {\n        'timespan':['06:00':'09:00'],\n        'category': ('sov','truck'),\n        'value': 3\n    },\n    {\n        'timespan':['16:00':'19:00'],\n        'category': ('sov','truck'),\n        'value': 3,\n    }\n]\n</code></pre> <p>Tip</p> <p>There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.</p> <p>User-defined variable by time of day</p> <p>Define a variable <code>access</code> to represent which categories can access the network and vary it by time of day.</p> <pre><code>#access\n{\n    # default value for access\n    'access': ('any'),\n    # scoped value for access\n    'sc_access': [\n        {\n            'timespan':['06:00':'09:00'],\n            'value': ('no-trucks')\n        },\n        {\n            'timespan':['16:00':'19:00'],\n            'value': ('hov2','hov3','trucks')\n        }\n    ]\n}\n</code></pre> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadLinksTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if links_df is of correct format and types.\n\n    Attributes:\n        model_link_id (int): Unique identifier for the link.\n        A (int): `model_node_id` of the link's start node. Foreign key to `road_nodes`.\n        B (int): `model_node_id` of the link's end node. Foreign key to `road_nodes`.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Simple A--&gt;B geometry of the link.\n        name (str): Name of the link.\n        rail_only (bool): If the link is only for rail. Default is False.\n        bus_only (bool): If the link is only for buses. Default is False.\n        drive_access (bool): If the link allows driving. Default is True.\n        bike_access (bool): If the link allows biking. Default is True.\n        walk_access (bool): If the link allows walking. Default is True.\n        truck_access (bool): If the link allows trucks. Default is True.\n        distance (float): Length of the link.\n        roadway (str): Type of roadway per [OSM definitions](https://wiki.openstreetmap.org/wiki/Key:highway#Roads).\n            Default is \"road\".\n        projects (str): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Comma-separated list of project names applied to the link. Default is \"\".\n        managed (int): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Indicator for the type of managed lane facility. Values can be:\n\n            - 0 indicating no managed lane on this link.\n            - 1 indicates that there is a managed lane on the link (std network) or that the link is a\n                managed lane (model network).\n            - -1 indicates that there is a parallel managed lane derived from this link (model network).\n        shape_id (str): Identifier referencing the primary key of the shapes table. Default is None.\n        lanes (int): Default number of lanes on the link. Default is 1.\n        sc_lanes (Optional[list[dict]]: List of scoped link values for the number of lanes. Default is None.\n            Example: `[{'timespan':['12:00':'15:00'], 'value': 3},{'timespan':['15:00':'19:00'], 'value': 2}]`.\n\n        price (float): Default price to use the link. Default is 0.\n        sc_price (Optional[list[dict]]): List of scoped link values for the price. Default is None.\n            Example: `[{'timespan':['15:00':'19:00'],'category': 'sov', 'value': 2.5}]`.\n        ref (Optional[str]): Reference numbers for link referring to a route or exit number per the\n            [OSM definition](https://wiki.openstreetmap.org/wiki/Key:ref). Default is None.\n        access (Optional[Any]): User-defined method to note access restrictions for the link. Default is None.\n        ML_projects (Optional[str]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Comma-separated list of project names applied to the managed lane. Default is \"\".\n        ML_lanes (Optional[int]): Default number of lanes on the managed lane. Default is None.\n        ML_price (Optional[float]): Default price to use the managed lane. Default is 0.\n        ML_access (Optional[Any]): User-defined method to note access restrictions for the managed lane. Default is None.\n        ML_access_point (Optional[bool]): If the link is an access point for the managed lane. Default is False.\n        ML_egress_point (Optional[bool]): If the link is an egress point for the managed lane. Default is False.\n        sc_ML_lanes (Optional[list[dict]]): List of scoped link values for the number of lanes on the managed lane.\n            Default is None.\n        sc_ML_price (Optional[list[dict]]): List of scoped link values for the price of the managed lane. Default is None.\n        sc_ML_access (Optional[list[dict]]): List of scoped link values for the access restrictions of the managed lane.\n            Default is None.\n        ML_geometry (Optional[GeoSeries]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Simple A--&gt;B geometry of the managed lane. Default is None.\n        ML_shape_id (Optional[str]): Identifier referencing the primary key of the shapes table for the managed lane.\n            Default is None.\n        osm_link_id (Optional[str]): Identifier referencing the OSM link ID. Default is \"\".\n        GP_A (Optional[int]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Identifier referencing the primary key of the associated general purpose link start node for\n            a managed lane link in a model network. Default is None.\n        GP_B (Optional[int]): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Identifier referencing the primary key of the associated general purpose link end node for\n            a managed lane link in a model network. Default is None.\n\n    !!! tip \"User Defined Properties\"\n\n        Additional properites may be defined and are assumed to have the same definition of OpenStreetMap if they\n        have overlapping property names.\n\n    ### Properties for parallel managed lanes\n\n    Properties for parallel managed lanes are prefixed with `ML_`. (Almost) any property,\n    including an ad-hoc one, can be made to apply to a parallel managed lane by applying\n    the prefix `ML_`, e.g. `ML_lanes`\n\n    !!! warning\n\n        The following properties should **not** be assigned an `ML_` prefix by the user\n        because they are assigned one within networkwrangler:\n\n        - `name`\n        - `A`\n        - `B`\n        - `model_link_id`\n\n    ### Time- or category-dependent properties\n\n    The following properties can be time-dependent, category-dependent, or both by adding `sc_`.\n    The \"plain\" property without the prefix becomes the default when no scoped property applies.\n\n    | Property | # of Lanes | Price |\n    | -----------| ----------------- | ---------------- |\n    | Default value | `lanes` | `price` |\n    | Time- and/or category-dependent value | `sc_lanes` | `sc_price` |\n    | Default value for managed lane | `ML_lanes` | `ML_price` |\n    | Time- and/or category-dependent value for managed lane | `sc_ML_lanes` | `sc_ML_price` |\n\n\n    !!! note \"previous format for scoped properties\"\n\n        Some previous tooling was developed around a previous method for serializing scoped properties.  In order to retain compatability with this format:\n\n        - `load_roadway_from_dir()`, `read_links()`, and associated functions will \"sniff\" the network for the old format and apply the converter function `translate_links_df_v0_to_v1()`\n        - `write_links()` has an boolean attribute to `convert_complex_properties_to_single_field` which can also be invoked from `write_roadway()` as `convert_complex_link_properties_to_single_field`.\n\n    #### Defining time-dependent properties\n\n    Time-dependent properties are defined as a list of dictionaries with timespans and values.\n\n    - Timespans must be defined as a list of HH:MM or HH:MM:SS using a 24-hour clock: `('06:00':'09:00')`.\n    - Timespans must not intersect.\n\n    !!! example  \"Time-dependent property\"\n\n        $3 peak-period pricing\n\n        ```python\n        # default price\n        'price' = 0\n        'sc_price':\n        [\n            {\n                'time':['06:00':'09:00'],\n                'value': 3\n            },\n            {\n                'timespan':['16:00':'19:00'],\n                'value': 3,\n            }\n        ]\n        ```\n\n    #### Defining time- and category-dependent properties\n\n    Properties co-dependent on time- and category are defined as a list of dictionaries with value, category and time defined.\n\n    !!! example \"time- and category-dependent property\"\n\n        A pricing strategy which only applies in peak period for trucks and sovs:\n\n        ```python\n        # default price\n        \"price\": 0\n        # price scoped by time of day\n        \"sc_price\":\n        [\n            {\n                'timespan':['06:00':'09:00'],\n                'category': ('sov','truck'),\n                'value': 3\n            },\n            {\n                'timespan':['16:00':'19:00'],\n                'category': ('sov','truck'),\n                'value': 3,\n            }\n        ]\n        ```\n\n    !!! tip\n\n        There is no limit on other, user-defined properties being listed as time-dependent or time- and category-dependent.\n\n    !!! example \"User-defined variable by time of day\"\n\n        Define a variable `access` to represent which categories can access the network and vary it by time of day.\n\n        ```python\n        #access\n        {\n            # default value for access\n            'access': ('any'),\n            # scoped value for access\n            'sc_access': [\n                {\n                    'timespan':['06:00':'09:00'],\n                    'value': ('no-trucks')\n                },\n                {\n                    'timespan':['16:00':'19:00'],\n                    'value': ('hov2','hov3','trucks')\n                }\n            ]\n        }\n        ```\n    \"\"\"\n\n    model_link_id: Series[int] = Field(coerce=True, unique=True)\n    model_link_id_idx: Optional[Series[int]] = Field(coerce=True, unique=True)\n    A: Series[int] = Field(nullable=False, coerce=True)\n    B: Series[int] = Field(nullable=False, coerce=True)\n    geometry: GeoSeries = Field(nullable=False)\n    name: Series[str] = Field(nullable=False, default=\"unknown\")\n    rail_only: Series[bool] = Field(coerce=True, nullable=False, default=False)\n    bus_only: Series[bool] = Field(coerce=True, nullable=False, default=False)\n    drive_access: Series[bool] = Field(coerce=True, nullable=False, default=True)\n    bike_access: Series[bool] = Field(coerce=True, nullable=False, default=True)\n    walk_access: Series[bool] = Field(coerce=True, nullable=False, default=True)\n    distance: Series[float] = Field(coerce=True, nullable=False)\n\n    roadway: Series[str] = Field(nullable=False, default=\"road\")\n    projects: Series[str] = Field(coerce=True, default=\"\")\n    managed: Series[int] = Field(coerce=True, nullable=False, default=0)\n\n    shape_id: Series[str] = Field(coerce=True, nullable=True)\n    lanes: Series[int] = Field(coerce=True, nullable=False)\n    price: Series[float] = Field(coerce=True, nullable=False, default=0)\n\n    # Optional Fields\n    ref: Optional[Series[str]] = Field(coerce=True, nullable=True, default=None)\n    access: Optional[Series[Any]] = Field(coerce=True, nullable=True, default=None)\n\n    sc_lanes: Optional[Series[object]] = Field(coerce=True, nullable=True, default=None)\n    sc_price: Optional[Series[object]] = Field(coerce=True, nullable=True, default=None)\n\n    ML_projects: Series[str] = Field(coerce=True, default=\"\")\n    ML_lanes: Optional[Series[Int64]] = Field(coerce=True, nullable=True, default=None)\n    ML_price: Optional[Series[float]] = Field(coerce=True, nullable=True, default=0)\n    ML_access: Optional[Series[Any]] = Field(coerce=True, nullable=True, default=True)\n    ML_access_point: Optional[Series[bool]] = Field(\n        coerce=True,\n        default=False,\n    )\n    ML_egress_point: Optional[Series[bool]] = Field(\n        coerce=True,\n        default=False,\n    )\n    sc_ML_lanes: Optional[Series[object]] = Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_price: Optional[Series[object]] = Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n    sc_ML_access: Optional[Series[object]] = Field(\n        coerce=True,\n        nullable=True,\n        default=None,\n    )\n\n    ML_geometry: Optional[GeoSeries] = Field(nullable=True, coerce=True, default=None)\n    ML_shape_id: Optional[Series[str]] = Field(nullable=True, coerce=True, default=None)\n\n    truck_access: Optional[Series[bool]] = Field(coerce=True, nullable=True, default=True)\n    osm_link_id: Series[str] = Field(coerce=True, nullable=True, default=\"\")\n    # todo this should be List[dict] but ranch output something else so had to have it be Any.\n    locationReferences: Optional[Series[Any]] = Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n\n    GP_A: Optional[Series[Int64]] = Field(coerce=True, nullable=True, default=None)\n    GP_B: Optional[Series[Int64]] = Field(coerce=True, nullable=True, default=None)\n\n    class Config:\n        \"\"\"Config for RoadLinksTable.\"\"\"\n\n        add_missing_columns = True\n        coerce = True\n        unique: ClassVar[list[str]] = [\"A\", \"B\"]\n\n    @pa.check(\"sc_*\", regex=True, element_wise=True)\n    def check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n        \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n        Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n        against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n        \"\"\"\n        if scoped_value is None or (not isinstance(scoped_value, list) and pd.isna(scoped_value)):\n            return True\n        return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable.check_scoped_fields","title":"network_wrangler.models.roadway.tables.RoadLinksTable.check_scoped_fields","text":"<pre><code>check_scoped_fields(scoped_value)\n</code></pre> <p>Checks that all fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 are valid ScopedLinkValueList.</p> <p>Custom check to validate fields starting with \u2018sc_\u2019 or \u2018sc_ML_\u2019 against a ScopedLinkValueItem model, handling both mandatory and optional fields.</p> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>@pa.check(\"sc_*\", regex=True, element_wise=True)\ndef check_scoped_fields(cls, scoped_value: Series) -&gt; Series[bool]:\n    \"\"\"Checks that all fields starting with 'sc_' or 'sc_ML_' are valid ScopedLinkValueList.\n\n    Custom check to validate fields starting with 'sc_' or 'sc_ML_'\n    against a ScopedLinkValueItem model, handling both mandatory and optional fields.\n    \"\"\"\n    if scoped_value is None or (not isinstance(scoped_value, list) and pd.isna(scoped_value)):\n        return True\n    return validate_pyd(scoped_value, ScopedLinkValueList)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadNodesTable","title":"network_wrangler.models.roadway.tables.RoadNodesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if nodes_df is of correct format and types.</p> <p>Must have a record for each node used by the <code>links</code> table and by the transit <code>shapes</code>, <code>stop_times</code>, and <code>stops</code> tables.</p> <p>Attributes:</p> <ul> <li> <code>model_node_id</code>               (<code>int</code>)           \u2013            <p>Unique identifier for the node.</p> </li> <li> <code>osm_node_id</code>               (<code>Optional[str]</code>)           \u2013            <p>Reference to open street map node id. Used for querying. Not guaranteed to be unique.</p> </li> <li> <code>X</code>               (<code>float</code>)           \u2013            <p>Longitude of the node in WGS84. Must be in the range of -180 to 180.</p> </li> <li> <code>Y</code>               (<code>float</code>)           \u2013            <p>Latitude of the node in WGS84. Must be in the range of -90 to 90.</p> </li> <li> <code>geometry</code>               (<code>GeoSeries</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited.</p> </li> </ul> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadNodesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if nodes_df is of correct format and types.\n\n    Must have a record for each node used by the `links` table and by the transit `shapes`, `stop_times`, and `stops` tables.\n\n    Attributes:\n        model_node_id (int): Unique identifier for the node.\n        osm_node_id (Optional[str]): Reference to open street map node id. Used for querying. Not guaranteed to be unique.\n        X (float): Longitude of the node in WGS84. Must be in the range of -180 to 180.\n        Y (float): Latitude of the node in WGS84. Must be in the range of -90 to 90.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n    \"\"\"\n\n    model_node_id: Series[int] = Field(coerce=True, unique=True, nullable=False)\n    model_node_idx: Optional[Series[int]] = Field(coerce=True, unique=True, nullable=False)\n    X: Series[float] = Field(coerce=True, nullable=False)\n    Y: Series[float] = Field(coerce=True, nullable=False)\n    geometry: GeoSeries\n\n    # optional fields\n    osm_node_id: Series[str] = Field(\n        coerce=True,\n        nullable=True,\n        default=\"\",\n    )\n    projects: Series[str] = Field(coerce=True, default=\"\")\n    inboundReferenceIds: Optional[Series[list[str]]] = Field(coerce=True, nullable=True)\n    outboundReferenceIds: Optional[Series[list[str]]] = Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadNodesTable.\"\"\"\n\n        add_missing_columns = True\n        coerce = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"model_node_id\"]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.tables.RoadShapesTable","title":"network_wrangler.models.roadway.tables.RoadShapesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Datamodel used to validate if shapes_df is of correct format and types.</p> <p>Should have a record for each <code>shape_id</code> referenced in <code>links</code> table.</p> <p>Attributes:</p> <ul> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>Unique identifier for the shape.</p> </li> <li> <code>geometry</code>               (<code>GeoSeries</code>)           \u2013            <p>Warning: this attribute is controlled by wrangler and should not be explicitly user-edited. Geometry of the shape.</p> </li> <li> <code>ref_shape_id</code>               (<code>Optional[str]</code>)           \u2013            <p>Reference to another <code>shape_id</code> that it may have been created from. Default is None.</p> </li> </ul> Source code in <code>network_wrangler/models/roadway/tables.py</code> <pre><code>class RoadShapesTable(DataFrameModel):\n    \"\"\"Datamodel used to validate if shapes_df is of correct format and types.\n\n    Should have a record for each `shape_id` referenced in `links` table.\n\n    Attributes:\n        shape_id (str): Unique identifier for the shape.\n        geometry (GeoSeries): **Warning**: this attribute is controlled by wrangler and should not be explicitly user-edited.\n            Geometry of the shape.\n        ref_shape_id (Optional[str]): Reference to another `shape_id` that it may\n            have been created from. Default is None.\n    \"\"\"\n\n    shape_id: Series[str] = Field(unique=True)\n    shape_id_idx: Optional[Series[int]] = Field(unique=True)\n\n    geometry: GeoSeries = Field()\n    ref_shape_id: Optional[Series] = Field(nullable=True)\n\n    class Config:\n        \"\"\"Config for RoadShapesTable.\"\"\"\n\n        coerce = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"shape_id\"]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.LocationReferences","title":"network_wrangler.models.roadway.types.LocationReferences  <code>module-attribute</code>","text":"<pre><code>LocationReferences = conlist(LocationReference, min_length=2)\n</code></pre> <p>List of at least two LocationReferences which define a path.</p>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.LocationReference","title":"network_wrangler.models.roadway.types.LocationReference","text":"<p>               Bases: <code>BaseModel</code></p> <p>SharedStreets-defined object for location reference.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class LocationReference(BaseModel):\n    \"\"\"SharedStreets-defined object for location reference.\"\"\"\n\n    sequence: PositiveInt\n    point: LatLongCoordinates\n    bearing: float = Field(None, ge=-360, le=360)\n    distanceToNextRef: NonNegativeFloat\n    intersectionId: str\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.ScopedLinkValueItem","title":"network_wrangler.models.roadway.types.ScopedLinkValueItem","text":"<p>               Bases: <code>RecordModel</code></p> <p>Define the value of a link property for a particular timespan or category.</p> <p>Attributes:</p> <ul> <li> <code>`category`</code>               (<code>str</code>)           \u2013            <p>Category or link user that this scoped value applies to, ex: <code>HOV2</code>, <code>truck</code>, etc.  Categories are user-defined with the exception of <code>any</code> which is reserved as the default category. Default is <code>DEFAULT_CATEGORY</code>, which is <code>all</code>.</p> </li> <li> <code>`timespan`</code>               (<code>list[TimeString]</code>)           \u2013            <p>timespan of the link property as defined as a list of two HH:MM(:SS) strings. Default is <code>DEFAULT_TIMESPAN</code>, which is <code>[\"00:00\", \"24:00\"]</code>.</p> </li> <li> <code>`value`</code>               (<code>Union[float, int, str]</code>)           \u2013            <p>Value of the link property for the given category and timespan.</p> </li> </ul> <p>Conflicting or matching scopes are not allowed in a list of ScopedLinkValueItems:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given category/timespan combination. This includes the default scopes as well as scopes that are contained within the given category AND timespan combination.</li> <li><code>overlapping</code>: a scope that fully or partially overlaps a given category OR timespan combination.  This includes the default scopes, all <code>matching</code> scopes and all scopes where at least one minute of timespan or one category overlap.</li> <li><code>conflicting</code>: a scope that is overlapping but not matching for a given category/timespan.</li> </ul> <p>NOTE: Default scope values of <code>category: any</code> and <code>timespan:[\"00:00\", \"24:00\"]</code> are not considered conflicting, but are applied to residual scopes.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopedLinkValueItem(RecordModel):\n    \"\"\"Define the value of a link property for a particular timespan or category.\n\n    Attributes:\n        `category` (str): Category or link user that this scoped value applies to, ex: `HOV2`,\n            `truck`, etc.  Categories are user-defined with the exception of `any` which is\n            reserved as the default category. Default is `DEFAULT_CATEGORY`, which is `all`.\n        `timespan` (list[TimeString]): timespan of the link property as defined as a list of\n            two HH:MM(:SS) strings. Default is `DEFAULT_TIMESPAN`, which is `[\"00:00\", \"24:00\"]`.\n        `value` (Union[float, int, str]): Value of the link property for the given category and\n            timespan.\n\n    Conflicting or matching scopes are not allowed in a list of ScopedLinkValueItems:\n\n    - `matching`: a scope that could be applied for a given category/timespan combination. This includes the default scopes as well as scopes that are contained within the given category AND timespan combination.\n    - `overlapping`: a scope that fully or partially overlaps a given category OR timespan combination.  This includes the default scopes, all `matching` scopes and all scopes where at least one minute of timespan or one category overlap.\n    - `conflicting`: a scope that is overlapping but not matching for a given category/timespan.\n\n    NOTE: Default scope values of `category: any` and `timespan:[\"00:00\", \"24:00\"]` are **not** considered conflicting, but are applied to residual scopes.\n    \"\"\"\n\n    require_any_of: ClassVar[AnyOf] = [[\"category\", \"timespan\"]]\n    model_config = ConfigDict(extra=\"forbid\")\n    category: Optional[Union[str, int]] = Field(default=DEFAULT_CATEGORY)\n    timespan: Optional[list[TimeString]] = Field(default=DEFAULT_TIMESPAN)\n    value: Union[int, float, str]\n\n    @property\n    def timespan_dt(self) -&gt; list[list[datetime]]:\n        \"\"\"Convert timespan to list of datetime objects.\"\"\"\n        return str_to_time_list(self.timespan)\n\n    @field_validator(\"timespan\")\n    @classmethod\n    def validate_timespan(cls, v):\n        \"\"\"Validate the timespan field.\"\"\"\n        if v is not None:\n            return validate_timespan_string(v)\n        return v\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.ScopedLinkValueItem.timespan_dt","title":"network_wrangler.models.roadway.types.ScopedLinkValueItem.timespan_dt  <code>property</code>","text":"<pre><code>timespan_dt\n</code></pre> <p>Convert timespan to list of datetime objects.</p>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.ScopedLinkValueItem.validate_timespan","title":"network_wrangler.models.roadway.types.ScopedLinkValueItem.validate_timespan  <code>classmethod</code>","text":"<pre><code>validate_timespan(v)\n</code></pre> <p>Validate the timespan field.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>@field_validator(\"timespan\")\n@classmethod\ndef validate_timespan(cls, v):\n    \"\"\"Validate the timespan field.\"\"\"\n    if v is not None:\n        return validate_timespan_string(v)\n    return v\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.ScopedLinkValueList","title":"network_wrangler.models.roadway.types.ScopedLinkValueList","text":"<p>               Bases: <code>RootListMixin</code>, <code>RootModel</code></p> <p>List of non-conflicting ScopedLinkValueItems.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>class ScopedLinkValueList(RootListMixin, RootModel):\n    \"\"\"List of non-conflicting ScopedLinkValueItems.\"\"\"\n\n    root: list[ScopedLinkValueItem]\n\n    def overlapping_timespans(self, timespan: Timespan):\n        \"\"\"Identify overlapping timespans in the list.\"\"\"\n        timespan_dt = str_to_time_list(timespan)\n        return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n\n    @model_validator(mode=\"after\")\n    def check_conflicting_scopes(self):\n        \"\"\"Check for conflicting scopes in the list.\"\"\"\n        conflicts = []\n        for i in self:\n            if i.timespan == DEFAULT_TIMESPAN:\n                continue\n            overlapping_ts_i = self.overlapping_timespans(i.timespan)\n            for j in overlapping_ts_i:\n                if j == i:\n                    continue\n                if j.category == i.category:\n                    conflicts.append((i, j))\n        if conflicts:\n            msg = \"Conflicting scopes in ScopedLinkValueList:\\n\"\n            WranglerLogger.error(msg + f\" Conflicts: \\n{conflicts}\")\n            raise ScopeLinkValueError(msg)\n\n        return self\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.ScopedLinkValueList.check_conflicting_scopes","title":"network_wrangler.models.roadway.types.ScopedLinkValueList.check_conflicting_scopes","text":"<pre><code>check_conflicting_scopes()\n</code></pre> <p>Check for conflicting scopes in the list.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_conflicting_scopes(self):\n    \"\"\"Check for conflicting scopes in the list.\"\"\"\n    conflicts = []\n    for i in self:\n        if i.timespan == DEFAULT_TIMESPAN:\n            continue\n        overlapping_ts_i = self.overlapping_timespans(i.timespan)\n        for j in overlapping_ts_i:\n            if j == i:\n                continue\n            if j.category == i.category:\n                conflicts.append((i, j))\n    if conflicts:\n        msg = \"Conflicting scopes in ScopedLinkValueList:\\n\"\n        WranglerLogger.error(msg + f\" Conflicts: \\n{conflicts}\")\n        raise ScopeLinkValueError(msg)\n\n    return self\n</code></pre>"},{"location":"api_roadway/#network_wrangler.models.roadway.types.ScopedLinkValueList.overlapping_timespans","title":"network_wrangler.models.roadway.types.ScopedLinkValueList.overlapping_timespans","text":"<pre><code>overlapping_timespans(timespan)\n</code></pre> <p>Identify overlapping timespans in the list.</p> Source code in <code>network_wrangler/models/roadway/types.py</code> <pre><code>def overlapping_timespans(self, timespan: Timespan):\n    \"\"\"Identify overlapping timespans in the list.\"\"\"\n    timespan_dt = str_to_time_list(timespan)\n    return [i for i in self if dt_overlaps(i.timespan_dt, timespan_dt)]\n</code></pre>"},{"location":"api_roadway/#roadway-links","title":"Roadway Links","text":"<p>Functions to read in and write out a RoadLinksTable.</p> <p>Functions for creating RoadLinksTables.</p> <p>Deletes links from RoadLinksTable.</p> <p>Edits RoadLinksTable properties.</p> <p>NOTE: Each public method will return a new, whole copy of the RoadLinksTable with associated edits. Private methods may return mutated originals.</p> <p>Usage:</p> <pre><code># Returns copy of links_df with lanes set to 2 for links in link_idx\nlinks_df = edit_link_property(links_df, link_idx, \"lanes\", {\"set\": 2})\n# Returns copy of links_df with price reduced by 50 for links in link_idx and raises error\n# if existing value doesn't match 100\nlinks_df = edit_link_properties(\n    links_df,\n    link_idx,\n    \"price\",\n    {\"existing\": 100, \"change\": -50},\n)\n# Returns copy of links_df with geometry of links with node_ids updated based on nodes_df\nlinks_df = edit_link_geometry_from_nodes(links_df, nodes_df, node_ids)\n</code></pre> <p>Functions to filter a RoadLinksTable based on various properties.</p> <p>Functions for updating roadway links with geometry from shapes.</p> <p>Utilities for filtering and querying scoped properties based on scoping dimensions.</p> <p>This module provides various utility functions for filtering and querying scoped properties based on scoping dimensions such as category and timespan. It includes functions for filtering scoped values based on non-overlapping or overlapping timespans, non-overlapping or overlapping categories, and matching exact category and timespan. It also includes functions for creating exploded dataframes for scoped properties and filtering them based on scope.</p> <p>Public Functions: - prop_for_scope: Creates a dataframe with the value of a property for a given category and     timespan. Can return maximum overlapping timespan value given a minimum number of overlapping     minutes, or strictly enforce timespans.</p> <p>Internal function terminology for scopes:</p> <ul> <li><code>matching</code> scope value: a scope that could be applied for a given category/timespan combination.     This includes the default scopes as well as scopes that are contained within the given     category AND timespan combination.</li> <li><code>overlapping</code> scope value: a scope that fully or partially overlaps a given category OR timespan     combination.  This includes the default scopes, all <code>matching</code> scopes and all scopes where     at lest one minute of timespan or one category overlap.</li> <li><code>conflicting</code> scope value: a scope that is overlapping but not matching for a given category/     timespan. By definition default scope values are not conflicting.</li> <li><code>independent</code> scope value: a scope value that is not overlapping.</li> </ul> <p>Usage:</p> <pre><code>model_links_df[\"lanes_AM_sov\"] = prop_for_scope(links_df, [\"6:00\":\"9:00\"], category=\"sov\")\n</code></pre> <p>Utilities for summarizing a RoadLinksTable.</p> <p>Utilities for validating a RoadLinksTable beyond its data model.</p> <p>Dataframe accessor shortcuts for RoadLinksTables allowing for easy filtering and editing.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.io.read_links","title":"network_wrangler.roadway.links.io.read_links","text":"<pre><code>read_links(filename, in_crs=LAT_LON_CRS, config=DefaultConfig, nodes_df=None, filter_to_nodes=False)\n</code></pre> <p>Reads links and returns a geodataframe of links conforming to RoadLinksTable.</p> <p>Sets index to be a copy of the primary key. Validates output dataframe using RoadLinksTable</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>file to read links in from.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system number any link geometries are stored in. Defaults to 4323.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig.</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>, default:                   <code>None</code> )           \u2013            <p>a RoadNodesTable to gather geometry from. Necesary if geometry is not provided. Defaults to None.</p> </li> <li> <code>filter_to_nodes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will filter links to only those that connect to nodes. Requires nodes_df to be provided. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/io.py</code> <pre><code>@validate_call_pyd\ndef read_links(\n    filename: Path,\n    in_crs: int = LAT_LON_CRS,\n    config: WranglerConfig = DefaultConfig,\n    nodes_df: DataFrame[RoadNodesTable] = None,\n    filter_to_nodes: bool = False,\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Reads links and returns a geodataframe of links conforming to RoadLinksTable.\n\n    Sets index to be a copy of the primary key.\n    Validates output dataframe using RoadLinksTable\n\n    Args:\n        filename (str): file to read links in from.\n        in_crs: coordinate reference system number any link geometries are stored in.\n            Defaults to 4323.\n        config: WranglerConfig instance. Defaults to DefaultConfig.\n        nodes_df: a RoadNodesTable to gather geometry from. Necesary if geometry is not\n            provided. Defaults to None.\n        filter_to_nodes: if True, will filter links to only those that connect to nodes. Requires\n            nodes_df to be provided. Defaults to False.\n    \"\"\"\n    WranglerLogger.info(f\"Reading links from {filename}.\")\n    start_t = time.time()\n    if filter_to_nodes is True and nodes_df is None:\n        msg = \"If filter_to_nodes is True, nodes_df must be provided.\"\n        raise ValueError(msg)\n\n    links_df = read_table(filename, read_speed=config.CPU.EST_PD_READ_SPEED)\n\n    if filter_to_nodes:\n        WranglerLogger.debug(\"Filtering links to only those that connect to nodes.\")\n        links_df = links_df[\n            links_df[\"A\"].isin(nodes_df.model_node_id) &amp; links_df[\"B\"].isin(nodes_df.model_node_id)\n        ]\n\n    WranglerLogger.debug(f\"Read {len(links_df)} links in {round(time.time() - start_t, 2)}.\")\n    links_df = data_to_links_df(links_df, in_crs=in_crs, nodes_df=nodes_df)\n    links_df.attrs[\"source_file\"] = filename\n    WranglerLogger.info(\n        f\"Read + transformed {len(links_df)} links from \\\n            {filename} in {round(time.time() - start_t, 2)}.\"\n    )\n    return links_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.io.write_links","title":"network_wrangler.roadway.links.io.write_links","text":"<pre><code>write_links(links_df, out_dir='.', convert_complex_properties_to_single_field=False, prefix='', file_format='json', overwrite=False, include_geometry=False)\n</code></pre> <p>Writes links to a file.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>DataFrame[RoadLinksTable] to write out.</p> </li> <li> <code>convert_complex_properties_to_single_field</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will convert complex properties to a single column consistent with v0 format.  This format is NOT valid with parquet and many other softwares. Defaults to False.</p> </li> <li> <code>out_dir</code>               (<code>Union[str, Path]</code>, default:                   <code>'.'</code> )           \u2013            <p>directory to write files to. Defaults to \u201c.\u201d.</p> </li> <li> <code>prefix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>prefix to add to the filename. Defaults to \u201c\u201d.</p> </li> <li> <code>file_format</code>               (<code>GeoFileTypes</code>, default:                   <code>'json'</code> )           \u2013            <p>file format to write out to. Defaults to \u201cjson\u201d.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will overwrite existing files. Defaults to False.</p> </li> <li> <code>include_geometry</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will include geometry in the output. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/io.py</code> <pre><code>@validate_call_pyd\ndef write_links(\n    links_df: DataFrame[RoadLinksTable],\n    out_dir: Union[str, Path] = \".\",\n    convert_complex_properties_to_single_field: bool = False,\n    prefix: str = \"\",\n    file_format: GeoFileTypes = \"json\",\n    overwrite: bool = False,\n    include_geometry: bool = False,\n) -&gt; None:\n    \"\"\"Writes links to a file.\n\n    Args:\n        links_df: DataFrame[RoadLinksTable] to write out.\n        convert_complex_properties_to_single_field: if True, will convert complex properties to a\n            single column consistent with v0 format.  This format is NOT valid\n            with parquet and many other softwares. Defaults to False.\n        out_dir: directory to write files to. Defaults to \".\".\n        prefix: prefix to add to the filename. Defaults to \"\".\n        file_format: file format to write out to. Defaults to \"json\".\n        overwrite: if True, will overwrite existing files. Defaults to False.\n        include_geometry: if True, will include geometry in the output. Defaults to False.\n    \"\"\"\n    if not include_geometry and file_format == \"geojson\":\n        file_format = \"json\"\n\n    links_file = Path(out_dir) / f\"{prefix}link.{file_format}\"\n\n    if convert_complex_properties_to_single_field:\n        if file_format == \"parquet\":\n            WranglerLogger.error(\n                \"convert_complex_properties_to_single_column is not supported with parquet. \\\n                Setting to False.\"\n            )\n            convert_complex_properties_to_single_field = False\n        v1_links_df = links_df.copy()\n        links_df = translate_links_df_v1_to_v0(v1_links_df)\n\n    if not include_geometry:\n        geo_cols = links_df.select_dtypes(include=[\"geometry\"]).columns.tolist()\n        links_df = pd.DataFrame(links_df)\n        links_df = links_df.drop(columns=geo_cols)\n\n    links_df = order_fields_from_data_model(links_df, RoadLinksTable)\n    write_table(links_df, links_file, overwrite=overwrite)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.create.copy_links","title":"network_wrangler.roadway.links.create.copy_links","text":"<pre><code>copy_links(links_df, link_id_lookup, node_id_lookup, updated_geometry_col=None, nodes_df=None, offset_meters=-5, copy_properties=None, rename_properties=None, name_prefix='copy of', validate=True)\n</code></pre> <p>Copy links and optionally offset them.</p> <p>Will get geometry from another column if provided, otherwise will use nodes_df and then offset_meters to offset from previous geometry.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>links dataframe of links to copy</p> </li> <li> <code>link_id_lookup</code>               (<code>dict[int, int]</code>)           \u2013            <p>lookup of new link ID from old link id.</p> </li> <li> <code>node_id_lookup</code>               (<code>dict[int, int]</code>)           \u2013            <p>lookup of new node ID from old node id.</p> </li> <li> <code>updated_geometry_col</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>name of the column to store the updated geometry. Will nodes_df for missing geometries if provided and offset_meters if not. Defaults to None.</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>, default:                   <code>None</code> )           \u2013            <p>nodes dataframe of nodes to use for new link geometry. Defaults to None. If not provided, will use offset_meters.</p> </li> <li> <code>offset_meters</code>               (<code>float</code>, default:                   <code>-5</code> )           \u2013            <p>distance to offset links if nodes_df is not provided. Defaults to -5.</p> </li> <li> <code>copy_properties</code>               (<code>list[str]</code>, default:                   <code>None</code> )           \u2013            <p>properties to keep. Defaults to [].</p> </li> <li> <code>rename_properties</code>               (<code>dict[str, str]</code>, default:                   <code>None</code> )           \u2013            <p>properties to rename. Defaults to {}. Will default to REQUIRED_RENAMES if keys in that dict are not provided.</p> </li> <li> <code>name_prefix</code>               (<code>str</code>, default:                   <code>'copy of'</code> )           \u2013            <p>format string for new names. Defaults to \u201ccopy of\u201d.</p> </li> <li> <code>validate</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to validate the output dataframe. Defaults to True. If set to false, you should validate the output dataframe before using it.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadLinksTable]</code>           \u2013            <p>DataFrame[RoadLinksTable]: offset links dataframe</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/create.py</code> <pre><code>def copy_links(\n    links_df: DataFrame[RoadLinksTable],\n    link_id_lookup: dict[int, int],\n    node_id_lookup: dict[int, int],\n    updated_geometry_col: Optional[str] = None,\n    nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    offset_meters: float = -5,\n    copy_properties: Optional[list[str]] = None,\n    rename_properties: Optional[dict[str, str]] = None,\n    name_prefix: str = \"copy of\",\n    validate: bool = True,\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Copy links and optionally offset them.\n\n    Will get geometry from another column if provided, otherwise will use nodes_df and then\n    offset_meters to offset from previous geometry.\n\n    Args:\n        links_df (DataFrame[RoadLinksTable]): links dataframe of links to copy\n        link_id_lookup (dict[int, int]): lookup of new link ID from old link id.\n        node_id_lookup (dict[int, int]): lookup of new node ID from old node id.\n        updated_geometry_col (str): name of the column to store the updated geometry.\n            Will nodes_df for missing geometries if provided and offset_meters if not.\n            Defaults to None.\n        nodes_df (DataFrame[RoadNodesTable]): nodes dataframe of nodes to use for new\n            link geometry. Defaults to None. If not provided, will use offset_meters.\n        offset_meters (float): distance to offset links if nodes_df is not provided.\n            Defaults to -5.\n        copy_properties (list[str], optional): properties to keep. Defaults to [].\n        rename_properties (dict[str, str], optional): properties to rename. Defaults to {}.\n            Will default to REQUIRED_RENAMES if keys in that dict are not provided.\n        name_prefix (str, optional): format string for new names. Defaults to \"copy of\".\n        validate (bool, optional): whether to validate the output dataframe. Defaults to True.\n            If set to false, you should validate the output dataframe before using it.\n\n    Returns:\n        DataFrame[RoadLinksTable]: offset links dataframe\n    \"\"\"\n    copy_properties = copy_properties or []\n    rename_properties = rename_properties or {}\n\n    REQUIRED_KEEP = [\"A\", \"B\", \"name\", \"distance\", \"geometry\", \"model_link_id\"]\n\n    # Should rename these columns to these columns - unless overriden by rename_properties\n    REQUIRED_RENAMES = {\n        \"A\": \"source_A\",\n        \"B\": \"source_B\",\n        \"model_link_id\": \"source_model_link_id\",\n        \"geometry\": \"source_geometry\",\n    }\n    # cannot rename a column TO these fields\n    FORBIDDEN_RENAMES = [\"A\", \"B\", \"model_link_id\", \"geometry\", \"name\"]\n    WranglerLogger.debug(f\"Copying {len(links_df)} links.\")\n\n    rename_properties = {k: v for k, v in rename_properties.items() if v not in FORBIDDEN_RENAMES}\n    REQUIRED_RENAMES.update(rename_properties)\n    # rename if different, otherwise copy\n    rename_properties = {k: v for k, v in REQUIRED_RENAMES.items() if k != v}\n    copy_properties += [\n        k for k, v in REQUIRED_RENAMES.items() if k == v and k not in copy_properties\n    ]\n\n    _missing_copy_properties = set(copy_properties) - set(links_df.columns)\n    if _missing_copy_properties:\n        WranglerLogger.warning(\n            f\"Specified properties to copy not found in links_df.\\\n            Proceeding without copying: {_missing_copy_properties}\"\n        )\n        copy_properties = [c for c in copy_properties if c not in _missing_copy_properties]\n\n    _missing_rename_properties = set(rename_properties.keys()) - set(links_df.columns)\n    if _missing_rename_properties:\n        WranglerLogger.warning(\n            f\"Specified properties to rename not found in links_df.\\\n            Proceeding without renaming: {_missing_rename_properties}\"\n        )\n        rename_properties = {\n            k: v for k, v in rename_properties.items() if k not in _missing_rename_properties\n        }\n\n    offset_links = copy.deepcopy(links_df)\n    drop_before_rename = [k for k in rename_properties.values() if k in offset_links.columns]\n    offset_links = offset_links.drop(columns=drop_before_rename)\n    offset_links = offset_links.rename(columns=rename_properties)\n\n    offset_links[\"A\"] = offset_links[\"source_A\"].map(node_id_lookup)\n    offset_links[\"B\"] = offset_links[\"source_B\"].map(node_id_lookup)\n    offset_links[\"model_link_id\"] = offset_links[\"source_model_link_id\"].map(link_id_lookup)\n    offset_links[\"name\"] = name_prefix + \" \" + offset_links[\"name\"]\n\n    if updated_geometry_col is not None:\n        offset_links = offset_links.rename(columns={updated_geometry_col: \"geometry\"})\n    else:\n        offset_links[\"geometry\"] = None\n\n    if nodes_df is None and offset_links.geometry.isna().values.any():\n        WranglerLogger.debug(\n            f\"Adding node-based geometry with for {sum(offset_links.geometry.isna())} links.\"\n        )\n        offset_links.loc[[offset_links.geometry.isna(), \"geometry\"]] = offset_geometry_meters(\n            offset_links[\"geometry\"],\n            offset_meters,\n        )\n    if offset_links.geometry.isna().values.any():\n        WranglerLogger.debug(\n            f\"Adding offset geometry with for {sum(offset_links.geometry.isna())} links.\"\n        )\n        offset_links.loc[[offset_links.geometry.isna(), \"geometry\"]] = linestring_from_nodes(\n            offset_links, nodes_df\n        )\n\n    offset_links = offset_links.set_geometry(\"geometry\", inplace=False)\n    offset_links.crs = links_df.crs\n    offset_links[\"distance\"] = length_of_linestring_miles(offset_links[\"geometry\"])\n\n    keep_properties = list(set(copy_properties + REQUIRED_KEEP + list(rename_properties.values())))\n    offset_links = offset_links[keep_properties]\n\n    # create and set index for new model_link_ids\n    # offset_links.attrs.update(RoadLinksAttrs)\n    offset_links = offset_links.reset_index(drop=True)\n    offset_links = set_df_index_to_pk(offset_links)\n\n    if validate:\n        offset_links = validate_df_to_model(offset_links, RoadLinksTable)\n    else:\n        WranglerLogger.warning(\n            \"Skipping validation of offset links. Validate to RoadLinksTable before using.\"\n        )\n    return offset_links\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.create.data_to_links_df","title":"network_wrangler.roadway.links.create.data_to_links_df","text":"<pre><code>data_to_links_df(links_df, in_crs=LAT_LON_CRS, nodes_df=None)\n</code></pre> <p>Create a links dataframe from list of link properties + link geometries or associated nodes.</p> <p>Sets index to be a copy of the primary key. Validates output dataframe using LinksSchema.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame</code>)           \u2013            <p>df or list of dictionaries of link properties</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system id for incoming links if geometry already exists. Defaults to LAT_LON_CRS. Will convert everything to LAT_LON_CRSif it doesn\u2019t match.</p> </li> <li> <code>nodes_df</code>               (<code>Union[None, DataFrame[RoadNodesTable]]</code>, default:                   <code>None</code> )           \u2013            <p>Associated notes geodataframe to use if geometries or location references not present. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadLinksTable]</code>           \u2013            <p>pd.DataFrame: description</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/create.py</code> <pre><code>@validate_call_pyd\ndef data_to_links_df(\n    links_df: Union[pd.DataFrame, list[dict]],\n    in_crs: int = LAT_LON_CRS,\n    nodes_df: Union[None, DataFrame[RoadNodesTable]] = None,\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Create a links dataframe from list of link properties + link geometries or associated nodes.\n\n    Sets index to be a copy of the primary key.\n    Validates output dataframe using LinksSchema.\n\n    Args:\n        links_df (pd.DataFrame): df or list of dictionaries of link properties\n        in_crs: coordinate reference system id for incoming links if geometry already exists.\n            Defaults to LAT_LON_CRS. Will convert everything to LAT_LON_CRSif it doesn't match.\n        nodes_df: Associated notes geodataframe to use if geometries or location references not\n            present. Defaults to None.\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    WranglerLogger.debug(f\"Creating {len(links_df)} links.\")\n    if not isinstance(links_df, pd.DataFrame):\n        links_df = pd.DataFrame(links_df)\n    # WranglerLogger.debug(f\"data_to_links_df.links_df input: \\n{links_df.head}.\")\n\n    v0_link_properties = detect_v0_scoped_link_properties(links_df)\n    if v0_link_properties:\n        links_df = translate_links_df_v0_to_v1(links_df, complex_properties=v0_link_properties)\n\n    links_df = _fill_missing_link_geometries_from_nodes(links_df, nodes_df)\n    # Now that have geometry, make sure is GDF\n    links_df = coerce_gdf(links_df, in_crs=in_crs, geometry=links_df.geometry)\n\n    links_df = _fill_missing_distance_from_geometry(links_df)\n\n    links_df = _harmonize_crs(links_df, LAT_LON_CRS)\n    nodes_df = _harmonize_crs(nodes_df, LAT_LON_CRS)\n\n    links_df.attrs.update(RoadLinksAttrs)\n    links_df = set_df_index_to_pk(links_df)\n    links_df.gdf_name = links_df.attrs[\"name\"]\n    links_df = validate_df_to_model(links_df, RoadLinksTable)\n\n    if len(links_df) &lt; SMALL_RECS:\n        WranglerLogger.debug(\n            f\"New Links: \\n{links_df[links_df.attrs['display_cols'] + ['geometry']]}\"\n        )\n    else:\n        WranglerLogger.debug(f\"{len(links_df)} new links.\")\n\n    return links_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.create.shape_id_from_link_geometry","title":"network_wrangler.roadway.links.create.shape_id_from_link_geometry","text":"<pre><code>shape_id_from_link_geometry(links_df)\n</code></pre> <p>Create a unique shape_id from the geometry of the link.</p> Source code in <code>network_wrangler/roadway/links/create.py</code> <pre><code>def shape_id_from_link_geometry(\n    links_df: pd.DataFrame,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Create a unique shape_id from the geometry of the link.\"\"\"\n    shape_ids = links_df[\"geometry\"].apply(create_unique_shape_id)\n    return shape_ids\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.delete.check_deletion_breaks_transit_shapes","title":"network_wrangler.roadway.links.delete.check_deletion_breaks_transit_shapes","text":"<pre><code>check_deletion_breaks_transit_shapes(links_df, del_link_ids, transit_net)\n</code></pre> <p>Check if any transit shapes go on the deleted links.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>DataFrame[RoadLinksTable] to delete links from.</p> </li> <li> <code>del_link_ids</code>               (<code>list[int]</code>)           \u2013            <p>list of link ids to delete.</p> </li> <li> <code>transit_net</code>               (<code>TransitNetwork</code>)           \u2013            <p>input TransitNetwork</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/delete.py</code> <pre><code>def check_deletion_breaks_transit_shapes(\n    links_df: DataFrame[RoadLinksTable], del_link_ids: list[int], transit_net: TransitNetwork\n) -&gt; bool:\n    \"\"\"Check if any transit shapes go on the deleted links.\n\n    Args:\n        links_df: DataFrame[RoadLinksTable] to delete links from.\n        del_link_ids: list of link ids to delete.\n        transit_net: input TransitNetwork\n\n    returns: true if there are broken shapes, false otherwise\n    \"\"\"\n    missing_links = shape_links_without_road_links(\n        transit_net.feed.shapes, links_df[~links_df.index.isin(del_link_ids)]\n    )\n    if not missing_links.empty:\n        msg = f\"Deletion breaks transit shapes:\\n{missing_links}\"\n        WranglerLogger.warning(msg)\n        return True\n    return False\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.delete.delete_links_by_ids","title":"network_wrangler.roadway.links.delete.delete_links_by_ids","text":"<pre><code>delete_links_by_ids(links_df, del_link_ids, ignore_missing=False, transit_net=None)\n</code></pre> <p>Delete links from a links table.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>DataFrame[RoadLinksTable] to delete links from.</p> </li> <li> <code>del_link_ids</code>               (<code>list[int]</code>)           \u2013            <p>list of link ids to delete.</p> </li> <li> <code>ignore_missing</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will not raise an error if a link id to delete is not in the network. Defaults to False.</p> </li> <li> <code>transit_net</code>               (<code>Optional[TransitNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>If provided, will check TransitNetwork and warn if deletion breaks transit shapes. Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/delete.py</code> <pre><code>def delete_links_by_ids(\n    links_df: DataFrame[RoadLinksTable],\n    del_link_ids: list[int],\n    ignore_missing: bool = False,\n    transit_net: Optional[TransitNetwork] = None,\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Delete links from a links table.\n\n    Args:\n        links_df: DataFrame[RoadLinksTable] to delete links from.\n        del_link_ids: list of link ids to delete.\n        ignore_missing: if True, will not raise an error if a link id to delete is not in\n            the network. Defaults to False.\n        transit_net: If provided, will check TransitNetwork and warn if deletion breaks transit shapes. Defaults to None.\n    \"\"\"\n    WranglerLogger.debug(f\"Deleting links with ids: \\n{del_link_ids}\")\n    _missing = set(del_link_ids) - set(links_df.index)\n    if _missing:\n        WranglerLogger.warning(f\"Links in network not there to delete: \\n{_missing}\")\n        if not ignore_missing:\n            msg = \"Links to delete are not in the network.\"\n            raise LinkDeletionError(msg)\n\n    if transit_net is not None:\n        check_deletion_breaks_transit_shapes(links_df, del_link_ids, transit_net)\n    return links_df.drop(labels=del_link_ids, errors=\"ignore\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.edit.edit_link_geometry_from_nodes","title":"network_wrangler.roadway.links.edit.edit_link_geometry_from_nodes","text":"<pre><code>edit_link_geometry_from_nodes(links_df, nodes_df, node_ids)\n</code></pre> <p>Returns a copy of links with updated geometry for given links for a given list of nodes.</p> <p>Should be called by any function that changes a node location.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>RoadLinksTable to update</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>RoadNodesTable to get updated node geometry from</p> </li> <li> <code>node_ids</code>               (<code>list[int]</code>)           \u2013            <p>list of node PKs with updated geometry</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/edit.py</code> <pre><code>@validate_call_pyd\ndef edit_link_geometry_from_nodes(\n    links_df: DataFrame[RoadLinksTable],\n    nodes_df: DataFrame[RoadNodesTable],\n    node_ids: list[int],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Returns a copy of links with updated geometry for given links for a given list of nodes.\n\n    Should be called by any function that changes a node location.\n\n    Args:\n        links_df: RoadLinksTable to update\n        nodes_df: RoadNodesTable to get updated node geometry from\n        node_ids: list of node PKs with updated geometry\n    \"\"\"\n    # WranglerLogger.debug(f\"nodes_df.loc[node_ids]:\\n {nodes_df.loc[node_ids]}\")\n    # TODO write wrapper on validate call so don't have to do this\n    links_df.attrs.update(RoadLinksAttrs)\n    nodes_df.attrs.update(RoadNodesAttrs)\n    links_df = copy.deepcopy(links_df)\n\n    updated_a_geometry = update_nodes_in_linestring_geometry(\n        links_df.loc[links_df.A.isin(node_ids)], nodes_df, 0\n    )\n    links_df.update(updated_a_geometry)\n\n    updated_b_geometry = update_nodes_in_linestring_geometry(\n        links_df.loc[links_df.B.isin(node_ids)], nodes_df, -1\n    )\n    links_df.update(updated_b_geometry)\n\n    _a_or_b_mask = links_df.A.isin(node_ids) | links_df.B.isin(node_ids)\n    WranglerLogger.debug(f\"links_df: \\n{links_df.loc[_a_or_b_mask, ['A', 'B', 'geometry']]}\")\n    return links_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.edit.edit_link_properties","title":"network_wrangler.roadway.links.edit.edit_link_properties","text":"<pre><code>edit_link_properties(links_df, link_idx, property_changes, project_name=None, config=DefaultConfig)\n</code></pre> <p>Return copy of RoadLinksTable with edited link properties for a list of links.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>links to edit</p> </li> <li> <code>link_idx</code>               (<code>list</code>)           \u2013            <p>list of link indices to change</p> </li> <li> <code>property_changes</code>               (<code>dict[str, dict]</code>)           \u2013            <p>dictionary of property changes</p> </li> <li> <code>project_name</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>optional name of the project to be applied</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/edit.py</code> <pre><code>@validate_call_pyd\ndef edit_link_properties(\n    links_df: DataFrame[RoadLinksTable],\n    link_idx: list,\n    property_changes: dict[str, dict],\n    project_name: Optional[str] = None,\n    config: WranglerConfig = DefaultConfig,\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Return copy of RoadLinksTable with edited link properties for a list of links.\n\n    Args:\n        links_df: links to edit\n        link_idx: list of link indices to change\n        property_changes: dictionary of property changes\n        project_name: optional name of the project to be applied\n        config: WranglerConfig instance. Defaults to DefaultConfig.\n    \"\"\"\n    links_df = copy.deepcopy(links_df)\n    # TODO write wrapper on validate call so don't have to do this\n    links_df.attrs.update(RoadLinksAttrs)\n    ml_property_changes = bool([k for k in property_changes if k.startswith(\"ML_\")])\n    existing_managed_lanes = len(links_df.loc[link_idx].of_type.managed) == 0\n    flag_create_managed_lane = existing_managed_lanes &amp; ml_property_changes\n\n    # WranglerLogger.debug(f\"property_changes: \\n{property_changes}\")\n    for property, prop_change in property_changes.items():\n        WranglerLogger.debug(f\"prop_dict: \\n{prop_change}\")\n        links_df = _edit_link_property(\n            links_df,\n            link_idx,\n            property,\n            prop_change,\n            config=config,\n        )\n\n    # Only want to set this once per project.\n    if project_name is not None:\n        links_df.loc[link_idx, \"projects\"] += f\"{project_name},\"\n\n    # if a managed lane created without access or egress, set it to True for all selected links\n    if flag_create_managed_lane:\n        if links_df.loc[link_idx].ML_access_point.sum() == 0:\n            WranglerLogger.warning(\n                \"Access point not set in project card for a new managed lane.\\\n                                   \\nSetting ML_access_point to True for selected links.\"\n            )\n            links_df.loc[link_idx, \"ML_access_point\"] = True\n        if links_df.loc[link_idx].ML_egress_point.sum() == 0:\n            WranglerLogger.warning(\n                \"Egress point not set in project card for a new managed lane.\\\n                                   \\nSetting ML_egress_point to True for selected links.\"\n            )\n            links_df.loc[link_idx, \"ML_egress_point\"] = True\n\n    links_df = validate_df_to_model(links_df, RoadLinksTable)\n    return links_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_link_properties_managed_lanes","title":"network_wrangler.roadway.links.filters.filter_link_properties_managed_lanes","text":"<pre><code>filter_link_properties_managed_lanes(links_df)\n</code></pre> <p>Filters links dataframe to only include managed lanes.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_link_properties_managed_lanes(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include managed lanes.\"\"\"\n    return [\n        i\n        for i in links_df.columns\n        if i.startswith(\"ML_\")\n        or (i.startswith(\"sc_ML_\") and i not in [\"ML_access_point\", \"ML_egress_point\"])\n    ]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_access_dummy","title":"network_wrangler.roadway.links.filters.filter_links_access_dummy","text":"<pre><code>filter_links_access_dummy(links_df)\n</code></pre> <p>Filters links dataframe to only include all access dummy links connecting managed lanes.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_access_dummy(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all access dummy links connecting managed lanes.\"\"\"\n    return links_df.loc[links_df[\"roadway\"] == \"ml_access_point\"]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_centroid_connector","title":"network_wrangler.roadway.links.filters.filter_links_centroid_connector","text":"<pre><code>filter_links_centroid_connector(links_df)\n</code></pre> <p>Filters links dataframe to only include all general purpose links.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_centroid_connector(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all general purpose links.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_drive_access","title":"network_wrangler.roadway.links.filters.filter_links_drive_access","text":"<pre><code>filter_links_drive_access(links_df)\n</code></pre> <p>Filters links dataframe to only include all links that vehicles can operate on.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_drive_access(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all links that vehicles can operate on.\"\"\"\n    return filter_links_to_modes(links_df, \"drive\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_dummy","title":"network_wrangler.roadway.links.filters.filter_links_dummy","text":"<pre><code>filter_links_dummy(links_df)\n</code></pre> <p>Filters links dataframe to only include all dummy links connecting managed lanes.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_dummy(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all dummy links connecting managed lanes.\"\"\"\n    return links_df.loc[\n        (links_df[\"roadway\"] == \"ml_access_point\") | (links_df[\"roadway\"] == \"ml_egress_point\")\n    ]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_egress_dummy","title":"network_wrangler.roadway.links.filters.filter_links_egress_dummy","text":"<pre><code>filter_links_egress_dummy(links_df)\n</code></pre> <p>Filters links dataframe to only include all egress dummy links connecting managed lanes.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_egress_dummy(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all egress dummy links connecting managed lanes.\"\"\"\n    return links_df.loc[links_df[\"roadway\"] == \"ml_egress_point\"]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_general_purpose","title":"network_wrangler.roadway.links.filters.filter_links_general_purpose","text":"<pre><code>filter_links_general_purpose(links_df)\n</code></pre> <p>Filters links dataframe to only include all general purpose links.</p> <p>NOTE: This will only return links without parallel managed lanes in a non-model-ready network.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_general_purpose(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all general purpose links.\n\n    NOTE: This will only return links without parallel managed lanes in a non-model-ready network.\n    \"\"\"\n    return links_df.loc[links_df[\"managed\"] &lt; 1]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_general_purpose_no_parallel_managed","title":"network_wrangler.roadway.links.filters.filter_links_general_purpose_no_parallel_managed","text":"<pre><code>filter_links_general_purpose_no_parallel_managed(links_df)\n</code></pre> <p>Filters links df to only include general purpose links without parallel managed lanes.</p> <p>NOTE: This will only return links without parallel managed lanes in a non-model-ready network.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_general_purpose_no_parallel_managed(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links df to only include general purpose links without parallel managed lanes.\n\n    NOTE: This will only return links without parallel managed lanes in a non-model-ready network.\n    \"\"\"\n    return links_df.loc[links_df[\"managed\"] == 0]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_managed_lanes","title":"network_wrangler.roadway.links.filters.filter_links_managed_lanes","text":"<pre><code>filter_links_managed_lanes(links_df)\n</code></pre> <p>Filters links dataframe to only include managed lanes.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_managed_lanes(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include managed lanes.\"\"\"\n    return links_df.loc[links_df[\"managed\"] == 1]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_not_in_ids","title":"network_wrangler.roadway.links.filters.filter_links_not_in_ids","text":"<pre><code>filter_links_not_in_ids(links_df, link_ids)\n</code></pre> <p>Filters links dataframe to NOT have link_ids.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_not_in_ids(\n    links_df: DataFrame[RoadLinksTable], link_ids: Union[list[int], pd.Series]\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to NOT have link_ids.\"\"\"\n    return links_df.loc[~links_df[\"model_link_id\"].isin(link_ids)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_parallel_general_purpose","title":"network_wrangler.roadway.links.filters.filter_links_parallel_general_purpose","text":"<pre><code>filter_links_parallel_general_purpose(links_df)\n</code></pre> <p>Filters links dataframe to only include general purpose links parallel to managed.</p> <p>NOTE This will return Null when not a model network.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_parallel_general_purpose(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include general purpose links parallel to managed.\n\n    NOTE This will return Null when not a model network.\n    \"\"\"\n    return links_df.loc[links_df[\"managed\"] == -1]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_pedbike_only","title":"network_wrangler.roadway.links.filters.filter_links_pedbike_only","text":"<pre><code>filter_links_pedbike_only(links_df)\n</code></pre> <p>Filters links dataframe to only include links that only ped/bikes can be on.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_pedbike_only(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include links that only ped/bikes can be on.\"\"\"\n    return links_df.loc[\n        (\n            ((links_df[\"walk_access\"].astype(bool)) | (links_df[\"bike_access\"].astype(bool)))\n            &amp; ~(links_df[\"drive_access\"].astype(bool))\n        )\n    ]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_to_ids","title":"network_wrangler.roadway.links.filters.filter_links_to_ids","text":"<pre><code>filter_links_to_ids(links_df, link_ids)\n</code></pre> <p>Filters links dataframe by link_ids.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_to_ids(\n    links_df: DataFrame[RoadLinksTable], link_ids: list[int]\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe by link_ids.\"\"\"\n    return links_df.loc[links_df[\"model_link_id\"].isin(link_ids)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_to_ml_access_points","title":"network_wrangler.roadway.links.filters.filter_links_to_ml_access_points","text":"<pre><code>filter_links_to_ml_access_points(links_df)\n</code></pre> <p>Filters links dataframe to only include all managed lane access points.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_to_ml_access_points(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all managed lane access points.\"\"\"\n    return links_df.loc[links_df[\"ML_access_point\"].fillna(False)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_to_ml_egress_points","title":"network_wrangler.roadway.links.filters.filter_links_to_ml_egress_points","text":"<pre><code>filter_links_to_ml_egress_points(links_df)\n</code></pre> <p>Filters links dataframe to only include all managed lane egress points.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_to_ml_egress_points(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all managed lane egress points.\"\"\"\n    return links_df.loc[links_df[\"ML_egress_point\"].fillna(False)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_to_modes","title":"network_wrangler.roadway.links.filters.filter_links_to_modes","text":"<pre><code>filter_links_to_modes(links_df, modes)\n</code></pre> <p>Filters links dataframe to only include links that are accessible by the modes in the list.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>RoadLinksTable</code>)           \u2013            <p>links dataframe</p> </li> <li> <code>modes</code>               (<code>List[str]</code>)           \u2013            <p>list of modes to filter by.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RoadLinksTable</code> (              <code>DataFrame[RoadLinksTable]</code> )          \u2013            <p>filtered links dataframe</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_to_modes(\n    links_df: DataFrame[RoadLinksTable], modes: Union[str, list[str]]\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include links that are accessible by the modes in the list.\n\n    Args:\n        links_df (RoadLinksTable): links dataframe\n        modes (List[str]): list of modes to filter by.\n\n    Returns:\n        RoadLinksTable: filtered links dataframe\n    \"\"\"\n    if \"any\" in modes:\n        return links_df\n    if isinstance(modes, str):\n        modes = [modes]\n    _mode_link_props = list({m for m in modes for m in MODES_TO_NETWORK_LINK_VARIABLES[m]})\n    return links_df.loc[links_df[_mode_link_props].any(axis=1)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_to_node_ids","title":"network_wrangler.roadway.links.filters.filter_links_to_node_ids","text":"<pre><code>filter_links_to_node_ids(links_df, node_ids)\n</code></pre> <p>Filters links dataframe to only include links with either A or B in node_ids.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_to_node_ids(\n    links_df: DataFrame[RoadLinksTable], node_ids: list[int]\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include links with either A or B in node_ids.\"\"\"\n    return links_df.loc[links_df[\"A\"].isin(node_ids) | links_df[\"B\"].isin(node_ids)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_to_path","title":"network_wrangler.roadway.links.filters.filter_links_to_path","text":"<pre><code>filter_links_to_path(links_df, node_id_path_list, ignore_missing=False)\n</code></pre> <p>Return selection of links dataframe with nodes along path defined by node_id_path_list.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>Links dataframe to select from</p> </li> <li> <code>node_id_path_list</code>               (<code>list[int]</code>)           \u2013            <p>List of node ids.</p> </li> <li> <code>ignore_missing</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will ignore if links noted by path node sequence don\u2019t exist in links_df and will just return what does exist. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_to_path(\n    links_df: DataFrame[RoadLinksTable],\n    node_id_path_list: list[int],\n    ignore_missing: bool = False,\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Return selection of links dataframe with nodes along path defined by node_id_path_list.\n\n    Args:\n        links_df: Links dataframe to select from\n        node_id_path_list: List of node ids.\n        ignore_missing: if True, will ignore if links noted by path node sequence don't exist in\n            links_df and will just return what does exist. Defaults to False.\n    \"\"\"\n    ab_pairs = [node_id_path_list[i : i + 2] for i, _ in enumerate(node_id_path_list)][:-1]\n    path_links_df = pd.DataFrame(ab_pairs, columns=[\"A\", \"B\"])\n\n    selected_links_df = path_links_df.merge(\n        links_df[[\"A\", \"B\", \"model_link_id\"]],\n        how=\"left\",\n        on=[\"A\", \"B\"],\n        indicator=True,\n    )\n    selected_link_ds = selected_links_df.model_link_id.unique().tolist()\n\n    if not ignore_missing:\n        missing_links_df = selected_links_df.loc[\n            selected_links_df._merge == \"left_only\", [\"A\", \"B\"]\n        ]\n        if len(missing_links_df):\n            WranglerLogger.error(f\"! Path links missing in links_df \\n {missing_links_df}\")\n            msg = \"Path links missing in links_df.\"\n            raise ValueError(msg)\n\n    return filter_links_to_ids(links_df, selected_link_ds)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_transit_access","title":"network_wrangler.roadway.links.filters.filter_links_transit_access","text":"<pre><code>filter_links_transit_access(links_df)\n</code></pre> <p>Filters links dataframe to only include all links that transit can operate on.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_transit_access(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all links that transit can operate on.\"\"\"\n    return filter_links_to_modes(links_df, \"transit\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.filters.filter_links_transit_only","title":"network_wrangler.roadway.links.filters.filter_links_transit_only","text":"<pre><code>filter_links_transit_only(links_df)\n</code></pre> <p>Filters links dataframe to only include all links that only transit can operate on.</p> Source code in <code>network_wrangler/roadway/links/filters.py</code> <pre><code>def filter_links_transit_only(\n    links_df: DataFrame[RoadLinksTable],\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Filters links dataframe to only include all links that only transit can operate on.\"\"\"\n    return links_df.loc[(links_df[\"bus_only\"].astype(bool)) | (links_df[\"rail_only\"].astype(bool))]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.geo.true_shape","title":"network_wrangler.roadway.links.geo.true_shape","text":"<pre><code>true_shape(links_df, shapes_df)\n</code></pre> <p>Updates geometry to have shape of shapes_df where available.</p> Source code in <code>network_wrangler/roadway/links/geo.py</code> <pre><code>def true_shape(\n    links_df: DataFrame[RoadLinksTable], shapes_df: DataFrame[RoadShapesTable]\n) -&gt; DataFrame[RoadLinksTable]:\n    \"\"\"Updates geometry to have shape of shapes_df where available.\"\"\"\n    return update_df_by_col_value(links_df, shapes_df, \"shape_id\", properties=[\"geometry\"])\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.scopes.prop_for_scope","title":"network_wrangler.roadway.links.scopes.prop_for_scope","text":"<pre><code>prop_for_scope(links_df, prop_name, timespan=DEFAULT_TIMESPAN, category=DEFAULT_CATEGORY, strict_timespan_match=False, min_overlap_minutes=60, allow_default=True)\n</code></pre> <p>Creates a df with the value of a property for a given category and timespan.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>(RoadLinksTable</p> </li> <li> <code>prop_name</code>               (<code>str</code>)           \u2013            <p>name of property to query</p> </li> <li> <code>timespan</code>               (<code>Union[None, list[TimeString]]</code>, default:                   <code>DEFAULT_TIMESPAN</code> )           \u2013            <p>TimespanString of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> </li> <li> <code>category</code>               (<code>Union[str, int, None]</code>, default:                   <code>DEFAULT_CATEGORY</code> )           \u2013            <p>category to query orig_df for overlapping records. Defaults to None.</p> </li> <li> <code>strict_timespan_match</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>boolean indicating if the returned df should only contain records that fully contain the query timespan. If set to True, min_overlap_minutes does not apply. Defaults to False.</p> </li> <li> <code>min_overlap_minutes</code>               (<code>int</code>, default:                   <code>60</code> )           \u2013            <p>minimum number of minutes the timespans need to overlap to keep. Defaults to 0.</p> </li> <li> <code>allow_default</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>boolean indicating if the default value should be returned if no scoped values are found. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame with <code>model_link_id</code> and <code>prop_name</code></p> </li> </ul> Source code in <code>network_wrangler/roadway/links/scopes.py</code> <pre><code>@validate_call_pyd\ndef prop_for_scope(\n    links_df: DataFrame[RoadLinksTable],\n    prop_name: str,\n    timespan: Union[None, list[TimeString]] = DEFAULT_TIMESPAN,\n    category: Union[str, int, None] = DEFAULT_CATEGORY,\n    strict_timespan_match: bool = False,\n    min_overlap_minutes: int = 60,\n    allow_default: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Creates a df with the value of a property for a given category and timespan.\n\n    Args:\n        links_df:(RoadLinksTable\n        prop_name: name of property to query\n        timespan: TimespanString of format ['HH:MM','HH:MM'] to query orig_df for overlapping\n            records.\n        category: category to query orig_df for overlapping records. Defaults to None.\n        strict_timespan_match: boolean indicating if the returned df should only contain\n            records that fully contain the query timespan. If set to True, min_overlap_minutes\n            does not apply. Defaults to False.\n        min_overlap_minutes: minimum number of minutes the timespans need to overlap to keep.\n            Defaults to 0.\n        allow_default: boolean indicating if the default value should be returned if no scoped\n            values are found. Defaults to True.\n\n    Returns:\n        pd.DataFrame with `model_link_id` and `prop_name`\n    \"\"\"\n    links_df = validate_df_to_model(links_df, RoadLinksTable)\n    timespan = timespan if timespan is not None else DEFAULT_TIMESPAN\n    category = category if category is not None else DEFAULT_CATEGORY\n\n    if prop_name not in links_df.columns:\n        msg = f\"{prop_name} not in dataframe.\"\n        raise ValueError(msg)\n\n    # Check if scoped values even exist and if can just return the default.\n    if f\"sc_{prop_name}\" not in links_df.columns or links_df[f\"sc_{prop_name}\"].isna().all():\n        if not allow_default:\n            msg = f\"{prop_name} does not have a scoped property column or it is null.\"\n            WranglerLogger.error(\n                msg + \" Set `allow_default = True` or fill column `sc_{prop_name}`.\"\n            )\n            raise ValueError(msg)\n        WranglerLogger.debug(f\"No scoped values {prop_name}. Returning default.\")\n        return copy.deepcopy(links_df[[\"model_link_id\", prop_name]])\n\n    # All possible scopings\n    candidate_scoped_prop_df = _create_exploded_df_for_scoped_prop(links_df, prop_name)\n\n    # Find scopes that apply\n    scoped_prop_df = _filter_exploded_df_to_scope(\n        candidate_scoped_prop_df,\n        timespan=timespan,\n        category=category,\n        strict_timespan_match=strict_timespan_match,\n        min_overlap_minutes=min_overlap_minutes,\n    )\n\n    # Attach them back to all links and update default.\n    result_df = copy.deepcopy(links_df[[\"model_link_id\", prop_name]])\n    result_df.loc[scoped_prop_df.index, prop_name] = scoped_prop_df[\"scoped\"]\n    WranglerLogger.debug(\n        f\"result_df[prop_name]: \\n{result_df.loc[scoped_prop_df.index, prop_name]}\"\n    )\n    return result_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.summary.link_summary","title":"network_wrangler.roadway.links.summary.link_summary","text":"<pre><code>link_summary(links_df)\n</code></pre> <p>Summarizes links by <code>link_summary_cats</code>: count, distance, and lane miles.</p> Source code in <code>network_wrangler/roadway/links/summary.py</code> <pre><code>def link_summary(links_df: DataFrame[RoadLinksTable]) -&gt; pd.DataFrame:\n    \"\"\"Summarizes links by `link_summary_cats`: count, distance, and lane miles.\"\"\"\n    data = {\n        \"count\": link_summary_cnt(links_df),\n        \"distance\": link_summary_miles(links_df),\n        \"lane miles\": link_summary_lane_miles(links_df),\n    }\n    return pd.DataFrame(data, index=link_summary_cats.keys())\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.summary.link_summary_cnt","title":"network_wrangler.roadway.links.summary.link_summary_cnt","text":"<pre><code>link_summary_cnt(links_df)\n</code></pre> <p>Dictionary of number of links by <code>link_summary_cats</code>.</p> Source code in <code>network_wrangler/roadway/links/summary.py</code> <pre><code>def link_summary_cnt(links_df: DataFrame[RoadLinksTable]) -&gt; dict[str, int]:\n    \"\"\"Dictionary of number of links by `link_summary_cats`.\"\"\"\n    return {k: len(v(links_df)) for k, v in link_summary_cats.items()}\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.summary.link_summary_lane_miles","title":"network_wrangler.roadway.links.summary.link_summary_lane_miles","text":"<pre><code>link_summary_lane_miles(links_df)\n</code></pre> <p>Dictionary of lane miles by <code>link_summary_cats</code>.</p> Source code in <code>network_wrangler/roadway/links/summary.py</code> <pre><code>def link_summary_lane_miles(links_df: DataFrame[RoadLinksTable]) -&gt; dict[str, float]:\n    \"\"\"Dictionary of lane miles by `link_summary_cats`.\"\"\"\n    return {k: calc_lane_miles(v(links_df)).sum() for k, v in link_summary_cats.items()}\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.summary.link_summary_miles","title":"network_wrangler.roadway.links.summary.link_summary_miles","text":"<pre><code>link_summary_miles(links_df)\n</code></pre> <p>Dictionary of miles by <code>link_summary_cats</code>.</p> Source code in <code>network_wrangler/roadway/links/summary.py</code> <pre><code>def link_summary_miles(links_df: DataFrame[RoadLinksTable]) -&gt; dict[str, float]:\n    \"\"\"Dictionary of miles by `link_summary_cats`.\"\"\"\n    return {k: v(links_df).distance.sum() for k, v in link_summary_cats.items()}\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.validate.validate_links_df","title":"network_wrangler.roadway.links.validate.validate_links_df","text":"<pre><code>validate_links_df(links_df, nodes_df=None, strict=False, errors_filename=Path('link_errors.csv'))\n</code></pre> <p>Validates a links df to RoadLinksTable and optionally checks if nodes are in the links.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame</code>)           \u2013            <p>The links dataframe.</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The nodes dataframe. Defaults to None.</p> </li> <li> <code>strict</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will validate to links_df without trying to parse it first.</p> </li> <li> <code>errors_filename</code>               (<code>Path</code>, default:                   <code>Path('link_errors.csv')</code> )           \u2013            <p>The output file for the validation errors. Defaults to \u201clink_errors.csv\u201d.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the links dataframe is valid.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/validate.py</code> <pre><code>def validate_links_df(\n    links_df: pd.DataFrame,\n    nodes_df: Optional[pd.DataFrame] = None,\n    strict: bool = False,\n    errors_filename: Path = Path(\"link_errors.csv\"),\n) -&gt; bool:\n    \"\"\"Validates a links df to RoadLinksTable and optionally checks if nodes are in the links.\n\n    Args:\n        links_df (pd.DataFrame): The links dataframe.\n        nodes_df (pd.DataFrame): The nodes dataframe. Defaults to None.\n        strict (bool): If True, will validate to links_df without trying to parse it first.\n        errors_filename (Path): The output file for the validation errors. Defaults\n            to \"link_errors.csv\".\n\n    Returns:\n        bool: True if the links dataframe is valid.\n    \"\"\"\n    from ...models.roadway.tables import RoadLinksTable  # noqa: PLC0415\n    from ...utils.models import TableValidationError, validate_df_to_model  # noqa: PLC0415\n\n    is_valid = True\n\n    if not strict:\n        from .create import data_to_links_df  # noqa: PLC0415\n\n        try:\n            links_df = data_to_links_df(links_df)\n        except Exception as e:\n            WranglerLogger.error(f\"!!! [Links invalid] - Failed to parse links_df\\n{e}\")\n            is_valid = False\n\n    try:\n        validate_df_to_model(links_df, RoadLinksTable, output_file=errors_filename)\n    except TableValidationError as e:\n        WranglerLogger.error(f\"!!! [Links invalid] - Failed Schema validation\\n{e}\")\n        is_valid = False\n\n    try:\n        validate_links_have_nodes(links_df, nodes_df)\n    except NodesInLinksMissingError as e:\n        WranglerLogger.error(f\"!!! [Links invalid] - Nodes missing in links\\n{e}\")\n        is_valid = False\n    return is_valid\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.validate.validate_links_file","title":"network_wrangler.roadway.links.validate.validate_links_file","text":"<pre><code>validate_links_file(links_filename, nodes_df=None, strict=False, errors_filename=Path('link_errors.csv'))\n</code></pre> <p>Validates a links file to RoadLinksTable and optionally checks if nodes are in the links.</p> <p>Parameters:</p> <ul> <li> <code>links_filename</code>               (<code>Path</code>)           \u2013            <p>The links file.</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>The nodes dataframe. Defaults to None.</p> </li> <li> <code>strict</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will validate to links_df without trying to parse it first.</p> </li> <li> <code>errors_filename</code>               (<code>Path</code>, default:                   <code>Path('link_errors.csv')</code> )           \u2013            <p>The output file for the validation errors. Defaults to \u201clink_errors.csv\u201d.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the links file is valid.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/validate.py</code> <pre><code>def validate_links_file(\n    links_filename: Path,\n    nodes_df: Optional[pd.DataFrame] = None,\n    strict: bool = False,\n    errors_filename: Path = Path(\"link_errors.csv\"),\n) -&gt; bool:\n    \"\"\"Validates a links file to RoadLinksTable and optionally checks if nodes are in the links.\n\n    Args:\n        links_filename (Path): The links file.\n        nodes_df (pd.DataFrame): The nodes dataframe. Defaults to None.\n        strict (bool): If True, will validate to links_df without trying to parse it first.\n        errors_filename (Path): The output file for the validation errors. Defaults\n            to \"link_errors.csv\".\n\n    Returns:\n        bool: True if the links file is valid.\n    \"\"\"\n    links_df = pd.read_csv(links_filename)\n    return validate_links_df(\n        links_df, nodes_df=nodes_df, strict=strict, errors_filename=errors_filename\n    )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.validate.validate_links_have_nodes","title":"network_wrangler.roadway.links.validate.validate_links_have_nodes","text":"<pre><code>validate_links_have_nodes(links_df, nodes_df)\n</code></pre> <p>Checks if links have nodes and returns a boolean.</p> <p>raises: NodesInLinksMissingError if nodes_df is missing and A or B node</p> Source code in <code>network_wrangler/roadway/links/validate.py</code> <pre><code>def validate_links_have_nodes(links_df: pd.DataFrame, nodes_df: pd.DataFrame) -&gt; bool:\n    \"\"\"Checks if links have nodes and returns a boolean.\n\n    raises: NodesInLinksMissingError if nodes_df is missing and A or B node\n    \"\"\"\n    nodes_in_links = list(set(links_df[\"A\"]).union(set(links_df[\"B\"])))\n    node_idx_in_links = nodes_df[nodes_df[\"model_node_id\"].isin(nodes_in_links)].index\n\n    fk_valid, fk_missing = fk_in_pk(nodes_df.index, node_idx_in_links)\n    if not fk_valid:\n        msg = \"Links are missing len{fk_missing} nodes.\"\n        WranglerLogger.error(msg + f\"\\n  Missing: {fk_missing}\")\n        raise NodesInLinksMissingError(msg)\n    return True\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor","text":"<p>Wrapper for various filters of RoadLinksTable.</p> <p>Methods:</p> <ul> <li> <code>links_df.of_type.managed</code>             \u2013              <p>filters links dataframe to only include managed lanes.</p> </li> <li> <code>links_df.of_type.parallel_general_purpose</code>             \u2013              <p>filters links dataframe to only include general purpose links parallel to managed.</p> </li> <li> <code>links_df.of_type.general_purpose</code>             \u2013              <p>filters links dataframe to only include all general purpose links.</p> </li> <li> <code>links_df.of_type.general_purpose_no_parallel_managed</code>             \u2013              <p>filters links dataframe to only include general purpose links without parallel managed lanes.</p> </li> <li> <code>links_df.of_type.access_dummy</code>             \u2013              <p>filters links dataframe to only include all access dummy links connecting managed lanes.</p> </li> <li> <code>links_df.of_type.egress_dummy</code>             \u2013              <p>filters links dataframe to only include all egress dummy links connecting managed lanes.</p> </li> <li> <code>links_df.of_type.dummy</code>             \u2013              <p>filters links dataframe to only include all dummy links connecting managed lanes.</p> </li> <li> <code>links_df.of_type.pedbike_only</code>             \u2013              <p>filters links dataframe to only include all links that only ped/bikes can be on.</p> </li> <li> <code>links_df.of_type.transit_only</code>             \u2013              <p>filters links dataframe to only include all links that only transit can be on.</p> </li> <li> <code>links_df.of_type.transit_access</code>             \u2013              <p>filters links dataframe to only include all links that transit can access.</p> </li> <li> <code>links_df.of_type.drive_access</code>             \u2013              <p>filters links dataframe to only include all links that drive can access.</p> </li> <li> <code>links_df.of_type.summary_df</code>             \u2013              <p>returns a summary of the links dataframe.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"of_type\")\nclass LinkOfTypeAccessor:\n    \"\"\"Wrapper for various filters of RoadLinksTable.\n\n    Methods:\n        links_df.of_type.managed: filters links dataframe to only include managed lanes.\n        links_df.of_type.parallel_general_purpose: filters links dataframe to only include\n            general purpose links parallel to managed.\n        links_df.of_type.general_purpose: filters links dataframe to only include all general\n            purpose links.\n        links_df.of_type.general_purpose_no_parallel_managed: filters links dataframe to only\n            include general purpose links without parallel managed lanes.\n        links_df.of_type.access_dummy: filters links dataframe to only include all access dummy\n            links connecting managed lanes.\n        links_df.of_type.egress_dummy: filters links dataframe to only include all egress dummy\n            links connecting managed lanes.\n        links_df.of_type.dummy: filters links dataframe to only include all dummy links\n            connecting managed lanes.\n        links_df.of_type.pedbike_only: filters links dataframe to only include all links that\n            only ped/bikes can be on.\n        links_df.of_type.transit_only: filters links dataframe to only include all links that\n            only transit can be on.\n        links_df.of_type.transit_access: filters links dataframe to only include all links\n            that transit can access.\n        links_df.of_type.drive_access: filters links dataframe to only include all links\n            that drive can access.\n        links_df.of_type.summary_df: returns a summary of the links dataframe.\n\n    \"\"\"\n\n    def __init__(self, links_df: DataFrame[RoadLinksTable]):\n        \"\"\"LinkOfTypeAccessor for RoadLinksTable.\"\"\"\n        self._links_df = links_df\n        try:\n            links_df.attrs[\"name\"] == \"road_links\"  # noqa: B015\n        except AttributeError:\n            WranglerLogger.warning(\n                \"`of_type` should only be used on 'road_links' dataframes. \\\n                No attr['name'] not found.\"\n            )\n        except AssertionError as e:\n            WranglerLogger.warning(\n                f\"`of_type` should only be used on 'road_links' dataframes. \\\n                Found type: {links_df.attr['name']}\"\n            )\n            msg = \"`of_type` is only available to network_links dataframes.\"\n            raise NotLinksError(msg) from e\n\n    @property\n    def managed(self):\n        \"\"\"Filters links dataframe to only include managed lanes.\"\"\"\n        return filter_links_managed_lanes(self._links_df)\n\n    @property\n    def parallel_general_purpose(self):\n        \"\"\"Filters links dataframe to general purpose links parallel to managed lanes.\"\"\"\n        ml_properties = filter_link_properties_managed_lanes(self._links_df)\n        keep_c = [c for c in self._links_df.columns if c not in ml_properties]\n        return filter_links_parallel_general_purpose(self._links_df[keep_c])\n\n    @property\n    def general_purpose(self):\n        \"\"\"Filters links dataframe to only include general purpose links.\"\"\"\n        ml_properties = filter_link_properties_managed_lanes(self._links_df)\n        keep_c = [c for c in self._links_df.columns if c not in ml_properties]\n        return filter_links_general_purpose(self._links_df[keep_c])\n\n    @property\n    def general_purpose_no_parallel_managed(self):\n        \"\"\"Filters links general purpose links without parallel managed lanes.\"\"\"\n        ml_properties = filter_link_properties_managed_lanes(self._links_df)\n        keep_c = [c for c in self._links_df.columns if c not in ml_properties]\n        return filter_links_general_purpose_no_parallel_managed(self._links_df[keep_c])\n\n    @property\n    def access_dummy(self):\n        \"\"\"Filters links dataframe to access dummy links connecting managed lanes.\"\"\"\n        return filter_links_access_dummy(self._links_df)\n\n    @property\n    def egress_dummy(self):\n        \"\"\"Filters links dataframe to egress dummy links connecting managed lanes.\"\"\"\n        return filter_links_egress_dummy(self._links_df)\n\n    @property\n    def dummy(self):\n        \"\"\"Filters links dataframe to dummy links connecting managed lanes.\"\"\"\n        return filter_links_dummy(self._links_df)\n\n    @property\n    def pedbike_only(self):\n        \"\"\"Filters links dataframe to links that only ped/bikes can be on.\"\"\"\n        return filter_links_pedbike_only(self._links_df)\n\n    @property\n    def transit_only(self):\n        \"\"\"Filters links dataframe to links that only transit can be on.\"\"\"\n        return filter_links_transit_only(self._links_df)\n\n    @property\n    def transit_access(self):\n        \"\"\"Filters links dataframe to all links that transit can access.\"\"\"\n        return filter_links_transit_access(self._links_df)\n\n    @property\n    def drive_access(self):\n        \"\"\"Filters links dataframe to only include all links that drive can access.\"\"\"\n        return filter_links_drive_access(self._links_df)\n\n    @property\n    def summary_df(self) -&gt; pd.DataFrame:\n        \"\"\"Returns a summary of the links dataframe.\"\"\"\n        return link_summary(self._links_df)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.access_dummy","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.access_dummy  <code>property</code>","text":"<pre><code>access_dummy\n</code></pre> <p>Filters links dataframe to access dummy links connecting managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.drive_access","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.drive_access  <code>property</code>","text":"<pre><code>drive_access\n</code></pre> <p>Filters links dataframe to only include all links that drive can access.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.dummy","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.dummy  <code>property</code>","text":"<pre><code>dummy\n</code></pre> <p>Filters links dataframe to dummy links connecting managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.egress_dummy","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.egress_dummy  <code>property</code>","text":"<pre><code>egress_dummy\n</code></pre> <p>Filters links dataframe to egress dummy links connecting managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.general_purpose","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.general_purpose  <code>property</code>","text":"<pre><code>general_purpose\n</code></pre> <p>Filters links dataframe to only include general purpose links.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.general_purpose_no_parallel_managed","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.general_purpose_no_parallel_managed  <code>property</code>","text":"<pre><code>general_purpose_no_parallel_managed\n</code></pre> <p>Filters links general purpose links without parallel managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.managed","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.managed  <code>property</code>","text":"<pre><code>managed\n</code></pre> <p>Filters links dataframe to only include managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.parallel_general_purpose","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.parallel_general_purpose  <code>property</code>","text":"<pre><code>parallel_general_purpose\n</code></pre> <p>Filters links dataframe to general purpose links parallel to managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.pedbike_only","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.pedbike_only  <code>property</code>","text":"<pre><code>pedbike_only\n</code></pre> <p>Filters links dataframe to links that only ped/bikes can be on.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.summary_df","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.summary_df  <code>property</code>","text":"<pre><code>summary_df\n</code></pre> <p>Returns a summary of the links dataframe.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.transit_access","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.transit_access  <code>property</code>","text":"<pre><code>transit_access\n</code></pre> <p>Filters links dataframe to all links that transit can access.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.transit_only","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.transit_only  <code>property</code>","text":"<pre><code>transit_only\n</code></pre> <p>Filters links dataframe to links that only transit can be on.</p>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.__init__","title":"network_wrangler.roadway.links.df_accessors.LinkOfTypeAccessor.__init__","text":"<pre><code>__init__(links_df)\n</code></pre> <p>LinkOfTypeAccessor for RoadLinksTable.</p> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>def __init__(self, links_df: DataFrame[RoadLinksTable]):\n    \"\"\"LinkOfTypeAccessor for RoadLinksTable.\"\"\"\n    self._links_df = links_df\n    try:\n        links_df.attrs[\"name\"] == \"road_links\"  # noqa: B015\n    except AttributeError:\n        WranglerLogger.warning(\n            \"`of_type` should only be used on 'road_links' dataframes. \\\n            No attr['name'] not found.\"\n        )\n    except AssertionError as e:\n        WranglerLogger.warning(\n            f\"`of_type` should only be used on 'road_links' dataframes. \\\n            Found type: {links_df.attr['name']}\"\n        )\n        msg = \"`of_type` is only available to network_links dataframes.\"\n        raise NotLinksError(msg) from e\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.ModeLinkAccessor","title":"network_wrangler.roadway.links.df_accessors.ModeLinkAccessor","text":"<p>Wrapper for filtering RoadLinksTable by modal ability: : links_df.mode_query(modes_list).</p> <p>Parameters:</p> <ul> <li> <code>modes</code>               (<code>list[str]</code>)           \u2013            <p>list of modes to filter by.</p> </li> </ul> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"mode_query\")\nclass ModeLinkAccessor:\n    \"\"\"Wrapper for filtering RoadLinksTable by modal ability: : links_df.mode_query(modes_list).\n\n    Args:\n        modes (list[str]): list of modes to filter by.\n    \"\"\"\n\n    def __init__(self, links_df: DataFrame[RoadLinksTable]):\n        \"\"\"ModeLinkAccessor for RoadLinksTable.\"\"\"\n        self._links_df = links_df\n        try:\n            assert links_df.attrs[\"name\"] == \"road_links\"\n        except AttributeError:\n            WranglerLogger.warning(\n                \"`mode_query` should only be used on 'road_links' dataframes. \\\n                No attr['name'] not found.\"\n            )\n        except AssertionError as err:\n            msg = \"`mode_query` is only available to network_links dataframes.\"\n            WranglerLogger.warning(msg + f\" Found type: {links_df.attr['name']}\")\n            raise NotLinksError(msg) from err\n\n    def __call__(self, modes: list[str]):\n        \"\"\"Filters links dataframe to  links that are accessible by the modes in the list.\"\"\"\n        return filter_links_to_modes(self._links_df, modes)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.ModeLinkAccessor.__call__","title":"network_wrangler.roadway.links.df_accessors.ModeLinkAccessor.__call__","text":"<pre><code>__call__(modes)\n</code></pre> <p>Filters links dataframe to  links that are accessible by the modes in the list.</p> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>def __call__(self, modes: list[str]):\n    \"\"\"Filters links dataframe to  links that are accessible by the modes in the list.\"\"\"\n    return filter_links_to_modes(self._links_df, modes)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.ModeLinkAccessor.__init__","title":"network_wrangler.roadway.links.df_accessors.ModeLinkAccessor.__init__","text":"<pre><code>__init__(links_df)\n</code></pre> <p>ModeLinkAccessor for RoadLinksTable.</p> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>def __init__(self, links_df: DataFrame[RoadLinksTable]):\n    \"\"\"ModeLinkAccessor for RoadLinksTable.\"\"\"\n    self._links_df = links_df\n    try:\n        assert links_df.attrs[\"name\"] == \"road_links\"\n    except AttributeError:\n        WranglerLogger.warning(\n            \"`mode_query` should only be used on 'road_links' dataframes. \\\n            No attr['name'] not found.\"\n        )\n    except AssertionError as err:\n        msg = \"`mode_query` is only available to network_links dataframes.\"\n        WranglerLogger.warning(msg + f\" Found type: {links_df.attr['name']}\")\n        raise NotLinksError(msg) from err\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.TrueShapeAccessor","title":"network_wrangler.roadway.links.df_accessors.TrueShapeAccessor","text":"<p>Wrapper for returning a gdf with true_shapes: links_df.true_shape(shapes_df).</p> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"true_shape\")\nclass TrueShapeAccessor:\n    \"\"\"Wrapper for returning a gdf with true_shapes: links_df.true_shape(shapes_df).\"\"\"\n\n    def __init__(self, links_df: DataFrame[RoadLinksTable]):\n        \"\"\"TrueShapeAccessor for RoadLinksTable.\"\"\"\n        self._links_df = links_df\n        try:\n            assert links_df.attrs[\"name\"] == \"road_links\"\n        except AttributeError:\n            WranglerLogger.warning(\n                \"`true_shape` should only be used on 'road_links' dataframes. \\\n                No attr['name'] not found.\"\n            )\n        except AssertionError as err:\n            msg = \"`true_shape` is only available to network_links dataframes.\"\n            WranglerLogger.warning(msg + f\" Found type: {links_df.attr['name']}\")\n            raise NotLinksError(msg) from err\n\n    def __call__(self, shapes_df: DataFrame[RoadShapesTable]):\n        \"\"\"Updates geometry to have shape of shapes_df where available.\"\"\"\n        return true_shape(self._links_df, shapes_df)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.TrueShapeAccessor.__call__","title":"network_wrangler.roadway.links.df_accessors.TrueShapeAccessor.__call__","text":"<pre><code>__call__(shapes_df)\n</code></pre> <p>Updates geometry to have shape of shapes_df where available.</p> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>def __call__(self, shapes_df: DataFrame[RoadShapesTable]):\n    \"\"\"Updates geometry to have shape of shapes_df where available.\"\"\"\n    return true_shape(self._links_df, shapes_df)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.links.df_accessors.TrueShapeAccessor.__init__","title":"network_wrangler.roadway.links.df_accessors.TrueShapeAccessor.__init__","text":"<pre><code>__init__(links_df)\n</code></pre> <p>TrueShapeAccessor for RoadLinksTable.</p> Source code in <code>network_wrangler/roadway/links/df_accessors.py</code> <pre><code>def __init__(self, links_df: DataFrame[RoadLinksTable]):\n    \"\"\"TrueShapeAccessor for RoadLinksTable.\"\"\"\n    self._links_df = links_df\n    try:\n        assert links_df.attrs[\"name\"] == \"road_links\"\n    except AttributeError:\n        WranglerLogger.warning(\n            \"`true_shape` should only be used on 'road_links' dataframes. \\\n            No attr['name'] not found.\"\n        )\n    except AssertionError as err:\n        msg = \"`true_shape` is only available to network_links dataframes.\"\n        WranglerLogger.warning(msg + f\" Found type: {links_df.attr['name']}\")\n        raise NotLinksError(msg) from err\n</code></pre>"},{"location":"api_roadway/#roadway-nodes","title":"Roadway Nodes","text":"<p>Functions for reading and writing nodes data.</p> <p>Functions for creating nodes from data sources.</p> <p>Functions for deleting nodes from a nodes table.</p> <p>Edits RoadNodesTable properties.</p> <p>NOTE: Each public method will return a new, whole copy of the RoadNodesTable with associated edits. Private methods may return mutated originals.</p> <p>Functions to filter nodes dataframe.</p> <p>Nodes submodule for creating, editing, filtering RoadNodes Table.</p>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.io.get_nodes","title":"network_wrangler.roadway.nodes.io.get_nodes","text":"<pre><code>get_nodes(transit_net=None, roadway_net=None, roadway_path=None, config=DefaultConfig)\n</code></pre> <p>Get nodes from a transit network, roadway network, or roadway file.</p> <p>Parameters:</p> <ul> <li> <code>transit_net</code>               (<code>Optional[TransitNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>TransitNetwork instance</p> </li> <li> <code>roadway_net</code>               (<code>Optional[RoadwayNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>RoadwayNetwork instance</p> </li> <li> <code>roadway_path</code>               (<code>Optional[Union[str, Path]]</code>, default:                   <code>None</code> )           \u2013            <p>path to a directory with roadway network</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig.</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/io.py</code> <pre><code>def get_nodes(\n    transit_net: Optional[TransitNetwork] = None,\n    roadway_net: Optional[RoadwayNetwork] = None,\n    roadway_path: Optional[Union[str, Path]] = None,\n    config: WranglerConfig = DefaultConfig,\n) -&gt; GeoDataFrame:\n    \"\"\"Get nodes from a transit network, roadway network, or roadway file.\n\n    Args:\n        transit_net: TransitNetwork instance\n        roadway_net: RoadwayNetwork instance\n        roadway_path: path to a directory with roadway network\n        config: WranglerConfig instance. Defaults to DefaultConfig.\n    \"\"\"\n    if transit_net is not None and transit_net.road_net is not None:\n        return transit_net.road_net.nodes_df\n    if roadway_net is not None:\n        return roadway_net.nodes_df\n    if roadway_path is not None:\n        nodes_path = Path(roadway_path)\n        if nodes_path.is_dir():\n            nodes_path = next(nodes_path.glob(\"*node*.\"))\n        return read_nodes(nodes_path, config=config)\n    msg = \"nodes_df must either be given or provided via an associated road_net or by providing a roadway_net path or instance.\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.io.nodes_df_to_geojson","title":"network_wrangler.roadway.nodes.io.nodes_df_to_geojson","text":"<pre><code>nodes_df_to_geojson(nodes_df, properties)\n</code></pre> <p>Converts a nodes dataframe to a geojson.</p> <p>Attribution: Geoff Boeing: https://geoffboeing.com/2015/10/exporting-python-data-geojson/.</p> Source code in <code>network_wrangler/roadway/nodes/io.py</code> <pre><code>@validate_call_pyd\ndef nodes_df_to_geojson(nodes_df: DataFrame[RoadNodesTable], properties: list[str]):\n    \"\"\"Converts a nodes dataframe to a geojson.\n\n    Attribution: Geoff Boeing:\n    https://geoffboeing.com/2015/10/exporting-python-data-geojson/.\n    \"\"\"\n    # TODO write wrapper on validate call so don't have to do this\n    nodes_df.attrs.update(RoadNodesAttrs)\n    geojson = {\"type\": \"FeatureCollection\", \"features\": []}\n    for _, row in nodes_df.iterrows():\n        feature: dict[str, Any] = {\n            \"type\": \"Feature\",\n            \"properties\": {},\n            \"geometry\": {\"type\": \"Point\", \"coordinates\": []},\n        }\n        feature[\"geometry\"][\"coordinates\"] = [row[\"geometry\"].x, row[\"geometry\"].y]\n        feature[\"properties\"][nodes_df.model_node_id] = row.name\n        for prop in properties:\n            feature[\"properties\"][prop] = row[prop]\n        geojson[\"features\"].append(feature)\n    return geojson\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.io.read_nodes","title":"network_wrangler.roadway.nodes.io.read_nodes","text":"<pre><code>read_nodes(filename, in_crs=LAT_LON_CRS, boundary_gdf=None, boundary_geocode=None, boundary_file=None, config=DefaultConfig)\n</code></pre> <p>Reads nodes and returns a geodataframe of nodes.</p> <p>Sets index to be a copy of the primary key. Validates output dataframe using NodesSchema.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>(Path, str)</code>)           \u2013            <p>file to read links in from.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system number that node data is in. Defaults to LAT_LON_CRS.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. efaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig.</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/io.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef read_nodes(\n    filename: Path,\n    in_crs: int = LAT_LON_CRS,\n    boundary_gdf: Optional[GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    config: WranglerConfig = DefaultConfig,\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Reads nodes and returns a geodataframe of nodes.\n\n    Sets index to be a copy of the primary key.\n    Validates output dataframe using NodesSchema.\n\n    Args:\n        filename (Path,str): file to read links in from.\n        in_crs: coordinate reference system number that node data is in. Defaults to LAT_LON_CRS.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            efaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        config: WranglerConfig instance. Defaults to DefaultConfig.\n    \"\"\"\n    WranglerLogger.debug(f\"Reading nodes from {filename}.\")\n\n    start_time = time.time()\n\n    nodes_df = read_table(\n        filename,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n        read_speed=config.CPU.EST_PD_READ_SPEED,\n    )\n    WranglerLogger.debug(\n        f\"Read {len(nodes_df)} nodes from file in {round(time.time() - start_time, 2)}.\"\n    )\n\n    nodes_df = data_to_nodes_df(nodes_df, in_crs=in_crs, config=config)\n    nodes_df.attrs[\"source_file\"] = filename\n    WranglerLogger.info(\n        f\"Read {len(nodes_df)} nodes from {filename} in {round(time.time() - start_time, 2)}.\"\n    )\n    nodes_df = validate_df_to_model(nodes_df, RoadNodesTable)\n    return nodes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.io.write_nodes","title":"network_wrangler.roadway.nodes.io.write_nodes","text":"<pre><code>write_nodes(nodes_df, out_dir, prefix, file_format='geojson', overwrite=True)\n</code></pre> <p>Writes RoadNodesTable to file.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>nodes dataframe</p> </li> <li> <code>out_dir</code>               (<code>Union[str, Path]</code>)           \u2013            <p>directory to write nodes to</p> </li> <li> <code>prefix</code>               (<code>str</code>)           \u2013            <p>prefix to add to nodes file name</p> </li> <li> <code>file_format</code>               (<code>GeoFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>format to write nodes in. e.g. \u201cgeojson\u201d shp\u201d \u201cparquet\u201d \u201ccsv\u201d \u201ctxt\u201d. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>whether to overwrite existing nodes file. Defaults to True.</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/io.py</code> <pre><code>@validate_call_pyd\ndef write_nodes(\n    nodes_df: DataFrame[RoadNodesTable],\n    out_dir: Union[str, Path],\n    prefix: str,\n    file_format: GeoFileTypes = \"geojson\",\n    overwrite: bool = True,\n) -&gt; None:\n    \"\"\"Writes RoadNodesTable to file.\n\n    Args:\n        nodes_df: nodes dataframe\n        out_dir: directory to write nodes to\n        prefix: prefix to add to nodes file name\n        file_format: format to write nodes in. e.g. \"geojson\" shp\" \"parquet\" \"csv\" \"txt\". Defaults\n            to \"geojson\".\n        overwrite: whether to overwrite existing nodes file. Defaults to True.\n    \"\"\"\n    nodes_file = Path(out_dir) / f\"{prefix}node.{file_format}\"\n    nodes_df = order_fields_from_data_model(nodes_df, RoadNodesTable)\n    write_table(nodes_df, nodes_file, overwrite=overwrite)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.create.data_to_nodes_df","title":"network_wrangler.roadway.nodes.create.data_to_nodes_df","text":"<pre><code>data_to_nodes_df(nodes_df, config=DefaultConfig, in_crs=LAT_LON_CRS)\n</code></pre> <p>Turn nodes data into official nodes dataframe.</p> <p>Adds missing geometry. Makes sure X and Y are consistent with geometry GeoSeries. Converts to LAT_LON_CRS. Copies and sets idx to primary_key. Validates output to NodesSchema.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>           \u2013            <p>Nodes dataframe or list of dictionaries that can be converted to a dataframe.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig. NOTE: Not currently used.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>Coordinate references system id incoming data xy is in, if it isn\u2019t already in a GeoDataFrame. Defaults to LAT_LON_CRS.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadNodesTable]</code>           \u2013            <p>gpd.GeoDataFrame: description</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/create.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef data_to_nodes_df(\n    nodes_df: Union[pd.DataFrame, gpd.GeoDataFrame, list[dict]],\n    config: WranglerConfig = DefaultConfig,  # noqa: ARG001\n    in_crs: int = LAT_LON_CRS,\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Turn nodes data into official nodes dataframe.\n\n    Adds missing geometry.\n    Makes sure X and Y are consistent with geometry GeoSeries.\n    Converts to LAT_LON_CRS.\n    Copies and sets idx to primary_key.\n    Validates output to NodesSchema.\n\n    Args:\n        nodes_df : Nodes dataframe or list of dictionaries that can be converted to a dataframe.\n        config: WranglerConfig instance. Defaults to DefaultConfig. NOTE: Not currently used.\n        in_crs: Coordinate references system id incoming data xy is in, if it isn't already\n            in a GeoDataFrame. Defaults to LAT_LON_CRS.\n\n    Returns:\n        gpd.GeoDataFrame: _description_\n    \"\"\"\n    WranglerLogger.debug(\"Turning node data into official nodes_df\")\n\n    if isinstance(nodes_df, gpd.GeoDataFrame) and nodes_df.crs != LAT_LON_CRS:\n        if nodes_df.crs is None:\n            nodes_df.crs = in_crs\n        nodes_df = nodes_df.to_crs(LAT_LON_CRS)\n\n    if not isinstance(nodes_df, gpd.GeoDataFrame) or nodes_df.geometry.isnull().values.any():\n        nodes_df = _create_node_geometries_from_xy(nodes_df, in_crs=in_crs, net_crs=LAT_LON_CRS)\n\n    # Make sure values are consistent\n    nodes_df[\"X\"] = nodes_df[\"geometry\"].apply(lambda g: g.x)\n    nodes_df[\"Y\"] = nodes_df[\"geometry\"].apply(lambda g: g.y)\n\n    if len(nodes_df) &lt; SMALL_RECS:\n        WranglerLogger.debug(f\"nodes_df: \\n{nodes_df[['model_node_id', 'geometry', 'X', 'Y']]}\")\n\n    # Validate and coerce to schema\n    nodes_df = validate_df_to_model(nodes_df, RoadNodesTable)\n    nodes_df.attrs.update(RoadNodesAttrs)\n    nodes_df.gdf_name = nodes_df.attrs[\"name\"]\n    nodes_df = set_df_index_to_pk(nodes_df)\n\n    return nodes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.create.generate_node_ids","title":"network_wrangler.roadway.nodes.create.generate_node_ids","text":"<pre><code>generate_node_ids(nodes_df, range, n)\n</code></pre> <p>Generate unique node ids for nodes_df.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>nodes dataframe to generate unique ids for.</p> </li> <li> <code>range</code>               (<code>tuple[int]</code>)           \u2013            <p>range of ids to generate from.</p> </li> <li> <code>n</code>               (<code>int</code>)           \u2013            <p>number of ids to generate.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[int]</code>           \u2013            <p>list[int]: list of unique node ids.</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/create.py</code> <pre><code>def generate_node_ids(nodes_df: DataFrame[RoadNodesTable], range: tuple[int], n: int) -&gt; list[int]:\n    \"\"\"Generate unique node ids for nodes_df.\n\n    Args:\n        nodes_df: nodes dataframe to generate unique ids for.\n        range: range of ids to generate from.\n        n: number of ids to generate.\n\n    Returns:\n        list[int]: list of unique node ids.\n    \"\"\"\n    if n &lt;= 0:\n        return []\n    existing_ids = set(nodes_df[\"model_node_id\"].unique())\n    new_ids = set(range) - existing_ids\n    if len(new_ids) &lt; n:\n        msg = f\"Only {len(new_ids)} new ids available, need {n}.\"\n        raise NodeAddError(msg)\n\n    return list(new_ids)[:n]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.delete.delete_nodes_by_ids","title":"network_wrangler.roadway.nodes.delete.delete_nodes_by_ids","text":"<pre><code>delete_nodes_by_ids(nodes_df, del_node_ids, ignore_missing=False)\n</code></pre> <p>Delete nodes from a nodes table.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>DataFrame[RoadNodesTable] to delete nodes from.</p> </li> <li> <code>del_node_ids</code>               (<code>list[int]</code>)           \u2013            <p>list of node ids to delete.</p> </li> <li> <code>ignore_missing</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will not raise an error if a node id to delete is not in the network. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/delete.py</code> <pre><code>def delete_nodes_by_ids(\n    nodes_df: DataFrame[RoadNodesTable], del_node_ids: list[int], ignore_missing: bool = False\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Delete nodes from a nodes table.\n\n    Args:\n        nodes_df: DataFrame[RoadNodesTable] to delete nodes from.\n        del_node_ids: list of node ids to delete.\n        ignore_missing: if True, will not raise an error if a node id to delete is not in\n            the network. Defaults to False.\n    \"\"\"\n    WranglerLogger.debug(f\"Deleting nodse with ids: \\n{del_node_ids}\")\n\n    _missing = set(del_node_ids) - set(nodes_df.index)\n    if _missing:\n        msg = \"Nodes to delete are not in the network.\"\n        WranglerLogger.warning(msg + f\"\\n{_missing}\")\n        if not ignore_missing:\n            raise NodeDeletionError(msg)\n    return nodes_df.drop(labels=del_node_ids, errors=\"ignore\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.edit.NodeGeometryChange","title":"network_wrangler.roadway.nodes.edit.NodeGeometryChange","text":"<p>               Bases: <code>RecordModel</code></p> <p>Value for setting node geometry given a model_node_id.</p> Source code in <code>network_wrangler/roadway/nodes/edit.py</code> <pre><code>class NodeGeometryChange(RecordModel):\n    \"\"\"Value for setting node geometry given a model_node_id.\"\"\"\n\n    model_config = ConfigDict(extra=\"ignore\")\n    X: float\n    Y: float\n    in_crs: Optional[int] = LAT_LON_CRS\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.edit.NodeGeometryChangeTable","title":"network_wrangler.roadway.nodes.edit.NodeGeometryChangeTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>DataFrameModel for setting node geometry given a model_node_id.</p> Source code in <code>network_wrangler/roadway/nodes/edit.py</code> <pre><code>class NodeGeometryChangeTable(DataFrameModel):\n    \"\"\"DataFrameModel for setting node geometry given a model_node_id.\"\"\"\n\n    model_node_id: Series[int]\n    X: Series[float] = Field(coerce=True)\n    Y: Series[float] = Field(coerce=True)\n    in_crs: Series[int] = Field(default=LAT_LON_CRS)\n\n    class Config:\n        \"\"\"Config for NodeGeometryChangeTable.\"\"\"\n\n        add_missing_columns = True\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.edit.NodeGeometryChangeTable.Config","title":"network_wrangler.roadway.nodes.edit.NodeGeometryChangeTable.Config","text":"<p>Config for NodeGeometryChangeTable.</p> Source code in <code>network_wrangler/roadway/nodes/edit.py</code> <pre><code>class Config:\n    \"\"\"Config for NodeGeometryChangeTable.\"\"\"\n\n    add_missing_columns = True\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.edit.edit_node_geometry","title":"network_wrangler.roadway.nodes.edit.edit_node_geometry","text":"<pre><code>edit_node_geometry(nodes_df, node_geometry_change_table)\n</code></pre> <p>Returns copied nodes table with geometry edited.</p> <p>Should be called from network so that accompanying links and shapes are also updated.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>RoadNodesTable to edit</p> </li> <li> <code>node_geometry_change_table</code>               (<code>DataFrame[NodeGeometryChangeTable]</code>)           \u2013            <p>NodeGeometryChangeTable with geometry changes</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/edit.py</code> <pre><code>@validate_call_pyd\ndef edit_node_geometry(\n    nodes_df: DataFrame[RoadNodesTable],\n    node_geometry_change_table: DataFrame[NodeGeometryChangeTable],\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Returns copied nodes table with geometry edited.\n\n    Should be called from network so that accompanying links and shapes are also updated.\n\n    Args:\n        nodes_df: RoadNodesTable to edit\n        node_geometry_change_table: NodeGeometryChangeTable with geometry changes\n    \"\"\"\n    # TODO write wrapper on validate call so don't have to do this\n    nodes_df.attrs.update(RoadNodesAttrs)\n    WranglerLogger.debug(f\"Updating node geometry for {len(node_geometry_change_table)} nodes.\")\n    WranglerLogger.debug(f\"Original nodes_df: \\n{nodes_df.head()}\")\n    # for now, require in_crs is the same for whole column\n    if node_geometry_change_table.in_crs.nunique() != 1:\n        msg = f\"in_crs must be the same for all nodes. Got: {node_geometry_change_table.in_crs}\"\n        WranglerLogger.error(msg)\n        raise NodeChangeError(msg)\n\n    in_crs = node_geometry_change_table.loc[0, \"in_crs\"]\n\n    # Create a table with all the new node geometry\n    geo_s = gpd.points_from_xy(node_geometry_change_table.X, node_geometry_change_table.Y)\n    geo_df = gpd.GeoDataFrame(node_geometry_change_table, geometry=geo_s, crs=in_crs)\n    geo_df = geo_df.to_crs(LAT_LON_CRS)\n    WranglerLogger.debug(f\"Updated geometry geo_df: \\n{geo_df}\")\n\n    # Update the nodes table with the new geometry\n    nodes_df = update_df_by_col_value(\n        nodes_df, geo_df, \"model_node_id\", properties=[\"X\", \"Y\", \"geometry\"]\n    )\n    nodes_df = validate_df_to_model(nodes_df, RoadNodesTable)\n\n    WranglerLogger.debug(f\"Updated nodes_df: \\n{nodes_df.head()}\")\n\n    return nodes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.edit.edit_node_property","title":"network_wrangler.roadway.nodes.edit.edit_node_property","text":"<pre><code>edit_node_property(nodes_df, node_idx, prop_name, prop_change, project_name=None, config=DefaultConfig, _geometry_ok=False)\n</code></pre> <p>Return copied nodes table with node property edited.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>RoadNodesTable to edit</p> </li> <li> <code>node_idx</code>               (<code>list[int]</code>)           \u2013            <p>list of node indices to change</p> </li> <li> <code>prop_name</code>               (<code>str</code>)           \u2013            <p>property name to change</p> </li> <li> <code>prop_change</code>               (<code>Union[dict, RoadPropertyChange]</code>)           \u2013            <p>dictionary of value from project_card</p> </li> <li> <code>project_name</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>optional name of the project to be applied</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance.</p> </li> <li> <code>_geometry_ok</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if False, will not let you change geometry-related fields. Should only be changed to True by internal processes that know that geometry is changing and will update it in appropriate places in network. Defaults to False. GENERALLY DO NOT TURN THIS ON.</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/edit.py</code> <pre><code>def edit_node_property(\n    nodes_df: DataFrame[RoadNodesTable],\n    node_idx: list[int],\n    prop_name: str,\n    prop_change: Union[dict, RoadPropertyChange],\n    project_name: Optional[str] = None,\n    config: WranglerConfig = DefaultConfig,\n    _geometry_ok: bool = False,\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Return copied nodes table with node property edited.\n\n    Args:\n        nodes_df: RoadNodesTable to edit\n        node_idx: list of node indices to change\n        prop_name: property name to change\n        prop_change: dictionary of value from project_card\n        project_name: optional name of the project to be applied\n        config: WranglerConfig instance.\n        _geometry_ok: if False, will not let you change geometry-related fields. Should\n            only be changed to True by internal processes that know that geometry is changing\n            and will update it in appropriate places in network. Defaults to False.\n            GENERALLY DO NOT TURN THIS ON.\n    \"\"\"\n    if not isinstance(prop_change, RoadPropertyChange):\n        prop_change = RoadPropertyChange(**prop_change)\n    prop_dict = prop_change.model_dump(exclude_none=True, by_alias=True)\n\n    # Allow the project card to override the default behavior of raising an error\n    existing_value_conflict = prop_change.get(\n        \"existing_value_conflict\", config.EDITS.EXISTING_VALUE_CONFLICT\n    )\n\n    # Should not be used to update node geometry fields unless explicity set to OK:\n    if prop_name in nodes_df.attrs[\"geometry_props\"] and not _geometry_ok:\n        msg = f\"Cannot unilaterally change geometry property.\"\n        raise NodeChangeError(msg)\n\n    # check existing if necessary\n    if not _check_existing_value_conflict(\n        nodes_df, node_idx, prop_name, prop_dict, existing_value_conflict\n    ):\n        return nodes_df\n\n    nodes_df = copy.deepcopy(nodes_df)\n\n    # if it is a new attribute then initialize with NaN values\n    if prop_name not in nodes_df:\n        nodes_df[prop_name] = None\n\n    # `set` and `change` just affect the simple property\n    if \"set\" in prop_dict:\n        nodes_df.loc[node_idx, prop_name] = prop_dict[\"set\"]\n    elif \"change\" in prop_dict:\n        nodes_df.loc[node_idx, prop_name] = nodes_df.loc[prop_name].apply(\n            lambda x: x + prop_dict[\"change\"]\n        )\n    else:\n        msg = f\"Couldn't find correct node change spec in: {prop_dict}\"\n        raise NodeChangeError(msg)\n\n    if project_name is not None:\n        nodes_df.loc[node_idx, \"projects\"] += f\"{project_name},\"\n\n    nodes_df = validate_df_to_model(nodes_df, RoadNodesTable)\n    return nodes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.filters.filter_nodes_to_ids","title":"network_wrangler.roadway.nodes.filters.filter_nodes_to_ids","text":"<pre><code>filter_nodes_to_ids(nodes_df, node_ids)\n</code></pre> <p>Filters nodes dataframe by node_ids.</p> <p>Parameters:</p> <ul> <li> <code>nodes_df</code>               (<code>DataFrame</code>)           \u2013            <p>nodes dataframe</p> </li> <li> <code>node_ids</code>               (<code>List[int]</code>)           \u2013            <p>list of node_ids to filter by.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadNodesTable]</code>           \u2013            <p>pd.DataFrame: filtered nodes dataframe</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/filters.py</code> <pre><code>def filter_nodes_to_ids(\n    nodes_df: DataFrame[RoadNodesTable], node_ids: list[int]\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Filters nodes dataframe by node_ids.\n\n    Args:\n        nodes_df (pd.DataFrame): nodes dataframe\n        node_ids (List[int]): list of node_ids to filter by.\n\n    Returns:\n        pd.DataFrame: filtered nodes dataframe\n    \"\"\"\n    return nodes_df.loc[nodes_df[\"model_node_id\"].isin(node_ids)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.filters.filter_nodes_to_link_ids","title":"network_wrangler.roadway.nodes.filters.filter_nodes_to_link_ids","text":"<pre><code>filter_nodes_to_link_ids(link_ids, links_df, nodes_df=None)\n</code></pre> <p>Filters nodes dataframe to those used by given link_ids.</p> <p>Parameters:</p> <ul> <li> <code>link_ids</code>               (<code>List[int]</code>)           \u2013            <p>list of link_ids</p> </li> <li> <code>links_df</code>               (<code>RoadLinksTable</code>)           \u2013            <p>links dataframe</p> </li> <li> <code>nodes_df</code>               (<code>RoadNodesTable</code>, default:                   <code>None</code> )           \u2013            <p>nodes dataframe</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadNodesTable]</code>           \u2013            <p>pd.DataFrame: nodes dataframe</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/filters.py</code> <pre><code>def filter_nodes_to_link_ids(\n    link_ids: list[int],\n    links_df: DataFrame[RoadLinksTable],\n    nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Filters nodes dataframe to those used by given link_ids.\n\n    Args:\n        link_ids (List[int]): list of link_ids\n        links_df (RoadLinksTable): links dataframe\n        nodes_df (RoadNodesTable): nodes dataframe\n\n    Returns:\n        pd.DataFrame: nodes dataframe\n    \"\"\"\n    _node_ids = node_ids_in_link_ids(link_ids, links_df, nodes_df)\n    return filter_nodes_to_ids(nodes_df, _node_ids)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.nodes.filters.filter_nodes_to_links","title":"network_wrangler.roadway.nodes.filters.filter_nodes_to_links","text":"<pre><code>filter_nodes_to_links(links_df, nodes_df)\n</code></pre> <p>Filters RoadNodesTable to those used by given links dataframe.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>RoadLinksTable</code>)           \u2013            <p>links dataframe</p> </li> <li> <code>nodes_df</code>               (<code>RoadNodesTable</code>)           \u2013            <p>nodes dataframe</p> </li> </ul> Source code in <code>network_wrangler/roadway/nodes/filters.py</code> <pre><code>def filter_nodes_to_links(\n    links_df: DataFrame[RoadLinksTable], nodes_df: DataFrame[RoadNodesTable]\n) -&gt; DataFrame[RoadNodesTable]:\n    \"\"\"Filters RoadNodesTable to those used by given links dataframe.\n\n    Args:\n        links_df (RoadLinksTable): links dataframe\n        nodes_df (RoadNodesTable): nodes dataframe\n    \"\"\"\n    _node_ids = node_ids_in_links(links_df, nodes_df)\n    nodes_in_links = nodes_df.loc[nodes_df.index.isin(_node_ids)]\n    WranglerLogger.debug(f\"Selected {len(nodes_in_links)} of {len(nodes_df)} nodes.\")\n    return nodes_in_links\n</code></pre>"},{"location":"api_roadway/#roadway-shapes","title":"Roadway Shapes","text":"<p>Functions to read and write RoadShapesTable.</p> <p>Functions to create RoadShapesTable from various data.</p> <p>Edits RoadShapesTable properties.</p> <p>NOTE: Each public method will return a whole copy of the RoadShapesTable with associated edits. Private methods may return mutated originals.</p> <p>Functions to delete shapes from RoadShapesTable.</p> <p>Helpter functions which filter a RoadShapesTable.</p> <p>Functions that query RoadShapesTable.</p>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.io.read_shapes","title":"network_wrangler.roadway.shapes.io.read_shapes","text":"<pre><code>read_shapes(filename, in_crs=LAT_LON_CRS, boundary_gdf=None, boundary_geocode=None, boundary_file=None, filter_to_shape_ids=None, config=DefaultConfig)\n</code></pre> <p>Reads shapes and returns a geodataframe of shapes if filename is found.</p> <p>Otherwise, returns empty GeoDataFrame conforming to ShapesSchema.</p> <p>Sets index to be a copy of the primary key. Validates output dataframe using ShapesSchema.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>str</code>)           \u2013            <p>file to read shapes in from.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system number file is in. Defaults to LAT_LON_CRS.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>filter_to_shape_ids</code>               (<code>Optional[list]</code>, default:                   <code>None</code> )           \u2013            <p>List of shape_ids to filter the input data to. Defaults to None.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig.</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/io.py</code> <pre><code>@validate_call_pyd\ndef read_shapes(\n    filename: Path,\n    in_crs: int = LAT_LON_CRS,\n    boundary_gdf: Optional[GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    filter_to_shape_ids: Optional[list] = None,\n    config: WranglerConfig = DefaultConfig,\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Reads shapes and returns a geodataframe of shapes if filename is found.\n\n    Otherwise, returns empty GeoDataFrame conforming to ShapesSchema.\n\n    Sets index to be a copy of the primary key.\n    Validates output dataframe using ShapesSchema.\n\n    Args:\n        filename (str): file to read shapes in from.\n        in_crs: coordinate reference system number file is in. Defaults to LAT_LON_CRS.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        filter_to_shape_ids: List of shape_ids to filter the input data to. Defaults to None.\n        config: WranglerConfig instance. Defaults to DefaultConfig.\n    \"\"\"\n    if not Path(filename).exists():\n        WranglerLogger.warning(\n            f\"Shapes file {filename} not found, but is optional. \\\n                               Returning empty shapes dataframe.\"\n        )\n        return empty_df_from_datamodel(RoadShapesTable, crs=LAT_LON_CRS).set_index(\n            \"shape_id_idx\", inplace=True\n        )\n\n    start_time = time.time()\n    WranglerLogger.debug(f\"Reading shapes from {filename}.\")\n\n    shapes_df = read_table(\n        filename,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n        read_speed=config.CPU.EST_PD_READ_SPEED,\n    )\n    if filter_to_shape_ids:\n        shapes_df = shapes_df[shapes_df[\"shape_id\"].isin(filter_to_shape_ids)]\n    WranglerLogger.debug(\n        f\"Read {len(shapes_df)} shapes from file in {round(time.time() - start_time, 2)}.\"\n    )\n    shapes_df = df_to_shapes_df(shapes_df, in_crs=in_crs)\n    shapes_df.attrs[\"source_file\"] = filename\n    WranglerLogger.info(\n        f\"Read {len(shapes_df)} shapes from {filename} in {round(time.time() - start_time, 2)}.\"\n    )\n    shapes_df = validate_df_to_model(shapes_df, RoadShapesTable)\n    return shapes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.io.write_shapes","title":"network_wrangler.roadway.shapes.io.write_shapes","text":"<pre><code>write_shapes(shapes_df, out_dir, prefix, format, overwrite)\n</code></pre> <p>Writes shapes to file.</p> <p>Parameters:</p> <ul> <li> <code>shapes_df</code>               (<code>DataFrame[RoadShapesTable]</code>)           \u2013            <p>DataFrame of shapes to write.</p> </li> <li> <code>out_dir</code>               (<code>Union[str, Path]</code>)           \u2013            <p>directory to write shapes to.</p> </li> <li> <code>prefix</code>               (<code>str</code>)           \u2013            <p>prefix to add to file name.</p> </li> <li> <code>format</code>               (<code>str</code>)           \u2013            <p>format to write shapes in.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>)           \u2013            <p>whether to overwrite file if it exists.</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/io.py</code> <pre><code>@validate_call_pyd\ndef write_shapes(\n    shapes_df: DataFrame[RoadShapesTable],\n    out_dir: Union[str, Path],\n    prefix: str,\n    format: str,\n    overwrite: bool,\n) -&gt; None:\n    \"\"\"Writes shapes to file.\n\n    Args:\n        shapes_df: DataFrame of shapes to write.\n        out_dir: directory to write shapes to.\n        prefix: prefix to add to file name.\n        format: format to write shapes in.\n        overwrite: whether to overwrite file if it exists.\n    \"\"\"\n    shapes_file = Path(out_dir) / f\"{prefix}shape.{format}\"\n    shapes_df = order_fields_from_data_model(shapes_df, RoadShapesTable)\n    write_table(shapes_df, shapes_file, overwrite=overwrite)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.create.add_offset_shapes","title":"network_wrangler.roadway.shapes.create.add_offset_shapes","text":"<pre><code>add_offset_shapes(shapes_df, shape_ids, offset_dist_meters=10, id_scalar=DefaultConfig.IDS.ROAD_SHAPE_ID_SCALAR)\n</code></pre> <p>Appends a RoadShapesTable with new shape records for shape_ids which are offset from orig.</p> <p>Parameters:</p> <ul> <li> <code>shapes_df</code>               (<code>RoadShapesTable</code>)           \u2013            <p>Original RoadShapesTable to add on to.</p> </li> <li> <code>shape_ids</code>               (<code>list</code>)           \u2013            <p>Shape_ids to create offsets for.</p> </li> <li> <code>offset_dist_meters</code>               (<code>float</code>, default:                   <code>10</code> )           \u2013            <p>Distance in meters to offset by. Defaults to 10.</p> </li> <li> <code>id_scalar</code>               (<code>int</code>, default:                   <code>ROAD_SHAPE_ID_SCALAR</code> )           \u2013            <p>Increment to add to shape_id. Defaults to SHAPE_ID_SCALAR.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RoadShapesTable</code> (              <code>DataFrame[RoadShapesTable]</code> )          \u2013            <p>with added offset shape_ids and a column <code>ref_shape_id</code> which references the shape_id which was offset to create it.</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/create.py</code> <pre><code>def add_offset_shapes(\n    shapes_df: DataFrame[RoadShapesTable],\n    shape_ids: list,\n    offset_dist_meters: float = 10,\n    id_scalar: int = DefaultConfig.IDS.ROAD_SHAPE_ID_SCALAR,\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Appends a RoadShapesTable with new shape records for shape_ids which are offset from orig.\n\n    Args:\n        shapes_df (RoadShapesTable): Original RoadShapesTable to add on to.\n        shape_ids (list): Shape_ids to create offsets for.\n        offset_dist_meters (float, optional): Distance in meters to offset by. Defaults to 10.\n        id_scalar (int, optional): Increment to add to shape_id. Defaults to SHAPE_ID_SCALAR.\n\n    Returns:\n        RoadShapesTable: with added offset shape_ids and a column `ref_shape_id` which references\n            the shape_id which was offset to create it.\n    \"\"\"\n    offset_shapes_df = create_offset_shapes(shapes_df, shape_ids, offset_dist_meters, id_scalar)\n    shapes_df = concat_with_attr([shapes_df, offset_shapes_df])\n    shapes_df = validate_df_to_model(shapes_df, RoadShapesTable)\n    return shapes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.create.create_offset_shapes","title":"network_wrangler.roadway.shapes.create.create_offset_shapes","text":"<pre><code>create_offset_shapes(shapes_df, shape_ids, offset_dist_meters=10, id_scalar=DefaultConfig.IDS.ROAD_SHAPE_ID_SCALAR)\n</code></pre> <p>Create a RoadShapesTable of new shape records for shape_ids which are offset.</p> <p>Parameters:</p> <ul> <li> <code>shapes_df</code>               (<code>RoadShapesTable</code>)           \u2013            <p>Original RoadShapesTable to add on to.</p> </li> <li> <code>shape_ids</code>               (<code>list</code>)           \u2013            <p>Shape_ids to create offsets for.</p> </li> <li> <code>offset_dist_meters</code>               (<code>float</code>, default:                   <code>10</code> )           \u2013            <p>Distance in meters to offset by. Defaults to 10.</p> </li> <li> <code>id_scalar</code>               (<code>int</code>, default:                   <code>ROAD_SHAPE_ID_SCALAR</code> )           \u2013            <p>Increment to add to shape_id. Defaults to ROAD_SHAPE_ID_SCALAR.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RoadShapesTable</code> (              <code>DataFrame[RoadShapesTable]</code> )          \u2013            <p>of offset shapes and a column <code>ref_shape_id</code> which references     the shape_id which was offset to create it.</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/create.py</code> <pre><code>def create_offset_shapes(\n    shapes_df: DataFrame[RoadShapesTable],\n    shape_ids: list,\n    offset_dist_meters: float = 10,\n    id_scalar: int = DefaultConfig.IDS.ROAD_SHAPE_ID_SCALAR,\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Create a RoadShapesTable of new shape records for shape_ids which are offset.\n\n    Args:\n        shapes_df (RoadShapesTable): Original RoadShapesTable to add on to.\n        shape_ids (list): Shape_ids to create offsets for.\n        offset_dist_meters (float, optional): Distance in meters to offset by. Defaults to 10.\n        id_scalar (int, optional): Increment to add to shape_id. Defaults to ROAD_SHAPE_ID_SCALAR.\n\n    Returns:\n      RoadShapesTable: of offset shapes and a column `ref_shape_id` which references\n            the shape_id which was offset to create it.\n    \"\"\"\n    offset_shapes_df = pd.DataFrame(\n        {\n            \"shape_id\": generate_list_of_new_ids_from_existing(\n                shape_ids, shapes_df.shape_ids.to_list, id_scalar\n            ),\n            \"ref_shape_id\": shape_ids,\n        }\n    )\n\n    ref_shapes_df = copy.deepcopy(shapes_df[shapes_df[\"shape_id\"].isin(shape_ids)])\n\n    ref_shapes_df[\"offset_shape_id\"] = generate_list_of_new_ids_from_existing(\n        ref_shapes_df.shape_id.to_list, shapes_df.shape_ids.to_list, id_scalar\n    )\n\n    ref_shapes_df[\"geometry\"] = offset_geometry_meters(ref_shapes_df.geometry, offset_dist_meters)\n\n    offset_shapes_df = ref_shapes_df.rename(\n        columns={\n            \"shape_id\": \"ref_shape_id\",\n            \"offset_shape_id\": \"shape_id\",\n        }\n    )\n\n    offset_shapes_gdf = gpd.GeoDataFrame(offset_shapes_df, geometry=\"geometry\", crs=shapes_df.crs)\n\n    offset_shapes_gdf = validate_df_to_model(offset_shapes_gdf, RoadShapesTable)\n\n    return offset_shapes_gdf\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.create.df_to_shapes_df","title":"network_wrangler.roadway.shapes.create.df_to_shapes_df","text":"<pre><code>df_to_shapes_df(shapes_df, in_crs=LAT_LON_CRS, config=DefaultConfig)\n</code></pre> <p>Sets index to be a copy of the primary key, validates to RoadShapesTable and aligns CRS.</p> <p>Parameters:</p> <ul> <li> <code>shapes_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>description</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system number of incoming df. ONLY used if shapes_df is not already set. Defaults to LAT_LON_CRS.</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig instance. Defaults to DefaultConfig. NOTE: Not currently used.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadShapesTable]</code>           \u2013            <p>DataFrame[RoadShapesTable]</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/create.py</code> <pre><code>def df_to_shapes_df(\n    shapes_df: gpd.GeoDataFrame,\n    in_crs: int = LAT_LON_CRS,\n    config: WranglerConfig = DefaultConfig,  # noqa: ARG001\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Sets index to be a copy of the primary key, validates to RoadShapesTable and aligns CRS.\n\n    Args:\n        shapes_df (gpd.GeoDataFrame): _description_\n        in_crs: coordinate reference system number of incoming df. ONLY used if shapes_df is not\n            already set. Defaults to LAT_LON_CRS.\n        config: WranglerConfig instance. Defaults to DefaultConfig. NOTE: Not currently used.\n\n    Returns:\n        DataFrame[RoadShapesTable]\n    \"\"\"\n    WranglerLogger.debug(f\"Creating {len(shapes_df)} shapes.\")\n    if not isinstance(shapes_df, gpd.GeoDataFrame):\n        shapes_df = coerce_gdf(shapes_df, in_crs=in_crs)\n\n    if shapes_df.crs != LAT_LON_CRS:\n        shapes_df = shapes_df.to_crs(LAT_LON_CRS)\n\n    shapes_df = _check_rename_old_column_aliases(shapes_df)\n\n    shapes_df.attrs.update(RoadShapesAttrs)\n    shapes_df = set_df_index_to_pk(shapes_df)\n    shapes_df.gdf_name = shapes_df.attrs[\"name\"]\n    shapes_df = validate_df_to_model(shapes_df, RoadShapesTable)\n\n    return shapes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.edit.edit_shape_geometry_from_nodes","title":"network_wrangler.roadway.shapes.edit.edit_shape_geometry_from_nodes","text":"<pre><code>edit_shape_geometry_from_nodes(shapes_df, links_df, nodes_df, node_ids)\n</code></pre> <p>Updates the geometry for shapes for a given list of nodes.</p> <p>Should be called by any function that changes a node location.</p> This will mutate the geometry of a shape in place for the start and end node <p>Parameters:</p> <ul> <li> <code>shapes_df</code>               (<code>DataFrame[RoadShapesTable]</code>)           \u2013            <p>RoadShapesTable</p> </li> <li> <code>links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>RoadLinksTable</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame[RoadNodesTable]</code>)           \u2013            <p>RoadNodesTable</p> </li> <li> <code>node_ids</code>               (<code>list[int]</code>)           \u2013            <p>list of node PKs with updated geometry</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/edit.py</code> <pre><code>def edit_shape_geometry_from_nodes(\n    shapes_df: DataFrame[RoadShapesTable],\n    links_df: DataFrame[RoadLinksTable],\n    nodes_df: DataFrame[RoadNodesTable],\n    node_ids: list[int],\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Updates the geometry for shapes for a given list of nodes.\n\n    Should be called by any function that changes a node location.\n\n    NOTE: This will mutate the geometry of a shape in place for the start and end node\n            ...but not the nodes in-between.  Something to consider.\n\n    Args:\n        shapes_df: RoadShapesTable\n        links_df: RoadLinksTable\n        nodes_df: RoadNodesTable\n        node_ids: list of node PKs with updated geometry\n    \"\"\"\n    shapes_df = copy.deepcopy(shapes_df)\n    links_A_df = links_df.loc[links_df.A.isin(node_ids)]\n    _tempshape_A_df = shapes_df[[\"shape_id\", \"geometry\"]].merge(\n        links_A_df[[\"shape_id\", \"A\"]], on=\"shape_id\", how=\"inner\"\n    )\n    _shape_ids_A = _tempshape_A_df.shape_id.unique().tolist()\n    if _shape_ids_A:\n        shapes_df[_shape_ids_A, \"geometry\"] = update_nodes_in_linestring_geometry(\n            _tempshape_A_df, nodes_df, 0\n        )\n\n    links_B_df = links_df.loc[links_df.B.isin(node_ids)]\n    _tempshape_B_df = shapes_df[[\"shape_id\", \"geometry\"]].merge(\n        links_B_df[[\"shape_id\", \"B\"]], on=\"shape_id\", how=\"inner\"\n    )\n    _shape_ids_B = _tempshape_B_df.shape_id.unique().tolist()\n    if _shape_ids_A:\n        shapes_df[_shape_ids_B, \"geometry\"] = update_nodes_in_linestring_geometry(\n            _tempshape_A_df, nodes_df, -1\n        )\n    return shapes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.delete.delete_shapes_by_ids","title":"network_wrangler.roadway.shapes.delete.delete_shapes_by_ids","text":"<pre><code>delete_shapes_by_ids(shapes_df, del_shape_ids, ignore_missing=False)\n</code></pre> <p>Deletes shapes from shapes_df by shape_id.</p> <p>Parameters:</p> <ul> <li> <code>shapes_df</code>               (<code>DataFrame[RoadShapesTable]</code>)           \u2013            <p>RoadShapesTable</p> </li> <li> <code>del_shape_ids</code>               (<code>list[int]</code>)           \u2013            <p>list of shape_ids to delete</p> </li> <li> <code>ignore_missing</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will not raise an error if shape_id is not found in shapes_df</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[RoadShapesTable]</code>           \u2013            <p>DataFrame[RoadShapesTable]: a copy of shapes_df with shapes removed</p> </li> </ul> Source code in <code>network_wrangler/roadway/shapes/delete.py</code> <pre><code>def delete_shapes_by_ids(\n    shapes_df: DataFrame[RoadShapesTable], del_shape_ids: list[int], ignore_missing: bool = False\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Deletes shapes from shapes_df by shape_id.\n\n    Args:\n        shapes_df: RoadShapesTable\n        del_shape_ids: list of shape_ids to delete\n        ignore_missing: if True, will not raise an error if shape_id is not found in shapes_df\n\n    Returns:\n        DataFrame[RoadShapesTable]: a copy of shapes_df with shapes removed\n    \"\"\"\n    WranglerLogger.debug(f\"Deleting shapes with ids: \\n{del_shape_ids}\")\n\n    _missing = set(del_shape_ids) - set(shapes_df.index)\n    if _missing:\n        WranglerLogger.warning(f\"Shapes in network not there to delete: \\n{_missing}\")\n        if not ignore_missing:\n            msg = \"Shapes to delete are not in the network.\"\n            raise ShapeDeletionError(msg)\n    return shapes_df.drop(labels=del_shape_ids, errors=\"ignore\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.filters.filter_shapes_to_links","title":"network_wrangler.roadway.shapes.filters.filter_shapes_to_links","text":"<pre><code>filter_shapes_to_links(shapes_df, links_df)\n</code></pre> <p>Shapes which are referenced in RoadLinksTable.</p> Source code in <code>network_wrangler/roadway/shapes/filters.py</code> <pre><code>def filter_shapes_to_links(\n    shapes_df: DataFrame[RoadShapesTable], links_df: DataFrame[RoadLinksTable]\n) -&gt; DataFrame[RoadShapesTable]:\n    \"\"\"Shapes which are referenced in RoadLinksTable.\"\"\"\n    return shapes_df.loc[shapes_df.shape_id.isin(links_df.shape_id)]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.shapes.shapes.shape_ids_without_links","title":"network_wrangler.roadway.shapes.shapes.shape_ids_without_links","text":"<pre><code>shape_ids_without_links(shapes_df, links_df)\n</code></pre> <p>List of shape ids that don\u2019t have associated links.</p> Source code in <code>network_wrangler/roadway/shapes/shapes.py</code> <pre><code>def shape_ids_without_links(\n    shapes_df: DataFrame[RoadShapesTable], links_df: DataFrame[RoadLinksTable]\n) -&gt; list[int]:\n    \"\"\"List of shape ids that don't have associated links.\"\"\"\n    return list(set(shapes_df.index) - set(links_df.shape_ids.to_list()))\n</code></pre>"},{"location":"api_roadway/#roadway-projects","title":"Roadway Projects","text":"<p>Functions for applying roadway link or node addition project cards to the roadway network.</p> <p>Wrapper function for applying code to change roadway network.</p> <p>Wrapper function for applying roadway deletion project card to RoadwayNetwork.</p> <p>Functions for applying roadway property change project cards to the roadway network.</p>"},{"location":"api_roadway/#network_wrangler.roadway.projects.add.apply_new_roadway","title":"network_wrangler.roadway.projects.add.apply_new_roadway","text":"<pre><code>apply_new_roadway(roadway_net, roadway_addition, project_name=None)\n</code></pre> <p>Add the new roadway features defined in the project card.</p> <p>New nodes are added first so that links can refer to any added nodes.</p> <p>Parameters:</p> <ul> <li> <code>roadway_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>input RoadwayNetwork to apply change to</p> </li> <li> <code>roadway_addition</code>               (<code>dict</code>)           \u2013            <p>dictionary conforming to RoadwayAddition model such as:</p> </li> <li> <code>project_name</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>optional name of the project to be applied</p> </li> </ul> Source code in <code>network_wrangler/roadway/projects/add.py</code> <pre><code>def apply_new_roadway(\n    roadway_net: RoadwayNetwork,\n    roadway_addition: dict,\n    project_name: Optional[str] = None,\n) -&gt; RoadwayNetwork:\n    \"\"\"Add the new roadway features defined in the project card.\n\n    New nodes are added first so that links can refer to any added nodes.\n\n    Args:\n        roadway_net: input RoadwayNetwork to apply change to\n        roadway_addition: dictionary conforming to RoadwayAddition model such as:\n\n        ```json\n            {\n                \"links\": [\n                    {\n                        \"model_link_id\": 1000,\n                        \"A\": 100,\n                        \"B\": 101,\n                        \"lanes\": 2,\n                        \"name\": \"Main St\"\n                    }\n                ],\n                \"nodes\": [\n                    {\n                        \"model_node_id\": 100,\n                        \"X\": 0,\n                        \"Y\": 0\n                    },\n                    {\n                        \"model_node_id\": 101,\n                        \"X\": 0,\n                        \"Y\": 100\n                    }\n                ],\n            }\n        ```\n        project_name: optional name of the project to be applied\n\n    returns: updated network with new links and nodes and associated geometries\n    \"\"\"\n    add_links, add_nodes = roadway_addition.get(\"links\", []), roadway_addition.get(\"nodes\", [])\n    if not add_links and not add_nodes:\n        msg = \"No links or nodes given to add.\"\n        raise NewRoadwayError(msg)\n\n    WranglerLogger.debug(\n        f\"Adding New Roadway Features: \\n-Links: \\n{add_links}\\n-Nodes: \\n{add_nodes}\"\n    )\n    if add_nodes:\n        _new_nodes_df = data_to_nodes_df(pd.DataFrame(add_nodes), config=roadway_net.config)\n        if project_name:\n            _new_nodes_df[\"projects\"] = f\"{project_name},\"\n        roadway_net.add_nodes(_new_nodes_df)\n\n    if add_links:\n        # make sure links refer to nodes in network\n        _missing_nodes = _node_ids_from_set_links(add_links) - set(roadway_net.nodes_df.index)\n        if _missing_nodes:\n            msg = \"Link additions use nodes not found in network.\"\n            WranglerLogger.error(msg + f\" Missing nodes for new links: {_missing_nodes}\")\n            raise NewRoadwayError(msg)\n        _new_links_df = data_to_links_df(\n            add_links,\n            nodes_df=roadway_net.nodes_df,\n        )\n        if project_name:\n            _new_links_df[\"projects\"] = f\"{project_name},\"\n\n        roadway_net.add_links(_new_links_df)\n\n    return roadway_net\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.projects.calculate.apply_calculated_roadway","title":"network_wrangler.roadway.projects.calculate.apply_calculated_roadway","text":"<pre><code>apply_calculated_roadway(roadway_net, pycode)\n</code></pre> <p>Changes roadway network object by executing pycode.</p> <p>Parameters:</p> <ul> <li> <code>roadway_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>network to manipulate</p> </li> <li> <code>pycode</code>               (<code>str</code>)           \u2013            <p>python code which changes values in the roadway network object</p> </li> </ul> Source code in <code>network_wrangler/roadway/projects/calculate.py</code> <pre><code>def apply_calculated_roadway(\n    roadway_net: RoadwayNetwork,\n    pycode: str,\n) -&gt; RoadwayNetwork:\n    \"\"\"Changes roadway network object by executing pycode.\n\n    Args:\n        roadway_net: network to manipulate\n        pycode: python code which changes values in the roadway network object\n    \"\"\"\n    WranglerLogger.debug(\"Applying calculated roadway project.\")\n    self = roadway_net\n    exec(pycode)\n\n    return roadway_net\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.projects.delete.apply_roadway_deletion","title":"network_wrangler.roadway.projects.delete.apply_roadway_deletion","text":"<pre><code>apply_roadway_deletion(roadway_net, roadway_deletion, transit_net=None)\n</code></pre> <p>Delete the roadway links or nodes defined in the project card.</p> <p>If deleting links and specified in RoadwayDeletion, will also clean up the shapes and nodes used by links. Defaults to not cleaning up shapes or nodes.</p> <p>Parameters:</p> <ul> <li> <code>roadway_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>input RoadwayNetwork to apply change to</p> </li> <li> <code>roadway_deletion</code>               (<code>Union[dict, RoadwayDeletion]</code>)           \u2013            <p>dictionary conforming to RoadwayDeletion</p> </li> <li> <code>transit_net</code>               (<code>Optional[TransitNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>input TransitNetwork which will be used to check if deletion breaks transit shapes. If None, will not check for broken shapes.</p> </li> </ul> Source code in <code>network_wrangler/roadway/projects/delete.py</code> <pre><code>def apply_roadway_deletion(\n    roadway_net: RoadwayNetwork,\n    roadway_deletion: Union[dict, RoadwayDeletion],\n    transit_net: Optional[TransitNetwork] = None,\n) -&gt; RoadwayNetwork:\n    \"\"\"Delete the roadway links or nodes defined in the project card.\n\n    If deleting links and specified in RoadwayDeletion, will also clean up the shapes and nodes\n    used by links. Defaults to not cleaning up shapes or nodes.\n\n    Args:\n        roadway_net: input RoadwayNetwork to apply change to\n        roadway_deletion: dictionary conforming to RoadwayDeletion\n        transit_net: input TransitNetwork which will be used to check if deletion breaks transit\n            shapes. If None, will not check for broken shapes.\n    \"\"\"\n    if not isinstance(roadway_deletion, RoadwayDeletion):\n        roadway_deletion = RoadwayDeletion(**roadway_deletion)\n\n    WranglerLogger.debug(f\"Deleting Roadway Features: \\n{roadway_deletion}\")\n\n    if roadway_deletion.links:\n        roadway_net.delete_links(\n            roadway_deletion.links.model_dump(exclude_none=True, by_alias=True),\n            clean_shapes=roadway_deletion.clean_shapes,\n            clean_nodes=roadway_deletion.clean_nodes,\n            transit_net=transit_net,\n        )\n\n    if roadway_deletion.nodes:\n        roadway_net.delete_nodes(\n            roadway_deletion.nodes.model_dump(exclude_none=True, by_alias=True),\n        )\n\n    return roadway_net\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.projects.edit_property.apply_roadway_property_change","title":"network_wrangler.roadway.projects.edit_property.apply_roadway_property_change","text":"<pre><code>apply_roadway_property_change(roadway_net, selection, property_changes, project_name=None)\n</code></pre> <p>Changes roadway properties for the selected features based on the project card.</p> <p>Parameters:</p> <ul> <li> <code>roadway_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>input RoadwayNetwork to apply change to</p> </li> <li> <code>selection</code>           \u2013            <p>roadway selection object</p> </li> <li> <code>property_changes</code>           \u2013            <p>dictionary of roadway properties to change. e.g.</p> <pre><code>#changes number of lanes 3 to 2 (reduction of 1) and adds a bicycle lane\nlanes:\n    existing: 3\n    change: -1\nbicycle_facility:\n    set: 2\n</code></pre> </li> <li> <code>project_name</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>optional name of the project to be applied</p> </li> </ul> Source code in <code>network_wrangler/roadway/projects/edit_property.py</code> <pre><code>def apply_roadway_property_change(\n    roadway_net: RoadwayNetwork,\n    selection: Union[RoadwayNodeSelection, RoadwayLinkSelection],\n    property_changes: dict[str, RoadPropertyChange],\n    project_name: Optional[str] = None,\n) -&gt; RoadwayNetwork:\n    \"\"\"Changes roadway properties for the selected features based on the project card.\n\n    Args:\n        roadway_net: input RoadwayNetwork to apply change to\n        selection : roadway selection object\n        property_changes : dictionary of roadway properties to change.\n            e.g.\n\n            ```yml\n            #changes number of lanes 3 to 2 (reduction of 1) and adds a bicycle lane\n            lanes:\n                existing: 3\n                change: -1\n            bicycle_facility:\n                set: 2\n            ```\n        project_name: optional name of the project to be applied\n    \"\"\"\n    WranglerLogger.debug(\"Applying roadway property change project.\")\n\n    if isinstance(selection, RoadwayLinkSelection):\n        roadway_net.links_df = edit_link_properties(\n            roadway_net.links_df,\n            selection.selected_links,\n            property_changes,\n            project_name=project_name,\n        )\n\n    elif isinstance(selection, RoadwayNodeSelection):\n        non_geo_changes = {\n            k: v for k, v in property_changes.items() if k not in NodeGeometryChange.model_fields\n        }\n        for property, property_dict in non_geo_changes.items():\n            prop_change = RoadPropertyChange(**property_dict)\n            roadway_net.nodes_df = edit_node_property(\n                roadway_net.nodes_df,\n                selection.selected_nodes,\n                property,\n                prop_change,\n                project_name=project_name,\n            )\n\n        geo_changes_df = _node_geo_change_from_property_changes(\n            property_changes, selection.selected_nodes\n        )\n        if geo_changes_df is not None:\n            roadway_net.move_nodes(geo_changes_df)\n\n    else:\n        msg = \"geometry_type must be either 'links' or 'nodes'\"\n        raise RoadwayPropertyChangeError(msg)\n\n    return roadway_net\n</code></pre>"},{"location":"api_roadway/#roadway-supporting-modules","title":"Roadway Supporting Modules","text":"<p>Functions for reading and writing roadway networks.</p> <p>Functions to clip a RoadwayNetwork object to a boundary.</p> <p>Clipped roadway is an independent roadway network that is a subset of the original roadway network.</p> <p>Unlike a Subnet, it is geographic selection defined by a bounday rather than a logical selection defined by a graph.</p> <p>Example usage:</p> <pre><code>from network_wrangler.roadway load_roadway_from_dir, write_roadway\nfrom network_wrangler.roadway.clip import clip_roadway\n\nstpaul_net = load_roadway_from_dir(example_dir / \"stpaul\")\nboundary_file = test_dir / \"data\" / \"ecolab.geojson\"\nclipped_network = clip_roadway(stpaul_net, boundary_file=boundary_file)\nwrite_roadway(clipped_network, out_dir, prefix=\"ecolab\", format=\"geojson\", true_shape=True)\n</code></pre> <p>Functions to create a model roadway network from a roadway network.</p> <p>Utility functions for RoadwayNetwork and ModelRoadwayNetwork classes.</p> <p>Validates a roadway network to the wrangler data model specifications.</p> <p>Segment class and related functions for working with segments of a RoadwayNetwork.</p> <p>A segment is a contiguous length of RoadwayNetwork defined by start/end nodes + link selections.</p> <p>Segments are defined by a selection dictionary and then searched for on the network using a shortest path graph search.</p> <p>Usage:</p> <pre><code>selection_dict = {\n    \"links\": {\"name\": [\"6th\", \"Sixth\", \"sixth\"]},\n    \"from\": {\"osm_node_id\": \"187899923\"},\n    \"to\": {\"osm_node_id\": \"187865924\"},\n}\n\nsegment = Segment(net, selection)\nsegment.segment_links_df\nsegment.segment_nodes\n</code></pre> <p>Subnet class for RoadwayNetwork object.</p> <p>Functions to convert RoadwayNetwork to osmnx graph and perform graph operations.</p>"},{"location":"api_roadway/#network_wrangler.roadway.io.convert_roadway_file_serialization","title":"network_wrangler.roadway.io.convert_roadway_file_serialization","text":"<pre><code>convert_roadway_file_serialization(in_path, in_format='geojson', out_dir=Path(), out_format='parquet', out_prefix='', overwrite=True, boundary_gdf=None, boundary_geocode=None, boundary_file=None, chunk_size=None)\n</code></pre> <p>Converts a files in a roadway from one serialization format to another without parsing.</p> <p>Does not do any validation.</p> <p>Parameters:</p> <ul> <li> <code>in_path</code>               (<code>Path</code>)           \u2013            <p>the path to the input directory.</p> </li> <li> <code>in_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the file formatof the input files. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>out_dir</code>               (<code>Path</code>, default:                   <code>Path()</code> )           \u2013            <p>the path were the output will be saved.</p> </li> <li> <code>out_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'parquet'</code> )           \u2013            <p>the format of the output files. Defaults to \u201cparquet\u201d.</p> </li> <li> <code>out_prefix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>the name prefix of the roadway files that will be generated. Defaults to \u201c\u201d.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>chunk_size</code>               (<code>Optional[int]</code>, default:                   <code>None</code> )           \u2013            <p>Size of chunk to process if want to force chunking. Defaults to None. Chunking will only apply to converting from json to parquet files.</p> </li> </ul> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def convert_roadway_file_serialization(\n    in_path: Path,\n    in_format: RoadwayFileTypes = \"geojson\",\n    out_dir: Path = Path(),\n    out_format: RoadwayFileTypes = \"parquet\",\n    out_prefix: str = \"\",\n    overwrite: bool = True,\n    boundary_gdf: Optional[GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    chunk_size: Optional[int] = None,\n):\n    \"\"\"Converts a files in a roadway from one serialization format to another without parsing.\n\n    Does not do any validation.\n\n    Args:\n        in_path: the path to the input directory.\n        in_format: the file formatof the input files. Defaults to \"geojson\".\n        out_dir: the path were the output will be saved.\n        out_format: the format of the output files. Defaults to \"parquet\".\n        out_prefix: the name prefix of the roadway files that will be generated. Defaults to \"\".\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        chunk_size: Size of chunk to process if want to force chunking. Defaults to None.\n            Chunking will only apply to converting from json to parquet files.\n    \"\"\"\n    links_in_file, nodes_in_file, shapes_in_file = id_roadway_file_paths_in_dir(in_path, in_format)\n    from ..utils.io_table import convert_file_serialization  # noqa: PLC0415\n\n    nodes_out_file = Path(out_dir / f\"{out_prefix}_nodes.{out_format}\")\n    convert_file_serialization(\n        nodes_in_file,\n        nodes_out_file,\n        overwrite=overwrite,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n        chunk_size=chunk_size,\n    )\n\n    if any([boundary_file, boundary_geocode, boundary_gdf is not None]):\n        node_filter_s = read_table(nodes_out_file).model_node_id\n    else:\n        node_filter_s = None\n\n    links_out_file = Path(out_dir / f\"{out_prefix}_links.{out_format}\")\n    if out_format == \"geojson\":\n        links_out_file = links_out_file.with_suffix(\".json\")\n\n    convert_file_serialization(\n        links_in_file,\n        links_out_file,\n        overwrite=overwrite,\n        node_filter_s=node_filter_s,\n        chunk_size=chunk_size,\n    )\n\n    if shapes_in_file:\n        shapes_out_file = Path(out_dir / f\"{out_prefix}_shapes.{out_format}\")\n        convert_file_serialization(\n            shapes_in_file,\n            shapes_out_file,\n            overwrite=overwrite,\n            boundary_gdf=boundary_gdf,\n            boundary_geocode=boundary_geocode,\n            boundary_file=boundary_file,\n            chunk_size=chunk_size,\n        )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.io.convert_roadway_network_serialization","title":"network_wrangler.roadway.io.convert_roadway_network_serialization","text":"<pre><code>convert_roadway_network_serialization(input_path, output_format='geojson', out_dir='.', input_file_format='geojson', out_prefix='', overwrite=True, boundary_gdf=None, boundary_geocode=None, boundary_file=None, filter_links_to_nodes=False)\n</code></pre> <p>Converts a roadway network from one serialization format to another with parsing.</p> <p>Performs validation and parsing.</p> <p>Parameters:</p> <ul> <li> <code>input_path</code>               (<code>Union[str, Path]</code>)           \u2013            <p>the path to the input directory.</p> </li> <li> <code>output_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the format of the output files. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>out_dir</code>               (<code>Union[str, Path]</code>, default:                   <code>'.'</code> )           \u2013            <p>the path were the output will be saved.</p> </li> <li> <code>input_file_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the format of the input files. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>out_prefix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>the name prefix of the roadway files that will be generated. Defaults to \u201c\u201d.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>filter_links_to_nodes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will filter the links to only those that have nodes. Defaults to False unless boundary_gdf, boundary_geocode, or boundary_file are provided.</p> </li> </ul> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def convert_roadway_network_serialization(\n    input_path: Union[str, Path],\n    output_format: RoadwayFileTypes = \"geojson\",\n    out_dir: Union[str, Path] = \".\",\n    input_file_format: RoadwayFileTypes = \"geojson\",\n    out_prefix: str = \"\",\n    overwrite: bool = True,\n    boundary_gdf: Optional[GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    filter_links_to_nodes: bool = False,\n):\n    \"\"\"Converts a roadway network from one serialization format to another with parsing.\n\n    Performs validation and parsing.\n\n    Args:\n        input_path: the path to the input directory.\n        output_format: the format of the output files. Defaults to \"geojson\".\n        out_dir: the path were the output will be saved.\n        input_file_format: the format of the input files. Defaults to \"geojson\".\n        out_prefix: the name prefix of the roadway files that will be generated. Defaults to \"\".\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        filter_links_to_nodes: if True, will filter the links to only those that have nodes.\n            Defaults to False unless boundary_gdf, boundary_geocode, or boundary_file are provided.\n    \"\"\"\n    if input_file_format is None:\n        input_file_format = \"geojson\"\n    WranglerLogger.info(\n        f\"Loading roadway network from {input_path} with format {input_file_format}\"\n    )\n    net = load_roadway_from_dir(\n        input_path,\n        file_format=input_file_format,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n        filter_links_to_nodes=filter_links_to_nodes,\n    )\n    WranglerLogger.info(f\"Writing roadway network to {out_dir} in {output_format} format.\")\n    write_roadway(\n        net,\n        prefix=out_prefix,\n        out_dir=out_dir,\n        file_format=output_format,\n        overwrite=overwrite,\n    )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.io.id_roadway_file_paths_in_dir","title":"network_wrangler.roadway.io.id_roadway_file_paths_in_dir","text":"<pre><code>id_roadway_file_paths_in_dir(dir, file_format='geojson')\n</code></pre> <p>Identifies the paths to the links, nodes, and shapes files in a directory.</p> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def id_roadway_file_paths_in_dir(\n    dir: Union[Path, str], file_format: RoadwayFileTypes = \"geojson\"\n) -&gt; tuple[Path, Path, Union[None, Path]]:\n    \"\"\"Identifies the paths to the links, nodes, and shapes files in a directory.\"\"\"\n    network_path = Path(dir)\n    if not network_path.is_dir():\n        msg = f\"Directory {network_path} does not exist\"\n        raise FileNotFoundError(msg)\n\n    _link_file_format = file_format\n    if \"geojson\" in file_format:\n        _link_file_format = \"json\"\n\n    try:\n        links_file = next(network_path.glob(f\"*link*{_link_file_format}\"))\n    except StopIteration as err:\n        msg = f\"No links file with {_link_file_format} file format found in {network_path}\"\n        raise FileNotFoundError(msg) from err\n\n    try:\n        nodes_file = next(network_path.glob(f\"*node*{file_format}\"))\n    except StopIteration as err:\n        msg = f\"No nodes file with {file_format} file format found in {network_path}\"\n        raise FileNotFoundError(msg) from err\n\n    try:\n        shapes_file = next(network_path.glob(f\"*shape*{file_format}\"))\n    except StopIteration:\n        # Shape file is optional so if not found, its ok.\n        shapes_file = None\n\n    return links_file, nodes_file, shapes_file\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.io.load_roadway","title":"network_wrangler.roadway.io.load_roadway","text":"<pre><code>load_roadway(links_file, nodes_file, shapes_file=None, in_crs=LAT_LON_CRS, read_in_shapes=False, boundary_gdf=None, boundary_geocode=None, boundary_file=None, filter_links_to_nodes=None, config=DefaultConfig)\n</code></pre> <p>Reads a network from the roadway network standard.</p> <p>Validates that it conforms to the schema.</p> <p>Parameters:</p> <ul> <li> <code>links_file</code>               (<code>Path</code>)           \u2013            <p>full path to the link file</p> </li> <li> <code>nodes_file</code>               (<code>Path</code>)           \u2013            <p>full path to the node file</p> </li> <li> <code>shapes_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>full path to the shape file. NOTE if not found, it will defaul to None and not raise an error.</p> </li> <li> <code>in_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system that network is in. Defaults to LAT_LON_CRS which defaults to 4326 which is WGS84 lat/long.</p> </li> <li> <code>read_in_shapes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will read shapes into network instead of only lazily reading them when they are called. Defaults to False.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>filter_links_to_nodes</code>               (<code>Optional[bool]</code>, default:                   <code>None</code> )           \u2013            <p>if True, will filter the links to only those that have nodes. Defaults to False unless boundary_gdf, boundary_geocode, or boundary_file are provided which defaults it to True.</p> </li> <li> <code>config</code>               (<code>ConfigInputTypes</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>a Configuration object to update with the new configuration. Can be a dictionary, a path to a file, or a list of paths to files or a WranglerConfig instance. Defaults to None and will load defaults.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RoadwayNetwork</code>           \u2013            <p>(RoadwayNetwork) instance of RoadwayNetwork</p> </li> </ul> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def load_roadway(\n    links_file: Path,\n    nodes_file: Path,\n    shapes_file: Optional[Path] = None,\n    in_crs: int = LAT_LON_CRS,\n    read_in_shapes: bool = False,\n    boundary_gdf: Optional[GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    filter_links_to_nodes: Optional[bool] = None,\n    config: ConfigInputTypes = DefaultConfig,\n) -&gt; RoadwayNetwork:\n    \"\"\"Reads a network from the roadway network standard.\n\n    Validates that it conforms to the schema.\n\n    Args:\n        links_file: full path to the link file\n        nodes_file: full path to the node file\n        shapes_file: full path to the shape file. NOTE if not found, it will defaul to None and not\n            raise an error.\n        in_crs: coordinate reference system that network is in. Defaults to LAT_LON_CRS which\n            defaults to 4326 which is WGS84 lat/long.\n        read_in_shapes: if True, will read shapes into network instead of only lazily\n            reading them when they are called. Defaults to False.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        filter_links_to_nodes: if True, will filter the links to only those that have nodes.\n            Defaults to False unless boundary_gdf, boundary_geocode, or boundary_file are provided\n            which defaults it to True.\n        config: a Configuration object to update with the new configuration. Can be\n            a dictionary, a path to a file, or a list of paths to files or a\n            WranglerConfig instance. Defaults to None and will load defaults.\n\n    Returns:\n        (RoadwayNetwork) instance of RoadwayNetwork\n    \"\"\"\n    from .network import RoadwayNetwork  # noqa: PLC0415\n\n    if not isinstance(config, WranglerConfig):\n        config = load_wrangler_config(config)\n\n    nodes_file = Path(nodes_file)\n    links_file = Path(links_file)\n    shapes_file = Path(shapes_file) if shapes_file else None\n    if read_in_shapes and shapes_file is not None and shapes_file.exists():\n        shapes_df = read_shapes(\n            shapes_file,\n            in_crs=in_crs,\n            config=config,\n            boundary_gdf=boundary_gdf,\n            boundary_geocode=boundary_geocode,\n            boundary_file=boundary_file,\n        )\n    else:\n        shapes_df = None\n    nodes_df = read_nodes(\n        nodes_file,\n        in_crs=in_crs,\n        config=config,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    if filter_links_to_nodes is None and any(\n        [boundary_file, boundary_geocode, boundary_gdf is not None]\n    ):\n        filter_links_to_nodes = True\n    elif filter_links_to_nodes is None:\n        filter_links_to_nodes = False\n\n    links_df = read_links(\n        links_file,\n        in_crs=in_crs,\n        config=config,\n        nodes_df=nodes_df,\n        filter_to_nodes=filter_links_to_nodes,\n    )\n\n    roadway_network = RoadwayNetwork(\n        links_df=links_df,\n        nodes_df=nodes_df,\n        shapes_df=shapes_df,\n        config=config,\n    )\n    if shapes_file and shapes_file.exists():\n        roadway_network._shapes_file = shapes_file\n    roadway_network._links_file = links_file\n    roadway_network._nodes_file = nodes_file\n\n    return roadway_network\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.io.load_roadway_from_dataframes","title":"network_wrangler.roadway.io.load_roadway_from_dataframes","text":"<pre><code>load_roadway_from_dataframes(links_df, nodes_df, shapes_df=None, config=DefaultConfig)\n</code></pre> <p>Creates a RoadwayNetwork from DataFrames with validation.</p> <p>Validates the DataFrames against their respective Pandera schemas before creating the network instance. This method is useful if the user is already working with networks in DataFrames and doesn\u2019t want to write it to disk just to read it again.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing roadway links data</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame containing roadway nodes data</p> </li> <li> <code>shapes_df</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>Optional GeoDataFrame containing roadway shapes data</p> </li> <li> <code>config</code>               (<code>ConfigInputTypes</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>a Configuration object to update with the new configuration. Can be a dictionary, a path to a file, or a list of paths to files or a WranglerConfig instance. Defaults to None and will load defaults.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RoadwayNetwork</code>           \u2013            <p>(RoadwayNetwork) instance with validated data</p> </li> </ul> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def load_roadway_from_dataframes(\n    links_df: DataFrame,\n    nodes_df: DataFrame,\n    shapes_df: Optional[GeoDataFrame] = None,\n    config: ConfigInputTypes = DefaultConfig,\n) -&gt; RoadwayNetwork:\n    \"\"\"Creates a RoadwayNetwork from DataFrames with validation.\n\n    Validates the DataFrames against their respective Pandera schemas before\n    creating the network instance. This method is useful if the user is already working with\n    networks in DataFrames and doesn't want to write it to disk just to read it again.\n\n    Args:\n        links_df: DataFrame containing roadway links data\n        nodes_df: DataFrame containing roadway nodes data\n        shapes_df: Optional GeoDataFrame containing roadway shapes data\n        config: a Configuration object to update with the new configuration. Can be\n            a dictionary, a path to a file, or a list of paths to files or a\n            WranglerConfig instance. Defaults to None and will load defaults.\n\n    Returns:\n        (RoadwayNetwork) instance with validated data\n    \"\"\"\n    from ..models.roadway.tables import (  # noqa: PLC0415\n        RoadLinksTable,\n        RoadNodesTable,\n        RoadShapesTable,\n    )\n    from ..utils.models import validate_df_to_model  # noqa: PLC0415\n    from .network import RoadwayNetwork  # noqa: PLC0415\n\n    if not isinstance(config, WranglerConfig):\n        config = load_wrangler_config(config)\n\n    # Validate DataFrames against Pandera schemas\n    WranglerLogger.debug(\"Validating nodes_df against RoadNodesTable schema\")\n    validated_nodes_df = validate_df_to_model(nodes_df, RoadNodesTable)\n\n    WranglerLogger.debug(\"Validating links_df against RoadLinksTable schema\")\n    validated_links_df = validate_df_to_model(links_df, RoadLinksTable)\n\n    validated_shapes_df = None\n    if shapes_df is not None:\n        WranglerLogger.debug(\"Validating shapes_df against RoadShapesTable schema\")\n        validated_shapes_df = validate_df_to_model(shapes_df, RoadShapesTable)\n\n    # Create RoadwayNetwork with validated DataFrames\n    roadway_network = RoadwayNetwork(\n        links_df=validated_links_df,\n        nodes_df=validated_nodes_df,\n        shapes_df=validated_shapes_df,\n        config=config,\n    )\n\n    return roadway_network\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.io.load_roadway_from_dir","title":"network_wrangler.roadway.io.load_roadway_from_dir","text":"<pre><code>load_roadway_from_dir(dir, file_format='geojson', read_in_shapes=False, boundary_gdf=None, boundary_geocode=None, boundary_file=None, filter_links_to_nodes=None, config=DefaultConfig)\n</code></pre> <p>Reads a network from the roadway network standard.</p> <p>Validates that it conforms to the schema.</p> <p>Parameters:</p> <ul> <li> <code>dir</code>               (<code>Union[Path, str]</code>)           \u2013            <p>the directory where the network files are located</p> </li> <li> <code>file_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the file format of the files. Defaults to \u201cgeojson\u201d</p> </li> <li> <code>read_in_shapes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will read shapes into network instead of only lazily reading them when they are called. Defaults to False.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>filter_links_to_nodes</code>               (<code>Optional[bool]</code>, default:                   <code>None</code> )           \u2013            <p>if True, will filter the links to only those that have nodes. Defaults to False unless boundary_gdf, boundary_geocode, or boundary_file are provided which defaults it to True.</p> </li> <li> <code>config</code>               (<code>ConfigInputTypes</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>a Configuration object to update with the new configuration. Can be a dictionary, a path to a file, or a list of paths to files or a WranglerConfig instance. Defaults to None and will load defaults.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RoadwayNetwork</code>           \u2013            <p>(RoadwayNetwork) instance of RoadwayNetwork</p> </li> </ul> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def load_roadway_from_dir(\n    dir: Union[Path, str],\n    file_format: RoadwayFileTypes = \"geojson\",\n    read_in_shapes: bool = False,\n    boundary_gdf: Optional[GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    filter_links_to_nodes: Optional[bool] = None,\n    config: ConfigInputTypes = DefaultConfig,\n) -&gt; RoadwayNetwork:\n    \"\"\"Reads a network from the roadway network standard.\n\n    Validates that it conforms to the schema.\n\n    Args:\n        dir: the directory where the network files are located\n        file_format: the file format of the files. Defaults to \"geojson\"\n        read_in_shapes: if True, will read shapes into network instead of only lazily\n            reading them when they are called. Defaults to False.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        filter_links_to_nodes: if True, will filter the links to only those that have nodes.\n            Defaults to False unless boundary_gdf, boundary_geocode, or boundary_file are provided\n            which defaults it to True.\n        config: a Configuration object to update with the new configuration. Can be\n            a dictionary, a path to a file, or a list of paths to files or a\n            WranglerConfig instance. Defaults to None and will load defaults.\n\n    Returns:\n        (RoadwayNetwork) instance of RoadwayNetwork\n    \"\"\"\n    links_file, nodes_file, shapes_file = id_roadway_file_paths_in_dir(dir, file_format)\n\n    return load_roadway(\n        links_file=links_file,\n        nodes_file=nodes_file,\n        shapes_file=shapes_file,\n        read_in_shapes=read_in_shapes,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n        filter_links_to_nodes=filter_links_to_nodes,\n        config=config,\n    )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.io.write_roadway","title":"network_wrangler.roadway.io.write_roadway","text":"<pre><code>write_roadway(net, out_dir='.', convert_complex_link_properties_to_single_field=False, prefix='', file_format='geojson', overwrite=True, true_shape=False)\n</code></pre> <p>Writes a network in the roadway network standard.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>Union[RoadwayNetwork, ModelRoadwayNetwork]</code>)           \u2013            <p>RoadwayNetwork or ModelRoadwayNetwork instance to write out.</p> </li> <li> <code>out_dir</code>               (<code>Union[Path, str]</code>, default:                   <code>'.'</code> )           \u2013            <p>the path were the output will be saved. Defaults to \u201c.\u201d.</p> </li> <li> <code>prefix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>the name prefix of the roadway files that will be generated.</p> </li> <li> <code>file_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the format of the output files. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>convert_complex_link_properties_to_single_field</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will convert complex link properties to a single column consistent with v0 format.  This format is NOT valid with parquet and many other softwares. Defaults to False.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True.</p> </li> <li> <code>true_shape</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will write the true shape of the links as found from shapes. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/io.py</code> <pre><code>def write_roadway(\n    net: Union[RoadwayNetwork, ModelRoadwayNetwork],\n    out_dir: Union[Path, str] = \".\",\n    convert_complex_link_properties_to_single_field: bool = False,\n    prefix: str = \"\",\n    file_format: RoadwayFileTypes = \"geojson\",\n    overwrite: bool = True,\n    true_shape: bool = False,\n) -&gt; None:\n    \"\"\"Writes a network in the roadway network standard.\n\n    Args:\n        net: RoadwayNetwork or ModelRoadwayNetwork instance to write out.\n        out_dir: the path were the output will be saved. Defaults to \".\".\n        prefix: the name prefix of the roadway files that will be generated.\n        file_format: the format of the output files. Defaults to \"geojson\".\n        convert_complex_link_properties_to_single_field: if True, will convert complex link\n            properties to a single column consistent with v0 format.  This format is NOT valid\n            with parquet and many other softwares. Defaults to False.\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True.\n        true_shape: if True, will write the true shape of the links as found from shapes.\n            Defaults to False.\n    \"\"\"\n    out_dir = Path(out_dir)\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    prefix = f\"{prefix}_\" if prefix else \"\"\n\n    links_df = net.links_df\n    if true_shape:\n        links_df = links_df.true_shape(net.shapes_df)\n\n    write_links(\n        net.links_df,\n        convert_complex_properties_to_single_field=convert_complex_link_properties_to_single_field,\n        out_dir=out_dir,\n        prefix=prefix,\n        file_format=file_format,\n        overwrite=overwrite,\n        include_geometry=true_shape,\n    )\n    write_nodes(net.nodes_df, out_dir, prefix, file_format, overwrite)\n\n    if not true_shape and not net.shapes_df.empty:\n        write_shapes(net.shapes_df, out_dir, prefix, file_format, overwrite)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.clip.clip_roadway","title":"network_wrangler.roadway.clip.clip_roadway","text":"<pre><code>clip_roadway(network, boundary_gdf=None, boundary_geocode=None, boundary_file=None)\n</code></pre> <p>Clip a RoadwayNetwork object to a boundary.</p> <p>Retains only the links within or crossing the boundary and all the nodes that those links connect to.  At least one of boundary_gdf, boundary_geocode, or boundary_file must be provided.</p> <p>Parameters:</p> <ul> <li> <code>network</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>RoadwayNetwork object to be clipped.</p> </li> <li> <code>boundary_gdf</code>               (<code>GeoDataFrame</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataframe of one or more polygons which define the boundary to clip to. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Union[str, dict]</code>, default:                   <code>None</code> )           \u2013            <p>Place name to clip data to as ascertained from open street maps\u2019s Nomatim API (e.g. \u201cHennipen County, MN, USA\u201d). Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Union[str, Path]</code>, default:                   <code>None</code> )           \u2013            <p>Geographic data file that can be read by GeoPandas (e.g. geojson, parquet, shp) that defines a geographic polygon area to clip to. Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/roadway/clip.py</code> <pre><code>def clip_roadway(\n    network: RoadwayNetwork,\n    boundary_gdf: gpd.GeoDataFrame = None,\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n) -&gt; RoadwayNetwork:\n    \"\"\"Clip a RoadwayNetwork object to a boundary.\n\n    Retains only the links within or crossing the boundary and all the nodes that those links\n    connect to.  At least one of boundary_gdf, boundary_geocode, or boundary_file must be provided.\n\n    Args:\n        network (RoadwayNetwork): RoadwayNetwork object to be clipped.\n        boundary_gdf (gpd.GeoDataFrame, optional): GeoDataframe of one or more polygons which\n            define the boundary to clip to. Defaults to None.\n        boundary_geocode (Union[str,dict], optional): Place name to clip data to as ascertained\n            from open street maps's Nomatim API (e.g. \"Hennipen County, MN, USA\").\n            Defaults to None.\n        boundary_file (Union[str,Path], optional): Geographic data file that can be read by\n            GeoPandas (e.g. geojson, parquet, shp) that defines a geographic polygon area to clip\n            to. Defaults to None.\n\n    Returns: RoadwayNetwork clipped to the defined boundary.\n    \"\"\"\n    trimmed_links_df, trimmed_nodes_df, trimmed_shapes_df = clip_roadway_to_dfs(\n        network=network,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n    from .network import RoadwayNetwork  # noqa: PLC0415\n\n    trimmed_net = RoadwayNetwork(\n        links_df=trimmed_links_df,\n        nodes_df=trimmed_nodes_df,\n        _shapes_df=trimmed_shapes_df,\n    )\n    return trimmed_net\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.clip.clip_roadway_to_dfs","title":"network_wrangler.roadway.clip.clip_roadway_to_dfs","text":"<pre><code>clip_roadway_to_dfs(network, boundary_gdf=None, boundary_geocode=None, boundary_file=None)\n</code></pre> <p>Clips a RoadwayNetwork object to a boundary and returns the resulting GeoDataFrames.</p> <p>Retains only the links within or crossing the boundary and all the nodes that those links connect to.</p> <p>Parameters:</p> <ul> <li> <code>network</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>RoadwayNetwork object to be clipped.</p> </li> <li> <code>boundary_gdf</code>               (<code>GeoDataFrame</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataframe of one or more polygons which define the boundary to clip to. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Union[str, dict]</code>, default:                   <code>None</code> )           \u2013            <p>Place name to clip data to as ascertained from open street maps\u2019s Nomatim API (e.g. \u201cHennipen County, MN, USA\u201d). Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Union[str, Path]</code>, default:                   <code>None</code> )           \u2013            <p>Geographic data file that can be read by GeoPandas (e.g. geojson, parquet, shp) that defines a geographic polygon area to clip to. Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/roadway/clip.py</code> <pre><code>def clip_roadway_to_dfs(\n    network: RoadwayNetwork,\n    boundary_gdf: gpd.GeoDataFrame = None,\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n) -&gt; tuple:\n    \"\"\"Clips a RoadwayNetwork object to a boundary and returns the resulting GeoDataFrames.\n\n    Retains only the links within or crossing the boundary and all the nodes that those links\n    connect to.\n\n    Args:\n        network (RoadwayNetwork): RoadwayNetwork object to be clipped.\n        boundary_gdf (gpd.GeoDataFrame, optional): GeoDataframe of one or more polygons which\n            define the boundary to clip to. Defaults to None.\n        boundary_geocode (Union[str,dict], optional): Place name to clip data to as ascertained\n            from open street maps's Nomatim API (e.g. \"Hennipen County, MN, USA\").\n            Defaults to None.\n        boundary_file (Union[str,Path], optional): Geographic data file that can be read by\n            GeoPandas (e.g. geojson, parquet, shp) that defines a geographic polygon area to clip\n            to. Defaults to None.\n\n    Returns: tuple of GeoDataFrames trimmed_links_df, trimmed_nodes_df, trimmed_shapes_df\n\n    \"\"\"\n    boundary_gdf = get_bounding_polygon(\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    # make sure boundary_gdf.crs == LAT_LON_CRS\n    if boundary_gdf.crs != LAT_LON_CRS:\n        WranglerLogger.debug(f\"Making boundary CRS consistent with network CRS: {LAT_LON_CRS}\")\n        boundary_gdf = boundary_gdf.to_crs(LAT_LON_CRS)\n    # get the boundary as a single polygon\n    boundary = boundary_gdf.geometry.union_all()\n    # get the links that intersect the boundary\n    WranglerLogger.debug(\"Finding roadway links that intersect boundary (spatial join).\")\n    filtered_links_df = network.links_df[network.links_df.geometry.intersects(boundary)]\n    WranglerLogger.debug(f\"filtered_links_df: \\n{filtered_links_df.head()}\")\n    # get the nodes that the links connect to\n    # WranglerLogger.debug(\"Finding roadway nodes that clipped links connect to.\")\n    filtered_node_ids = node_ids_in_links(filtered_links_df, network.nodes_df)\n    filtered_nodes_df = network.nodes_df[network.nodes_df.index.isin(filtered_node_ids)]\n    # WranglerLogger.debug(f\"filtered_nodes_df:\\n{filtered_nodes_df.head()}\")\n    # get shapes the links use\n    WranglerLogger.debug(\"Finding roadway shapes that clipped links connect to.\")\n    filtered_shapes_df = network.shapes_df[\n        network.shapes_df.index.isin(filtered_links_df[\"shape_id\"])\n    ]\n    trimmed_links_df = copy.deepcopy(filtered_links_df)\n    trimmed_nodes_df = copy.deepcopy(filtered_nodes_df)\n    trimmed_shapes_df = copy.deepcopy(filtered_shapes_df)\n    return trimmed_links_df, trimmed_nodes_df, trimmed_shapes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.COPY_FROM_GP_TO_ML","title":"network_wrangler.roadway.model_roadway.COPY_FROM_GP_TO_ML  <code>module-attribute</code>","text":"<pre><code>COPY_FROM_GP_TO_ML = ['ref', 'roadway', 'access', 'distance', 'bike_access', 'drive_access', 'walk_access', 'bus_only', 'rail_only']\n</code></pre> <p>List of attributes to copy from a general purpose lane to access and egress dummy links.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.COPY_TO_ACCESS_EGRESS","title":"network_wrangler.roadway.model_roadway.COPY_TO_ACCESS_EGRESS  <code>module-attribute</code>","text":"<pre><code>COPY_TO_ACCESS_EGRESS = ['ref', 'ML_access', 'ML_drive_access', 'ML_bus_only', 'ML_rail_only']\n</code></pre> <p>List of attributes that must be provided in managed lanes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork","text":"<p>Roadway Network Object compatible with travel modeling.</p> <p>Compatability includes: (1) separation of managed lane facilities and their connection to general purpose lanes     using dummy links.</p> Attr Source code in <code>network_wrangler/roadway/model_roadway.py</code> <pre><code>class ModelRoadwayNetwork:\n    \"\"\"Roadway Network Object compatible with travel modeling.\n\n    Compatability includes:\n    (1) separation of managed lane facilities and their connection to general purpose lanes\n        using dummy links.\n\n    Attr:\n        net: associated RoadwayNetwork object\n        links_df: dataframe of model-compatible links\n        nodes_df: dataframe of model-compatible nodes\n        ml_link_id_lookup:  lookup from general purpose link ids to link ids  of their\n            managed lane counterparts.\n        ml_node_id_lookup: lookup from general purpose node ids to node ids of their\n            managed lane counterparts.\n        _net_hash: hash of the the input links and nodes in order to detect changes.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        net,\n        ml_link_id_lookup: Optional[dict[int, int]] = None,\n        ml_node_id_lookup: Optional[dict[int, int]] = None,\n    ):\n        \"\"\"Constructor for ModelRoadwayNetwork.\n\n        NOTE: in order to be associated with the RoadwayNetwork, this should be called from\n        RoadwayNetwork.model_net which will lazily construct it.\n\n        Args:\n            net: Associated roadway network.\n            ml_link_id_lookup (dict[int, int]): lookup from general purpose link ids to link ids\n                of their managed lane counterparts. Defaults to None which will generate a new one\n                using the provided method.\n            ml_node_id_lookup (dict[int, int]): lookup from general purpose node ids to node ids\n                of their managed lane counterparts. Defaults to None which will generate a new one\n                using the provided method.\n        \"\"\"\n        self.net = net\n\n        if ml_link_id_lookup is None:\n            if self.net.config.IDS.ML_LINK_ID_METHOD == \"range\":\n                self.ml_link_id_lookup = _generate_ml_link_id_lookup_from_range(\n                    self.net.links_df, self.net.config.IDS.ML_LINK_ID_RANGE\n                )\n            elif self.net.config.IDS.ML_LINK_ID_METHOD == \"scalar\":\n                self.ml_link_id_lookup = _generate_ml_link_id_lookup_from_scalar(\n                    self.net.links_df, self.net.config.IDS.ML_LINK_ID_SCALAR\n                )\n            else:\n                msg = \"ml_link_id_method must be 'range' or 'scalar'.\"\n                WranglerLogger.error(msg + f\" Got {self.net.config.IDS.ML_LINK_ID_METHOD}\")\n                raise ValueError(msg)\n        else:\n            self.ml_link_id_lookup = ml_link_id_lookup\n\n        if ml_node_id_lookup is None:\n            if self.net.config.IDS.ML_NODE_ID_METHOD == \"range\":\n                self.ml_node_id_lookup = _generate_ml_node_id_from_range(\n                    self.net.nodes_df, self.net.links_df, self.net.config.IDS.ML_NODE_ID_RANGE\n                )\n            elif self.net.config.IDS.ML_NODE_ID_METHOD == \"scalar\":\n                self.ml_node_id_lookup = _generate_ml_node_id_lookup_from_scalar(\n                    self.net.nodes_df, self.net.links_df, self.net.config.IDS.ML_NODE_ID_SCALAR\n                )\n            else:\n                msg = \"ml_node_id_method must be 'range' or 'scalar'.\"\n                WranglerLogger.error(msg + f\" Got {self.net.config.IDS.ML_NODE_ID_METHOD}\")\n                raise ValueError(msg)\n        else:\n            self.ml_node_id_lookup = ml_node_id_lookup\n\n        if len(self.net.links_df.of_type.managed) == 0:\n            self.links_df, self.nodes_df = self.net.links_df, self.net.nodes_df\n        else:\n            self.links_df, self.nodes_df = model_links_nodes_from_net(\n                self.net, self.ml_link_id_lookup, self.ml_node_id_lookup\n            )\n        self._net_hash = copy.deepcopy(net.network_hash)\n\n    @property\n    def ml_config(self) -&gt; dict:\n        \"\"\"Convenience method for lanaged lane configuration.\"\"\"\n        return self.net.config.MODEL_ROADWAY\n\n    @property\n    def shapes_df(self) -&gt; DataFrame[RoadShapesTable]:\n        \"\"\"Shapes dataframe.\"\"\"\n        return self.net.shapes_df\n\n    @property\n    def ml_links_df(self) -&gt; pd.DataFrame:\n        \"\"\"Managed lanes links.\"\"\"\n        return self.links_df.of_type.managed\n\n    @property\n    def gp_links_df(self) -&gt; pd.DataFrame:\n        \"\"\"GP lanes on links that have managed lanes next to them.\"\"\"\n        return self.links_df.of_type.parallel_general_purpose\n\n    @property\n    def dummy_links_df(self) -&gt; pd.DataFrame:\n        \"\"\"GP lanes on links that have managed lanes next to them.\"\"\"\n        return self.links_df.of_type.dummy\n\n    @property\n    def summary(self) -&gt; dict:\n        \"\"\"Quick summary dictionary of number of links, nodes.\"\"\"\n        d = {\"links\": len(self.links_df), \"nodes\": len(self.nodes_df)}\n        return d\n\n    @property\n    def compare_links_df(self) -&gt; pd.DataFrame:\n        \"\"\"Comparison of the original network and the model network.\"\"\"\n        return compare_links([self.net.links_df, self.links_df], names=[\"Roadway\", \"ModelRoadway\"])\n\n    @property\n    def compare_net_df(self) -&gt; pd.DataFrame:\n        \"\"\"Comparison of the original network and the model network.\"\"\"\n        return compare_networks([self.net, self], names=[\"Roadway\", \"ModelRoadway\"])\n\n    def write(\n        self,\n        out_dir: Path = Path(),\n        convert_complex_link_properties_to_single_field: bool = False,\n        prefix: str = \"\",\n        file_format: RoadwayFileTypes = \"geojson\",\n        overwrite: bool = True,\n        true_shape: bool = False,\n    ) -&gt; None:\n        \"\"\"Writes a network in the roadway network standard.\n\n        Args:\n            out_dir: the path were the output will be saved.\n            convert_complex_link_properties_to_single_field: if True, will convert complex properties to a\n                single column consistent with v0 format.  This format is NOT valid\n                with parquet and many other softwares. Defaults to False.\n            prefix: the name prefix of the roadway files that will be generated.\n            file_format: the format of the output files. Defaults to \"geojson\".\n            overwrite: if True, will overwrite the files if they already exist. Defaults to True.\n            true_shape: if True, will write the true shape of the links as found from shapes.\n                Defaults to False.\n        \"\"\"\n        write_roadway(\n            self,\n            out_dir=out_dir,\n            convert_complex_link_properties_to_single_field=convert_complex_link_properties_to_single_field,\n            prefix=prefix,\n            file_format=file_format,\n            overwrite=overwrite,\n            true_shape=true_shape,\n        )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.compare_links_df","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.compare_links_df  <code>property</code>","text":"<pre><code>compare_links_df\n</code></pre> <p>Comparison of the original network and the model network.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.compare_net_df","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.compare_net_df  <code>property</code>","text":"<pre><code>compare_net_df\n</code></pre> <p>Comparison of the original network and the model network.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.dummy_links_df","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.dummy_links_df  <code>property</code>","text":"<pre><code>dummy_links_df\n</code></pre> <p>GP lanes on links that have managed lanes next to them.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.gp_links_df","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.gp_links_df  <code>property</code>","text":"<pre><code>gp_links_df\n</code></pre> <p>GP lanes on links that have managed lanes next to them.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.ml_config","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.ml_config  <code>property</code>","text":"<pre><code>ml_config\n</code></pre> <p>Convenience method for lanaged lane configuration.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.ml_links_df","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.ml_links_df  <code>property</code>","text":"<pre><code>ml_links_df\n</code></pre> <p>Managed lanes links.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.shapes_df","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.shapes_df  <code>property</code>","text":"<pre><code>shapes_df\n</code></pre> <p>Shapes dataframe.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.summary","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.summary  <code>property</code>","text":"<pre><code>summary\n</code></pre> <p>Quick summary dictionary of number of links, nodes.</p>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.__init__","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.__init__","text":"<pre><code>__init__(net, ml_link_id_lookup=None, ml_node_id_lookup=None)\n</code></pre> <p>Constructor for ModelRoadwayNetwork.</p> <p>NOTE: in order to be associated with the RoadwayNetwork, this should be called from RoadwayNetwork.model_net which will lazily construct it.</p> <p>Parameters:</p> <ul> <li> <code>net</code>           \u2013            <p>Associated roadway network.</p> </li> <li> <code>ml_link_id_lookup</code>               (<code>dict[int, int]</code>, default:                   <code>None</code> )           \u2013            <p>lookup from general purpose link ids to link ids of their managed lane counterparts. Defaults to None which will generate a new one using the provided method.</p> </li> <li> <code>ml_node_id_lookup</code>               (<code>dict[int, int]</code>, default:                   <code>None</code> )           \u2013            <p>lookup from general purpose node ids to node ids of their managed lane counterparts. Defaults to None which will generate a new one using the provided method.</p> </li> </ul> Source code in <code>network_wrangler/roadway/model_roadway.py</code> <pre><code>def __init__(\n    self,\n    net,\n    ml_link_id_lookup: Optional[dict[int, int]] = None,\n    ml_node_id_lookup: Optional[dict[int, int]] = None,\n):\n    \"\"\"Constructor for ModelRoadwayNetwork.\n\n    NOTE: in order to be associated with the RoadwayNetwork, this should be called from\n    RoadwayNetwork.model_net which will lazily construct it.\n\n    Args:\n        net: Associated roadway network.\n        ml_link_id_lookup (dict[int, int]): lookup from general purpose link ids to link ids\n            of their managed lane counterparts. Defaults to None which will generate a new one\n            using the provided method.\n        ml_node_id_lookup (dict[int, int]): lookup from general purpose node ids to node ids\n            of their managed lane counterparts. Defaults to None which will generate a new one\n            using the provided method.\n    \"\"\"\n    self.net = net\n\n    if ml_link_id_lookup is None:\n        if self.net.config.IDS.ML_LINK_ID_METHOD == \"range\":\n            self.ml_link_id_lookup = _generate_ml_link_id_lookup_from_range(\n                self.net.links_df, self.net.config.IDS.ML_LINK_ID_RANGE\n            )\n        elif self.net.config.IDS.ML_LINK_ID_METHOD == \"scalar\":\n            self.ml_link_id_lookup = _generate_ml_link_id_lookup_from_scalar(\n                self.net.links_df, self.net.config.IDS.ML_LINK_ID_SCALAR\n            )\n        else:\n            msg = \"ml_link_id_method must be 'range' or 'scalar'.\"\n            WranglerLogger.error(msg + f\" Got {self.net.config.IDS.ML_LINK_ID_METHOD}\")\n            raise ValueError(msg)\n    else:\n        self.ml_link_id_lookup = ml_link_id_lookup\n\n    if ml_node_id_lookup is None:\n        if self.net.config.IDS.ML_NODE_ID_METHOD == \"range\":\n            self.ml_node_id_lookup = _generate_ml_node_id_from_range(\n                self.net.nodes_df, self.net.links_df, self.net.config.IDS.ML_NODE_ID_RANGE\n            )\n        elif self.net.config.IDS.ML_NODE_ID_METHOD == \"scalar\":\n            self.ml_node_id_lookup = _generate_ml_node_id_lookup_from_scalar(\n                self.net.nodes_df, self.net.links_df, self.net.config.IDS.ML_NODE_ID_SCALAR\n            )\n        else:\n            msg = \"ml_node_id_method must be 'range' or 'scalar'.\"\n            WranglerLogger.error(msg + f\" Got {self.net.config.IDS.ML_NODE_ID_METHOD}\")\n            raise ValueError(msg)\n    else:\n        self.ml_node_id_lookup = ml_node_id_lookup\n\n    if len(self.net.links_df.of_type.managed) == 0:\n        self.links_df, self.nodes_df = self.net.links_df, self.net.nodes_df\n    else:\n        self.links_df, self.nodes_df = model_links_nodes_from_net(\n            self.net, self.ml_link_id_lookup, self.ml_node_id_lookup\n        )\n    self._net_hash = copy.deepcopy(net.network_hash)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.write","title":"network_wrangler.roadway.model_roadway.ModelRoadwayNetwork.write","text":"<pre><code>write(out_dir=Path(), convert_complex_link_properties_to_single_field=False, prefix='', file_format='geojson', overwrite=True, true_shape=False)\n</code></pre> <p>Writes a network in the roadway network standard.</p> <p>Parameters:</p> <ul> <li> <code>out_dir</code>               (<code>Path</code>, default:                   <code>Path()</code> )           \u2013            <p>the path were the output will be saved.</p> </li> <li> <code>convert_complex_link_properties_to_single_field</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will convert complex properties to a single column consistent with v0 format.  This format is NOT valid with parquet and many other softwares. Defaults to False.</p> </li> <li> <code>prefix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>the name prefix of the roadway files that will be generated.</p> </li> <li> <code>file_format</code>               (<code>RoadwayFileTypes</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the format of the output files. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True.</p> </li> <li> <code>true_shape</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will write the true shape of the links as found from shapes. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/roadway/model_roadway.py</code> <pre><code>def write(\n    self,\n    out_dir: Path = Path(),\n    convert_complex_link_properties_to_single_field: bool = False,\n    prefix: str = \"\",\n    file_format: RoadwayFileTypes = \"geojson\",\n    overwrite: bool = True,\n    true_shape: bool = False,\n) -&gt; None:\n    \"\"\"Writes a network in the roadway network standard.\n\n    Args:\n        out_dir: the path were the output will be saved.\n        convert_complex_link_properties_to_single_field: if True, will convert complex properties to a\n            single column consistent with v0 format.  This format is NOT valid\n            with parquet and many other softwares. Defaults to False.\n        prefix: the name prefix of the roadway files that will be generated.\n        file_format: the format of the output files. Defaults to \"geojson\".\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True.\n        true_shape: if True, will write the true shape of the links as found from shapes.\n            Defaults to False.\n    \"\"\"\n    write_roadway(\n        self,\n        out_dir=out_dir,\n        convert_complex_link_properties_to_single_field=convert_complex_link_properties_to_single_field,\n        prefix=prefix,\n        file_format=file_format,\n        overwrite=overwrite,\n        true_shape=true_shape,\n    )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.model_links_nodes_from_net","title":"network_wrangler.roadway.model_roadway.model_links_nodes_from_net","text":"<pre><code>model_links_nodes_from_net(net, ml_link_id_lookup, ml_node_id_lookup)\n</code></pre> <p>Create a roadway network with managed lanes links separated out.</p> <p>Add new parallel managed lane links, access/egress links, and add shapes corresponding to the new links</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>RoadwayNetwork instance</p> </li> <li> <code>ml_link_id_lookup</code>               (<code>dict[int, int]</code>)           \u2013            <p>lookup table for managed lane link ids to their general purpose lane counterparts.</p> </li> <li> <code>ml_node_id_lookup</code>               (<code>dict[int, int]</code>)           \u2013            <p>lookup table for managed lane node ids to their general purpose lane counterparts.</p> </li> </ul> Source code in <code>network_wrangler/roadway/model_roadway.py</code> <pre><code>def model_links_nodes_from_net(\n    net: RoadwayNetwork, ml_link_id_lookup: dict[int, int], ml_node_id_lookup: dict[int, int]\n) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Create a roadway network with managed lanes links separated out.\n\n    Add new parallel managed lane links, access/egress links,\n    and add shapes corresponding to the new links\n\n    Args:\n        net: RoadwayNetwork instance\n        ml_link_id_lookup: lookup table for managed lane link ids to their general purpose lane\n            counterparts.\n        ml_node_id_lookup: lookup table for managed lane node ids to their general purpose lane\n            counterparts.\n\n    returns: tuple of links and nodes dataframes with managed lanes separated out\n    \"\"\"\n    WranglerLogger.info(\"Separating managed lane links from general purpose links\")\n\n    copy_cols_gp_ml = list(\n        set(COPY_FROM_GP_TO_ML + net.config.MODEL_ROADWAY.ADDITIONAL_COPY_FROM_GP_TO_ML)\n    )\n    _m_links_df = _separate_ml_links(\n        net.links_df,\n        ml_link_id_lookup,\n        ml_node_id_lookup,\n        offset_meters=net.config.MODEL_ROADWAY.ML_OFFSET_METERS,\n        copy_from_gp_to_ml=copy_cols_gp_ml,\n    )\n    _m_nodes_df = _create_ml_nodes_from_links(_m_links_df, ml_node_id_lookup)\n    m_nodes_df = concat_with_attr([net.nodes_df, _m_nodes_df])\n\n    copy_ae_fields = list(\n        set(COPY_TO_ACCESS_EGRESS + net.config.MODEL_ROADWAY.ADDITIONAL_COPY_TO_ACCESS_EGRESS)\n    )\n    _access_egress_links_df = _create_dummy_connector_links(\n        net.links_df,\n        m_nodes_df,\n        ml_link_id_lookup,\n        ml_node_id_lookup,\n        copy_fields=copy_ae_fields,\n    )\n    m_links_df = concat_with_attr([_m_links_df, _access_egress_links_df])\n    return m_links_df, m_nodes_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.model_roadway.strip_ML_from_prop_list","title":"network_wrangler.roadway.model_roadway.strip_ML_from_prop_list","text":"<pre><code>strip_ML_from_prop_list(property_list)\n</code></pre> <p>Strips \u2018ML_\u2019 from property list but keeps necessary access/egress point cols.</p> Source code in <code>network_wrangler/roadway/model_roadway.py</code> <pre><code>def strip_ML_from_prop_list(property_list: list[str]) -&gt; list[str]:\n    \"\"\"Strips 'ML_' from property list but keeps necessary access/egress point cols.\"\"\"\n    keep_same = [\"ML_access_point\", \"ML_egress_point\"]\n    pl = [p.removeprefix(\"ML_\") if p not in keep_same else p for p in property_list]\n    pl = [p.replace(\"_ML_\", \"_\") if p not in keep_same else p for p in pl]\n    return pl\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.utils.compare_links","title":"network_wrangler.roadway.utils.compare_links","text":"<pre><code>compare_links(links, names=None)\n</code></pre> <p>Compare the summary of links in a list of dataframes.</p> <p>Parameters:</p> <ul> <li> <code>links</code>               (<code>list[DataFrame]</code>)           \u2013            <p>list of dataframes</p> </li> <li> <code>names</code>               (<code>Optional[list[str]]</code>, default:                   <code>None</code> )           \u2013            <p>list of names for the dataframes</p> </li> </ul> Source code in <code>network_wrangler/roadway/utils.py</code> <pre><code>def compare_links(\n    links: list[pd.DataFrame],\n    names: Optional[list[str]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Compare the summary of links in a list of dataframes.\n\n    Args:\n        links: list of dataframes\n        names: list of names for the dataframes\n    \"\"\"\n    if names is None:\n        names = [\"links\" + str(i) for i in range(1, len(links) + 1)]\n    df = pd.DataFrame({name: link.of_type.summary for name, link in zip(names, links)})\n    return df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.utils.compare_networks","title":"network_wrangler.roadway.utils.compare_networks","text":"<pre><code>compare_networks(nets, names=None)\n</code></pre> <p>Compare the summary of networks in a list of networks.</p> <p>Parameters:</p> <ul> <li> <code>nets</code>               (<code>list[Union[RoadwayNetwork, ModelRoadwayNetwork]]</code>)           \u2013            <p>list of networks</p> </li> <li> <code>names</code>               (<code>Optional[list[str]]</code>, default:                   <code>None</code> )           \u2013            <p>list of names for the networks</p> </li> </ul> Source code in <code>network_wrangler/roadway/utils.py</code> <pre><code>def compare_networks(\n    nets: list[Union[RoadwayNetwork, ModelRoadwayNetwork]],\n    names: Optional[list[str]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Compare the summary of networks in a list of networks.\n\n    Args:\n        nets: list of networks\n        names: list of names for the networks\n    \"\"\"\n    if names is None:\n        names = [\"net\" + str(i) for i in range(1, len(nets) + 1)]\n    df = pd.DataFrame({name: net.summary for name, net in zip(names, nets)})\n    return df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.utils.create_unique_shape_id","title":"network_wrangler.roadway.utils.create_unique_shape_id","text":"<pre><code>create_unique_shape_id(line_string)\n</code></pre> <p>A unique hash id using the coordinates of the geometry using first and last locations.</p> <p>Args: line_string: Line Geometry as a LineString</p> <p>Returns: string</p> Source code in <code>network_wrangler/roadway/utils.py</code> <pre><code>def create_unique_shape_id(line_string: LineString):\n    \"\"\"A unique hash id using the coordinates of the geometry using first and last locations.\n\n    Args:\n    line_string: Line Geometry as a LineString\n\n    Returns: string\n    \"\"\"\n    x1, y1 = line_string.coords[0]  # first coordinate (A node)\n    x2, y2 = line_string.coords[-1]  # last coordinate (B node)\n\n    message = f\"Geometry {x1} {y1} {x2} {y2}\"\n    unhashed = message.encode(\"utf-8\")\n    hash = hashlib.md5(unhashed).hexdigest()\n\n    return hash\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.utils.diff_nets","title":"network_wrangler.roadway.utils.diff_nets","text":"<pre><code>diff_nets(net1, net2)\n</code></pre> <p>Diff two RoadwayNetworks and return True if they are different.</p> <p>Ignore locationReferences as they are not used in the network.</p> <p>Parameters:</p> <ul> <li> <code>net1</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>First network to compare</p> </li> <li> <code>net2</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>Second network to compare</p> </li> </ul> Source code in <code>network_wrangler/roadway/utils.py</code> <pre><code>def diff_nets(net1: RoadwayNetwork, net2: RoadwayNetwork) -&gt; bool:\n    \"\"\"Diff two RoadwayNetworks and return True if they are different.\n\n    Ignore locationReferences as they are not used in the network.\n\n    Args:\n        net1 (RoadwayNetwork): First network to compare\n        net2 (RoadwayNetwork): Second network to compare\n    \"\"\"\n    # Need to ignore b/c there are tiny differences in how this complex time is serialized and\n    # in order to evaluate if they are equivelant you need to do an elemement by element comparison\n    # which takes forever.\n    IGNORE_COLS = [\"locationReferences\"]\n    WranglerLogger.debug(\"Comparing networks.\")\n    WranglerLogger.info(\"----Comparing links----\")\n    diff_links = diff_dfs(net1.links_df, net2.links_df, ignore=IGNORE_COLS)\n    WranglerLogger.info(\"----Comparing nodes----\")\n    diff_nodes = diff_dfs(net1.nodes_df, net2.nodes_df, ignore=IGNORE_COLS)\n    WranglerLogger.info(\"----Comparing shapes----\")\n    if net1.shapes_df is None and net1.shapes_df.empty:\n        diff_shapes = False\n    else:\n        diff_shapes = diff_dfs(net1.shapes_df, net2.shapes_df, ignore=IGNORE_COLS)\n    diff = any([diff_links, diff_nodes, diff_shapes])\n    if diff:\n        WranglerLogger.error(\"!!! Differences in networks.\")\n    else:\n        WranglerLogger.info(\"Networks same for properties in common\")\n    return diff\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.utils.set_df_index_to_pk","title":"network_wrangler.roadway.utils.set_df_index_to_pk","text":"<pre><code>set_df_index_to_pk(df)\n</code></pre> <p>Sets the index of the dataframe to be a copy of the primary key.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>data frame to set the index of</p> </li> </ul> Source code in <code>network_wrangler/roadway/utils.py</code> <pre><code>def set_df_index_to_pk(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Sets the index of the dataframe to be a copy of the primary key.\n\n    Args:\n        df (pd.DataFrame): data frame to set the index of\n    \"\"\"\n    if df.index.name != df.attrs[\"idx_col\"]:\n        df[df.attrs[\"idx_col\"]] = df[df.attrs[\"primary_key\"]]\n        df = df.set_index(df.attrs[\"idx_col\"])\n    return df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.validate.validate_roadway_files","title":"network_wrangler.roadway.validate.validate_roadway_files","text":"<pre><code>validate_roadway_files(links_file, nodes_file, shapes_file=None, strict=False, output_dir=Path())\n</code></pre> <p>Validates the roadway network files strictly to the wrangler data model specifications.</p> <p>Parameters:</p> <ul> <li> <code>links_file</code>               (<code>str</code>)           \u2013            <p>The path to the links file.</p> </li> <li> <code>nodes_file</code>               (<code>str</code>)           \u2013            <p>The path to the nodes file.</p> </li> <li> <code>shapes_file</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The path to the shapes file.</p> </li> <li> <code>strict</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will validate the roadway network strictly without parsing and filling in data.</p> </li> <li> <code>output_dir</code>               (<code>str</code>, default:                   <code>Path()</code> )           \u2013            <p>The output directory for the validation report. Defaults to \u201c.\u201d.</p> </li> </ul> Source code in <code>network_wrangler/roadway/validate.py</code> <pre><code>def validate_roadway_files(\n    links_file: Path,\n    nodes_file: Path,\n    shapes_file: Optional[Path] = None,\n    strict: bool = False,\n    output_dir: Path = Path(),\n):\n    \"\"\"Validates the roadway network files strictly to the wrangler data model specifications.\n\n    Args:\n        links_file (str): The path to the links file.\n        nodes_file (str): The path to the nodes file.\n        shapes_file (str): The path to the shapes file.\n        strict (bool): If True, will validate the roadway network strictly without\n            parsing and filling in data.\n        output_dir (str): The output directory for the validation report. Defaults to \".\".\n    \"\"\"\n    valid = {\"net\": True, \"links\": True, \"nodes\": True}\n\n    nodes_df = read_table(nodes_file)\n    valid[\"links\"] = validate_nodes_df(\n        nodes_df, strict=strict, errors_filename=Path(output_dir) / \"node_errors.csv\"\n    )\n\n    links_df = read_table(links_file)\n    valid[\"links\"] = validate_links_df(\n        links_df,\n        nodes_df=nodes_df,\n        strict=strict,\n        errors_filename=Path(output_dir) / \"link_errors.csv\",\n    )\n\n    if shapes_file:\n        valid[\"shapes\"] = True\n        shapes_df = read_table(shapes_file)\n        valid[\"shapes\"] = validate_shapes_df(\n            shapes_df, strict=strict, errors_filename=Path(output_dir) / \"shape_errors.csv\"\n        )\n\n    try:\n        RoadwayNetwork(links_df=links_df, nodes_df=nodes_df, _shapes_df=shapes_df)\n    except Exception as e:\n        WranglerLogger.error(f\"!!! [Network invalid] - Failed Loading to object\\n{e}\")\n        valid[\"net\"] = False\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.validate.validate_roadway_in_dir","title":"network_wrangler.roadway.validate.validate_roadway_in_dir","text":"<pre><code>validate_roadway_in_dir(directory, file_format='geojson', strict=False, output_dir=Path())\n</code></pre> <p>Validates a roadway network in a directory to the wrangler data model specifications.</p> <p>Parameters:</p> <ul> <li> <code>directory</code>               (<code>str</code>)           \u2013            <p>The roadway network file directory.</p> </li> <li> <code>file_format(str)</code>           \u2013            <p>The formats of roadway network file name.</p> </li> <li> <code>strict</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will validate the roadway network strictly without parsing and filling in data.</p> </li> <li> <code>output_dir</code>               (<code>str</code>, default:                   <code>Path()</code> )           \u2013            <p>The output directory for the validation report. Defaults to \u201c.\u201d.</p> </li> </ul> Source code in <code>network_wrangler/roadway/validate.py</code> <pre><code>def validate_roadway_in_dir(\n    directory: Path,\n    file_format: RoadwayFileTypes = \"geojson\",\n    strict: bool = False,\n    output_dir: Path = Path(),\n):\n    \"\"\"Validates a roadway network in a directory to the wrangler data model specifications.\n\n    Args:\n        directory (str): The roadway network file directory.\n        file_format(str): The formats of roadway network file name.\n        strict (bool): If True, will validate the roadway network strictly without\n            parsing and filling in data.\n        output_dir (str): The output directory for the validation report. Defaults to \".\".\n    \"\"\"\n    links_file, nodes_file, shapes_file = id_roadway_file_paths_in_dir(directory, file_format)\n    validate_roadway_files(\n        links_file, nodes_file, shapes_file, strict=strict, output_dir=output_dir\n    )\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.DEFAULT_MAX_SEARCH_BREADTH","title":"network_wrangler.roadway.segment.DEFAULT_MAX_SEARCH_BREADTH  <code>module-attribute</code>","text":"<pre><code>DEFAULT_MAX_SEARCH_BREADTH = 10\n</code></pre> <p>Factor to multiply sp_weight_col by to use for weights in shortest path.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.DEFAULT_SUBNET_SP_WEIGHT_FACTOR","title":"network_wrangler.roadway.segment.DEFAULT_SUBNET_SP_WEIGHT_FACTOR  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SUBNET_SP_WEIGHT_FACTOR = 100\n</code></pre> <p>Column to use for weights in shortest path.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment","title":"network_wrangler.roadway.segment.Segment","text":"<p>A contiguous length of RoadwayNetwork defined by start/end nodes + link selections.</p> <p>Segments are defined by a selection dictionary and then searched for on the network using a shortest path graph search.</p> <p>Usage:</p> <pre><code>selection_dict = {\n    \"links\": {\"name\":['6th','Sixth','sixth']},\n    \"from\": {\"osm_node_id\": '187899923'},\n    \"to\": {\"osm_node_id\": '187865924'}\n}\n\nnet = RoadwayNetwork(...)\n\nsegment = Segment(net = net, selection)\n\n# lazily evaluated dataframe of links in segment (if found) from segment.net\nsegment.segment_links_df\n\n# lazily evaluated list of nodes primary keys that are in segment (if found)\nsegment.segment_nodes\n</code></pre> attr Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>class Segment:\n    \"\"\"A contiguous length of RoadwayNetwork defined by start/end nodes + link selections.\n\n    Segments are defined by a selection dictionary and then searched for on the network using\n    a shortest path graph search.\n\n    Usage:\n\n    ```\n    selection_dict = {\n        \"links\": {\"name\":['6th','Sixth','sixth']},\n        \"from\": {\"osm_node_id\": '187899923'},\n        \"to\": {\"osm_node_id\": '187865924'}\n    }\n\n    net = RoadwayNetwork(...)\n\n    segment = Segment(net = net, selection)\n\n    # lazily evaluated dataframe of links in segment (if found) from segment.net\n    segment.segment_links_df\n\n    # lazily evaluated list of nodes primary keys that are in segment (if found)\n    segment.segment_nodes\n    ```\n\n    attr:\n        net: Associated RoadwayNetwork object\n        selection: RoadwayLinkSelection\n        from_node_id: value of the primary key (usually model_node_id) for segment start node\n        to_node_id: value of the primary key (usually model_node_id) for segment end node\n        subnet: Subnet object (and associated graph) on which to do shortest path search\n        segment_nodes: list of primary keys of nodes within the selected segment. Will be lazily\n            evaluated as the result of connected_path_search().\n        segment_nodes_df: dataframe selection from net.modes_df for segment_nodes. Lazily evaluated\n            based on segment_nodes.\n        segment_links: list of primary keys of links which connect together segment_nodes. Lazily\n            evaluated based on segment_links_df.\n        segment_links_df: dataframe selection from net.links_df for segment_links. Lazily\n            evaluated based on segment_links_df.\n        max_search_breadth: maximum number of nodes to search for in connected_path_search.\n            Defaults to DEFAULT_MAX_SEGMENT_SEARCH_BREADTH which is 10.\n    \"\"\"\n\n    def __init__(\n        self,\n        net: RoadwayNetwork,\n        selection: RoadwayLinkSelection,\n        max_search_breadth: int = DEFAULT_MAX_SEARCH_BREADTH,\n    ):\n        \"\"\"Initialize a roadway segment object.\n\n        Args:\n            net (RoadwayNetwork): Associated RoadwayNetwork object\n            selection (RoadwayLinkSelection): Selection of type `segment`.\n            max_search_breadth (int, optional): Maximum number of nodes to search for in\n                connected_path_search. Defaults to DEFAULT_MAX_SEGMENT_SEARCH_BREADTH.\n        \"\"\"\n        self.net = net\n        self.max_search_breadth = max_search_breadth\n        if selection.selection_method != \"segment\":\n            msg = \"Selection object passed to Segment must be of type `segment`\"\n            raise SegmentFormatError(msg)\n        self.selection = selection\n\n        # segment members are identified by storing nodes along a route\n        self._segment_nodes: Union[list, None] = None\n\n        # Initialize calculated, read-only attr.\n        self._from_node_id: Union[int, None] = None\n        self._to_node_id: Union[int, None] = None\n\n        self.subnet = self._generate_subnet(self.segment_sel_dict)\n\n        WranglerLogger.debug(f\"Segment created: {self}\")\n\n    @property\n    def modes(self) -&gt; list[str]:\n        \"\"\"List of modes in the selection.\"\"\"\n        return self.selection.modes if self.selection.modes else DEFAULT_SEARCH_MODES\n\n    @property\n    def segment_sel_dict(self) -&gt; dict:\n        \"\"\"Selection dictionary which only has keys related to initial segment link selection.\"\"\"\n        return self.selection.segment_selection_dict\n\n    @property\n    def from_node_id(self) -&gt; int:\n        \"\"\"Find start node in selection dict and return its primary key.\"\"\"\n        if self._from_node_id is not None:\n            return self._from_node_id\n        self._from_node_id = self.get_node_id(self.selection.selection_data.from_)\n        return self._from_node_id\n\n    @property\n    def to_node_id(self) -&gt; int:\n        \"\"\"Find end node in selection dict and return its primary key.\"\"\"\n        if self._to_node_id is not None:\n            return self._to_node_id\n        self._to_node_id = self.get_node_id(self.selection.selection_data.to)\n        return self._to_node_id\n\n    @property\n    def segment_nodes(self) -&gt; list[int]:\n        \"\"\"Primary keys of nodes in segment.\"\"\"\n        if self._segment_nodes is None:\n            WranglerLogger.debug(\"Segment not found yet so conducting connected_path_search.\")\n            self.connected_path_search()\n        if self._segment_nodes is None:\n            msg = \"No segment nodes found.\"\n            raise SegmentSelectionError(msg)\n        return self._segment_nodes\n\n    @property\n    def segment_nodes_df(self) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Roadway network nodes filtered to nodes in segment.\"\"\"\n        return self.net.nodes_df.loc[self.segment_nodes]\n\n    @property\n    def segment_from_node_s(self) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Roadway network nodes filtered to segment start node.\"\"\"\n        return self.segment_nodes_df.loc[self.from_node_id]\n\n    @property\n    def segment_to_node_s(self) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Roadway network nodes filtered to segment end node.\"\"\"\n        return self.segment_nodes_df.loc[self.to_node_id]\n\n    @property\n    def segment_links_df(self) -&gt; DataFrame[RoadLinksTable]:\n        \"\"\"Roadway network links filtered to segment links.\"\"\"\n        modal_links_df = self.net.links_df.mode_query(self.modes)\n        segment_links_df = filter_links_to_path(modal_links_df, self.segment_nodes)\n        return segment_links_df\n\n    @property\n    def segment_links(self) -&gt; list[int]:\n        \"\"\"Primary keys of links in segment.\"\"\"\n        return self.segment_links_df.index.tolist()\n\n    def get_node_id(self, node_selection_data: SelectNodeDict) -&gt; int:\n        \"\"\"Get the primary key of a node based on the selection data.\"\"\"\n        node = self.get_node(node_selection_data)\n        return node[\"model_node_id\"].values[0]\n\n    def get_node(self, node_selection_data: SelectNodeDict):\n        \"\"\"Get single node based on the selection data.\"\"\"\n        node_selection_dict = {\n            k: v\n            for k, v in node_selection_data.asdict.items()\n            if k in self.selection.node_query_fields\n        }\n        node_df = self.net.nodes_df.isin_dict(node_selection_dict)\n        if len(node_df) != 1:\n            msg = f\"Node selection not unique. Found {len(node_df)} nodes.\"\n            raise SegmentSelectionError(msg)\n        return node_df\n\n    def connected_path_search(\n        self,\n    ) -&gt; None:\n        \"\"\"Finds a path from from_node_id to to_node_id based on the weight col value/factor.\"\"\"\n        WranglerLogger.debug(\"Calculating shortest path from graph\")\n        _found = False\n        _found = self._find_subnet_shortest_path()\n\n        while not _found and self.subnet._i &lt;= self.max_search_breadth:\n            self.subnet._expand_subnet_breadth()\n            _found = self._find_subnet_shortest_path()\n\n        if not _found:\n            msg = f\"No connected path found from {self.O.pk} and {self.D_pk}\"\n            WranglerLogger.debug(msg)\n            raise SegmentSelectionError(msg)\n\n    def _generate_subnet(self, selection_dict: dict) -&gt; Subnet:\n        \"\"\"Generate a subnet of the roadway network on which to search for connected segment.\n\n        Args:\n            selection_dict: selection dictionary to use for generating subnet\n        \"\"\"\n        if not selection_dict:\n            msg = \"No selection provided to generate subnet from.\"\n            raise SegmentFormatError(msg)\n\n        WranglerLogger.debug(f\"Creating subnet from dictionary: {selection_dict}\")\n        subnet = generate_subnet_from_link_selection_dict(\n            self.net,\n            modes=self.modes,\n            link_selection_dict=selection_dict,\n        )\n        # expand network to find at least the origin and destination nodes\n        subnet.expand_to_nodes(\n            [self.from_node_id, self.to_node_id], max_search_breadth=self.max_search_breadth\n        )\n        return subnet\n\n    def _find_subnet_shortest_path(\n        self,\n    ) -&gt; bool:\n        \"\"\"Finds shortest path from from_node_id to to_node_id using self.subnet.graph.\n\n        Sets self._segment_nodes to resulting path nodes\n\n        Returns:\n            bool: True if shortest path was found\n        \"\"\"\n        WranglerLogger.debug(\n            f\"Calculating shortest path from {self.from_node_id} to {self.to_node_id} using\\\n        {self.subnet._sp_weight_col} as weight with a factor of {self.subnet._sp_weight_factor}\"\n        )\n\n        self._segment_nodes = shortest_path(self.subnet.graph, self.from_node_id, self.to_node_id)\n\n        if not self._segment_nodes:\n            WranglerLogger.debug(f\"No SP from {self.from_node_id} to {self.to_node_id} Found.\")\n            return False\n\n        return True\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.from_node_id","title":"network_wrangler.roadway.segment.Segment.from_node_id  <code>property</code>","text":"<pre><code>from_node_id\n</code></pre> <p>Find start node in selection dict and return its primary key.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.modes","title":"network_wrangler.roadway.segment.Segment.modes  <code>property</code>","text":"<pre><code>modes\n</code></pre> <p>List of modes in the selection.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_from_node_s","title":"network_wrangler.roadway.segment.Segment.segment_from_node_s  <code>property</code>","text":"<pre><code>segment_from_node_s\n</code></pre> <p>Roadway network nodes filtered to segment start node.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_links","title":"network_wrangler.roadway.segment.Segment.segment_links  <code>property</code>","text":"<pre><code>segment_links\n</code></pre> <p>Primary keys of links in segment.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_links_df","title":"network_wrangler.roadway.segment.Segment.segment_links_df  <code>property</code>","text":"<pre><code>segment_links_df\n</code></pre> <p>Roadway network links filtered to segment links.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_nodes","title":"network_wrangler.roadway.segment.Segment.segment_nodes  <code>property</code>","text":"<pre><code>segment_nodes\n</code></pre> <p>Primary keys of nodes in segment.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_nodes_df","title":"network_wrangler.roadway.segment.Segment.segment_nodes_df  <code>property</code>","text":"<pre><code>segment_nodes_df\n</code></pre> <p>Roadway network nodes filtered to nodes in segment.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_sel_dict","title":"network_wrangler.roadway.segment.Segment.segment_sel_dict  <code>property</code>","text":"<pre><code>segment_sel_dict\n</code></pre> <p>Selection dictionary which only has keys related to initial segment link selection.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.segment_to_node_s","title":"network_wrangler.roadway.segment.Segment.segment_to_node_s  <code>property</code>","text":"<pre><code>segment_to_node_s\n</code></pre> <p>Roadway network nodes filtered to segment end node.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.to_node_id","title":"network_wrangler.roadway.segment.Segment.to_node_id  <code>property</code>","text":"<pre><code>to_node_id\n</code></pre> <p>Find end node in selection dict and return its primary key.</p>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.__init__","title":"network_wrangler.roadway.segment.Segment.__init__","text":"<pre><code>__init__(net, selection, max_search_breadth=DEFAULT_MAX_SEARCH_BREADTH)\n</code></pre> <p>Initialize a roadway segment object.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>Associated RoadwayNetwork object</p> </li> <li> <code>selection</code>               (<code>RoadwayLinkSelection</code>)           \u2013            <p>Selection of type <code>segment</code>.</p> </li> <li> <code>max_search_breadth</code>               (<code>int</code>, default:                   <code>DEFAULT_MAX_SEARCH_BREADTH</code> )           \u2013            <p>Maximum number of nodes to search for in connected_path_search. Defaults to DEFAULT_MAX_SEGMENT_SEARCH_BREADTH.</p> </li> </ul> Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>def __init__(\n    self,\n    net: RoadwayNetwork,\n    selection: RoadwayLinkSelection,\n    max_search_breadth: int = DEFAULT_MAX_SEARCH_BREADTH,\n):\n    \"\"\"Initialize a roadway segment object.\n\n    Args:\n        net (RoadwayNetwork): Associated RoadwayNetwork object\n        selection (RoadwayLinkSelection): Selection of type `segment`.\n        max_search_breadth (int, optional): Maximum number of nodes to search for in\n            connected_path_search. Defaults to DEFAULT_MAX_SEGMENT_SEARCH_BREADTH.\n    \"\"\"\n    self.net = net\n    self.max_search_breadth = max_search_breadth\n    if selection.selection_method != \"segment\":\n        msg = \"Selection object passed to Segment must be of type `segment`\"\n        raise SegmentFormatError(msg)\n    self.selection = selection\n\n    # segment members are identified by storing nodes along a route\n    self._segment_nodes: Union[list, None] = None\n\n    # Initialize calculated, read-only attr.\n    self._from_node_id: Union[int, None] = None\n    self._to_node_id: Union[int, None] = None\n\n    self.subnet = self._generate_subnet(self.segment_sel_dict)\n\n    WranglerLogger.debug(f\"Segment created: {self}\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.connected_path_search","title":"network_wrangler.roadway.segment.Segment.connected_path_search","text":"<pre><code>connected_path_search()\n</code></pre> <p>Finds a path from from_node_id to to_node_id based on the weight col value/factor.</p> Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>def connected_path_search(\n    self,\n) -&gt; None:\n    \"\"\"Finds a path from from_node_id to to_node_id based on the weight col value/factor.\"\"\"\n    WranglerLogger.debug(\"Calculating shortest path from graph\")\n    _found = False\n    _found = self._find_subnet_shortest_path()\n\n    while not _found and self.subnet._i &lt;= self.max_search_breadth:\n        self.subnet._expand_subnet_breadth()\n        _found = self._find_subnet_shortest_path()\n\n    if not _found:\n        msg = f\"No connected path found from {self.O.pk} and {self.D_pk}\"\n        WranglerLogger.debug(msg)\n        raise SegmentSelectionError(msg)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.get_node","title":"network_wrangler.roadway.segment.Segment.get_node","text":"<pre><code>get_node(node_selection_data)\n</code></pre> <p>Get single node based on the selection data.</p> Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>def get_node(self, node_selection_data: SelectNodeDict):\n    \"\"\"Get single node based on the selection data.\"\"\"\n    node_selection_dict = {\n        k: v\n        for k, v in node_selection_data.asdict.items()\n        if k in self.selection.node_query_fields\n    }\n    node_df = self.net.nodes_df.isin_dict(node_selection_dict)\n    if len(node_df) != 1:\n        msg = f\"Node selection not unique. Found {len(node_df)} nodes.\"\n        raise SegmentSelectionError(msg)\n    return node_df\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.Segment.get_node_id","title":"network_wrangler.roadway.segment.Segment.get_node_id","text":"<pre><code>get_node_id(node_selection_data)\n</code></pre> <p>Get the primary key of a node based on the selection data.</p> Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>def get_node_id(self, node_selection_data: SelectNodeDict) -&gt; int:\n    \"\"\"Get the primary key of a node based on the selection data.\"\"\"\n    node = self.get_node(node_selection_data)\n    return node[\"model_node_id\"].values[0]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.generate_subnet_from_link_selection_dict","title":"network_wrangler.roadway.segment.generate_subnet_from_link_selection_dict","text":"<pre><code>generate_subnet_from_link_selection_dict(net, link_selection_dict, modes=DEFAULT_SEARCH_MODES, sp_weight_col=SUBNET_SP_WEIGHT_COL, sp_weight_factor=DEFAULT_SUBNET_SP_WEIGHT_FACTOR, **kwargs)\n</code></pre> <p>Generates a Subnet object from a link selection dictionary.</p> <p>First will search based on \u201cname\u201d in selection_dict but if not found, will search     using the \u201cref\u201d field instead.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>RoadwayNetwork object.</p> </li> <li> <code>link_selection_dict</code>               (<code>dict</code>)           \u2013            <p>dictionary of attributes to search for.</p> </li> <li> <code>modes</code>               (<code>list[str]</code>, default:                   <code>DEFAULT_SEARCH_MODES</code> )           \u2013            <p>List of modes to limit subnet to. Defaults to DEFAULT_SEARCH_MODES.</p> </li> <li> <code>sp_weight_col</code>               (<code>str</code>, default:                   <code>SUBNET_SP_WEIGHT_COL</code> )           \u2013            <p>Column to use for weights in shortest path.  Defaults to SUBNET_SP_WEIGHT_COL.</p> </li> <li> <code>sp_weight_factor</code>               (<code>float</code>, default:                   <code>DEFAULT_SUBNET_SP_WEIGHT_FACTOR</code> )           \u2013            <p>Factor to multiply sp_weight_col by to use for weights in shortest path. Defaults to DEFAULT_SUBNET_SP_WEIGHT_FACTOR.</p> </li> <li> <code>kwargs</code>           \u2013            <p>other kwargs to pass to Subnet initiation</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Subnet</code> (              <code>Subnet</code> )          \u2013            <p>Subnet object.</p> </li> </ul> Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>def generate_subnet_from_link_selection_dict(\n    net,\n    link_selection_dict: dict,\n    modes: list[str] = DEFAULT_SEARCH_MODES,\n    sp_weight_col: str = SUBNET_SP_WEIGHT_COL,\n    sp_weight_factor: float = DEFAULT_SUBNET_SP_WEIGHT_FACTOR,\n    **kwargs,\n) -&gt; Subnet:\n    \"\"\"Generates a Subnet object from a link selection dictionary.\n\n    First will search based on \"name\" in selection_dict but if not found, will search\n        using the \"ref\" field instead.\n\n    Args:\n        net (RoadwayNetwork): RoadwayNetwork object.\n        link_selection_dict: dictionary of attributes to search for.\n        modes: List of modes to limit subnet to. Defaults to DEFAULT_SEARCH_MODES.\n        sp_weight_col: Column to use for weights in shortest path.  Defaults to SUBNET_SP_WEIGHT_COL.\n        sp_weight_factor: Factor to multiply sp_weight_col by to use for weights in shortest path.\n            Defaults to DEFAULT_SUBNET_SP_WEIGHT_FACTOR.\n        kwargs: other kwargs to pass to Subnet initiation\n\n    Returns:\n        Subnet: Subnet object.\n    \"\"\"\n    link_sd_options = _generate_subnet_link_selection_dict_options(link_selection_dict)\n    for sd in link_sd_options:\n        WranglerLogger.debug(f\"Trying link selection:\\n{sd}\")\n        subnet_links_df = copy.deepcopy(net.links_df.mode_query(modes))\n        subnet_links_df = subnet_links_df.dict_query(sd)\n        if len(subnet_links_df) &gt; 0:\n            break\n    if len(subnet_links_df) == 0:\n        WranglerLogger.error(f\"Selection didn't return subnet links: {link_selection_dict}\")\n        msg = \"No links found with selection.\"\n        raise SubnetCreationError(msg)\n\n    subnet_links_df[\"i\"] = 0\n    subnet = Subnet(\n        net=net,\n        subnet_links_df=subnet_links_df,\n        modes=modes,\n        sp_weight_col=sp_weight_col,\n        sp_weight_factor=sp_weight_factor,\n        **kwargs,\n    )\n\n    WranglerLogger.debug(\n        f\"Found subnet from link selection with {len(subnet.subnet_links_df)} links.\"\n    )\n    return subnet\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.segment.identify_segment_endpoints","title":"network_wrangler.roadway.segment.identify_segment_endpoints","text":"<pre><code>identify_segment_endpoints(net, mode='drive', min_connecting_links=10, max_link_deviation=2)\n</code></pre> <p>This has not been revisited or refactored and may or may not contain useful code.</p> <p>Parameters:</p> <ul> <li> <code>net</code>           \u2013            <p>RoadwayNetwork to find segments for</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'drive'</code> )           \u2013            <p>list of modes of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code>. Defaults to \u201cdrive\u201d.</p> </li> <li> <code>min_connecting_links</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>number of links that should be connected with same name or ref to be considered a segment (minus max_link_deviation). Defaults to 10.</p> </li> <li> <code>max_link_deviation</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>maximum links that don\u2019t have the same name or ref to still be considered a segment. Defaults to 2.</p> </li> </ul> Source code in <code>network_wrangler/roadway/segment.py</code> <pre><code>def identify_segment_endpoints(\n    net,\n    mode: str = \"drive\",\n    min_connecting_links: int = 10,\n    max_link_deviation: int = 2,\n) -&gt; pd.DataFrame:\n    \"\"\"This has not been revisited or refactored and may or may not contain useful code.\n\n    Args:\n        net: RoadwayNetwork to find segments for\n        mode:  list of modes of the network, one of `drive`,`transit`,\n            `walk`, `bike`. Defaults to \"drive\".\n        min_connecting_links: number of links that should be connected with same name or ref\n            to be considered a segment (minus max_link_deviation). Defaults to 10.\n        max_link_deviation: maximum links that don't have the same name or ref to still be\n            considered a segment. Defaults to 2.\n\n    \"\"\"\n    msg = \"This function has not been revisited or refactored to work.\"\n    raise NotImplementedError(msg)\n    SEGMENT_IDENTIFIERS = [\"name\", \"ref\"]\n\n    NAME_PER_NODE = 4\n    REF_PER_NODE = 2\n\n    # make a copy so it is a full dataframe rather than a slice.\n    _links_df = copy.deepcopy(net.links_df.mode_query(mode))\n\n    _nodes_df = copy.deepcopy(\n        net.nodes_in_links(\n            _links_df,\n        )\n    )\n    from .network import add_incident_link_data_to_nodes  # noqa: PLC0415\n\n    _nodes_df = add_incident_link_data_to_nodes(\n        links_df=_links_df,\n        nodes_df=_nodes_df,\n        link_variables=[*SEGMENT_IDENTIFIERS, \"distance\"],\n    )\n\n    # WranglerLogger.debug(f\"Node/Link table elements: {len(_nodes_df)}\"\")\n\n    # Screen out segments that have blank name AND refs\n    _nodes_df = _nodes_df.replace(r\"^\\s*$\", np.nan, regex=True).dropna(subset=[\"name\", \"ref\"])\n\n    # WranglerLogger.debug(f\"Node/Link recs after dropping empty name AND ref : {len(_nodes_df)}\")\n\n    # Screen out segments that aren't likely to be long enough\n    # Minus 1 in case ref or name is missing on an intermediate link\n    _min_ref_in_table = REF_PER_NODE * (min_connecting_links - max_link_deviation)\n    _min_name_in_table = NAME_PER_NODE * (min_connecting_links - max_link_deviation)\n\n    _nodes_df[\"ref_freq\"] = _nodes_df[\"ref\"].map(_nodes_df[\"ref\"].value_counts())\n    _nodes_df[\"name_freq\"] = _nodes_df[\"name\"].map(_nodes_df[\"name\"].value_counts())\n\n    _nodes_df = _nodes_df.loc[\n        (_nodes_df[\"ref_freq\"] &gt;= _min_ref_in_table)\n        &amp; (_nodes_df[\"name_freq\"] &gt;= _min_name_in_table)\n    ]\n\n    _display_cols = [\n        net.nodes_df.model_node_id,\n        \"name\",\n        \"ref\",\n        \"distance\",\n        \"ref_freq\",\n        \"name_freq\",\n    ]\n    msg = f\"Node/Link table has n = {len(_nodes_df)} after screening segments for min length: \\n\\\n        {_nodes_df[_display_cols]}\"\n    WranglerLogger.debug(msg)\n\n    # ----------------------------------------\n    # Find nodes that are likely endpoints\n    # ----------------------------------------\n\n    # - Likely have one incident link and one outgoing link\n    _max_ref_endpoints = REF_PER_NODE / 2\n    _max_name_endpoints = NAME_PER_NODE / 2\n    # - Attach frequency  of node/ref\n    _nodes_df = _nodes_df.merge(\n        _nodes_df.groupby(by=[net.nodes_df.model_node_id, \"ref\"]).size().rename(\"ref_N_freq\"),\n        on=[net.nodes_df.model_node_id, \"ref\"],\n    )\n\n    _display_cols = [\"model_node_id\", \"ref\", \"name\", \"ref_N_freq\"]\n    # WranglerLogger.debug(f\"_ref_count+_nodes:\\n{_nodes_df[_display_cols]})\n    # - Attach frequency  of node/name\n    _nodes_df = _nodes_df.merge(\n        _nodes_df.groupby(by=[net.nodes_df.model_node_id, \"name\"]).size().rename(\"name_N_freq\"),\n        on=[net.nodes_df.model_node_id, \"name\"],\n    )\n    _display_cols = [\"model_node_id\", \"ref\", \"name\", \"name_N_freq\"]\n    # WranglerLogger.debug(f\"_name_count+_nodes:\\n{_nodes_df[_display_cols]}\")\n\n    _display_cols = [\n        net.nodes_df.model_node_id,\n        \"name\",\n        \"ref\",\n        \"distance\",\n        \"ref_N_freq\",\n        \"name_N_freq\",\n    ]\n    # WranglerLogger.debug(f\"Possible segment endpoints:\\n{_nodes_df[_display_cols]}\")\n    # - Filter possible endpoint list based on node/name node/ref frequency\n    _nodes_df = _nodes_df.loc[\n        (_nodes_df[\"ref_N_freq\"] &lt;= _max_ref_endpoints)\n        | (_nodes_df[\"name_N_freq\"] &lt;= _max_name_endpoints)\n    ]\n    _gb_cols = [\n        net.nodes_df.model_node_id,\n        \"name\",\n        \"ref\",\n        \"ref_N_freq\",\n        \"name_N_freq\",\n    ]\n\n    msg = f\"{len(_nodes_df)} Likely segment endpoints with req_ref&lt;= {_max_ref_endpoints} or\\\n            freq_name&lt;={_max_name_endpoints}\\n{_nodes_df.groupby(_gb_cols)}\"\n    # WranglerLogger.debug(msg)\n    # ----------------------------------------\n    # Assign a segment id\n    # ----------------------------------------\n    _nodes_df[\"segment_id\"], _segments = pd.factorize(_nodes_df.name + _nodes_df.ref)\n\n    WranglerLogger.debug(f\"{len(_segments)} Segments: \\n{chr(10).join(_segments.tolist())}\")\n\n    # ----------------------------------------\n    # Drop segments without at least two nodes\n    # ----------------------------------------\n\n    # https://stackoverflow.com/questions/13446480/python-pandas-remove-entries-based-on-the-number-of-occurrences\n    _min_nodes = 2\n    _nodes_df = _nodes_df[\n        _nodes_df.groupby([\"segment_id\", net.nodes_df.model_node_id])[\n            net.nodes_df.model_node_id\n        ].transform(len)\n        &gt;= _min_nodes\n    ]\n\n    msg = f\"{len(_nodes_df)} segments with at least {_min_nodes} nodes: \\n\\\n        {_nodes_df.groupby(['segment_id'])}\"\n    # WranglerLogger.debug(msg)\n\n    # ----------------------------------------\n    # For segments with more than two nodes, find farthest apart pairs\n    # ----------------------------------------\n\n    def _max_segment_distance(row):\n        _segment_nodes = _nodes_df.loc[_nodes_df[\"segment_id\"] == row[\"segment_id\"]]\n        dist = _segment_nodes.geometry.distance(row.geometry)\n        return max(dist.dropna())\n\n    _nodes_df[\"seg_distance\"] = _nodes_df.apply(_max_segment_distance, axis=1)\n    _nodes_df = _nodes_df.merge(\n        _nodes_df.groupby(\"segment_id\").seg_distance.agg(max).rename(\"max_seg_distance\"),\n        on=\"segment_id\",\n    )\n\n    _nodes_df = _nodes_df.loc[\n        (_nodes_df[\"max_seg_distance\"] == _nodes_df[\"seg_distance\"])\n        &amp; (_nodes_df[\"seg_distance\"] &gt; 0)\n    ].drop_duplicates(subset=[net.nodes_df.model_node_id, \"segment_id\"])\n\n    # ----------------------------------------\n    # Reassign segment id for final segments\n    # ----------------------------------------\n    _nodes_df[\"segment_id\"], _segments = pd.factorize(_nodes_df.name + _nodes_df.ref)\n\n    _display_cols = [\n        net.nodes_df.model_node_id,\n        \"name\",\n        \"ref\",\n        \"segment_id\",\n        \"seg_distance\",\n    ]\n\n    WranglerLogger.debug(\n        f\"Start and end of {len(_segments)} Segments: \\n{_nodes_df[_display_cols]}\"\n    )\n\n    _return_cols = [\n        \"segment_id\",\n        net.nodes_df.model_node_id,\n        \"geometry\",\n        \"name\",\n        \"ref\",\n    ]\n    return _nodes_df[_return_cols]\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.DEFAULT_SUBNET_MAX_SEARCH_BREADTH","title":"network_wrangler.roadway.subnet.DEFAULT_SUBNET_MAX_SEARCH_BREADTH  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SUBNET_MAX_SEARCH_BREADTH = 10\n</code></pre> <p>Factor to multiply sp_weight_col by to use for weights in shortest path.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.DEFAULT_SUBNET_SP_WEIGHT_FACTOR","title":"network_wrangler.roadway.subnet.DEFAULT_SUBNET_SP_WEIGHT_FACTOR  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SUBNET_SP_WEIGHT_FACTOR = 100\n</code></pre> <p>Column to use for weights in shortest path.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet","title":"network_wrangler.roadway.subnet.Subnet","text":"<p>Subnet is a connected selection of links/nodes from a RoadwayNetwork object.</p> <p>Subnets are used for things like identifying Segments.</p> <p>Usage:</p> <pre><code>selection_dict = {\n    \"links\": {\"name\": [\"6th\", \"Sixth\", \"sixth\"]},\n    \"from\": {\"osm_node_id\": \"187899923\"},\n    \"to\": {\"osm_node_id\": \"187865924\"},\n}\n\nsegment = Segment(net=RoadwayNetwork(...), selection_dict=selection_dict)\n# used to store graph\nself._segment_route_nodes = shortest_path(segment.subnet.graph, start_node_pk, end_node_pk)\n</code></pre> attr Source code in <code>network_wrangler/roadway/subnet.py</code> <pre><code>class Subnet:\n    \"\"\"Subnet is a connected selection of links/nodes from a RoadwayNetwork object.\n\n    Subnets are used for things like identifying Segments.\n\n    Usage:\n\n    ```\n    selection_dict = {\n        \"links\": {\"name\": [\"6th\", \"Sixth\", \"sixth\"]},\n        \"from\": {\"osm_node_id\": \"187899923\"},\n        \"to\": {\"osm_node_id\": \"187865924\"},\n    }\n\n    segment = Segment(net=RoadwayNetwork(...), selection_dict=selection_dict)\n    # used to store graph\n    self._segment_route_nodes = shortest_path(segment.subnet.graph, start_node_pk, end_node_pk)\n    ```\n\n    attr:\n        net: Associated RoadwayNetwork object\n        selection_dict: segment selection dictionary, which is is used to create initial subnet\n            based on name and ref\n        subnet_links_df: initial subnets can alternately be defined by a dataframe of links.\n        graph_hash: unique hash of subnet_links_df, _sp_weight_col and _sp_weight_factor. Used\n            to identify if any of these have changed and thus if a new graph should be generated.\n        graph: returns the nx.MultiDigraph of subne which is stored in self._graph and lazily\n            evaluated when called if graph_hash has changed becusae it is an expensive operation.\n        num_links: number of links in the subnet\n        subnet_nodes: lazily evaluated list of node primary keys based on subnet_links_df\n        subnet_nodes_df: lazily evaluated selection of net.nodes_df based on subnet_links_df\n\n    \"\"\"\n\n    def __init__(\n        self,\n        net: RoadwayNetwork,\n        modes: Optional[list] = DEFAULT_SEARCH_MODES,\n        subnet_links_df: pd.DataFrame = None,\n        i: int = 0,\n        sp_weight_factor: float = DEFAULT_SUBNET_SP_WEIGHT_FACTOR,\n        sp_weight_col: str = SUBNET_SP_WEIGHT_COL,\n        max_search_breadth: int = DEFAULT_SUBNET_MAX_SEARCH_BREADTH,\n    ):\n        \"\"\"Generates and returns a Subnet object.\n\n        Args:\n            net (RoadwayNetwork): Associated RoadwayNetwork object.\n            modes: List of modes to limit subnet to. Defaults to DEFAULT_SEARCH_MODES.\n            subnet_links_df (pd.DataFrame, optional): Initial links to include in subnet.\n                Optional if define a selection_dict and will default to result of\n                self.generate_subnet_from_selection_dict(selection_dict)\n            i: Expansion iteration number. Shouldn't need to change this as it will be done\n                internally. Defaults to 0.\n            sp_weight_col: Column to use for weights in shortest path.  Will not\n                likely need to be changed. Defaults to \"i\" which is the iteration #.\n            sp_weight_factor: Factor to multiply sp_weight_col by to use for\n                weights in shortest path.  Will not likely need to be changed.\n                Defaults to DEFAULT_SP_WEIGHT_FACTOR.\n            max_search_breadth: Maximum expansions of the subnet network to find\n                the shortest path after the initial selection based on `name`. Will not likely\n                need to be changed unless network contains a lot of ambiguity.\n                Defaults to DEFAULT_MAX_SEARCH_BREADTH.\n        \"\"\"\n        self.net = net\n        self.modes = modes\n        self._subnet_links_df = subnet_links_df\n        self._i = i\n        self._sp_weight_col = sp_weight_col\n        self._sp_weight_factor = sp_weight_factor\n        self._max_search_breadth = max_search_breadth\n        self._graph = None\n        self._graph_link_hash = None\n\n    @property\n    def exists(self) -&gt; bool:\n        \"\"\"Returns True if subnet_links_df is not None and has at least one link.\"\"\"\n        if self.subnet_links_df is None:\n            return False\n        if len(self.subnet_links_df) == 0:\n            return False\n        if len(self.subnet_links_df) &gt; 0:\n            return True\n        msg = \"Something's not right.\"\n        raise SubnetCreationError(msg)\n\n    @property\n    def subnet_links_df(self) -&gt; DataFrame[RoadLinksTable]:\n        \"\"\"Links in the subnet.\"\"\"\n        return self._subnet_links_df\n\n    @property\n    def graph_hash(self) -&gt; str:\n        \"\"\"Hash of the links in order to detect a network change from when graph created.\"\"\"\n        _value = [\n            self.subnet_links_df.df_hash(),\n            self._sp_weight_col,\n            str(self._sp_weight_factor),\n        ]\n        _enc_value = str.encode(\"-\".join(_value))\n        _hash = hashlib.sha256(_enc_value).hexdigest()\n        return _hash\n\n    @property\n    def graph(self) -&gt; MultiDiGraph:\n        \"\"\"nx.MultiDiGraph of the subnet.\"\"\"\n        if self.graph_hash != self._graph_link_hash:\n            self._graph = links_nodes_to_ox_graph(\n                self.subnet_links_df,\n                self.subnet_nodes_df,\n                sp_weight_col=self._sp_weight_col,\n                sp_weight_factor=self._sp_weight_factor,\n            )\n        return self._graph\n\n    @property\n    def num_links(self):\n        \"\"\"Number of links in the subnet.\"\"\"\n        return len(self.subnet_links_df)\n\n    @property\n    def subnet_nodes(self) -&gt; pd.Series:\n        \"\"\"List of node_ids in the subnet.\"\"\"\n        if self.subnet_links_df is None:\n            msg = \"Must set self.subnet_links_df before accessing subnet_nodes.\"\n            raise ValueError(msg)\n        return node_ids_in_links(self.subnet_links_df, self.net.nodes_df)\n\n    @property\n    def subnet_nodes_df(self) -&gt; DataFrame[RoadNodesTable]:\n        \"\"\"Nodes filtered to subnet.\"\"\"\n        return self.net.nodes_df.loc[self.subnet_nodes]\n\n    def expand_to_nodes(self, nodes_list: list, max_search_breadth: int) -&gt; None:\n        \"\"\"Expand network to include list of nodes.\n\n        Will stop expanding and generate a SubnetExpansionError if meet max_search_breadth before\n        finding the nodes.\n\n        Args:\n            nodes_list: a list of node primary keys to expand subnet to include.\n            max_search_breadth: maximum number of expansions to make before giving up.\n        \"\"\"\n        WranglerLogger.debug(f\"Expanding subnet to includes nodes: {nodes_list}\")\n\n        # expand network to find nodes in the list\n        while not set(nodes_list).issubset(self.subnet_nodes) and self._i &lt;= max_search_breadth:\n            self._expand_subnet_breadth()\n\n        if not set(nodes_list).issubset(self.subnet_nodes):\n            msg = f\"Can't find nodes {nodes_list} before achieving maximum\\\n                network expansion iterations of {max_search_breadth}\"\n            raise SubnetExpansionError(msg)\n\n    def _expand_subnet_breadth(self) -&gt; None:\n        \"\"\"Add one degree of breadth to self.subnet_links_df and add property.\"\"\"\n        self._i += 1\n\n        WranglerLogger.debug(f\"Adding Breadth to Subnet: i={self._i}\")\n\n        _modal_links_df = self.net.links_df.mode_query(self.modes)\n        # find links where A node is connected to subnet but not B node\n        _outbound_links_df = _modal_links_df.loc[\n            _modal_links_df.A.isin(self.subnet_nodes) &amp; ~_modal_links_df.B.isin(self.subnet_nodes)\n        ]\n\n        WranglerLogger.debug(f\"_outbound_links_df links: {len(_outbound_links_df)}\")\n\n        # find links where B node is connected to subnet but not A node\n        _inbound_links_df = _modal_links_df.loc[\n            _modal_links_df.B.isin(self.subnet_nodes) &amp; ~_modal_links_df.A.isin(self.subnet_nodes)\n        ]\n\n        WranglerLogger.debug(f\"_inbound_links_df links: {len(_inbound_links_df)}\")\n\n        # find links where A and B nodes are connected to subnet but not in subnet\n        _both_AB_connected_links_df = _modal_links_df.loc[\n            _modal_links_df.B.isin(self.subnet_nodes)\n            &amp; _modal_links_df.A.isin(self.subnet_nodes)\n            &amp; ~_modal_links_df.index.isin(self.subnet_links_df.index.tolist())\n        ]\n\n        WranglerLogger.debug(\n            f\"{len(_both_AB_connected_links_df)} links where both A and B are connected to subnet\\\n             but aren't in subnet.\"\n        )\n\n        _add_links_df = concat_with_attr(\n            [_both_AB_connected_links_df, _inbound_links_df, _outbound_links_df]\n        )\n\n        _add_links_df[\"i\"] = self._i\n        WranglerLogger.debug(f\"Links to add: {len(_add_links_df)}\")\n\n        WranglerLogger.debug(f\"{self.num_links} initial subnet links\")\n\n        self._subnet_links_df = concat_with_attr([self.subnet_links_df, _add_links_df])\n\n        WranglerLogger.debug(f\"{self.num_links} expanded subnet links\")\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.exists","title":"network_wrangler.roadway.subnet.Subnet.exists  <code>property</code>","text":"<pre><code>exists\n</code></pre> <p>Returns True if subnet_links_df is not None and has at least one link.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.graph","title":"network_wrangler.roadway.subnet.Subnet.graph  <code>property</code>","text":"<pre><code>graph\n</code></pre> <p>nx.MultiDiGraph of the subnet.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.graph_hash","title":"network_wrangler.roadway.subnet.Subnet.graph_hash  <code>property</code>","text":"<pre><code>graph_hash\n</code></pre> <p>Hash of the links in order to detect a network change from when graph created.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.num_links","title":"network_wrangler.roadway.subnet.Subnet.num_links  <code>property</code>","text":"<pre><code>num_links\n</code></pre> <p>Number of links in the subnet.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.subnet_links_df","title":"network_wrangler.roadway.subnet.Subnet.subnet_links_df  <code>property</code>","text":"<pre><code>subnet_links_df\n</code></pre> <p>Links in the subnet.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.subnet_nodes","title":"network_wrangler.roadway.subnet.Subnet.subnet_nodes  <code>property</code>","text":"<pre><code>subnet_nodes\n</code></pre> <p>List of node_ids in the subnet.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.subnet_nodes_df","title":"network_wrangler.roadway.subnet.Subnet.subnet_nodes_df  <code>property</code>","text":"<pre><code>subnet_nodes_df\n</code></pre> <p>Nodes filtered to subnet.</p>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.__init__","title":"network_wrangler.roadway.subnet.Subnet.__init__","text":"<pre><code>__init__(net, modes=DEFAULT_SEARCH_MODES, subnet_links_df=None, i=0, sp_weight_factor=DEFAULT_SUBNET_SP_WEIGHT_FACTOR, sp_weight_col=SUBNET_SP_WEIGHT_COL, max_search_breadth=DEFAULT_SUBNET_MAX_SEARCH_BREADTH)\n</code></pre> <p>Generates and returns a Subnet object.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>Associated RoadwayNetwork object.</p> </li> <li> <code>modes</code>               (<code>Optional[list]</code>, default:                   <code>DEFAULT_SEARCH_MODES</code> )           \u2013            <p>List of modes to limit subnet to. Defaults to DEFAULT_SEARCH_MODES.</p> </li> <li> <code>subnet_links_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>Initial links to include in subnet. Optional if define a selection_dict and will default to result of self.generate_subnet_from_selection_dict(selection_dict)</p> </li> <li> <code>i</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Expansion iteration number. Shouldn\u2019t need to change this as it will be done internally. Defaults to 0.</p> </li> <li> <code>sp_weight_col</code>               (<code>str</code>, default:                   <code>SUBNET_SP_WEIGHT_COL</code> )           \u2013            <p>Column to use for weights in shortest path.  Will not likely need to be changed. Defaults to \u201ci\u201d which is the iteration #.</p> </li> <li> <code>sp_weight_factor</code>               (<code>float</code>, default:                   <code>DEFAULT_SUBNET_SP_WEIGHT_FACTOR</code> )           \u2013            <p>Factor to multiply sp_weight_col by to use for weights in shortest path.  Will not likely need to be changed. Defaults to DEFAULT_SP_WEIGHT_FACTOR.</p> </li> <li> <code>max_search_breadth</code>               (<code>int</code>, default:                   <code>DEFAULT_SUBNET_MAX_SEARCH_BREADTH</code> )           \u2013            <p>Maximum expansions of the subnet network to find the shortest path after the initial selection based on <code>name</code>. Will not likely need to be changed unless network contains a lot of ambiguity. Defaults to DEFAULT_MAX_SEARCH_BREADTH.</p> </li> </ul> Source code in <code>network_wrangler/roadway/subnet.py</code> <pre><code>def __init__(\n    self,\n    net: RoadwayNetwork,\n    modes: Optional[list] = DEFAULT_SEARCH_MODES,\n    subnet_links_df: pd.DataFrame = None,\n    i: int = 0,\n    sp_weight_factor: float = DEFAULT_SUBNET_SP_WEIGHT_FACTOR,\n    sp_weight_col: str = SUBNET_SP_WEIGHT_COL,\n    max_search_breadth: int = DEFAULT_SUBNET_MAX_SEARCH_BREADTH,\n):\n    \"\"\"Generates and returns a Subnet object.\n\n    Args:\n        net (RoadwayNetwork): Associated RoadwayNetwork object.\n        modes: List of modes to limit subnet to. Defaults to DEFAULT_SEARCH_MODES.\n        subnet_links_df (pd.DataFrame, optional): Initial links to include in subnet.\n            Optional if define a selection_dict and will default to result of\n            self.generate_subnet_from_selection_dict(selection_dict)\n        i: Expansion iteration number. Shouldn't need to change this as it will be done\n            internally. Defaults to 0.\n        sp_weight_col: Column to use for weights in shortest path.  Will not\n            likely need to be changed. Defaults to \"i\" which is the iteration #.\n        sp_weight_factor: Factor to multiply sp_weight_col by to use for\n            weights in shortest path.  Will not likely need to be changed.\n            Defaults to DEFAULT_SP_WEIGHT_FACTOR.\n        max_search_breadth: Maximum expansions of the subnet network to find\n            the shortest path after the initial selection based on `name`. Will not likely\n            need to be changed unless network contains a lot of ambiguity.\n            Defaults to DEFAULT_MAX_SEARCH_BREADTH.\n    \"\"\"\n    self.net = net\n    self.modes = modes\n    self._subnet_links_df = subnet_links_df\n    self._i = i\n    self._sp_weight_col = sp_weight_col\n    self._sp_weight_factor = sp_weight_factor\n    self._max_search_breadth = max_search_breadth\n    self._graph = None\n    self._graph_link_hash = None\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.subnet.Subnet.expand_to_nodes","title":"network_wrangler.roadway.subnet.Subnet.expand_to_nodes","text":"<pre><code>expand_to_nodes(nodes_list, max_search_breadth)\n</code></pre> <p>Expand network to include list of nodes.</p> <p>Will stop expanding and generate a SubnetExpansionError if meet max_search_breadth before finding the nodes.</p> <p>Parameters:</p> <ul> <li> <code>nodes_list</code>               (<code>list</code>)           \u2013            <p>a list of node primary keys to expand subnet to include.</p> </li> <li> <code>max_search_breadth</code>               (<code>int</code>)           \u2013            <p>maximum number of expansions to make before giving up.</p> </li> </ul> Source code in <code>network_wrangler/roadway/subnet.py</code> <pre><code>def expand_to_nodes(self, nodes_list: list, max_search_breadth: int) -&gt; None:\n    \"\"\"Expand network to include list of nodes.\n\n    Will stop expanding and generate a SubnetExpansionError if meet max_search_breadth before\n    finding the nodes.\n\n    Args:\n        nodes_list: a list of node primary keys to expand subnet to include.\n        max_search_breadth: maximum number of expansions to make before giving up.\n    \"\"\"\n    WranglerLogger.debug(f\"Expanding subnet to includes nodes: {nodes_list}\")\n\n    # expand network to find nodes in the list\n    while not set(nodes_list).issubset(self.subnet_nodes) and self._i &lt;= max_search_breadth:\n        self._expand_subnet_breadth()\n\n    if not set(nodes_list).issubset(self.subnet_nodes):\n        msg = f\"Can't find nodes {nodes_list} before achieving maximum\\\n            network expansion iterations of {max_search_breadth}\"\n        raise SubnetExpansionError(msg)\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.graph.DEFAULT_GRAPH_WEIGHT_COL","title":"network_wrangler.roadway.graph.DEFAULT_GRAPH_WEIGHT_COL  <code>module-attribute</code>","text":"<pre><code>DEFAULT_GRAPH_WEIGHT_COL = 'distance'\n</code></pre> <p>Factor to multiply sp_weight_col by to use for weights in shortest path.</p>"},{"location":"api_roadway/#network_wrangler.roadway.graph.ox_major_version","title":"network_wrangler.roadway.graph.ox_major_version  <code>module-attribute</code>","text":"<pre><code>ox_major_version = int(split('.')[0])\n</code></pre> <p>Column to use for weights in shortest path.</p>"},{"location":"api_roadway/#network_wrangler.roadway.graph.assess_connectivity","title":"network_wrangler.roadway.graph.assess_connectivity","text":"<pre><code>assess_connectivity(net, mode='', ignore_end_nodes=True)\n</code></pre> <p>Network graph and list of disconnected subgraphs described by a list of their member nodes.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>RoadwayNetwork object</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>mode of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code></p> </li> <li> <code>ignore_end_nodes</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, ignores stray singleton nodes</p> </li> </ul> <p>Tuple of</p> <ul> <li>           \u2013            <p>Network Graph (osmnx flavored networkX DiGraph)</p> </li> <li>           \u2013            <p>List of disconnected subgraphs described by the list of their member nodes (as described by their <code>model_node_id</code>)</p> </li> </ul> Source code in <code>network_wrangler/roadway/graph.py</code> <pre><code>def assess_connectivity(\n    net: RoadwayNetwork,\n    mode: str = \"\",\n    ignore_end_nodes: bool = True,\n):\n    \"\"\"Network graph and list of disconnected subgraphs described by a list of their member nodes.\n\n    Args:\n        net: RoadwayNetwork object\n        mode:  mode of the network, one of `drive`,`transit`,\n            `walk`, `bike`\n        ignore_end_nodes: if True, ignores stray singleton nodes\n\n    Returns: Tuple of\n        Network Graph (osmnx flavored networkX DiGraph)\n        List of disconnected subgraphs described by the list of their\n            member nodes (as described by their `model_node_id`)\n    \"\"\"\n    WranglerLogger.debug(f\"Assessing network connectivity for mode: {mode}\")\n\n    G = net.get_modal_graph(mode)\n\n    sub_graph_nodes = [\n        list(s) for s in sorted(nx.strongly_connected_components(G), key=len, reverse=True)\n    ]\n\n    # sorted on decreasing length, dropping the main sub-graph\n    disconnected_sub_graph_nodes = sub_graph_nodes[1:]\n\n    # dropping the sub-graphs with only 1 node\n    if ignore_end_nodes:\n        disconnected_sub_graph_nodes = [\n            list(s) for s in disconnected_sub_graph_nodes if len(s) &gt; 1\n        ]\n\n    WranglerLogger.info(\n        f\"{net.nodes_df.model_node_id} for disconnected networks for mode = {mode}:\\n\"\n        + \"\\n\".join(list(map(str, disconnected_sub_graph_nodes))),\n    )\n    return G, disconnected_sub_graph_nodes\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.graph.links_nodes_to_ox_graph","title":"network_wrangler.roadway.graph.links_nodes_to_ox_graph","text":"<pre><code>links_nodes_to_ox_graph(links_df, nodes_df, sp_weight_col='distance', sp_weight_factor=1)\n</code></pre> <p>Create an osmnx-flavored network graph from nodes and links dfs.</p> <p>osmnx doesn\u2019t like values that are arrays, so remove the variables that have arrays.  osmnx also requires that certain variables be filled in, so do that too.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>links_df from RoadwayNetwork</p> </li> <li> <code>nodes_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>nodes_df from RoadwayNetwork</p> </li> <li> <code>sp_weight_col</code>               (<code>str</code>, default:                   <code>'distance'</code> )           \u2013            <p>column to use for weights. Defaults to <code>distance</code>.</p> </li> <li> <code>sp_weight_factor</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>multiple to apply to the weights. Defaults to 1.</p> </li> </ul> Source code in <code>network_wrangler/roadway/graph.py</code> <pre><code>def links_nodes_to_ox_graph(\n    links_df: GeoDataFrame,\n    nodes_df: GeoDataFrame,\n    sp_weight_col: str = \"distance\",\n    sp_weight_factor: float = 1,\n):\n    \"\"\"Create an osmnx-flavored network graph from nodes and links dfs.\n\n    osmnx doesn't like values that are arrays, so remove the variables\n    that have arrays.  osmnx also requires that certain variables\n    be filled in, so do that too.\n\n    Args:\n        links_df: links_df from RoadwayNetwork\n        nodes_df: nodes_df from RoadwayNetwork\n        sp_weight_col: column to use for weights. Defaults to `distance`.\n        sp_weight_factor: multiple to apply to the weights. Defaults to 1.\n\n    Returns: a networkx multidigraph\n    \"\"\"\n    WranglerLogger.debug(\"starting ox_graph()\")\n    graph_nodes_df = _nodes_to_graph_nodes(nodes_df)\n    graph_links_df = _links_to_graph_links(\n        links_df,\n        sp_weight_col=sp_weight_col,\n        sp_weight_factor=sp_weight_factor,\n    )\n\n    try:\n        WranglerLogger.debug(\"starting ox.gdfs_to_graph()\")\n        G = ox.graph_from_gdfs(graph_nodes_df, graph_links_df)\n\n    except AttributeError as attr_error:\n        if attr_error.args[0] == \"module 'osmnx' has no attribute 'graph_from_gdfs'\":\n            # This is the only exception for which we have a workaround\n            # Does this still work given the u,v,key multi-indexing?\n            #\n            WranglerLogger.warn(\n                \"Please upgrade your OSMNX package. For now, using deprecated\\\n                        osmnx.gdfs_to_graph because osmnx.graph_from_gdfs not found\"\n            )\n            G = ox.gdfs_to_graph(graph_nodes_df, graph_links_df)\n        else:\n            # for other AttributeErrors, raise further\n            raise attr_error\n    except Exception as e:\n        raise e\n\n    WranglerLogger.debug(\"Created osmnx graph from RoadwayNetwork\")\n    return G\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.graph.net_to_graph","title":"network_wrangler.roadway.graph.net_to_graph","text":"<pre><code>net_to_graph(net, mode=None)\n</code></pre> <p>Converts a network to a MultiDiGraph.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>RoadwayNetwork object</p> </li> <li> <code>mode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>mode of the network, one of <code>drive</code>,<code>transit</code>, <code>walk</code>, <code>bike</code></p> </li> </ul> Source code in <code>network_wrangler/roadway/graph.py</code> <pre><code>def net_to_graph(net: RoadwayNetwork, mode: Optional[str] = None) -&gt; nx.MultiDiGraph:\n    \"\"\"Converts a network to a MultiDiGraph.\n\n    Args:\n        net: RoadwayNetwork object\n        mode: mode of the network, one of `drive`,`transit`,\n            `walk`, `bike`\n\n    Returns: networkx: osmnx: DiGraph  of network\n    \"\"\"\n    _links_df = net.links_df.mode_query(mode)\n\n    _nodes_df = net.nodes_in_links()\n\n    G = links_nodes_to_ox_graph(_links_df, _nodes_df)\n\n    return G\n</code></pre>"},{"location":"api_roadway/#network_wrangler.roadway.graph.shortest_path","title":"network_wrangler.roadway.graph.shortest_path","text":"<pre><code>shortest_path(G, O_id, D_id, sp_weight_property='weight')\n</code></pre> <p>Calculates the shortest path between two nodes in a network.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>MultiDiGraph</code>)           \u2013            <p>osmnx MultiDiGraph, created using links_nodes_to_ox_graph</p> </li> <li> <code>O_id</code>           \u2013            <p>primary key for start node</p> </li> <li> <code>D_id</code>           \u2013            <p>primary key for end node</p> </li> <li> <code>sp_weight_property</code>           \u2013            <p>link property to use as weight in finding shortest path. Defaults to \u201cweight\u201d.</p> </li> </ul> <ul> <li>Boolean if shortest path found</li> <li>nx Directed graph of graph links</li> <li>route of shortest path nodes as List</li> <li>links in shortest path selected from links_df</li> </ul> Source code in <code>network_wrangler/roadway/graph.py</code> <pre><code>def shortest_path(\n    G: nx.MultiDiGraph, O_id, D_id, sp_weight_property=\"weight\"\n) -&gt; Union[list, None]:\n    \"\"\"Calculates the shortest path between two nodes in a network.\n\n    Args:\n        G: osmnx MultiDiGraph, created using links_nodes_to_ox_graph\n        O_id: primary key for start node\n        D_id: primary key for end node\n        sp_weight_property: link property to use as weight in finding shortest path.\n            Defaults to \"weight\".\n\n    Returns: tuple with length of four\n    - Boolean if shortest path found\n    - nx Directed graph of graph links\n    - route of shortest path nodes as List\n    - links in shortest path selected from links_df\n    \"\"\"\n    try:\n        sp_route = nx.shortest_path(G, O_id, D_id, weight=sp_weight_property)\n        WranglerLogger.debug(\"Shortest path successfully routed\")\n    except nx.NetworkXNoPath:\n        WranglerLogger.debug(f\"No SP from {O_id} to {D_id} Found.\")\n        return None\n    except Exception as e:\n        raise e\n\n    return sp_route\n</code></pre>"},{"location":"api_transit/","title":"Transit","text":""},{"location":"api_transit/#tables","title":"Tables","text":"<p>Data models for various GTFS tables using pandera library.</p> <p>The module includes the following classes:</p> <ul> <li>AgenciesTable: Optional. Represents the Agency table in the GTFS dataset.</li> <li>WranglerStopsTable: Represents the Stops table in the GTFS dataset.</li> <li>RoutesTable: Represents the Routes table in the GTFS dataset.</li> <li>WranglerShapesTable: Represents the Shapes table in the GTFS dataset.</li> <li>WranglerStopTimesTable: Represents the Stop Times table in the GTFS dataset.</li> <li>WranglerTripsTable: Represents the Trips table in the GTFS dataset.</li> </ul> <p>Each table model leverages the Pydantic data models defined in the records module to define the data model for the corresponding table. The classes also include additional configurations for, such as uniqueness constraints.</p> <p>Validating a table to the WranglerStopsTable</p> <pre><code>from network_wrangler.models.gtfs.tables import WranglerStopsTable\nfrom network_wrangler.utils.modesl import validate_df_to_model\n\nvalidated_stops_df = validate_df_to_model(stops_df, WranglerStopsTable)\n</code></pre> <p>Data Model for Pure GTFS Feed (not wrangler-flavored).</p>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.AgenciesTable","title":"network_wrangler.models.gtfs.tables.AgenciesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Agency table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#agencytxt</p> <p>Attributes:</p> <ul> <li> <code>agency_id</code>               (<code>str</code>)           \u2013            <p>The agency_id. Primary key. Required to be unique.</p> </li> <li> <code>agency_name</code>               (<code>str</code>)           \u2013            <p>The agency name.</p> </li> <li> <code>agency_url</code>               (<code>str</code>)           \u2013            <p>The agency URL.</p> </li> <li> <code>agency_timezone</code>               (<code>str</code>)           \u2013            <p>The agency timezone.</p> </li> <li> <code>agency_lang</code>               (<code>str</code>)           \u2013            <p>The agency language.</p> </li> <li> <code>agency_phone</code>               (<code>str</code>)           \u2013            <p>The agency phone number.</p> </li> <li> <code>agency_fare_url</code>               (<code>str</code>)           \u2013            <p>The agency fare URL.</p> </li> <li> <code>agency_email</code>               (<code>str</code>)           \u2013            <p>The agency email.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class AgenciesTable(DataFrameModel):\n    \"\"\"Represents the Agency table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#agencytxt&gt;\n\n    Attributes:\n        agency_id (str): The agency_id. Primary key. Required to be unique.\n        agency_name (str): The agency name.\n        agency_url (str): The agency URL.\n        agency_timezone (str): The agency timezone.\n        agency_lang (str): The agency language.\n        agency_phone (str): The agency phone number.\n        agency_fare_url (str): The agency fare URL.\n        agency_email (str): The agency email.\n    \"\"\"\n\n    agency_id: Series[str] = Field(coerce=True, nullable=False, unique=True)\n    agency_name: Series[str] = Field(coerce=True, nullable=True)\n    agency_url: Series[HttpURL] = Field(coerce=True, nullable=True)\n    agency_timezone: Series[str] = Field(coerce=True, nullable=True)\n    agency_lang: Series[str] = Field(coerce=True, nullable=True)\n    agency_phone: Series[str] = Field(coerce=True, nullable=True)\n    agency_fare_url: Series[str] = Field(coerce=True, nullable=True)\n    agency_email: Series[str] = Field(coerce=True, nullable=True)\n\n    class Config:\n        \"\"\"Config for the AgenciesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"agency_id\"]\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.FrequenciesTable","title":"network_wrangler.models.gtfs.tables.FrequenciesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Frequency table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#frequenciestxt</p> <p>The primary key of this table is a composite key of <code>trip_id</code> and <code>start_time</code>.</p> <p>Attributes:</p> <ul> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>trip_id</code> in the trips table.</p> </li> <li> <code>start_time</code>               (<code>TimeString</code>)           \u2013            <p>The start time in HH:MM:SS format.</p> </li> <li> <code>end_time</code>               (<code>TimeString</code>)           \u2013            <p>The end time in HH:MM:SS format.</p> </li> <li> <code>headway_secs</code>               (<code>int</code>)           \u2013            <p>The headway in seconds.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class FrequenciesTable(DataFrameModel):\n    \"\"\"Represents the Frequency table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#frequenciestxt&gt;\n\n    The primary key of this table is a composite key of `trip_id` and `start_time`.\n\n    Attributes:\n        trip_id (str): Foreign key to `trip_id` in the trips table.\n        start_time (TimeString): The start time in HH:MM:SS format.\n        end_time (TimeString): The end time in HH:MM:SS format.\n        headway_secs (int): The headway in seconds.\n    \"\"\"\n\n    trip_id: Series[str] = Field(nullable=False, coerce=True)\n    start_time: Series[TimeString] = Field(\n        nullable=False, coerce=True, default=DEFAULT_TIMESPAN[0]\n    )\n    end_time: Series[TimeString] = Field(nullable=False, coerce=True, default=DEFAULT_TIMESPAN[1])\n    headway_secs: Series[int] = Field(\n        coerce=True,\n        ge=1,\n        nullable=False,\n    )\n\n    class Config:\n        \"\"\"Config for the FrequenciesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        unique: ClassVar[list[str]] = [\"trip_id\", \"start_time\"]\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\", \"start_time\"]\n        _fk: ClassVar[TableForeignKeys] = {\"trip_id\": (\"trips\", \"trip_id\")}\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.RoutesTable","title":"network_wrangler.models.gtfs.tables.RoutesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Routes table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#routestxt</p> <p>Attributes:</p> <ul> <li> <code>route_id</code>               (<code>str</code>)           \u2013            <p>The route_id. Primary key. Required to be unique.</p> </li> <li> <code>route_short_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The route short name.</p> </li> <li> <code>route_long_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The route long name.</p> </li> <li> <code>route_type</code>               (<code>RouteType</code>)           \u2013            <p>The route type. Required. Values can be: - 0: Tram, Streetcar, Light rail - 1: Subway, Metro - 2: Rail - 3: Bus</p> </li> <li> <code>agency_id</code>               (<code>Optional[str]</code>)           \u2013            <p>The agency_id. Foreign key to agency_id in the agencies table.</p> </li> <li> <code>route_desc</code>               (<code>Optional[str]</code>)           \u2013            <p>The route description.</p> </li> <li> <code>route_url</code>               (<code>Optional[str]</code>)           \u2013            <p>The route URL.</p> </li> <li> <code>route_color</code>               (<code>Optional[str]</code>)           \u2013            <p>The route color.</p> </li> <li> <code>route_text_color</code>               (<code>Optional[str]</code>)           \u2013            <p>The route text color.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class RoutesTable(DataFrameModel):\n    \"\"\"Represents the Routes table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#routestxt&gt;\n\n    Attributes:\n        route_id (str): The route_id. Primary key. Required to be unique.\n        route_short_name (Optional[str]): The route short name.\n        route_long_name (Optional[str]): The route long name.\n        route_type (RouteType): The route type. Required. Values can be:\n            - 0: Tram, Streetcar, Light rail\n            - 1: Subway, Metro\n            - 2: Rail\n            - 3: Bus\n        agency_id (Optional[str]): The agency_id. Foreign key to agency_id in the agencies table.\n        route_desc (Optional[str]): The route description.\n        route_url (Optional[str]): The route URL.\n        route_color (Optional[str]): The route color.\n        route_text_color (Optional[str]): The route text color.\n    \"\"\"\n\n    route_id: Series[str] = Field(nullable=False, unique=True, coerce=True)\n    route_short_name: Series[str] = Field(nullable=True, coerce=True)\n    route_long_name: Series[str] = Field(nullable=True, coerce=True)\n    route_type: Series[Category] = Field(\n        dtype_kwargs={\"categories\": RouteType}, coerce=True, nullable=False\n    )\n\n    # Optional Fields\n    agency_id: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    route_desc: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    route_url: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    route_color: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    route_text_color: Optional[Series[str]] = Field(nullable=True, coerce=True)\n\n    class Config:\n        \"\"\"Config for the RoutesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"route_id\"]\n        _fk: ClassVar[TableForeignKeys] = {\"agency_id\": (\"agencies\", \"agency_id\")}\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.ShapesTable","title":"network_wrangler.models.gtfs.tables.ShapesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Shapes table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#shapestxt</p> <p>Attributes:</p> <ul> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>The shape_id. Primary key. Required to be unique.</p> </li> <li> <code>shape_pt_lat</code>               (<code>float</code>)           \u2013            <p>The shape point latitude.</p> </li> <li> <code>shape_pt_lon</code>               (<code>float</code>)           \u2013            <p>The shape point longitude.</p> </li> <li> <code>shape_pt_sequence</code>               (<code>int</code>)           \u2013            <p>The shape point sequence.</p> </li> <li> <code>shape_dist_traveled</code>               (<code>Optional[float]</code>)           \u2013            <p>The shape distance traveled.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class ShapesTable(DataFrameModel):\n    \"\"\"Represents the Shapes table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#shapestxt&gt;\n\n    Attributes:\n        shape_id (str): The shape_id. Primary key. Required to be unique.\n        shape_pt_lat (float): The shape point latitude.\n        shape_pt_lon (float): The shape point longitude.\n        shape_pt_sequence (int): The shape point sequence.\n        shape_dist_traveled (Optional[float]): The shape distance traveled.\n    \"\"\"\n\n    shape_id: Series[str] = Field(nullable=False, coerce=True)\n    shape_pt_lat: Series[float] = Field(coerce=True, nullable=False, ge=-90, le=90)\n    shape_pt_lon: Series[float] = Field(coerce=True, nullable=False, ge=-180, le=180)\n    shape_pt_sequence: Series[int] = Field(coerce=True, nullable=False, ge=0)\n\n    # Optional\n    shape_dist_traveled: Optional[Series[float]] = Field(coerce=True, nullable=True, ge=0)\n\n    class Config:\n        \"\"\"Config for the ShapesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"shape_id\", \"shape_pt_sequence\"]\n        _fk: ClassVar[TableForeignKeys] = {}\n        unique: ClassVar[list[str]] = [\"shape_id\", \"shape_pt_sequence\"]\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.StopTimesTable","title":"network_wrangler.models.gtfs.tables.StopTimesTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Stop Times table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#stop_timestxt</p> <p>The primary key of this table is a composite key of <code>trip_id</code> and <code>stop_sequence</code>.</p> <p>Attributes:</p> <ul> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>trip_id</code> in the trips table.</p> </li> <li> <code>stop_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>stop_id</code> in the stops table.</p> </li> <li> <code>stop_sequence</code>               (<code>int</code>)           \u2013            <p>The stop sequence.</p> </li> <li> <code>pickup_type</code>               (<code>PickupDropoffType</code>)           \u2013            <p>The pickup type. Values can be: - 0: Regularly scheduled pickup - 1: No pickup available - 2: Must phone agency to arrange pickup - 3: Must coordinate with driver to arrange pickup</p> </li> <li> <code>drop_off_type</code>               (<code>PickupDropoffType</code>)           \u2013            <p>The drop off type. Values can be: - 0: Regularly scheduled drop off - 1: No drop off available - 2: Must phone agency to arrange drop off - 3: Must coordinate with driver to arrange drop off</p> </li> <li> <code>arrival_time</code>               (<code>TimeString</code>)           \u2013            <p>The arrival time in HH:MM:SS format.</p> </li> <li> <code>departure_time</code>               (<code>TimeString</code>)           \u2013            <p>The departure time in HH:MM:SS format.</p> </li> <li> <code>shape_dist_traveled</code>               (<code>Optional[float]</code>)           \u2013            <p>The shape distance traveled.</p> </li> <li> <code>timepoint</code>               (<code>Optional[TimepointType]</code>)           \u2013            <p>The timepoint type. Values can be: - 0: The stop is not a timepoint - 1: The stop is a timepoint</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class StopTimesTable(DataFrameModel):\n    \"\"\"Represents the Stop Times table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#stop_timestxt&gt;\n\n    The primary key of this table is a composite key of `trip_id` and `stop_sequence`.\n\n    Attributes:\n        trip_id (str): Foreign key to `trip_id` in the trips table.\n        stop_id (str): Foreign key to `stop_id` in the stops table.\n        stop_sequence (int): The stop sequence.\n        pickup_type (PickupDropoffType): The pickup type. Values can be:\n            - 0: Regularly scheduled pickup\n            - 1: No pickup available\n            - 2: Must phone agency to arrange pickup\n            - 3: Must coordinate with driver to arrange pickup\n        drop_off_type (PickupDropoffType): The drop off type. Values can be:\n            - 0: Regularly scheduled drop off\n            - 1: No drop off available\n            - 2: Must phone agency to arrange drop off\n            - 3: Must coordinate with driver to arrange drop off\n        arrival_time (TimeString): The arrival time in HH:MM:SS format.\n        departure_time (TimeString): The departure time in HH:MM:SS format.\n        shape_dist_traveled (Optional[float]): The shape distance traveled.\n        timepoint (Optional[TimepointType]): The timepoint type. Values can be:\n            - 0: The stop is not a timepoint\n            - 1: The stop is a timepoint\n    \"\"\"\n\n    trip_id: Series[str] = Field(nullable=False, coerce=True)\n    stop_id: Series[str] = Field(nullable=False, coerce=True)\n    stop_sequence: Series[int] = Field(nullable=False, coerce=True, ge=0)\n    pickup_type: Series[Category] = Field(\n        dtype_kwargs={\"categories\": PickupDropoffType},\n        nullable=True,\n        coerce=True,\n    )\n    drop_off_type: Series[Category] = Field(\n        dtype_kwargs={\"categories\": PickupDropoffType},\n        nullable=True,\n        coerce=True,\n    )\n    arrival_time: Series[pa.Timestamp] = Field(nullable=True, default=pd.NaT, coerce=True)\n    departure_time: Series[pa.Timestamp] = Field(nullable=True, default=pd.NaT, coerce=True)\n\n    # Optional\n    shape_dist_traveled: Optional[Series[float]] = Field(coerce=True, nullable=True, ge=0)\n    timepoint: Optional[Series[Category]] = Field(\n        dtype_kwargs={\"categories\": TimepointType}, coerce=True, default=0\n    )\n\n    class Config:\n        \"\"\"Config for the StopTimesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\", \"stop_sequence\"]\n        _fk: ClassVar[TableForeignKeys] = {\n            \"trip_id\": (\"trips\", \"trip_id\"),\n            \"stop_id\": (\"stops\", \"stop_id\"),\n        }\n\n        unique: ClassVar[list[str]] = [\"trip_id\", \"stop_sequence\"]\n\n    @pa.dataframe_parser\n    def parse_times(cls, df):\n        \"\"\"Parse time strings to timestamps.\"\"\"\n        # Convert string times to timestamps\n        if \"arrival_time\" in df.columns and \"departure_time\" in df.columns:\n            # Convert string times to timestamps using str_to_time_series\n            df[\"arrival_time\"] = str_to_time_series(df[\"arrival_time\"])\n            df[\"departure_time\"] = str_to_time_series(df[\"departure_time\"])\n\n        return df\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.StopTimesTable.parse_times","title":"network_wrangler.models.gtfs.tables.StopTimesTable.parse_times","text":"<pre><code>parse_times(df)\n</code></pre> <p>Parse time strings to timestamps.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>@pa.dataframe_parser\ndef parse_times(cls, df):\n    \"\"\"Parse time strings to timestamps.\"\"\"\n    # Convert string times to timestamps\n    if \"arrival_time\" in df.columns and \"departure_time\" in df.columns:\n        # Convert string times to timestamps using str_to_time_series\n        df[\"arrival_time\"] = str_to_time_series(df[\"arrival_time\"])\n        df[\"departure_time\"] = str_to_time_series(df[\"departure_time\"])\n\n    return df\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.StopsTable","title":"network_wrangler.models.gtfs.tables.StopsTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Stops table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#stopstxt</p> <p>Attributes:</p> <ul> <li> <code>stop_id</code>               (<code>str</code>)           \u2013            <p>The stop_id. Primary key. Required to be unique.</p> </li> <li> <code>stop_lat</code>               (<code>float</code>)           \u2013            <p>The stop latitude.</p> </li> <li> <code>stop_lon</code>               (<code>float</code>)           \u2013            <p>The stop longitude.</p> </li> <li> <code>wheelchair_boarding</code>               (<code>Optional[int]</code>)           \u2013            <p>The wheelchair boarding.</p> </li> <li> <code>stop_code</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop code.</p> </li> <li> <code>stop_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop name.</p> </li> <li> <code>tts_stop_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The text-to-speech stop name.</p> </li> <li> <code>stop_desc</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop description.</p> </li> <li> <code>zone_id</code>               (<code>Optional[str]</code>)           \u2013            <p>The zone id.</p> </li> <li> <code>stop_url</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop URL.</p> </li> <li> <code>location_type</code>               (<code>Optional[LocationType]</code>)           \u2013            <p>The location type. Values can be: - 0: stop platform - 1: station - 2: entrance/exit - 3: generic node - 4: boarding area Default of blank assumes a stop platform.</p> </li> <li> <code>parent_station</code>               (<code>Optional[str]</code>)           \u2013            <p>The <code>stop_id</code> of the parent station.</p> </li> <li> <code>stop_timezone</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop timezone.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class StopsTable(DataFrameModel):\n    \"\"\"Represents the Stops table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#stopstxt&gt;\n\n    Attributes:\n        stop_id (str): The stop_id. Primary key. Required to be unique.\n        stop_lat (float): The stop latitude.\n        stop_lon (float): The stop longitude.\n        wheelchair_boarding (Optional[int]): The wheelchair boarding.\n        stop_code (Optional[str]): The stop code.\n        stop_name (Optional[str]): The stop name.\n        tts_stop_name (Optional[str]): The text-to-speech stop name.\n        stop_desc (Optional[str]): The stop description.\n        zone_id (Optional[str]): The zone id.\n        stop_url (Optional[str]): The stop URL.\n        location_type (Optional[LocationType]): The location type. Values can be:\n            - 0: stop platform\n            - 1: station\n            - 2: entrance/exit\n            - 3: generic node\n            - 4: boarding area\n            Default of blank assumes a stop platform.\n        parent_station (Optional[str]): The `stop_id` of the parent station.\n        stop_timezone (Optional[str]): The stop timezone.\n    \"\"\"\n\n    stop_id: Series[str] = Field(coerce=True, nullable=False, unique=True)\n    stop_lat: Series[float] = Field(coerce=True, nullable=False, ge=-90, le=90)\n    stop_lon: Series[float] = Field(coerce=True, nullable=False, ge=-180, le=180)\n\n    # Optional Fields\n    wheelchair_boarding: Optional[Series[Category]] = Field(\n        dtype_kwargs={\"categories\": WheelchairAccessible}, coerce=True, default=0\n    )\n    stop_code: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    stop_name: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    tts_stop_name: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    stop_desc: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    zone_id: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    stop_url: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    location_type: Optional[Series[Category]] = Field(\n        dtype_kwargs={\"categories\": LocationType},\n        nullable=True,\n        coerce=True,\n        default=0,\n    )\n    parent_station: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    stop_timezone: Optional[Series[str]] = Field(nullable=True, coerce=True)\n\n    class Config:\n        \"\"\"Config for the StopsTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"stop_id\"]\n        _fk: ClassVar[TableForeignKeys] = {\"parent_station\": (\"stops\", \"stop_id\")}\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.TripsTable","title":"network_wrangler.models.gtfs.tables.TripsTable","text":"<p>               Bases: <code>DataFrameModel</code></p> <p>Represents the Trips table in the GTFS dataset.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#tripstxt</p> <p>Attributes:</p> <ul> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>Primary key. Required to be unique.</p> </li> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>shape_id</code> in the shapes table.</p> </li> <li> <code>direction_id</code>               (<code>DirectionID</code>)           \u2013            <p>The direction id. Required. Values can be: - 0: Outbound - 1: Inbound</p> </li> <li> <code>service_id</code>               (<code>str</code>)           \u2013            <p>The service id.</p> </li> <li> <code>route_id</code>               (<code>str</code>)           \u2013            <p>The route id. Foreign key to <code>route_id</code> in the routes table.</p> </li> <li> <code>trip_short_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The trip short name.</p> </li> <li> <code>trip_headsign</code>               (<code>Optional[str]</code>)           \u2013            <p>The trip headsign.</p> </li> <li> <code>block_id</code>               (<code>Optional[str]</code>)           \u2013            <p>The block id.</p> </li> <li> <code>wheelchair_accessible</code>               (<code>Optional[int]</code>)           \u2013            <p>The wheelchair accessible. Values can be: - 0: No information - 1: Allowed - 2: Not allowed</p> </li> <li> <code>bikes_allowed</code>               (<code>Optional[int]</code>)           \u2013            <p>The bikes allowed. Values can be: - 0: No information - 1: Allowed - 2: Not allowed</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class TripsTable(DataFrameModel):\n    \"\"\"Represents the Trips table in the GTFS dataset.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#tripstxt&gt;\n\n    Attributes:\n        trip_id (str): Primary key. Required to be unique.\n        shape_id (str): Foreign key to `shape_id` in the shapes table.\n        direction_id (DirectionID): The direction id. Required. Values can be:\n            - 0: Outbound\n            - 1: Inbound\n        service_id (str): The service id.\n        route_id (str): The route id. Foreign key to `route_id` in the routes table.\n        trip_short_name (Optional[str]): The trip short name.\n        trip_headsign (Optional[str]): The trip headsign.\n        block_id (Optional[str]): The block id.\n        wheelchair_accessible (Optional[int]): The wheelchair accessible. Values can be:\n            - 0: No information\n            - 1: Allowed\n            - 2: Not allowed\n        bikes_allowed (Optional[int]): The bikes allowed. Values can be:\n            - 0: No information\n            - 1: Allowed\n            - 2: Not allowed\n    \"\"\"\n\n    trip_id: Series[str] = Field(nullable=False, unique=True, coerce=True)\n    shape_id: Series[str] = Field(nullable=False, coerce=True)\n    direction_id: Series[Category] = Field(\n        dtype_kwargs={\"categories\": DirectionID}, coerce=True, nullable=False, default=0\n    )\n    service_id: Series[str] = Field(nullable=False, coerce=True, default=\"1\")\n    route_id: Series[str] = Field(nullable=False, coerce=True)\n\n    # Optional Fields\n    trip_short_name: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    trip_headsign: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    block_id: Optional[Series[str]] = Field(nullable=True, coerce=True)\n    wheelchair_accessible: Optional[Series[Category]] = Field(\n        dtype_kwargs={\"categories\": WheelchairAccessible}, coerce=True, default=0\n    )\n    bikes_allowed: Optional[Series[Category]] = Field(\n        dtype_kwargs={\"categories\": BikesAllowed},\n        coerce=True,\n        default=0,\n    )\n\n    class Config:\n        \"\"\"Config for the TripsTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\"]\n        _fk: ClassVar[TableForeignKeys] = {\"route_id\": (\"routes\", \"route_id\")}\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerFrequenciesTable","title":"network_wrangler.models.gtfs.tables.WranglerFrequenciesTable","text":"<p>               Bases: <code>FrequenciesTable</code></p> <p>Wrangler flavor of GTFS FrequenciesTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#frequenciestxt</p> <p>The primary key of this table is a composite key of <code>trip_id</code> and <code>start_time</code>.</p> <p>Attributes:</p> <ul> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>trip_id</code> in the trips table.</p> </li> <li> <code>start_time</code>               (<code>datetime</code>)           \u2013            <p>The start time in datetime format.</p> </li> <li> <code>end_time</code>               (<code>datetime</code>)           \u2013            <p>The end time in datetime format.</p> </li> <li> <code>headway_secs</code>               (<code>int</code>)           \u2013            <p>The headway in seconds.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerFrequenciesTable(FrequenciesTable):\n    \"\"\"Wrangler flavor of GTFS FrequenciesTable.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#frequenciestxt&gt;\n\n    The primary key of this table is a composite key of `trip_id` and `start_time`.\n\n    Attributes:\n        trip_id (str): Foreign key to `trip_id` in the trips table.\n        start_time (datetime.datetime): The start time in datetime format.\n        end_time (datetime.datetime): The end time in datetime format.\n        headway_secs (int): The headway in seconds.\n    \"\"\"\n\n    projects: Series[str] = Field(coerce=True, default=\"\")\n    start_time: Series = Field(\n        nullable=False, coerce=True, default=str_to_time(DEFAULT_TIMESPAN[0])\n    )\n    end_time: Series = Field(nullable=False, coerce=True, default=str_to_time(DEFAULT_TIMESPAN[1]))\n\n    class Config:\n        \"\"\"Config for the FrequenciesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        unique: ClassVar[list[str]] = [\"trip_id\", \"start_time\"]\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\", \"start_time\"]\n        _fk: ClassVar[TableForeignKeys] = {\"trip_id\": (\"trips\", \"trip_id\")}\n\n    @pa.parser(\"start_time\")\n    def st_to_timestamp(cls, series: Series) -&gt; Series[Timestamp]:\n        \"\"\"Check that start time is timestamp.\"\"\"\n        series = series.fillna(str_to_time(DEFAULT_TIMESPAN[0]))\n        if series.dtype == \"datetime64[ns]\":\n            return series\n        series = str_to_time_series(series)\n        return series.astype(\"datetime64[ns]\")\n\n    @pa.parser(\"end_time\")\n    def et_to_timestamp(cls, series: Series) -&gt; Series[Timestamp]:\n        \"\"\"Check that start time is timestamp.\"\"\"\n        series = series.fillna(str_to_time(DEFAULT_TIMESPAN[1]))\n        if series.dtype == \"datetime64[ns]\":\n            return series\n        return str_to_time_series(series)\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerFrequenciesTable.et_to_timestamp","title":"network_wrangler.models.gtfs.tables.WranglerFrequenciesTable.et_to_timestamp","text":"<pre><code>et_to_timestamp(series)\n</code></pre> <p>Check that start time is timestamp.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>@pa.parser(\"end_time\")\ndef et_to_timestamp(cls, series: Series) -&gt; Series[Timestamp]:\n    \"\"\"Check that start time is timestamp.\"\"\"\n    series = series.fillna(str_to_time(DEFAULT_TIMESPAN[1]))\n    if series.dtype == \"datetime64[ns]\":\n        return series\n    return str_to_time_series(series)\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerFrequenciesTable.st_to_timestamp","title":"network_wrangler.models.gtfs.tables.WranglerFrequenciesTable.st_to_timestamp","text":"<pre><code>st_to_timestamp(series)\n</code></pre> <p>Check that start time is timestamp.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>@pa.parser(\"start_time\")\ndef st_to_timestamp(cls, series: Series) -&gt; Series[Timestamp]:\n    \"\"\"Check that start time is timestamp.\"\"\"\n    series = series.fillna(str_to_time(DEFAULT_TIMESPAN[0]))\n    if series.dtype == \"datetime64[ns]\":\n        return series\n    series = str_to_time_series(series)\n    return series.astype(\"datetime64[ns]\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerShapesTable","title":"network_wrangler.models.gtfs.tables.WranglerShapesTable","text":"<p>               Bases: <code>ShapesTable</code></p> <p>Wrangler flavor of GTFS ShapesTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#shapestxt</p> <p>Attributes:</p> <ul> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>The shape_id. Primary key. Required to be unique.</p> </li> <li> <code>shape_pt_lat</code>               (<code>float</code>)           \u2013            <p>The shape point latitude.</p> </li> <li> <code>shape_pt_lon</code>               (<code>float</code>)           \u2013            <p>The shape point longitude.</p> </li> <li> <code>shape_pt_sequence</code>               (<code>int</code>)           \u2013            <p>The shape point sequence.</p> </li> <li> <code>shape_dist_traveled</code>               (<code>Optional[float]</code>)           \u2013            <p>The shape distance traveled.</p> </li> <li> <code>shape_model_node_id</code>               (<code>int</code>)           \u2013            <p>The <code>model_node_id</code> of the shape point. Foreign key to the <code>model_node_id</code> in the nodes table.</p> </li> <li> <code>projects</code>               (<code>str</code>)           \u2013            <p>A comma-separated string value for projects that have been applied to this shape.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerShapesTable(ShapesTable):\n    \"\"\"Wrangler flavor of GTFS ShapesTable.\n\n     For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#shapestxt&gt;\n\n    Attributes:\n        shape_id (str): The shape_id. Primary key. Required to be unique.\n        shape_pt_lat (float): The shape point latitude.\n        shape_pt_lon (float): The shape point longitude.\n        shape_pt_sequence (int): The shape point sequence.\n        shape_dist_traveled (Optional[float]): The shape distance traveled.\n        shape_model_node_id (int): The `model_node_id` of the shape point. Foreign key to the `model_node_id` in the nodes table.\n        projects (str): A comma-separated string value for projects that have been applied to this shape.\n    \"\"\"\n\n    shape_model_node_id: Series[int] = Field(coerce=True, nullable=False)\n    projects: Series[str] = Field(coerce=True, default=\"\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerStopTimesTable","title":"network_wrangler.models.gtfs.tables.WranglerStopTimesTable","text":"<p>               Bases: <code>StopTimesTable</code></p> <p>Wrangler flavor of GTFS StopTimesTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#stop_timestxt</p> <p>The primary key of this table is a composite key of <code>trip_id</code> and <code>stop_sequence</code>.</p> <p>Attributes:</p> <ul> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>trip_id</code> in the trips table.</p> </li> <li> <code>stop_id</code>               (<code>int</code>)           \u2013            <p>Foreign key to <code>stop_id</code> in the stops table.</p> </li> <li> <code>stop_sequence</code>               (<code>int</code>)           \u2013            <p>The stop sequence.</p> </li> <li> <code>pickup_type</code>               (<code>PickupDropoffType</code>)           \u2013            <p>The pickup type. Values can be: - 0: Regularly scheduled pickup - 1: No pickup available - 2: Must phone agency to arrange pickup - 3: Must coordinate with driver to arrange pickup</p> </li> <li> <code>drop_off_type</code>               (<code>PickupDropoffType</code>)           \u2013            <p>The drop off type. Values can be: - 0: Regularly scheduled drop off - 1: No drop off available - 2: Must phone agency to arrange drop off - 3: Must coordinate with driver to arrange drop off</p> </li> <li> <code>shape_dist_traveled</code>               (<code>Optional[float]</code>)           \u2013            <p>The shape distance traveled.</p> </li> <li> <code>timepoint</code>               (<code>Optional[TimepointType]</code>)           \u2013            <p>The timepoint type. Values can be: - 0: The stop is not a timepoint - 1: The stop is a timepoint</p> </li> <li> <code>projects</code>               (<code>str</code>)           \u2013            <p>A comma-separated string value for projects that have been applied to this stop.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerStopTimesTable(StopTimesTable):\n    \"\"\"Wrangler flavor of GTFS StopTimesTable.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#stop_timestxt&gt;\n\n    The primary key of this table is a composite key of `trip_id` and `stop_sequence`.\n\n    Attributes:\n        trip_id (str): Foreign key to `trip_id` in the trips table.\n        stop_id (int): Foreign key to `stop_id` in the stops table.\n        stop_sequence (int): The stop sequence.\n        pickup_type (PickupDropoffType): The pickup type. Values can be:\n            - 0: Regularly scheduled pickup\n            - 1: No pickup available\n            - 2: Must phone agency to arrange pickup\n            - 3: Must coordinate with driver to arrange pickup\n        drop_off_type (PickupDropoffType): The drop off type. Values can be:\n            - 0: Regularly scheduled drop off\n            - 1: No drop off available\n            - 2: Must phone agency to arrange drop off\n            - 3: Must coordinate with driver to arrange drop off\n        shape_dist_traveled (Optional[float]): The shape distance traveled.\n        timepoint (Optional[TimepointType]): The timepoint type. Values can be:\n            - 0: The stop is not a timepoint\n            - 1: The stop is a timepoint\n        projects (str): A comma-separated string value for projects that have been applied to this stop.\n    \"\"\"\n\n    stop_id: Series[int] = Field(nullable=False, coerce=True, description=\"The model_node_id.\")\n    projects: Series[str] = Field(coerce=True, default=\"\")\n    arrival_time: Series[pa.Timestamp] = Field(nullable=True, default=pd.NaT, coerce=True)\n    departure_time: Series[pa.Timestamp] = Field(nullable=True, default=pd.NaT, coerce=True)\n\n    class Config:\n        \"\"\"Config for the StopTimesTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\", \"stop_sequence\"]\n        _fk: ClassVar[TableForeignKeys] = {\n            \"trip_id\": (\"trips\", \"trip_id\"),\n            \"stop_id\": (\"stops\", \"stop_id\"),\n        }\n\n        unique: ClassVar[list[str]] = [\"trip_id\", \"stop_sequence\"]\n\n    @pa.dataframe_parser\n    def parse_times(cls, df):\n        \"\"\"Parse time strings to timestamps.\"\"\"\n        # Convert string times to timestamps\n        if \"arrival_time\" in df.columns and \"departure_time\" in df.columns:\n            # Convert string times to timestamps using str_to_time_series\n            df[\"arrival_time\"] = str_to_time_series(df[\"arrival_time\"])\n            df[\"departure_time\"] = str_to_time_series(df[\"departure_time\"])\n\n        return df\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerStopTimesTable.parse_times","title":"network_wrangler.models.gtfs.tables.WranglerStopTimesTable.parse_times","text":"<pre><code>parse_times(df)\n</code></pre> <p>Parse time strings to timestamps.</p> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>@pa.dataframe_parser\ndef parse_times(cls, df):\n    \"\"\"Parse time strings to timestamps.\"\"\"\n    # Convert string times to timestamps\n    if \"arrival_time\" in df.columns and \"departure_time\" in df.columns:\n        # Convert string times to timestamps using str_to_time_series\n        df[\"arrival_time\"] = str_to_time_series(df[\"arrival_time\"])\n        df[\"departure_time\"] = str_to_time_series(df[\"departure_time\"])\n\n    return df\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerStopsTable","title":"network_wrangler.models.gtfs.tables.WranglerStopsTable","text":"<p>               Bases: <code>StopsTable</code></p> <p>Wrangler flavor of GTFS StopsTable.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#stopstxt</p> <p>Attributes:</p> <ul> <li> <code>stop_id</code>               (<code>int</code>)           \u2013            <p>The stop_id. Primary key. Required to be unique. Wrangler assumes that this is a reference to a roadway node and as such must be an integer</p> </li> <li> <code>stop_lat</code>               (<code>float</code>)           \u2013            <p>The stop latitude.</p> </li> <li> <code>stop_lon</code>               (<code>float</code>)           \u2013            <p>The stop longitude.</p> </li> <li> <code>wheelchair_boarding</code>               (<code>Optional[int]</code>)           \u2013            <p>The wheelchair boarding.</p> </li> <li> <code>stop_code</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop code.</p> </li> <li> <code>stop_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop name.</p> </li> <li> <code>tts_stop_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The text-to-speech stop name.</p> </li> <li> <code>stop_desc</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop description.</p> </li> <li> <code>zone_id</code>               (<code>Optional[str]</code>)           \u2013            <p>The zone id.</p> </li> <li> <code>stop_url</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop URL.</p> </li> <li> <code>location_type</code>               (<code>Optional[LocationType]</code>)           \u2013            <p>The location type. Values can be: - 0: stop platform - 1: station - 2: entrance/exit - 3: generic node - 4: boarding area Default of blank assumes a stop platform.</p> </li> <li> <code>parent_station</code>               (<code>Optional[int]</code>)           \u2013            <p>The <code>stop_id</code> of the parent station. Since stop_id is an integer in Wrangler, this field is also an integer</p> </li> <li> <code>stop_timezone</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop timezone.</p> </li> <li> <code>stop_id_GTFS</code>               (<code>Optional[str]</code>)           \u2013            <p>The stop_id from the GTFS data.</p> </li> <li> <code>projects</code>               (<code>str</code>)           \u2013            <p>A comma-separated string value for projects that have been applied to this stop.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerStopsTable(StopsTable):\n    \"\"\"Wrangler flavor of GTFS StopsTable.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#stopstxt&gt;\n\n    Attributes:\n        stop_id (int): The stop_id. Primary key. Required to be unique. **Wrangler assumes that this is a reference to a roadway node and as such must be an integer**\n        stop_lat (float): The stop latitude.\n        stop_lon (float): The stop longitude.\n        wheelchair_boarding (Optional[int]): The wheelchair boarding.\n        stop_code (Optional[str]): The stop code.\n        stop_name (Optional[str]): The stop name.\n        tts_stop_name (Optional[str]): The text-to-speech stop name.\n        stop_desc (Optional[str]): The stop description.\n        zone_id (Optional[str]): The zone id.\n        stop_url (Optional[str]): The stop URL.\n        location_type (Optional[LocationType]): The location type. Values can be:\n            - 0: stop platform\n            - 1: station\n            - 2: entrance/exit\n            - 3: generic node\n            - 4: boarding area\n            Default of blank assumes a stop platform.\n        parent_station (Optional[int]): The `stop_id` of the parent station. **Since stop_id is an integer in Wrangler, this field is also an integer**\n        stop_timezone (Optional[str]): The stop timezone.\n        stop_id_GTFS (Optional[str]): The stop_id from the GTFS data.\n        projects (str): A comma-separated string value for projects that have been applied to this stop.\n    \"\"\"\n\n    stop_id: Series[int] = Field(\n        coerce=True, nullable=False, unique=True, description=\"The model_node_id.\"\n    )\n    stop_id_GTFS: Series[str] = Field(\n        coerce=True,\n        nullable=True,\n        description=\"The stop_id from the GTFS data\",\n    )\n    stop_lat: Series[float] = Field(coerce=True, nullable=True, ge=-90, le=90)\n    stop_lon: Series[float] = Field(coerce=True, nullable=True, ge=-180, le=180)\n    projects: Series[str] = Field(coerce=True, default=\"\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.tables.WranglerTripsTable","title":"network_wrangler.models.gtfs.tables.WranglerTripsTable","text":"<p>               Bases: <code>TripsTable</code></p> <p>Represents the Trips table in the Wrangler feed, adding projects list.</p> <p>For field definitions, see the GTFS reference: https://gtfs.org/documentation/schedule/reference/#tripstxt</p> <p>Attributes:</p> <ul> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>Primary key. Required to be unique.</p> </li> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>Foreign key to <code>shape_id</code> in the shapes table.</p> </li> <li> <code>direction_id</code>               (<code>DirectionID</code>)           \u2013            <p>The direction id. Required. Values can be: - 0: Outbound - 1: Inbound</p> </li> <li> <code>service_id</code>               (<code>str</code>)           \u2013            <p>The service id.</p> </li> <li> <code>route_id</code>               (<code>str</code>)           \u2013            <p>The route id. Foreign key to <code>route_id</code> in the routes table.</p> </li> <li> <code>trip_short_name</code>               (<code>Optional[str]</code>)           \u2013            <p>The trip short name.</p> </li> <li> <code>trip_headsign</code>               (<code>Optional[str]</code>)           \u2013            <p>The trip headsign.</p> </li> <li> <code>block_id</code>               (<code>Optional[str]</code>)           \u2013            <p>The block id.</p> </li> <li> <code>wheelchair_accessible</code>               (<code>Optional[int]</code>)           \u2013            <p>The wheelchair accessible. Values can be: - 0: No information - 1: Allowed - 2: Not allowed</p> </li> <li> <code>bikes_allowed</code>               (<code>Optional[int]</code>)           \u2013            <p>The bikes allowed. Values can be: - 0: No information - 1: Allowed - 2: Not allowed</p> </li> <li> <code>projects</code>               (<code>str</code>)           \u2013            <p>A comma-separated string value for projects that have been applied to this trip.</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/tables.py</code> <pre><code>class WranglerTripsTable(TripsTable):\n    \"\"\"Represents the Trips table in the Wrangler feed, adding projects list.\n\n    For field definitions, see the GTFS reference: &lt;https://gtfs.org/documentation/schedule/reference/#tripstxt&gt;\n\n    Attributes:\n        trip_id (str): Primary key. Required to be unique.\n        shape_id (str): Foreign key to `shape_id` in the shapes table.\n        direction_id (DirectionID): The direction id. Required. Values can be:\n            - 0: Outbound\n            - 1: Inbound\n        service_id (str): The service id.\n        route_id (str): The route id. Foreign key to `route_id` in the routes table.\n        trip_short_name (Optional[str]): The trip short name.\n        trip_headsign (Optional[str]): The trip headsign.\n        block_id (Optional[str]): The block id.\n        wheelchair_accessible (Optional[int]): The wheelchair accessible. Values can be:\n            - 0: No information\n            - 1: Allowed\n            - 2: Not allowed\n        bikes_allowed (Optional[int]): The bikes allowed. Values can be:\n            - 0: No information\n            - 1: Allowed\n            - 2: Not allowed\n        projects (str): A comma-separated string value for projects that have been applied to this trip.\n    \"\"\"\n\n    projects: Series[str] = Field(coerce=True, default=\"\")\n\n    class Config:\n        \"\"\"Config for the WranglerTripsTable data model.\"\"\"\n\n        coerce = True\n        add_missing_columns = True\n        _pk: ClassVar[TablePrimaryKeys] = [\"trip_id\"]\n        _fk: ClassVar[TableForeignKeys] = {\"route_id\": (\"routes\", \"route_id\")}\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.gtfs.GtfsModel","title":"network_wrangler.models.gtfs.gtfs.GtfsModel","text":"<p>               Bases: <code>DBModelMixin</code></p> <p>Wrapper class around GTFS feed.</p> <p>This is the pure GTFS model version of Feed</p> <p>Most functionality derives from mixin class <code>DBModelMixin</code> which provides:</p> <ul> <li>validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)</li> <li>validation of fks when setting a table attribute (e.g. self.trips = trips_df)</li> <li>hashing and deep copy functionality</li> <li>overload of eq to apply only to tables in table_names.</li> <li>convenience methods for accessing tables</li> </ul> <p>Attributes:</p> <ul> <li> <code>table_names</code>               (<code>list[str]</code>)           \u2013            <p>list of table names in GTFS feed.</p> </li> <li> <code>tables</code>               (<code>list[DataFrame]</code>)           \u2013            <p>list tables as dataframes.</p> </li> <li> <code>stop_times</code>               (<code>DataFrame[StopTimesTable]</code>)           \u2013            <p>stop_times dataframe with roadway node_ids</p> </li> <li> <code>stops</code>               (<code>DataFrame[WranglerStopsTable]</code>)           \u2013            <p>stops dataframe</p> </li> <li> <code>shapes</code>               (<code>DataFrame[ShapesTable]</code>)           \u2013            <p>shapes dataframe</p> </li> <li> <code>trips</code>               (<code>DataFrame[TripsTable]</code>)           \u2013            <p>trips dataframe</p> </li> <li> <code>frequencies</code>               (<code>Optional[DataFrame[FrequenciesTable]]</code>)           \u2013            <p>frequencies dataframe</p> </li> <li> <code>routes</code>               (<code>DataFrame[RoutesTable]</code>)           \u2013            <p>route dataframe</p> </li> <li> <code>net</code>               (<code>Optional[TransitNetwork]</code>)           \u2013            <p>TransitNetwork object</p> </li> </ul> Source code in <code>network_wrangler/models/gtfs/gtfs.py</code> <pre><code>class GtfsModel(DBModelMixin):\n    \"\"\"Wrapper class around GTFS feed.\n\n    This is the pure GTFS model version of [Feed][network_wrangler.transit.feed.feed.Feed]\n\n    Most functionality derives from mixin class\n    [`DBModelMixin`][network_wrangler.models._base.db.DBModelMixin] which provides:\n\n    - validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)\n    - validation of fks when setting a table attribute (e.g. self.trips = trips_df)\n    - hashing and deep copy functionality\n    - overload of __eq__ to apply only to tables in table_names.\n    - convenience methods for accessing tables\n\n    Attributes:\n        table_names (list[str]): list of table names in GTFS feed.\n        tables (list[DataFrame]): list tables as dataframes.\n        stop_times (DataFrame[StopTimesTable]): stop_times dataframe with roadway node_ids\n        stops (DataFrame[WranglerStopsTable]): stops dataframe\n        shapes (DataFrame[ShapesTable]): shapes dataframe\n        trips (DataFrame[TripsTable]): trips dataframe\n        frequencies (Optional[DataFrame[FrequenciesTable]]): frequencies dataframe\n        routes (DataFrame[RoutesTable]): route dataframe\n        net (Optional[TransitNetwork]): TransitNetwork object\n    \"\"\"\n\n    # the ordering here matters because the stops need to be added before stop_times if\n    # stop times needs to be converted\n    _table_models: ClassVar[dict] = {\n        \"agencies\": AgenciesTable,\n        \"frequencies\": FrequenciesTable,\n        \"routes\": RoutesTable,\n        \"shapes\": ShapesTable,\n        \"stops\": StopsTable,\n        \"trips\": TripsTable,\n        \"stop_times\": StopTimesTable,\n    }\n\n    table_names: ClassVar[list[str]] = [\n        \"routes\",\n        \"shapes\",\n        \"stops\",\n        \"trips\",\n        \"stop_times\",\n    ]\n\n    optional_table_names: ClassVar[list[str]] = [\"agencies\", \"frequencies\"]\n\n    def __init__(self, **kwargs):\n        \"\"\"Initialize GTFS model.\"\"\"\n        self.initialize_tables(**kwargs)\n\n        # Set extra provided attributes.\n        extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n        for k, v in extra_attr:\n            self.__setattr__(k, v)\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.gtfs.GtfsModel.__init__","title":"network_wrangler.models.gtfs.gtfs.GtfsModel.__init__","text":"<pre><code>__init__(**kwargs)\n</code></pre> <p>Initialize GTFS model.</p> Source code in <code>network_wrangler/models/gtfs/gtfs.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Initialize GTFS model.\"\"\"\n    self.initialize_tables(**kwargs)\n\n    # Set extra provided attributes.\n    extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n    for k, v in extra_attr:\n        self.__setattr__(k, v)\n</code></pre>"},{"location":"api_transit/#network_wrangler.models.gtfs.gtfs.GtfsValidationError","title":"network_wrangler.models.gtfs.gtfs.GtfsValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised for errors in the GTFS feed.</p> Source code in <code>network_wrangler/models/gtfs/gtfs.py</code> <pre><code>class GtfsValidationError(Exception):\n    \"\"\"Exception raised for errors in the GTFS feed.\"\"\"\n</code></pre>"},{"location":"api_transit/#feed","title":"Feed","text":"<p>Main functionality for GTFS tables including Feed object.</p> <p>Filters and queries of a gtfs frequencies table.</p> <p>Filters and queries of a gtfs routes table and route_ids.</p> <p>Filters, queries of a gtfs shapes table and node patterns.</p> <p>Filters and queries of a gtfs stop_times table.</p> <p>Filters and queries of a gtfs stops table and stop_ids.</p> <p>Filters and queries of a gtfs trips table and trip_ids.</p> <p>Functions for translating transit tables into visualizable links relatable to roadway network.</p> <p>Functions to create segments from shapes and shape_links.</p>"},{"location":"api_transit/#network_wrangler.transit.feed.feed.Feed","title":"network_wrangler.transit.feed.feed.Feed","text":"<p>               Bases: <code>DBModelMixin</code></p> <p>Wrapper class around Wrangler flavored GTFS feed.</p> <p>Most functionality derives from mixin class <code>DBModelMixin</code> which provides:</p> <ul> <li>validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)</li> <li>validation of fks when setting a table attribute (e.g. self.trips = trips_df)</li> <li>hashing and deep copy functionality</li> <li>overload of eq to apply only to tables in table_names.</li> <li>convenience methods for accessing tables</li> </ul> <p>What is Wrangler-flavored GTFS?</p> <p>A Wrangler-flavored GTFS feed differs from a GTFS feed in the following ways:</p> <ul> <li><code>frequencies.txt</code> is required</li> <li><code>shapes.txt</code> requires additional field, <code>shape_model_node_id</code>, corresponding to <code>model_node_id</code> in the <code>RoadwayNetwork</code></li> <li><code>stops.txt</code> - <code>stop_id</code> is required to be an int</li> </ul> <p>Attributes:</p> <ul> <li> <code>table_names</code>               (<code>list[str]</code>)           \u2013            <p>list of table names in GTFS feed.</p> </li> <li> <code>tables</code>               (<code>list[DataFrame]</code>)           \u2013            <p>list tables as dataframes.</p> </li> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>stop_times dataframe with roadway node_ids</p> </li> <li> <code>stops</code>               (<code>DataFrame[WranglerStopsTable]</code>)           \u2013            <p>stops dataframe</p> </li> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>shapes dataframe</p> </li> <li> <code>trips</code>               (<code>DataFrame[WranglerTripsTable]</code>)           \u2013            <p>trips dataframe</p> </li> <li> <code>frequencies</code>               (<code>DataFrame[WranglerFrequenciesTable]</code>)           \u2013            <p>frequencies dataframe</p> </li> <li> <code>routes</code>               (<code>DataFrame[RoutesTable]</code>)           \u2013            <p>route dataframe</p> </li> <li> <code>agencies</code>               (<code>Optional[DataFrame[AgenciesTable]]</code>)           \u2013            <p>agencies dataframe</p> </li> <li> <code>net</code>               (<code>Optional[TransitNetwork]</code>)           \u2013            <p>TransitNetwork object</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>class Feed(DBModelMixin):\n    \"\"\"Wrapper class around Wrangler flavored GTFS feed.\n\n    Most functionality derives from mixin class\n    [`DBModelMixin`][network_wrangler.models._base.db.DBModelMixin] which provides:\n\n    - validation of tables to schemas when setting a table attribute (e.g. self.trips = trips_df)\n    - validation of fks when setting a table attribute (e.g. self.trips = trips_df)\n    - hashing and deep copy functionality\n    - overload of __eq__ to apply only to tables in table_names.\n    - convenience methods for accessing tables\n\n    !!! note \"What is Wrangler-flavored GTFS?\"\n\n        A Wrangler-flavored GTFS feed differs from a GTFS feed in the following ways:\n\n        * `frequencies.txt` is required\n        * `shapes.txt` requires additional field, `shape_model_node_id`, corresponding to `model_node_id` in the `RoadwayNetwork`\n        * `stops.txt` - `stop_id` is required to be an int\n\n    Attributes:\n        table_names (list[str]): list of table names in GTFS feed.\n        tables (list[DataFrame]): list tables as dataframes.\n        stop_times (DataFrame[WranglerStopTimesTable]): stop_times dataframe with roadway node_ids\n        stops (DataFrame[WranglerStopsTable]): stops dataframe\n        shapes (DataFrame[WranglerShapesTable]): shapes dataframe\n        trips (DataFrame[WranglerTripsTable]): trips dataframe\n        frequencies (DataFrame[WranglerFrequenciesTable]): frequencies dataframe\n        routes (DataFrame[RoutesTable]): route dataframe\n        agencies (Optional[DataFrame[AgenciesTable]]): agencies dataframe\n        net (Optional[TransitNetwork]): TransitNetwork object\n    \"\"\"\n\n    # the ordering here matters because the stops need to be added before stop_times if\n    # stop times needs to be converted\n    _table_models: ClassVar[dict] = {\n        \"agencies\": AgenciesTable,\n        \"frequencies\": WranglerFrequenciesTable,\n        \"routes\": RoutesTable,\n        \"shapes\": WranglerShapesTable,\n        \"stops\": WranglerStopsTable,\n        \"trips\": WranglerTripsTable,\n        \"stop_times\": WranglerStopTimesTable,\n    }\n\n    # Define the converters if the table needs to be converted to a Wrangler table.\n    # Format: \"table_name\": converter_function\n    _converters: ClassVar[dict[str, Callable]] = {}\n\n    table_names: ClassVar[list[str]] = [\n        \"frequencies\",\n        \"routes\",\n        \"shapes\",\n        \"stops\",\n        \"trips\",\n        \"stop_times\",\n    ]\n\n    optional_table_names: ClassVar[list[str]] = [\"agencies\"]\n\n    def __init__(self, **kwargs):\n        \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n        Args:\n            kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n        \"\"\"\n        self._net = None\n        self.feed_path: Path = None\n        self.initialize_tables(**kwargs)\n\n        # Set extra provided attributes but just FYI in logger.\n        extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n        if extra_attr:\n            WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n        for k, v in extra_attr:\n            self.__setattr__(k, v)\n\n    def set_by_id(\n        self,\n        table_name: str,\n        set_df: pd.DataFrame,\n        id_property: str = \"index\",\n        properties: Optional[list[str]] = None,\n    ):\n        \"\"\"Set one or more property values based on an ID property for a given table.\n\n        Args:\n            table_name (str): Name of the table to modify.\n            set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n                values to set for the specified property where `&lt;id_property&gt;` is unique.\n            id_property: Property to use as ID to set by. Defaults to \"index\".\n            properties: List of properties to set which are in set_df. If not specified, will set\n                all properties.\n        \"\"\"\n        if not set_df[id_property].is_unique:\n            msg = f\"{id_property} must be unique in set_df.\"\n            _dupes = set_df[id_property][set_df[id_property].duplicated()]\n            WranglerLogger.error(msg + f\"Found duplicates: {_dupes.sum()}\")\n\n            raise ValueError(msg)\n        table_df = self.get_table(table_name)\n        updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n        self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.feed.Feed.__init__","title":"network_wrangler.transit.feed.feed.Feed.__init__","text":"<pre><code>__init__(**kwargs)\n</code></pre> <p>Create a Feed object from a dictionary of DataFrames representing a GTFS feed.</p> <p>Parameters:</p> <ul> <li> <code>kwargs</code>           \u2013            <p>A dictionary containing DataFrames representing the tables of a GTFS feed.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"Create a Feed object from a dictionary of DataFrames representing a GTFS feed.\n\n    Args:\n        kwargs: A dictionary containing DataFrames representing the tables of a GTFS feed.\n    \"\"\"\n    self._net = None\n    self.feed_path: Path = None\n    self.initialize_tables(**kwargs)\n\n    # Set extra provided attributes but just FYI in logger.\n    extra_attr = {k: v for k, v in kwargs.items() if k not in self.table_names}\n    if extra_attr:\n        WranglerLogger.info(f\"Adding additional attributes to Feed: {extra_attr.keys()}\")\n    for k, v in extra_attr:\n        self.__setattr__(k, v)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.feed.Feed.set_by_id","title":"network_wrangler.transit.feed.feed.Feed.set_by_id","text":"<pre><code>set_by_id(table_name, set_df, id_property='index', properties=None)\n</code></pre> <p>Set one or more property values based on an ID property for a given table.</p> <p>Parameters:</p> <ul> <li> <code>table_name</code>               (<code>str</code>)           \u2013            <p>Name of the table to modify.</p> </li> <li> <code>set_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame with columns <code>&lt;id_property&gt;</code> and <code>value</code> containing values to set for the specified property where <code>&lt;id_property&gt;</code> is unique.</p> </li> <li> <code>id_property</code>               (<code>str</code>, default:                   <code>'index'</code> )           \u2013            <p>Property to use as ID to set by. Defaults to \u201cindex\u201d.</p> </li> <li> <code>properties</code>               (<code>Optional[list[str]]</code>, default:                   <code>None</code> )           \u2013            <p>List of properties to set which are in set_df. If not specified, will set all properties.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def set_by_id(\n    self,\n    table_name: str,\n    set_df: pd.DataFrame,\n    id_property: str = \"index\",\n    properties: Optional[list[str]] = None,\n):\n    \"\"\"Set one or more property values based on an ID property for a given table.\n\n    Args:\n        table_name (str): Name of the table to modify.\n        set_df (pd.DataFrame): DataFrame with columns `&lt;id_property&gt;` and `value` containing\n            values to set for the specified property where `&lt;id_property&gt;` is unique.\n        id_property: Property to use as ID to set by. Defaults to \"index\".\n        properties: List of properties to set which are in set_df. If not specified, will set\n            all properties.\n    \"\"\"\n    if not set_df[id_property].is_unique:\n        msg = f\"{id_property} must be unique in set_df.\"\n        _dupes = set_df[id_property][set_df[id_property].duplicated()]\n        WranglerLogger.error(msg + f\"Found duplicates: {_dupes.sum()}\")\n\n        raise ValueError(msg)\n    table_df = self.get_table(table_name)\n    updated_df = update_df_by_col_value(table_df, set_df, id_property, properties=properties)\n    self.__dict__[table_name] = updated_df\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.feed.merge_shapes_to_stop_times","title":"network_wrangler.transit.feed.feed.merge_shapes_to_stop_times","text":"<pre><code>merge_shapes_to_stop_times(stop_times, shapes, trips)\n</code></pre> <p>Add shape_id and shape_pt_sequence to stop_times dataframe.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>stop_times dataframe to add shape_id and shape_pt_sequence to.</p> </li> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>shapes dataframe to add to stop_times.</p> </li> <li> <code>trips</code>               (<code>DataFrame[WranglerTripsTable]</code>)           \u2013            <p>trips dataframe to link stop_times to shapes</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[WranglerStopTimesTable]</code>           \u2013            <p>stop_times dataframe with shape_id and shape_pt_sequence added.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def merge_shapes_to_stop_times(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Add shape_id and shape_pt_sequence to stop_times dataframe.\n\n    Args:\n        stop_times: stop_times dataframe to add shape_id and shape_pt_sequence to.\n        shapes: shapes dataframe to add to stop_times.\n        trips: trips dataframe to link stop_times to shapes\n\n    Returns:\n        stop_times dataframe with shape_id and shape_pt_sequence added.\n    \"\"\"\n    stop_times_w_shape_id = stop_times.merge(\n        trips[[\"trip_id\", \"shape_id\"]], on=\"trip_id\", how=\"left\"\n    )\n\n    stop_times_w_shapes = stop_times_w_shape_id.merge(\n        shapes,\n        how=\"left\",\n        left_on=[\"shape_id\", \"stop_id\"],\n        right_on=[\"shape_id\", \"shape_model_node_id\"],\n    )\n    stop_times_w_shapes = stop_times_w_shapes.drop(columns=[\"shape_model_node_id\"])\n    return stop_times_w_shapes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.feed.stop_count_by_trip","title":"network_wrangler.transit.feed.feed.stop_count_by_trip","text":"<pre><code>stop_count_by_trip(stop_times)\n</code></pre> <p>Returns dataframe with trip_id and stop_count from stop_times.</p> Source code in <code>network_wrangler/transit/feed/feed.py</code> <pre><code>def stop_count_by_trip(\n    stop_times: DataFrame[WranglerStopTimesTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe with trip_id and stop_count from stop_times.\"\"\"\n    stops_count = stop_times.groupby(\"trip_id\").size()\n    return stops_count.reset_index(name=\"stop_count\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.frequencies.frequencies_for_trips","title":"network_wrangler.transit.feed.frequencies.frequencies_for_trips","text":"<pre><code>frequencies_for_trips(frequencies, trips)\n</code></pre> <p>Filter frequenceis dataframe to records associated with trips table.</p> Source code in <code>network_wrangler/transit/feed/frequencies.py</code> <pre><code>def frequencies_for_trips(\n    frequencies: DataFrame[WranglerFrequenciesTable], trips: DataFrame[WranglerTripsTable]\n) -&gt; DataFrame[WranglerFrequenciesTable]:\n    \"\"\"Filter frequenceis dataframe to records associated with trips table.\"\"\"\n    _sel_trips = trips.trip_id.unique().tolist()\n    filtered_frequencies = frequencies[frequencies.trip_id.isin(_sel_trips)]\n    WranglerLogger.debug(\n        f\"Filtered frequencies to {len(filtered_frequencies)}/{len(frequencies)} \\\n                         records that referenced one of {len(trips)} trips.\"\n    )\n    return filtered_frequencies\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.routes.route_ids_for_trip_ids","title":"network_wrangler.transit.feed.routes.route_ids_for_trip_ids","text":"<pre><code>route_ids_for_trip_ids(trips, trip_ids)\n</code></pre> <p>Returns route ids for given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/routes.py</code> <pre><code>def route_ids_for_trip_ids(trips: DataFrame[WranglerTripsTable], trip_ids: list[str]) -&gt; list[str]:\n    \"\"\"Returns route ids for given list of trip_ids.\"\"\"\n    return trips[trips[\"trip_id\"].isin(trip_ids)].route_id.unique().tolist()\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.routes.routes_for_trip_ids","title":"network_wrangler.transit.feed.routes.routes_for_trip_ids","text":"<pre><code>routes_for_trip_ids(routes, trips, trip_ids)\n</code></pre> <p>Returns route records for given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/routes.py</code> <pre><code>def routes_for_trip_ids(\n    routes: DataFrame[RoutesTable], trips: DataFrame[WranglerTripsTable], trip_ids: list[str]\n) -&gt; DataFrame[RoutesTable]:\n    \"\"\"Returns route records for given list of trip_ids.\"\"\"\n    route_ids = route_ids_for_trip_ids(trips, trip_ids)\n    return routes.loc[routes.route_id.isin(route_ids)]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.routes.routes_for_trips","title":"network_wrangler.transit.feed.routes.routes_for_trips","text":"<pre><code>routes_for_trips(routes, trips)\n</code></pre> <p>Filter routes dataframe to records associated with trip records.</p> Source code in <code>network_wrangler/transit/feed/routes.py</code> <pre><code>def routes_for_trips(\n    routes: DataFrame[RoutesTable], trips: DataFrame[WranglerTripsTable]\n) -&gt; DataFrame[RoutesTable]:\n    \"\"\"Filter routes dataframe to records associated with trip records.\"\"\"\n    _sel_routes = trips.route_id.unique().tolist()\n    filtered_routes = routes[routes.route_id.isin(_sel_routes)]\n    WranglerLogger.debug(\n        f\"Filtered routes to {len(filtered_routes)}/{len(routes)} \\\n                         records that referenced one of {len(trips)} trips.\"\n    )\n    return filtered_routes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.find_nearest_stops","title":"network_wrangler.transit.feed.shapes.find_nearest_stops","text":"<pre><code>find_nearest_stops(shapes, trips, stop_times, trip_id, node_id, pickup_dropoff='either')\n</code></pre> <p>Returns node_ids (before and after) of nearest node_ids that are stops for a given trip_id.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>WranglerShapesTable</code>)           \u2013            <p>WranglerShapesTable</p> </li> <li> <code>trips</code>               (<code>WranglerTripsTable</code>)           \u2013            <p>WranglerTripsTable</p> </li> <li> <code>stop_times</code>               (<code>WranglerStopTimesTable</code>)           \u2013            <p>WranglerStopTimesTable</p> </li> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>trip id to find nearest stops for</p> </li> <li> <code>node_id</code>               (<code>int</code>)           \u2013            <p>node_id to find nearest stops for</p> </li> <li> <code>pickup_dropoff</code>               (<code>PickupDropoffAvailability</code>, default:                   <code>'either'</code> )           \u2013            <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code> (              <code>tuple[int, int]</code> )          \u2013            <p>node_ids for stop before and stop after</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def find_nearest_stops(\n    shapes: WranglerShapesTable,\n    trips: WranglerTripsTable,\n    stop_times: WranglerStopTimesTable,\n    trip_id: str,\n    node_id: int,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; tuple[int, int]:\n    \"\"\"Returns node_ids (before and after) of nearest node_ids that are stops for a given trip_id.\n\n    Args:\n        shapes: WranglerShapesTable\n        trips: WranglerTripsTable\n        stop_times: WranglerStopTimesTable\n        trip_id: trip id to find nearest stops for\n        node_id: node_id to find nearest stops for\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n\n    Returns:\n        tuple: node_ids for stop before and stop after\n    \"\"\"\n    shapes = shapes_with_stop_id_for_trip_id(\n        shapes, trips, stop_times, trip_id, pickup_dropoff=pickup_dropoff\n    )\n    WranglerLogger.debug(f\"Looking for stops near node_id: {node_id}\")\n    if node_id not in shapes[\"shape_model_node_id\"].values:\n        msg = f\"Node ID {node_id} not in shapes for trip {trip_id}\"\n        raise ValueError(msg)\n    # Find index of node_id in shapes\n    node_idx = shapes[shapes[\"shape_model_node_id\"] == node_id].index[0]\n\n    # Find stops before and after new stop in shapes sequence\n    nodes_before = shapes.loc[: node_idx - 1]\n    stops_before = nodes_before.loc[nodes_before[\"stop_id\"].notna()]\n    stop_node_before = 0 if stops_before.empty else stops_before.iloc[-1][\"shape_model_node_id\"]\n\n    nodes_after = shapes.loc[node_idx + 1 :]\n    stops_after = nodes_after.loc[nodes_after[\"stop_id\"].notna()]\n    stop_node_after = 0 if stops_after.empty else stops_after.iloc[0][\"shape_model_node_id\"]\n\n    return stop_node_before, stop_node_after\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.node_pattern_for_shape_id","title":"network_wrangler.transit.feed.shapes.node_pattern_for_shape_id","text":"<pre><code>node_pattern_for_shape_id(shapes, shape_id)\n</code></pre> <p>Returns node pattern of a shape.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def node_pattern_for_shape_id(shapes: DataFrame[WranglerShapesTable], shape_id: str) -&gt; list[int]:\n    \"\"\"Returns node pattern of a shape.\"\"\"\n    shape_df = shapes.loc[shapes[\"shape_id\"] == shape_id]\n    shape_df = shape_df.sort_values(by=[\"shape_pt_sequence\"])\n    return shape_df[\"shape_model_node_id\"].to_list()\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shape_id_for_trip_id","title":"network_wrangler.transit.feed.shapes.shape_id_for_trip_id","text":"<pre><code>shape_id_for_trip_id(trips, trip_id)\n</code></pre> <p>Returns a shape_id for a given trip_id.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shape_id_for_trip_id(trips: WranglerTripsTable, trip_id: str) -&gt; str:\n    \"\"\"Returns a shape_id for a given trip_id.\"\"\"\n    return trips.loc[trips.trip_id == trip_id, \"shape_id\"].values[0]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shape_ids_for_trip_ids","title":"network_wrangler.transit.feed.shapes.shape_ids_for_trip_ids","text":"<pre><code>shape_ids_for_trip_ids(trips, trip_ids)\n</code></pre> <p>Returns a list of shape_ids for a given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shape_ids_for_trip_ids(trips: DataFrame[WranglerTripsTable], trip_ids: list[str]) -&gt; list[str]:\n    \"\"\"Returns a list of shape_ids for a given list of trip_ids.\"\"\"\n    return trips[trips[\"trip_id\"].isin(trip_ids)].shape_id.unique().tolist()\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_for_road_links","title":"network_wrangler.transit.feed.shapes.shapes_for_road_links","text":"<pre><code>shapes_for_road_links(shapes, links_df)\n</code></pre> <p>Filter shapes dataframe to records associated with links dataframe.</p> <p>EX:</p> <p>shapes = pd.DataFrame({     \u201cshape_id\u201d: [\u201c1\u201d, \u201c1\u201d, \u201c1\u201d, \u201c1\u201d, \u201c2\u201d, \u201c2\u201d, \u201c2\u201d, \u201c2\u201d, \u201c2\u201d],     \u201cshape_pt_sequence\u201d: [1, 2, 3, 4, 1, 2, 3, 4, 5],     \u201cshape_model_node_id\u201d: [1, 2, 3, 4, 2, 3, 1, 5, 4] })</p> <p>links_df = pd.DataFrame({     \u201cA\u201d: [1, 2, 3],     \u201cB\u201d: [2, 3, 4] })</p> <p>shapes</p> <p>shape_id   shape_pt_sequence   shape_model_node_id should retain 1          1                  1                        TRUE 1          2                  2                        TRUE 1          3                  3                        TRUE 1          4                  4                        TRUE 1          5                  5                       FALSE 2          1                  1                        TRUE 2          2                  2                        TRUE 2          3                  3                        TRUE 2          4                  1                       FALSE 2          5                  5                       FALSE 2          6                  4                       FALSE 2          7                  1                       FALSE - not largest segment 2          8                  2                       FALSE - not largest segment</p> <p>links_df</p> <p>A   B 1   2 2   3 3   4</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_road_links(\n    shapes: DataFrame[WranglerShapesTable], links_df: pd.DataFrame\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Filter shapes dataframe to records associated with links dataframe.\n\n    EX:\n\n    &gt; shapes = pd.DataFrame({\n        \"shape_id\": [\"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"2\", \"2\", \"2\"],\n        \"shape_pt_sequence\": [1, 2, 3, 4, 1, 2, 3, 4, 5],\n        \"shape_model_node_id\": [1, 2, 3, 4, 2, 3, 1, 5, 4]\n    })\n\n    &gt; links_df = pd.DataFrame({\n        \"A\": [1, 2, 3],\n        \"B\": [2, 3, 4]\n    })\n\n    &gt; shapes\n\n    shape_id   shape_pt_sequence   shape_model_node_id *should retain*\n    1          1                  1                        TRUE\n    1          2                  2                        TRUE\n    1          3                  3                        TRUE\n    1          4                  4                        TRUE\n    1          5                  5                       FALSE\n    2          1                  1                        TRUE\n    2          2                  2                        TRUE\n    2          3                  3                        TRUE\n    2          4                  1                       FALSE\n    2          5                  5                       FALSE\n    2          6                  4                       FALSE\n    2          7                  1                       FALSE - not largest segment\n    2          8                  2                       FALSE - not largest segment\n\n    &gt; links_df\n\n    A   B\n    1   2\n    2   3\n    3   4\n    \"\"\"\n    \"\"\"\n    &gt; shape_links\n\n    shape_id  shape_pt_sequence_A  shape_model_node_id_A shape_pt_sequence_B shape_model_node_id_B\n    1          1                        1                       2                        2\n    1          2                        2                       3                        3\n    1          3                        3                       4                        4\n    1          4                        4                       5                        5\n    2          1                        1                       2                        2\n    2          2                        2                       3                        3\n    2          3                        3                       4                        1\n    2          4                        1                       5                        5\n    2          5                        5                       6                        4\n    2          6                        4                       7                        1\n    2          7                        1                       8                        2\n    \"\"\"\n    shape_links = shapes_to_shape_links(shapes)\n\n    \"\"\"\n    &gt; shape_links_w_links\n\n    shape_id  shape_pt_sequence_A shape_pt_sequence_B  A  B\n    1          1                         2             1  2\n    1          2                         3             2  3\n    1          3                         4             3  4\n    2          1                         2             1  2\n    2          2                         3             2  3\n    2          7                         8             1  2\n    \"\"\"\n\n    shape_links_w_links = shape_links.merge(\n        links_df[[\"A\", \"B\"]],\n        how=\"inner\",\n        on=[\"A\", \"B\"],\n    )\n\n    \"\"\"\n    Find largest segment of each shape_id that is in the links\n\n    &gt; longest_shape_segments\n    shape_id, segment_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq\n    1          1                        1                       4\n    2          1                        1                       3\n    \"\"\"\n    longest_shape_segments = shape_links_to_longest_shape_segments(shape_links_w_links)\n\n    \"\"\"\n    &gt; shapes\n\n    shape_id   shape_pt_sequence   shape_model_node_id\n    1          1                  1\n    1          2                  2\n    1          3                  3\n    1          4                  4\n    2          1                  1\n    2          2                  2\n    2          3                  3\n    \"\"\"\n    filtered_shapes = filter_shapes_to_segments(shapes, longest_shape_segments)\n    filtered_shapes = filtered_shapes.reset_index(drop=True)\n    return filtered_shapes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_for_shape_id","title":"network_wrangler.transit.feed.shapes.shapes_for_shape_id","text":"<pre><code>shapes_for_shape_id(shapes, shape_id)\n</code></pre> <p>Returns shape records for a given shape_id.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_shape_id(\n    shapes: DataFrame[WranglerShapesTable], shape_id: str\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shape records for a given shape_id.\"\"\"\n    shapes = shapes.loc[shapes.shape_id == shape_id]\n    return shapes.sort_values(by=[\"shape_pt_sequence\"])\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_for_trip_id","title":"network_wrangler.transit.feed.shapes.shapes_for_trip_id","text":"<pre><code>shapes_for_trip_id(shapes, trips, trip_id)\n</code></pre> <p>Returns shape records for a single given trip_id.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_trip_id(\n    shapes: DataFrame[WranglerShapesTable], trips: DataFrame[WranglerTripsTable], trip_id: str\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shape records for a single given trip_id.\"\"\"\n    shape_id = shape_id_for_trip_id(trips, trip_id)\n    return shapes.loc[shapes.shape_id == shape_id]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_for_trip_ids","title":"network_wrangler.transit.feed.shapes.shapes_for_trip_ids","text":"<pre><code>shapes_for_trip_ids(shapes, trips, trip_ids)\n</code></pre> <p>Returns shape records for list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_trip_ids(\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n    trip_ids: list[str],\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shape records for list of trip_ids.\"\"\"\n    shape_ids = shape_ids_for_trip_ids(trips, trip_ids)\n    return shapes.loc[shapes.shape_id.isin(shape_ids)]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_for_trips","title":"network_wrangler.transit.feed.shapes.shapes_for_trips","text":"<pre><code>shapes_for_trips(shapes, trips)\n</code></pre> <p>Filter shapes dataframe to records associated with trips table.</p> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_for_trips(\n    shapes: DataFrame[WranglerShapesTable], trips: DataFrame[WranglerTripsTable]\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Filter shapes dataframe to records associated with trips table.\"\"\"\n    _sel_shapes = trips.shape_id.unique().tolist()\n    filtered_shapes = shapes[shapes.shape_id.isin(_sel_shapes)]\n    WranglerLogger.debug(\n        f\"Filtered shapes to {len(filtered_shapes)}/{len(shapes)} \\\n                         records that referenced one of {len(trips)} trips.\"\n    )\n    return filtered_shapes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_with_stop_id_for_trip_id","title":"network_wrangler.transit.feed.shapes.shapes_with_stop_id_for_trip_id","text":"<pre><code>shapes_with_stop_id_for_trip_id(shapes, trips, stop_times, trip_id, pickup_dropoff='either')\n</code></pre> <p>Returns shapes.txt for a given trip_id with the stop_id added based on pickup_type.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>WranglerShapesTable</p> </li> <li> <code>trips</code>               (<code>DataFrame[WranglerTripsTable]</code>)           \u2013            <p>WranglerTripsTable</p> </li> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>WranglerStopTimesTable</p> </li> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>trip id to select</p> </li> <li> <code>pickup_dropoff</code>               (<code>PickupDropoffAvailability</code>, default:                   <code>'either'</code> )           \u2013            <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_with_stop_id_for_trip_id(\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shapes.txt for a given trip_id with the stop_id added based on pickup_type.\n\n    Args:\n        shapes: WranglerShapesTable\n        trips: WranglerTripsTable\n        stop_times: WranglerStopTimesTable\n        trip_id: trip id to select\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n    \"\"\"\n    from .stop_times import stop_times_for_pickup_dropoff_trip_id  # noqa: PLC0415\n\n    shapes = shapes_for_trip_id(shapes, trips, trip_id)\n    trip_stop_times = stop_times_for_pickup_dropoff_trip_id(\n        stop_times, trip_id, pickup_dropoff=pickup_dropoff\n    )\n\n    stop_times_cols = [\n        \"stop_id\",\n        \"trip_id\",\n        \"pickup_type\",\n        \"drop_off_type\",\n    ]\n\n    shape_with_trip_stops = shapes.merge(\n        trip_stop_times[stop_times_cols],\n        how=\"left\",\n        right_on=\"stop_id\",\n        left_on=\"shape_model_node_id\",\n    )\n    shape_with_trip_stops = shape_with_trip_stops.sort_values(by=[\"shape_pt_sequence\"])\n    return shape_with_trip_stops\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.shapes.shapes_with_stops_for_shape_id","title":"network_wrangler.transit.feed.shapes.shapes_with_stops_for_shape_id","text":"<pre><code>shapes_with_stops_for_shape_id(shapes, trips, stop_times, shape_id)\n</code></pre> <p>Returns a DataFrame containing shapes with associated stops for a given shape_id.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>DataFrame containing shape data.</p> </li> <li> <code>trips</code>               (<code>DataFrame[WranglerTripsTable]</code>)           \u2013            <p>DataFrame containing trip data.</p> </li> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>DataFrame containing stop times data.</p> </li> <li> <code>shape_id</code>               (<code>str</code>)           \u2013            <p>The shape_id for which to retrieve shapes with stops.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[WranglerShapesTable]</code>           \u2013            <p>DataFrame[WranglerShapesTable]: DataFrame containing shapes with associated stops.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/shapes.py</code> <pre><code>def shapes_with_stops_for_shape_id(\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shape_id: str,\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns a DataFrame containing shapes with associated stops for a given shape_id.\n\n    Parameters:\n        shapes (DataFrame[WranglerShapesTable]): DataFrame containing shape data.\n        trips (DataFrame[WranglerTripsTable]): DataFrame containing trip data.\n        stop_times (DataFrame[WranglerStopTimesTable]): DataFrame containing stop times data.\n        shape_id (str): The shape_id for which to retrieve shapes with stops.\n\n    Returns:\n        DataFrame[WranglerShapesTable]: DataFrame containing shapes with associated stops.\n    \"\"\"\n    from .trips import trip_ids_for_shape_id  # noqa: PLC0415\n\n    trip_ids = trip_ids_for_shape_id(trips, shape_id)\n    all_shape_stop_times = concat_with_attr(\n        [shapes_with_stop_id_for_trip_id(shapes, trips, stop_times, t) for t in trip_ids]\n    )\n    shapes_with_stops = all_shape_stop_times[all_shape_stop_times[\"stop_id\"].notna()]\n    shapes_with_stops = shapes_with_stops.sort_values(by=[\"shape_pt_sequence\"])\n    return shapes_with_stops\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_longest_segments","title":"network_wrangler.transit.feed.stop_times.stop_times_for_longest_segments","text":"<pre><code>stop_times_for_longest_segments(stop_times)\n</code></pre> <p>Find the longest segment of each trip_id that is in the stop_times.</p> <p>Segment ends defined based on interruptions in <code>stop_sequence</code>.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_longest_segments(\n    stop_times: DataFrame[WranglerStopTimesTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Find the longest segment of each trip_id that is in the stop_times.\n\n    Segment ends defined based on interruptions in `stop_sequence`.\n    \"\"\"\n    stop_times = stop_times.sort_values(by=[\"trip_id\", \"stop_sequence\"])\n\n    stop_times[\"prev_stop_sequence\"] = stop_times.groupby(\"trip_id\")[\"stop_sequence\"].shift(1)\n    stop_times[\"gap\"] = (stop_times[\"stop_sequence\"] - stop_times[\"prev_stop_sequence\"]).ne(\n        1\n    ) | stop_times[\"prev_stop_sequence\"].isna()\n\n    stop_times[\"segment_id\"] = stop_times[\"gap\"].cumsum()\n    # WranglerLogger.debug(f\"stop_times with segment_id:\\n{stop_times}\")\n\n    # Calculate the length of each segment\n    segment_lengths = (\n        stop_times.groupby([\"trip_id\", \"segment_id\"]).size().reset_index(name=\"segment_length\")\n    )\n\n    # Identify the longest segment for each trip\n    idx = segment_lengths.groupby(\"trip_id\")[\"segment_length\"].idxmax()\n    longest_segments = segment_lengths.loc[idx]\n\n    # Merge longest segment info back to stop_times\n    stop_times = stop_times.merge(\n        longest_segments[[\"trip_id\", \"segment_id\"]],\n        on=[\"trip_id\", \"segment_id\"],\n        how=\"inner\",\n    )\n\n    # Drop temporary columns used for calculations\n    stop_times.drop(columns=[\"prev_stop_sequence\", \"gap\", \"segment_id\"], inplace=True)\n    # WranglerLogger.debug(f\"stop_timesw/longest segments:\\n{stop_times}\")\n    return stop_times\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_min_stops","title":"network_wrangler.transit.feed.stop_times.stop_times_for_min_stops","text":"<pre><code>stop_times_for_min_stops(stop_times, min_stops)\n</code></pre> <p>Filter stop_times dataframe to only the records which have &gt;= min_stops for the trip.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>stoptimestable to filter</p> </li> <li> <code>min_stops</code>               (<code>int</code>)           \u2013            <p>minimum stops to require to keep trip in stoptimes</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_min_stops(\n    stop_times: DataFrame[WranglerStopTimesTable], min_stops: int\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filter stop_times dataframe to only the records which have &gt;= min_stops for the trip.\n\n    Args:\n        stop_times: stoptimestable to filter\n        min_stops: minimum stops to require to keep trip in stoptimes\n    \"\"\"\n    stop_ct_by_trip_df = stop_count_by_trip(stop_times)\n\n    # Filter to obtain DataFrame of trips with stop counts &gt;= min_stops\n    min_stop_ct_trip_df = stop_ct_by_trip_df[stop_ct_by_trip_df.stop_count &gt;= min_stops]\n    if len(min_stop_ct_trip_df) == 0:\n        msg = f\"No trips meet threshold of minimum stops: {min_stops}\"\n        raise ValueError(msg)\n    WranglerLogger.debug(\n        f\"Found {len(min_stop_ct_trip_df)} trips with a minimum of {min_stops} stops.\"\n    )\n\n    # Filter the original stop_times DataFrame to only include trips with &gt;= min_stops\n    filtered_stop_times = stop_times.merge(\n        min_stop_ct_trip_df[\"trip_id\"], on=\"trip_id\", how=\"inner\"\n    )\n    WranglerLogger.debug(\n        f\"Filter stop times to {len(filtered_stop_times)}/{len(stop_times)}\\\n            w/a minimum of {min_stops} stops.\"\n    )\n\n    return filtered_stop_times\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_pickup_dropoff_trip_id","title":"network_wrangler.transit.feed.stop_times.stop_times_for_pickup_dropoff_trip_id","text":"<pre><code>stop_times_for_pickup_dropoff_trip_id(stop_times, trip_id, pickup_dropoff='either')\n</code></pre> <p>Filters stop_times for a given trip_id based on pickup type.</p> <p>GTFS values for pickup_type and drop_off_type\u201d     0 or empty - Regularly scheduled pickup/dropoff.     1 - No pickup/dropoff available.     2 - Must phone agency to arrange pickup/dropoff.     3 - Must coordinate with driver to arrange pickup/dropoff.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>A WranglerStopTimesTable to query.</p> </li> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>trip_id to get stop pattern for</p> </li> <li> <code>pickup_dropoff</code>               (<code>PickupDropoffAvailability</code>, default:                   <code>'either'</code> )           \u2013            <p>str indicating logic for selecting stops based on pickup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201cany\u201d: all stoptime records \u201ceither\u201d: either pickup_type or dropoff_type != 1 \u201cboth\u201d: both pickup_type and dropoff_type != 1 \u201cpickup_only\u201d: dropoff = 1; pickup != 1 \u201cdropoff_only\u201d:  pickup = 1; dropoff != 1</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>@validate_call_pyd\ndef stop_times_for_pickup_dropoff_trip_id(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filters stop_times for a given trip_id based on pickup type.\n\n    GTFS values for pickup_type and drop_off_type\"\n        0 or empty - Regularly scheduled pickup/dropoff.\n        1 - No pickup/dropoff available.\n        2 - Must phone agency to arrange pickup/dropoff.\n        3 - Must coordinate with driver to arrange pickup/dropoff.\n\n    Args:\n        stop_times: A WranglerStopTimesTable to query.\n        trip_id: trip_id to get stop pattern for\n        pickup_dropoff: str indicating logic for selecting stops based on pickup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"any\": all stoptime records\n            \"either\": either pickup_type or dropoff_type != 1\n            \"both\": both pickup_type and dropoff_type != 1\n            \"pickup_only\": dropoff = 1; pickup != 1\n            \"dropoff_only\":  pickup = 1; dropoff != 1\n    \"\"\"\n    trip_stop_pattern = stop_times_for_trip_id(stop_times, trip_id)\n\n    if pickup_dropoff == \"any\":\n        return trip_stop_pattern\n\n    pickup_type_selection = {\n        \"either\": (trip_stop_pattern.pickup_type != 1) | (trip_stop_pattern.drop_off_type != 1),\n        \"both\": (trip_stop_pattern.pickup_type != 1) &amp; (trip_stop_pattern.drop_off_type != 1),\n        \"pickup_only\": (trip_stop_pattern.pickup_type != 1)\n        &amp; (trip_stop_pattern.drop_off_type == 1),\n        \"dropoff_only\": (trip_stop_pattern.drop_off_type != 1)\n        &amp; (trip_stop_pattern.pickup_type == 1),\n    }\n\n    selection = pickup_type_selection[pickup_dropoff]\n    trip_stops = trip_stop_pattern[selection]\n\n    return trip_stops\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_route_ids","title":"network_wrangler.transit.feed.stop_times.stop_times_for_route_ids","text":"<pre><code>stop_times_for_route_ids(stop_times, trips, route_ids)\n</code></pre> <p>Returns a stop_time records for a list of route_ids.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_route_ids(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trips: DataFrame[WranglerTripsTable],\n    route_ids: list[str],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns a stop_time records for a list of route_ids.\"\"\"\n    trip_ids = trips.loc[trips.route_id.isin(route_ids)].trip_id.unique()\n    return stop_times_for_trip_ids(stop_times, trip_ids)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_shapes","title":"network_wrangler.transit.feed.stop_times.stop_times_for_shapes","text":"<pre><code>stop_times_for_shapes(stop_times, shapes, trips)\n</code></pre> <p>Filter stop_times dataframe to records associated with shapes dataframe.</p> <p>Where multiple segments of stop_times are found to match shapes, retain only the longest.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>stop_times dataframe to filter</p> </li> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>shapes dataframe to stop_times to.</p> </li> <li> <code>trips</code>               (<code>DataFrame[WranglerTripsTable]</code>)           \u2013            <p>trips to link stop_times to shapess</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[WranglerStopTimesTable]</code>           \u2013            <p>filtered stop_times dataframe</p> </li> </ul> <ul> <li>should be retained <p>stop_times</p> </li> </ul> <p>trip_id   stop_sequence   stop_id t1          1                  1 t1          2                  2 t1          3                  3 t1           4                  5 t2          1                  1 *t2          2                  3 t2           3                  7</p> <p>shapes</p> <p>shape_id   shape_pt_sequence   shape_model_node_id s1          1                  1 s1          2                  2 s1          3                  3 s1          4                  4 s2          1                  1 s2          2                  2 s2          3                  3</p> <p>trips</p> <p>trip_id   shape_id t1          s1 t2          s2</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_shapes(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    shapes: DataFrame[WranglerShapesTable],\n    trips: DataFrame[WranglerTripsTable],\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filter stop_times dataframe to records associated with shapes dataframe.\n\n    Where multiple segments of stop_times are found to match shapes, retain only the longest.\n\n    Args:\n        stop_times: stop_times dataframe to filter\n        shapes: shapes dataframe to stop_times to.\n        trips: trips to link stop_times to shapess\n\n    Returns:\n        filtered stop_times dataframe\n\n    EX:\n    * should be retained\n    &gt; stop_times\n\n    trip_id   stop_sequence   stop_id\n    *t1          1                  1\n    *t1          2                  2\n    *t1          3                  3\n    t1           4                  5\n    *t2          1                  1\n    *t2          2                  3\n    t2           3                  7\n\n    &gt; shapes\n\n    shape_id   shape_pt_sequence   shape_model_node_id\n    s1          1                  1\n    s1          2                  2\n    s1          3                  3\n    s1          4                  4\n    s2          1                  1\n    s2          2                  2\n    s2          3                  3\n\n    &gt; trips\n\n    trip_id   shape_id\n    t1          s1\n    t2          s2\n    \"\"\"\n    \"\"\"\n    &gt; stop_times_w_shapes\n\n    trip_id   stop_sequence   stop_id    shape_id   shape_pt_sequence\n    *t1          1                  1        s1          1\n    *t1          2                  2        s1          2\n    *t1          3                  3        s1          3\n    t1           4                  5        NA          NA\n    *t2          1                  1        s2          1\n    *t2          2                  3        s2          2\n    t2           3                  7        NA          NA\n\n    \"\"\"\n    stop_times_w_shapes = merge_shapes_to_stop_times(stop_times, shapes, trips)\n    # WranglerLogger.debug(f\"stop_times_w_shapes :\\n{stop_times_w_shapes}\")\n    \"\"\"\n    &gt; stop_times_w_shapes\n\n    trip_id   stop_sequence   stop_id   shape_id   shape_pt_sequence\n    *t1          1               1        s1          1\n    *t1          2               2        s1          2\n    *t1          3               3        s1          3\n    *t2          1               1        s2          1\n    *t2          2               3        s2          2\n\n    \"\"\"\n    filtered_stop_times = stop_times_w_shapes[stop_times_w_shapes[\"shape_pt_sequence\"].notna()]\n    # WranglerLogger.debug(f\"filtered_stop_times:\\n{filtered_stop_times}\")\n\n    # Filter out any stop_times the shape_pt_sequence is not ascending\n    valid_stop_times = filtered_stop_times.groupby(\"trip_id\").filter(\n        lambda x: x[\"shape_pt_sequence\"].is_monotonic_increasing\n    )\n    # WranglerLogger.debug(f\"valid_stop_times:\\n{valid_stop_times}\")\n\n    valid_stop_times = valid_stop_times.drop(columns=[\"shape_id\", \"shape_pt_sequence\"])\n\n    longest_valid_stop_times = stop_times_for_longest_segments(valid_stop_times)\n    longest_valid_stop_times = longest_valid_stop_times.reset_index(drop=True)\n\n    return longest_valid_stop_times\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_stops","title":"network_wrangler.transit.feed.stop_times.stop_times_for_stops","text":"<pre><code>stop_times_for_stops(stop_times, stops)\n</code></pre> <p>Filter stop_times dataframe to only have stop_times associated with stops records.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_stops(\n    stop_times: DataFrame[WranglerStopTimesTable], stops: DataFrame[WranglerStopsTable]\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Filter stop_times dataframe to only have stop_times associated with stops records.\"\"\"\n    _sel_stops = stops.stop_id.unique().tolist()\n    filtered_stop_times = stop_times[stop_times.stop_id.isin(_sel_stops)]\n    WranglerLogger.debug(\n        f\"Filtered stop_times to {len(filtered_stop_times)}/{len(stop_times)} \\\n                         records that referenced one of {len(stops)} stops.\"\n    )\n    return filtered_stop_times\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_trip_id","title":"network_wrangler.transit.feed.stop_times.stop_times_for_trip_id","text":"<pre><code>stop_times_for_trip_id(stop_times, trip_id)\n</code></pre> <p>Returns a stop_time records for a given trip_id.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_trip_id(\n    stop_times: DataFrame[WranglerStopTimesTable], trip_id: str\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns a stop_time records for a given trip_id.\"\"\"\n    stop_times = stop_times.loc[stop_times.trip_id == trip_id]\n    return stop_times.sort_values(by=[\"stop_sequence\"])\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_trip_ids","title":"network_wrangler.transit.feed.stop_times.stop_times_for_trip_ids","text":"<pre><code>stop_times_for_trip_ids(stop_times, trip_ids)\n</code></pre> <p>Returns a stop_time records for a given list of trip_ids.</p> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_trip_ids(\n    stop_times: DataFrame[WranglerStopTimesTable], trip_ids: list[str]\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns a stop_time records for a given list of trip_ids.\"\"\"\n    stop_times = stop_times.loc[stop_times.trip_id.isin(trip_ids)]\n    return stop_times.sort_values(by=[\"stop_sequence\"])\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stop_times.stop_times_for_trip_node_segment","title":"network_wrangler.transit.feed.stop_times.stop_times_for_trip_node_segment","text":"<pre><code>stop_times_for_trip_node_segment(stop_times, trip_id, node_id_start, node_id_end, include_start=True, include_end=True)\n</code></pre> <p>Returns stop_times for a given trip_id between two nodes or with those nodes included.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>WranglerStopTimesTable</p> </li> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>trip id to select</p> </li> <li> <code>node_id_start</code>               (<code>int</code>)           \u2013            <p>int of the starting node</p> </li> <li> <code>node_id_end</code>               (<code>int</code>)           \u2013            <p>int of the ending node</p> </li> <li> <code>include_start</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>bool indicating if the start node should be included in the segment. Defaults to True.</p> </li> <li> <code>include_end</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>bool indicating if the end node should be included in the segment. Defaults to True.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/stop_times.py</code> <pre><code>def stop_times_for_trip_node_segment(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    node_id_start: int,\n    node_id_end: int,\n    include_start: bool = True,\n    include_end: bool = True,\n) -&gt; DataFrame[WranglerStopTimesTable]:\n    \"\"\"Returns stop_times for a given trip_id between two nodes or with those nodes included.\n\n    Args:\n        stop_times: WranglerStopTimesTable\n        trip_id: trip id to select\n        node_id_start: int of the starting node\n        node_id_end: int of the ending node\n        include_start: bool indicating if the start node should be included in the segment.\n            Defaults to True.\n        include_end: bool indicating if the end node should be included in the segment.\n            Defaults to True.\n    \"\"\"\n    stop_times = stop_times_for_trip_id(stop_times, trip_id)\n    start_idx = stop_times[stop_times[\"stop_id\"] == node_id_start].index[0]\n    end_idx = stop_times[stop_times[\"stop_id\"] == node_id_end].index[0]\n    if not include_start:\n        start_idx += 1\n    if include_end:\n        end_idx += 1\n    return stop_times.loc[start_idx:end_idx]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stops.node_is_stop","title":"network_wrangler.transit.feed.stops.node_is_stop","text":"<pre><code>node_is_stop(stops, stop_times, node_id, trip_id, pickup_dropoff='either')\n</code></pre> <p>Returns boolean indicating if a (or list of) node(s)) is (are) stops for a given trip_id.</p> <p>Parameters:</p> <ul> <li> <code>stops</code>               (<code>DataFrame[WranglerStopsTable]</code>)           \u2013            <p>WranglerStopsTable</p> </li> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>WranglerStopTimesTable</p> </li> <li> <code>node_id</code>               (<code>Union[int, list[int]]</code>)           \u2013            <p>node ID for roadway</p> </li> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>trip_id to get stop pattern for</p> </li> <li> <code>pickup_dropoff</code>               (<code>PickupDropoffAvailability</code>, default:                   <code>'either'</code> )           \u2013            <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>def node_is_stop(\n    stops: DataFrame[WranglerStopsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    node_id: Union[int, list[int]],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; Union[bool, list[bool]]:\n    \"\"\"Returns boolean indicating if a (or list of) node(s)) is (are) stops for a given trip_id.\n\n    Args:\n        stops: WranglerStopsTable\n        stop_times: WranglerStopTimesTable\n        node_id: node ID for roadway\n        trip_id: trip_id to get stop pattern for\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n    \"\"\"\n    trip_stop_nodes = stops_for_trip_id(stops, stop_times, trip_id, pickup_dropoff=pickup_dropoff)[\n        \"stop_id\"\n    ]\n    if isinstance(node_id, list):\n        return [n in trip_stop_nodes.values for n in node_id]\n    return node_id in trip_stop_nodes.values\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stops.stop_id_pattern_for_trip","title":"network_wrangler.transit.feed.stops.stop_id_pattern_for_trip","text":"<pre><code>stop_id_pattern_for_trip(stop_times, trip_id, pickup_dropoff='either')\n</code></pre> <p>Returns a stop pattern for a given trip_id given by a list of stop_ids.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>WranglerStopTimesTable</p> </li> <li> <code>trip_id</code>               (<code>str</code>)           \u2013            <p>trip_id to get stop pattern for</p> </li> <li> <code>pickup_dropoff</code>               (<code>PickupDropoffAvailability</code>, default:                   <code>'either'</code> )           \u2013            <p>str indicating logic for selecting stops based on piackup and dropoff availability at stop. Defaults to \u201ceither\u201d. \u201ceither\u201d: either pickup_type or dropoff_type &gt; 0 \u201cboth\u201d: both pickup_type or dropoff_type &gt; 0 \u201cpickup_only\u201d: only pickup &gt; 0 \u201cdropoff_only\u201d: only dropoff &gt; 0</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>@validate_call_pyd\ndef stop_id_pattern_for_trip(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"either\",\n) -&gt; list[str]:\n    \"\"\"Returns a stop pattern for a given trip_id given by a list of stop_ids.\n\n    Args:\n        stop_times: WranglerStopTimesTable\n        trip_id: trip_id to get stop pattern for\n        pickup_dropoff: str indicating logic for selecting stops based on piackup and dropoff\n            availability at stop. Defaults to \"either\".\n            \"either\": either pickup_type or dropoff_type &gt; 0\n            \"both\": both pickup_type or dropoff_type &gt; 0\n            \"pickup_only\": only pickup &gt; 0\n            \"dropoff_only\": only dropoff &gt; 0\n    \"\"\"\n    from .stop_times import stop_times_for_pickup_dropoff_trip_id  # noqa: PLC0415\n\n    trip_stops = stop_times_for_pickup_dropoff_trip_id(\n        stop_times, trip_id, pickup_dropoff=pickup_dropoff\n    )\n    return trip_stops.stop_id.to_list()\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stops.stops_for_stop_times","title":"network_wrangler.transit.feed.stops.stops_for_stop_times","text":"<pre><code>stops_for_stop_times(stops, stop_times)\n</code></pre> <p>Filter stops dataframe to only have stops associated with stop_times records.</p> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>def stops_for_stop_times(\n    stops: DataFrame[WranglerStopsTable], stop_times: DataFrame[WranglerStopTimesTable]\n) -&gt; DataFrame[WranglerStopsTable]:\n    \"\"\"Filter stops dataframe to only have stops associated with stop_times records.\"\"\"\n    _sel_stops_ge_min = stop_times.stop_id.unique().tolist()\n    filtered_stops = stops[stops.stop_id.isin(_sel_stops_ge_min)]\n    WranglerLogger.debug(\n        f\"Filtered stops to {len(filtered_stops)}/{len(stops)} \\\n                         records that referenced one of {len(stop_times)} stop_times.\"\n    )\n    return filtered_stops\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.stops.stops_for_trip_id","title":"network_wrangler.transit.feed.stops.stops_for_trip_id","text":"<pre><code>stops_for_trip_id(stops, stop_times, trip_id, pickup_dropoff='any')\n</code></pre> <p>Returns stops.txt which are used for a given trip_id.</p> Source code in <code>network_wrangler/transit/feed/stops.py</code> <pre><code>def stops_for_trip_id(\n    stops: DataFrame[WranglerStopsTable],\n    stop_times: DataFrame[WranglerStopTimesTable],\n    trip_id: str,\n    pickup_dropoff: PickupDropoffAvailability = \"any\",\n) -&gt; DataFrame[WranglerStopsTable]:\n    \"\"\"Returns stops.txt which are used for a given trip_id.\"\"\"\n    stop_ids = stop_id_pattern_for_trip(stop_times, trip_id, pickup_dropoff=pickup_dropoff)\n    return stops.loc[stops.stop_id.isin(stop_ids)]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.trips.trip_ids_for_shape_id","title":"network_wrangler.transit.feed.trips.trip_ids_for_shape_id","text":"<pre><code>trip_ids_for_shape_id(trips, shape_id)\n</code></pre> <p>Returns a list of trip_ids for a given shape_id.</p> Source code in <code>network_wrangler/transit/feed/trips.py</code> <pre><code>def trip_ids_for_shape_id(trips: DataFrame[WranglerTripsTable], shape_id: str) -&gt; list[str]:\n    \"\"\"Returns a list of trip_ids for a given shape_id.\"\"\"\n    return trips_for_shape_id(trips, shape_id)[\"trip_id\"].unique().tolist()\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.trips.trips_for_shape_id","title":"network_wrangler.transit.feed.trips.trips_for_shape_id","text":"<pre><code>trips_for_shape_id(trips, shape_id)\n</code></pre> <p>Returns a trips records for a given shape_id.</p> Source code in <code>network_wrangler/transit/feed/trips.py</code> <pre><code>def trips_for_shape_id(\n    trips: DataFrame[WranglerTripsTable], shape_id: str\n) -&gt; DataFrame[WranglerTripsTable]:\n    \"\"\"Returns a trips records for a given shape_id.\"\"\"\n    return trips.loc[trips.shape_id == shape_id]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.trips.trips_for_stop_times","title":"network_wrangler.transit.feed.trips.trips_for_stop_times","text":"<pre><code>trips_for_stop_times(trips, stop_times)\n</code></pre> <p>Filter trips dataframe to records associated with stop_time records.</p> Source code in <code>network_wrangler/transit/feed/trips.py</code> <pre><code>def trips_for_stop_times(\n    trips: DataFrame[WranglerTripsTable], stop_times: DataFrame[WranglerStopTimesTable]\n) -&gt; DataFrame[WranglerTripsTable]:\n    \"\"\"Filter trips dataframe to records associated with stop_time records.\"\"\"\n    _sel_trips = stop_times.trip_id.unique().tolist()\n    filtered_trips = trips[trips.trip_id.isin(_sel_trips)]\n    WranglerLogger.debug(\n        f\"Filtered trips to {len(filtered_trips)}/{len(trips)} \\\n                         records that referenced one of {len(stop_times)} stop_times.\"\n    )\n    return filtered_trips\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_links.shapes_to_shape_links","title":"network_wrangler.transit.feed.transit_links.shapes_to_shape_links","text":"<pre><code>shapes_to_shape_links(shapes)\n</code></pre> <p>Converts shapes DataFrame to shape links DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>The input shapes DataFrame.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The resulting shape links DataFrame.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def shapes_to_shape_links(shapes: DataFrame[WranglerShapesTable]) -&gt; pd.DataFrame:\n    \"\"\"Converts shapes DataFrame to shape links DataFrame.\n\n    Args:\n        shapes (DataFrame[WranglerShapesTable]): The input shapes DataFrame.\n\n    Returns:\n        pd.DataFrame: The resulting shape links DataFrame.\n    \"\"\"\n    return point_seq_to_links(\n        shapes,\n        id_field=\"shape_id\",\n        seq_field=\"shape_pt_sequence\",\n        node_id_field=\"shape_model_node_id\",\n    )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_links.stop_times_to_stop_times_links","title":"network_wrangler.transit.feed.transit_links.stop_times_to_stop_times_links","text":"<pre><code>stop_times_to_stop_times_links(stop_times, from_field='A', to_field='B')\n</code></pre> <p>Converts stop times to stop times links.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>The stop times data.</p> </li> <li> <code>from_field</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>The name of the field representing the \u2018from\u2019 stop. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_field</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>The name of the field representing the \u2018to\u2019 stop. Defaults to \u201cB\u201d.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The resulting stop times links.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def stop_times_to_stop_times_links(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; pd.DataFrame:\n    \"\"\"Converts stop times to stop times links.\n\n    Args:\n        stop_times (DataFrame[WranglerStopTimesTable]): The stop times data.\n        from_field (str, optional): The name of the field representing the 'from' stop.\n            Defaults to \"A\".\n        to_field (str, optional): The name of the field representing the 'to' stop.\n            Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: The resulting stop times links.\n    \"\"\"\n    return point_seq_to_links(\n        stop_times,\n        id_field=\"trip_id\",\n        seq_field=\"stop_sequence\",\n        node_id_field=\"stop_id\",\n        from_field=from_field,\n        to_field=to_field,\n    )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_links.unique_shape_links","title":"network_wrangler.transit.feed.transit_links.unique_shape_links","text":"<pre><code>unique_shape_links(shapes, from_field='A', to_field='B')\n</code></pre> <p>Returns a DataFrame containing unique shape links based on the provided shapes DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>The input DataFrame containing shape information.</p> </li> <li> <code>from_field</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>The name of the column representing the \u2018from\u2019 field. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_field</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>The name of the column representing the \u2018to\u2019 field. Defaults to \u201cB\u201d.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: DataFrame containing unique shape links based on the provided shapes df.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def unique_shape_links(\n    shapes: DataFrame[WranglerShapesTable], from_field: str = \"A\", to_field: str = \"B\"\n) -&gt; pd.DataFrame:\n    \"\"\"Returns a DataFrame containing unique shape links based on the provided shapes DataFrame.\n\n    Parameters:\n        shapes (DataFrame[WranglerShapesTable]): The input DataFrame containing shape information.\n        from_field (str, optional): The name of the column representing the 'from' field.\n            Defaults to \"A\".\n        to_field (str, optional): The name of the column representing the 'to' field.\n            Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: DataFrame containing unique shape links based on the provided shapes df.\n    \"\"\"\n    shape_links = shapes_to_shape_links(shapes)\n    # WranglerLogger.debug(f\"Shape links: \\n {shape_links[['shape_id', from_field, to_field]]}\")\n\n    _agg_dict: dict[str, Union[type, str]] = {\"shape_id\": list}\n    _opt_fields = [f\"shape_pt_{v}_{t}\" for v in [\"lat\", \"lon\"] for t in [from_field, to_field]]\n    for f in _opt_fields:\n        if f in shape_links:\n            _agg_dict[f] = \"first\"\n\n    unique_shape_links = shape_links.groupby([from_field, to_field]).agg(_agg_dict).reset_index()\n    return unique_shape_links\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_links.unique_stop_time_links","title":"network_wrangler.transit.feed.transit_links.unique_stop_time_links","text":"<pre><code>unique_stop_time_links(stop_times, from_field='A', to_field='B')\n</code></pre> <p>Returns a DataFrame containing unique stop time links based on the given stop times DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>The DataFrame containing stop times data.</p> </li> <li> <code>from_field</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>The name of the column representing the \u2018from\u2019 field in the stop times DataFrame. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_field</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>The name of the column representing the \u2018to\u2019 field in the stop times DataFrame. Defaults to \u201cB\u201d.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing unique stop time links with columns \u2018from_field\u2019, \u2018to_field\u2019, and \u2018trip_id\u2019.</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_links.py</code> <pre><code>def unique_stop_time_links(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; pd.DataFrame:\n    \"\"\"Returns a DataFrame containing unique stop time links based on the given stop times DataFrame.\n\n    Parameters:\n        stop_times (DataFrame[WranglerStopTimesTable]): The DataFrame containing stop times data.\n        from_field (str, optional): The name of the column representing the 'from' field in the\n            stop times DataFrame. Defaults to \"A\".\n        to_field (str, optional): The name of the column representing the 'to' field in the stop\n            times DataFrame. Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: A DataFrame containing unique stop time links with columns 'from_field',\n            'to_field', and 'trip_id'.\n    \"\"\"\n    links = stop_times_to_stop_times_links(stop_times, from_field=from_field, to_field=to_field)\n    unique_links = links.groupby([from_field, to_field])[\"trip_id\"].apply(list).reset_index()\n    return unique_links\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_segments.filter_shapes_to_segments","title":"network_wrangler.transit.feed.transit_segments.filter_shapes_to_segments","text":"<pre><code>filter_shapes_to_segments(shapes, segments)\n</code></pre> <p>Filter shapes dataframe to records associated with segments dataframe.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>shapes dataframe to filter</p> </li> <li> <code>segments</code>               (<code>DataFrame</code>)           \u2013            <p>segments dataframe to filter by with shape_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq . Should have one record per shape_id.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame[WranglerShapesTable]</code>           \u2013            <p>filtered shapes dataframe</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_segments.py</code> <pre><code>def filter_shapes_to_segments(\n    shapes: DataFrame[WranglerShapesTable], segments: pd.DataFrame\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Filter shapes dataframe to records associated with segments dataframe.\n\n    Args:\n        shapes: shapes dataframe to filter\n        segments: segments dataframe to filter by with shape_id, segment_start_shape_pt_seq,\n            segment_end_shape_pt_seq . Should have one record per shape_id.\n\n    Returns:\n        filtered shapes dataframe\n    \"\"\"\n    shapes_w_segs = shapes.merge(segments, on=\"shape_id\", how=\"left\")\n\n    # Retain only those points within the segment sequences\n    filtered_shapes = shapes_w_segs[\n        (shapes_w_segs[\"shape_pt_sequence\"] &gt;= shapes_w_segs[\"segment_start_shape_pt_seq\"])\n        &amp; (shapes_w_segs[\"shape_pt_sequence\"] &lt;= shapes_w_segs[\"segment_end_shape_pt_seq\"])\n    ]\n\n    drop_cols = [\n        \"segment_id\",\n        \"segment_start_shape_pt_seq\",\n        \"segment_end_shape_pt_seq\",\n        \"segment_length\",\n    ]\n    filtered_shapes = filtered_shapes.drop(columns=drop_cols)\n\n    return filtered_shapes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_segments.shape_links_to_longest_shape_segments","title":"network_wrangler.transit.feed.transit_segments.shape_links_to_longest_shape_segments","text":"<pre><code>shape_links_to_longest_shape_segments(shape_links)\n</code></pre> <p>Find the longest segment of each shape_id that is in the links.</p> <p>Parameters:</p> <ul> <li> <code>shape_links</code>           \u2013            <p>DataFrame with shape_id, shape_pt_sequence_A, shape_pt_sequence_B</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>DataFrame with shape_id, segment_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_segments.py</code> <pre><code>def shape_links_to_longest_shape_segments(shape_links) -&gt; pd.DataFrame:\n    \"\"\"Find the longest segment of each shape_id that is in the links.\n\n    Args:\n        shape_links: DataFrame with shape_id, shape_pt_sequence_A, shape_pt_sequence_B\n\n    Returns:\n        DataFrame with shape_id, segment_id, segment_start_shape_pt_seq, segment_end_shape_pt_seq\n    \"\"\"\n    segments = shape_links_to_segments(shape_links)\n    idx = segments.groupby(\"shape_id\")[\"segment_length\"].idxmax()\n    longest_segments = segments.loc[idx]\n    return longest_segments\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.feed.transit_segments.shape_links_to_segments","title":"network_wrangler.transit.feed.transit_segments.shape_links_to_segments","text":"<pre><code>shape_links_to_segments(shape_links)\n</code></pre> <p>Convert shape_links to segments by shape_id with segments of continuous shape_pt_sequence.</p> <p>DataFrame with shape_id, segment_id, segment_start_shape_pt_seq,</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>segment_end_shape_pt_seq</p> </li> </ul> Source code in <code>network_wrangler/transit/feed/transit_segments.py</code> <pre><code>def shape_links_to_segments(shape_links) -&gt; pd.DataFrame:\n    \"\"\"Convert shape_links to segments by shape_id with segments of continuous shape_pt_sequence.\n\n    Returns: DataFrame with shape_id, segment_id, segment_start_shape_pt_seq,\n        segment_end_shape_pt_seq\n    \"\"\"\n    shape_links[\"gap\"] = shape_links.groupby(\"shape_id\")[\"shape_pt_sequence_A\"].diff().gt(1)\n    shape_links[\"segment_id\"] = shape_links.groupby(\"shape_id\")[\"gap\"].cumsum()\n\n    # Define segment starts and ends\n    segment_definitions = (\n        shape_links.groupby([\"shape_id\", \"segment_id\"])\n        .agg(\n            segment_start_shape_pt_seq=(\"shape_pt_sequence_A\", \"min\"),\n            segment_end_shape_pt_seq=(\"shape_pt_sequence_B\", \"max\"),\n        )\n        .reset_index()\n    )\n\n    # Optionally calculate segment lengths for further uses\n    segment_definitions[\"segment_length\"] = (\n        segment_definitions[\"segment_end_shape_pt_seq\"]\n        - segment_definitions[\"segment_start_shape_pt_seq\"]\n        + 1\n    )\n\n    return segment_definitions\n</code></pre>"},{"location":"api_transit/#transit-projects","title":"Transit Projects","text":"<p>Functions for adding a transit route to a TransitNetwork.</p> <p>Module for applying calculated transit projects to a transit network object.</p> <p>These projects are stored in project card <code>pycode</code> property as python code strings which are executed to change the transit network object.</p> <p>Functions for adding a transit route to a TransitNetwork.</p> <p>Functions for editing transit properties in a TransitNetwork.</p> <p>Functions for editing the transit route shapes and stop patterns.</p>"},{"location":"api_transit/#network_wrangler.transit.projects.add_route.apply_transit_route_addition","title":"network_wrangler.transit.projects.add_route.apply_transit_route_addition","text":"<pre><code>apply_transit_route_addition(net, transit_route_addition, reference_road_net=None)\n</code></pre> <p>Add transit route to TransitNetwork.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>TransitNetwork</code>)           \u2013            <p>Network to modify.</p> </li> <li> <code>transit_route_addition</code>               (<code>dict</code>)           \u2013            <p>route dictionary to add to the feed.</p> </li> <li> <code>reference_road_net</code>               (<code>Optional[RoadwayNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>(RoadwayNetwork, optional): Reference roadway network to use for adding shapes and stops. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TransitNetwork</code> (              <code>TransitNetwork</code> )          \u2013            <p>Modified network.</p> </li> </ul> Source code in <code>network_wrangler/transit/projects/add_route.py</code> <pre><code>def apply_transit_route_addition(\n    net: TransitNetwork,\n    transit_route_addition: dict,\n    reference_road_net: Optional[RoadwayNetwork] = None,\n) -&gt; TransitNetwork:\n    \"\"\"Add transit route to TransitNetwork.\n\n    Args:\n        net (TransitNetwork): Network to modify.\n        transit_route_addition: route dictionary to add to the feed.\n        reference_road_net: (RoadwayNetwork, optional): Reference roadway network to use for adding shapes and stops. Defaults to None.\n\n    Returns:\n        TransitNetwork: Modified network.\n    \"\"\"\n    WranglerLogger.debug(\"Applying add transit route project.\")\n\n    add_routes = transit_route_addition[\"routes\"]\n\n    road_net = net.road_net if reference_road_net is None else reference_road_net\n    if road_net is None:\n        WranglerLogger.error(\n            \"! Must have a reference road network set in order to update transit \\\n                         routin.  Either provide as an input to this function or set it for the \\\n                         transit network: &gt;&gt; transit_net.road_net = ...\"\n        )\n        msg = \"Must have a reference road network set in order to update transit routing.\"\n        raise TransitRouteAddError(msg)\n\n    net.feed = _add_route_to_feed(net.feed, add_routes, road_net)\n\n    return net\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.projects.calculate.apply_calculated_transit","title":"network_wrangler.transit.projects.calculate.apply_calculated_transit","text":"<pre><code>apply_calculated_transit(net, pycode)\n</code></pre> <p>Changes transit network object by executing pycode.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>TransitNetwork</code>)           \u2013            <p>transit network to manipulate</p> </li> <li> <code>pycode</code>               (<code>str</code>)           \u2013            <p>python code which changes values in the transit network object</p> </li> </ul> Source code in <code>network_wrangler/transit/projects/calculate.py</code> <pre><code>def apply_calculated_transit(\n    net: TransitNetwork,\n    pycode: str,\n) -&gt; TransitNetwork:\n    \"\"\"Changes transit network object by executing pycode.\n\n    Args:\n        net: transit network to manipulate\n        pycode: python code which changes values in the transit network object\n    \"\"\"\n    WranglerLogger.debug(\"Applying calculated transit project.\")\n    exec(pycode)\n\n    return net\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.projects.delete_service.apply_transit_service_deletion","title":"network_wrangler.transit.projects.delete_service.apply_transit_service_deletion","text":"<pre><code>apply_transit_service_deletion(net, selection, clean_shapes=False, clean_routes=False)\n</code></pre> <p>Delete transit service to TransitNetwork.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>TransitNetwork</code>)           \u2013            <p>Network to modify.</p> </li> <li> <code>selection</code>               (<code>TransitSelection</code>)           \u2013            <p>TransitSelection object, created from a selection dictionary.</p> </li> <li> <code>clean_shapes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, remove shapes not used by any trips. Defaults to False.</p> </li> <li> <code>clean_routes</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, remove routes not used by any trips. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TransitNetwork</code> (              <code>TransitNetwork</code> )          \u2013            <p>Modified network.</p> </li> </ul> Source code in <code>network_wrangler/transit/projects/delete_service.py</code> <pre><code>def apply_transit_service_deletion(\n    net: TransitNetwork,\n    selection: TransitSelection,\n    clean_shapes: Optional[bool] = False,\n    clean_routes: Optional[bool] = False,\n) -&gt; TransitNetwork:\n    \"\"\"Delete transit service to TransitNetwork.\n\n    Args:\n        net (TransitNetwork): Network to modify.\n        selection: TransitSelection object, created from a selection dictionary.\n        clean_shapes (bool, optional): If True, remove shapes not used by any trips.\n            Defaults to False.\n        clean_routes (bool, optional): If True, remove routes not used by any trips.\n            Defaults to False.\n\n    Returns:\n        TransitNetwork: Modified network.\n    \"\"\"\n    WranglerLogger.debug(\"Applying delete transit service project.\")\n\n    trip_ids = selection.selected_trips\n    net.feed = _delete_trips_from_feed(\n        net.feed, trip_ids, clean_shapes=clean_shapes, clean_routes=clean_routes\n    )\n\n    return net\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.projects.edit_property.apply_transit_property_change","title":"network_wrangler.transit.projects.edit_property.apply_transit_property_change","text":"<pre><code>apply_transit_property_change(net, selection, property_changes, project_name=None)\n</code></pre> <p>Apply changes to transit properties.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>TransitNetwork</code>)           \u2013            <p>Network to modify.</p> </li> <li> <code>selection</code>               (<code>TransitSelection</code>)           \u2013            <p>Selection of trips to modify.</p> </li> <li> <code>property_changes</code>               (<code>dict</code>)           \u2013            <p>Dictionary of properties to change.</p> </li> <li> <code>project_name</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Name of the project. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TransitNetwork</code> (              <code>TransitNetwork</code> )          \u2013            <p>Modified network.</p> </li> </ul> Source code in <code>network_wrangler/transit/projects/edit_property.py</code> <pre><code>def apply_transit_property_change(\n    net: TransitNetwork,\n    selection: TransitSelection,\n    property_changes: dict,\n    project_name: Optional[str] = None,\n) -&gt; TransitNetwork:\n    \"\"\"Apply changes to transit properties.\n\n    Args:\n        net (TransitNetwork): Network to modify.\n        selection (TransitSelection): Selection of trips to modify.\n        property_changes (dict): Dictionary of properties to change.\n        project_name (str, optional): Name of the project. Defaults to None.\n\n    Returns:\n        TransitNetwork: Modified network.\n    \"\"\"\n    WranglerLogger.debug(\"Applying transit property change project.\")\n    for property, property_change in property_changes.items():\n        net = _apply_transit_property_change_to_table(\n            net,\n            selection,\n            property,\n            property_change,\n            project_name=project_name,\n        )\n    return net\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.projects.edit_routing.apply_transit_routing_change","title":"network_wrangler.transit.projects.edit_routing.apply_transit_routing_change","text":"<pre><code>apply_transit_routing_change(net, selection, routing_change, reference_road_net=None, project_name=None)\n</code></pre> <p>Apply a routing change to the transit network, including stop updates.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>TransitNetwork</code>)           \u2013            <p>TransitNetwork object to apply routing change to.</p> </li> <li> <code>selection</code>               (<code>Selection</code>)           \u2013            <p>TransitSelection object, created from a selection dictionary.</p> </li> <li> <code>routing_change</code>               (<code>dict</code>)           \u2013            <p>Routing Change dictionary, e.g. <pre><code>{\n    \"existing\": [46665, 150855],\n    \"set\": [-46665, 150855, 46665, 150855],\n}\n</code></pre></p> </li> <li> <code>shape_id_scalar</code>               (<code>int</code>)           \u2013            <p>Initial scalar value to add to duplicated shape_ids to create a new shape_id. Defaults to SHAPE_ID_SCALAR.</p> </li> <li> <code>reference_road_net</code>               (<code>RoadwayNetwork</code>, default:                   <code>None</code> )           \u2013            <p>Reference roadway network to use for updating shapes and stops. Defaults to None.</p> </li> <li> <code>project_name</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Name of the project. Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/transit/projects/edit_routing.py</code> <pre><code>def apply_transit_routing_change(\n    net: TransitNetwork,\n    selection: TransitSelection,\n    routing_change: dict,\n    reference_road_net: Optional[RoadwayNetwork] = None,\n    project_name: Optional[str] = None,\n) -&gt; TransitNetwork:\n    \"\"\"Apply a routing change to the transit network, including stop updates.\n\n    Args:\n        net (TransitNetwork): TransitNetwork object to apply routing change to.\n        selection (Selection): TransitSelection object, created from a selection dictionary.\n        routing_change (dict): Routing Change dictionary, e.g.\n            ```python\n            {\n                \"existing\": [46665, 150855],\n                \"set\": [-46665, 150855, 46665, 150855],\n            }\n            ```\n        shape_id_scalar (int, optional): Initial scalar value to add to duplicated shape_ids to\n            create a new shape_id. Defaults to SHAPE_ID_SCALAR.\n        reference_road_net (RoadwayNetwork, optional): Reference roadway network to use for\n            updating shapes and stops. Defaults to None.\n        project_name (str, optional): Name of the project. Defaults to None.\n    \"\"\"\n    WranglerLogger.debug(\"Applying transit routing change project.\")\n    WranglerLogger.debug(f\"...selection: {selection.selection_dict}\")\n    WranglerLogger.debug(f\"...routing: {routing_change}\")\n\n    # ---- Secure all inputs needed --------------\n    updated_feed = copy.deepcopy(net.feed)\n    trip_ids = selection.selected_trips\n    if project_name:\n        updated_feed.trips.loc[updated_feed.trips.trip_id.isin(trip_ids), \"projects\"] += (\n            f\"{project_name},\"\n        )\n\n    road_net = net.road_net if reference_road_net is None else reference_road_net\n    if road_net is None:\n        WranglerLogger.error(\n            \"! Must have a reference road network set in order to update transit \\\n                         routin.  Either provide as an input to this function or set it for the \\\n                         transit network: &gt;&gt; transit_net.road_net = ...\"\n        )\n        msg = \"Must have a reference road network set in order to update transit routing.\"\n        raise TransitRoutingChangeError(msg)\n\n    # ---- update each shape that is used by selected trips to use new routing -------\n    shape_ids = shape_ids_for_trip_ids(updated_feed.trips, trip_ids)\n    # WranglerLogger.debug(f\"shape_ids: {shape_ids}\")\n    for shape_id in shape_ids:\n        updated_feed.shapes, updated_feed.trips = _update_shapes_and_trips(\n            updated_feed,\n            shape_id,\n            trip_ids,\n            routing_change[\"set\"],\n            net.config.IDS.TRANSIT_SHAPE_ID_SCALAR,\n            road_net,\n            routing_existing=routing_change.get(\"existing\", []),\n            project_name=project_name,\n        )\n    # WranglerLogger.debug(f\"updated_feed.shapes: \\n{updated_feed.shapes}\")\n    # WranglerLogger.debug(f\"updated_feed.trips: \\n{updated_feed.trips}\")\n    # ---- Check if any stops need adding to stops.txt and add if they do ----------\n    updated_feed.stops = _update_stops(\n        updated_feed, routing_change[\"set\"], road_net, project_name=project_name\n    )\n    # WranglerLogger.debug(f\"updated_feed.stops: \\n{updated_feed.stops}\")\n    # ---- Update stop_times --------------------------------------------------------\n    for trip_id in trip_ids:\n        updated_feed.stop_times = _update_stop_times_for_trip(\n            updated_feed,\n            trip_id,\n            routing_change[\"set\"],\n            routing_change.get(\"existing\", []),\n        )\n\n    # ---- Check result -------------------------------------------------------------\n    _show_col = [\n        \"trip_id\",\n        \"stop_id\",\n        \"stop_sequence\",\n        \"departure_time\",\n        \"arrival_time\",\n    ]\n    _ex_stoptimes = updated_feed.stop_times.loc[\n        updated_feed.stop_times.trip_id == trip_ids[0], _show_col\n    ]\n    # WranglerLogger.debug(f\"stop_times for first updated trip: \\n {_ex_stoptimes}\")\n\n    # ---- Update transit network with updated feed.\n    net.feed = updated_feed\n    # WranglerLogger.debug(f\"net.feed.stops: \\n {net.feed.stops}\")\n    return net\n</code></pre>"},{"location":"api_transit/#transit-helper-modules","title":"Transit Helper Modules","text":"<p>Functions to clip a TransitNetwork object to a boundary.</p> <p>Clipped transit is an independent transit network that is a subset of the original transit network.</p> <p>Example usage:</p> <pre><code>from network_wrangler.transit load_transit, write_transit\nfrom network_wrangler.transit.clip import clip_transit\n\nstpaul_transit = load_transit(example_dir / \"stpaul\")\nboundary_file = test_dir / \"data\" / \"ecolab.geojson\"\nclipped_network = clip_transit(stpaul_transit, boundary_file=boundary_file)\nwrite_transit(clipped_network, out_dir, prefix=\"ecolab\", format=\"geojson\", true_shape=True)\n</code></pre> <p>Utilities for working with transit geodataframes.</p> <p>Functions for reading and writing transit feeds and networks.</p> <p>ModelTransit class and functions for managing consistency between roadway and transit networks.</p> <p>NOTE: this is not thoroughly tested and may not be fully functional.</p> <p>Classes and functions for selecting transit trips from a transit network.</p> <p>Usage:</p> <p>Create a TransitSelection object by providing a TransitNetwork object and a selection dictionary:</p> <pre><code>```python\nselection_dict = {\n    \"links\": {...},\n    \"nodes\": {...},\n    \"route_properties\": {...},\n    \"trip_properties\": {...},\n    \"timespans\": {...},\n}\ntransit_selection = TransitSelection(transit_network, selection_dict)\n```\n</code></pre> <p>Access the selected trip ids or dataframe as follows:</p> <pre><code>```python\nselected_trips = transit_selection.selected_trips\nselected_trips_df = transit_selection.selected_trips_df\n```\n</code></pre> <p>Note: The selection dictionary should conform to the SelectTransitTrips model defined in the models.projects.transit_selection module.</p> <p>Functions to check for transit network validity and consistency with roadway network.</p>"},{"location":"api_transit/#network_wrangler.transit.clip.clip_feed_to_boundary","title":"network_wrangler.transit.clip.clip_feed_to_boundary","text":"<pre><code>clip_feed_to_boundary(feed, ref_nodes_df, boundary_gdf=None, boundary_geocode=None, boundary_file=None, min_stops=DEFAULT_MIN_STOPS)\n</code></pre> <p>Clips a transit Feed object to a boundary and returns the resulting GeoDataFrames.</p> <p>Retains only the stops within the boundary and trips that traverse them subject to a minimum number of stops per trip as defined by <code>min_stops</code>.</p> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Feed</code>)           \u2013            <p>Feed object to be clipped.</p> </li> <li> <code>ref_nodes_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>geodataframe with node geometry to reference</p> </li> <li> <code>boundary_geocode</code>               (<code>Union[str, dict]</code>, default:                   <code>None</code> )           \u2013            <p>A geocode string or dictionary representing the boundary. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Union[str, Path]</code>, default:                   <code>None</code> )           \u2013            <p>A path to the boundary file. Only used if boundary_geocode is None. Defaults to None.</p> </li> <li> <code>boundary_gdf</code>               (<code>GeoDataFrame</code>, default:                   <code>None</code> )           \u2013            <p>A GeoDataFrame representing the boundary. Only used if boundary_geocode and boundary_file are None. Defaults to None.</p> </li> <li> <code>min_stops</code>               (<code>int</code>, default:                   <code>DEFAULT_MIN_STOPS</code> )           \u2013            <p>minimum number of stops needed to retain a transit trip within clipped area. Defaults to DEFAULT_MIN_STOPS which is set to 2.</p> </li> </ul> Source code in <code>network_wrangler/transit/clip.py</code> <pre><code>def clip_feed_to_boundary(\n    feed: Feed,\n    ref_nodes_df: gpd.GeoDataFrame,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    min_stops: int = DEFAULT_MIN_STOPS,\n) -&gt; Feed:\n    \"\"\"Clips a transit Feed object to a boundary and returns the resulting GeoDataFrames.\n\n    Retains only the stops within the boundary and trips that traverse them subject to a minimum\n    number of stops per trip as defined by `min_stops`.\n\n    Args:\n        feed: Feed object to be clipped.\n        ref_nodes_df: geodataframe with node geometry to reference\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            boundary_geocode is None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if boundary_geocode and boundary_file are None. Defaults to None.\n        min_stops: minimum number of stops needed to retain a transit trip within clipped area.\n            Defaults to DEFAULT_MIN_STOPS which is set to 2.\n\n    Returns: Feed object trimmed to the boundary.\n    \"\"\"\n    WranglerLogger.info(\"Clipping transit network to boundary.\")\n\n    boundary_gdf = get_bounding_polygon(\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    shape_links_gdf = shapes_to_shape_links_gdf(feed.shapes, ref_nodes_df=ref_nodes_df)\n\n    # make sure boundary_gdf.crs == network.crs\n    if boundary_gdf.crs != shape_links_gdf.crs:\n        boundary_gdf = boundary_gdf.to_crs(shape_links_gdf.crs)\n\n    # get the boundary as a single polygon\n    boundary = boundary_gdf.geometry.union_all()\n    # get the shape_links that intersect the boundary\n    clipped_shape_links = shape_links_gdf[shape_links_gdf.geometry.intersects(boundary)]\n\n    # nodes within clipped_shape_links\n    node_ids = list(set(clipped_shape_links.A.to_list() + clipped_shape_links.B.to_list()))\n    WranglerLogger.debug(f\"Clipping network to {len(node_ids)} nodes.\")\n    if not node_ids:\n        msg = \"No nodes found within the boundary.\"\n        raise ValueError(msg)\n    return _clip_feed_to_nodes(feed, node_ids, min_stops=min_stops)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.clip.clip_feed_to_roadway","title":"network_wrangler.transit.clip.clip_feed_to_roadway","text":"<pre><code>clip_feed_to_roadway(feed, roadway_net, min_stops=DEFAULT_MIN_STOPS)\n</code></pre> <p>Returns a copy of transit feed clipped to the roadway network.</p> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Feed</code>)           \u2013            <p>Transit Feed to clip.</p> </li> <li> <code>roadway_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>Roadway network to clip to.</p> </li> <li> <code>min_stops</code>               (<code>int</code>, default:                   <code>DEFAULT_MIN_STOPS</code> )           \u2013            <p>minimum number of stops needed to retain a transit trip within clipped area. Defaults to DEFAULT_MIN_STOPS which is set to 2.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no stops found within the roadway network.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Feed</code> (              <code>Feed</code> )          \u2013            <p>Clipped deep copy of feed limited to the roadway network.</p> </li> </ul> Source code in <code>network_wrangler/transit/clip.py</code> <pre><code>def clip_feed_to_roadway(\n    feed: Feed,\n    roadway_net: RoadwayNetwork,\n    min_stops: int = DEFAULT_MIN_STOPS,\n) -&gt; Feed:\n    \"\"\"Returns a copy of transit feed clipped to the roadway network.\n\n    Args:\n        feed (Feed): Transit Feed to clip.\n        roadway_net: Roadway network to clip to.\n        min_stops: minimum number of stops needed to retain a transit trip within clipped area.\n            Defaults to DEFAULT_MIN_STOPS which is set to 2.\n\n    Raises:\n        ValueError: If no stops found within the roadway network.\n\n    Returns:\n        Feed: Clipped deep copy of feed limited to the roadway network.\n    \"\"\"\n    WranglerLogger.info(\"Clipping transit network to roadway network.\")\n\n    clipped_feed = _remove_links_from_feed(feed, roadway_net.links_df, min_stops=min_stops)\n\n    return clipped_feed\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.clip.clip_transit","title":"network_wrangler.transit.clip.clip_transit","text":"<pre><code>clip_transit(network, node_ids=None, boundary_geocode=None, boundary_file=None, boundary_gdf=None, ref_nodes_df=None, roadway_net=None, min_stops=DEFAULT_MIN_STOPS)\n</code></pre> <p>Returns a new TransitNetwork clipped to a boundary as determined by arguments.</p> <p>Will clip based on which arguments are provided as prioritized below:</p> <ol> <li>If <code>node_ids</code> provided, will clip based on <code>node_ids</code></li> <li>If <code>boundary_geocode</code> provided, will clip based on on search in OSM for that jurisdiction     boundary using reference geometry from <code>ref_nodes_df</code>, <code>roadway_net</code>, or <code>roadway_path</code></li> <li>If <code>boundary_file</code> provided, will clip based on that polygon  using reference geometry     from <code>ref_nodes_df</code>, <code>roadway_net</code>, or <code>roadway_path</code></li> <li>If <code>boundary_gdf</code> provided, will clip based on that geodataframe  using reference geometry     from <code>ref_nodes_df</code>, <code>roadway_net</code>, or <code>roadway_path</code></li> <li>If <code>roadway_net</code> provided, will clip based on that roadway network</li> </ol> <p>Parameters:</p> <ul> <li> <code>network</code>               (<code>TransitNetwork</code>)           \u2013            <p>TransitNetwork to clip.</p> </li> <li> <code>node_ids</code>               (<code>list[str]</code>, default:                   <code>None</code> )           \u2013            <p>A list of node_ids to clip to. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Union[str, dict]</code>, default:                   <code>None</code> )           \u2013            <p>A geocode string or dictionary representing the boundary. Only used if node_ids are None. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Union[str, Path]</code>, default:                   <code>None</code> )           \u2013            <p>A path to the boundary file. Only used if node_ids and boundary_geocode are None. Defaults to None.</p> </li> <li> <code>boundary_gdf</code>               (<code>GeoDataFrame</code>, default:                   <code>None</code> )           \u2013            <p>A GeoDataFrame representing the boundary. Only used if node_ids, boundary_geocode and boundary_file are None. Defaults to None.</p> </li> <li> <code>ref_nodes_df</code>               (<code>Optional[Union[None, GeoDataFrame]]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame of geographic references for node_ids.  Only used if node_ids is None and one of boundary_* is not None.</p> </li> <li> <code>roadway_net</code>               (<code>Optional[Union[None, RoadwayNetwork]]</code>, default:                   <code>None</code> )           \u2013            <p>Roadway Network  instance to clip transit network to.  Only used if node_ids is None and allof boundary_* are None</p> </li> <li> <code>min_stops</code>               (<code>int</code>, default:                   <code>DEFAULT_MIN_STOPS</code> )           \u2013            <p>minimum number of stops needed to retain a transit trip within clipped area. Defaults to DEFAULT_MIN_STOPS which is set to 2.</p> </li> </ul> Source code in <code>network_wrangler/transit/clip.py</code> <pre><code>def clip_transit(\n    network: Union[TransitNetwork, str, Path],\n    node_ids: Optional[Union[None, list[str]]] = None,\n    boundary_geocode: Optional[Union[str, dict, None]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    boundary_gdf: Optional[Union[None, gpd.GeoDataFrame]] = None,\n    ref_nodes_df: Optional[Union[None, gpd.GeoDataFrame]] = None,\n    roadway_net: Optional[Union[None, RoadwayNetwork]] = None,\n    min_stops: int = DEFAULT_MIN_STOPS,\n) -&gt; TransitNetwork:\n    \"\"\"Returns a new TransitNetwork clipped to a boundary as determined by arguments.\n\n    Will clip based on which arguments are provided as prioritized below:\n\n    1. If `node_ids` provided, will clip based on `node_ids`\n    2. If `boundary_geocode` provided, will clip based on on search in OSM for that jurisdiction\n        boundary using reference geometry from `ref_nodes_df`, `roadway_net`, or `roadway_path`\n    3. If `boundary_file` provided, will clip based on that polygon  using reference geometry\n        from `ref_nodes_df`, `roadway_net`, or `roadway_path`\n    4. If `boundary_gdf` provided, will clip based on that geodataframe  using reference geometry\n        from `ref_nodes_df`, `roadway_net`, or `roadway_path`\n    5. If `roadway_net` provided, will clip based on that roadway network\n\n    Args:\n        network (TransitNetwork): TransitNetwork to clip.\n        node_ids (list[str], optional): A list of node_ids to clip to. Defaults to None.\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Only used if node_ids are None. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            node_ids and boundary_geocode are None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if node_ids, boundary_geocode and boundary_file are None. Defaults to None.\n        ref_nodes_df: GeoDataFrame of geographic references for node_ids.  Only used if\n            node_ids is None and one of boundary_* is not None.\n        roadway_net: Roadway Network  instance to clip transit network to.  Only used if\n            node_ids is None and allof boundary_* are None\n        min_stops: minimum number of stops needed to retain a transit trip within clipped area.\n            Defaults to DEFAULT_MIN_STOPS which is set to 2.\n    \"\"\"\n    if not isinstance(network, TransitNetwork):\n        network = load_transit(network)\n    set_roadway_network = False\n    feed = network.feed\n\n    if node_ids is not None:\n        clipped_feed = _clip_feed_to_nodes(feed, node_ids=node_ids, min_stops=min_stops)\n    elif any(i is not None for i in [boundary_file, boundary_geocode, boundary_gdf]):\n        if ref_nodes_df is None:\n            ref_nodes_df = get_nodes(transit_net=network, roadway_net=roadway_net)\n\n        clipped_feed = clip_feed_to_boundary(\n            feed,\n            ref_nodes_df,\n            boundary_file=boundary_file,\n            boundary_geocode=boundary_geocode,\n            boundary_gdf=boundary_gdf,\n            min_stops=min_stops,\n        )\n    elif roadway_net is not None:\n        clipped_feed = clip_feed_to_roadway(feed, roadway_net=roadway_net)\n        set_roadway_network = True\n    else:\n        msg = \"Missing required arguments from clip_transit\"\n        raise ValueError(msg)\n\n    # create a new TransitNetwork object with the clipped feed dataframes\n    clipped_net = TransitNetwork(clipped_feed)\n\n    if set_roadway_network:\n        WranglerLogger.info(\"Setting roadway network for clipped transit network.\")\n        clipped_net.road_net = roadway_net\n    return clipped_net\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.geo.shapes_to_shape_links_gdf","title":"network_wrangler.transit.geo.shapes_to_shape_links_gdf","text":"<pre><code>shapes_to_shape_links_gdf(shapes, ref_nodes_df=None, from_field='A', to_field='B', crs=LAT_LON_CRS)\n</code></pre> <p>Translates shapes to shape links geodataframe using geometry from ref_nodes_df if provided.</p> <p>TODO: Add join to links and then shapes to get true geometry.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>Feed shapes table</p> </li> <li> <code>ref_nodes_df</code>               (<code>Optional[DataFrame[RoadNodesTable]]</code>, default:                   <code>None</code> )           \u2013            <p>If specified, will use geometry from these nodes.  Otherwise, will use geometry in shapes file. Defaults to None.</p> </li> <li> <code>from_field</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>Field used for the link\u2019s from node <code>model_node_id</code>. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_field</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>Field used for the link\u2019s to node <code>model_node_id</code>. Defaults to \u201cB\u201d.</p> </li> <li> <code>crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>Coordinate reference system. SHouldn\u2019t be changed unless you know what you are doing. Defaults to LAT_LON_CRS which is WGS84 lat/long.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GeoDataFrame</code>           \u2013            <p>gpd.GeoDataFrame: description</p> </li> </ul> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def shapes_to_shape_links_gdf(\n    shapes: DataFrame[WranglerShapesTable],\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n    crs: int = LAT_LON_CRS,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Translates shapes to shape links geodataframe using geometry from ref_nodes_df if provided.\n\n    TODO: Add join to links and then shapes to get true geometry.\n\n    Args:\n        shapes: Feed shapes table\n        ref_nodes_df: If specified, will use geometry from these nodes.  Otherwise, will use\n            geometry in shapes file. Defaults to None.\n        from_field: Field used for the link's from node `model_node_id`. Defaults to \"A\".\n        to_field: Field used for the link's to node `model_node_id`. Defaults to \"B\".\n        crs (int, optional): Coordinate reference system. SHouldn't be changed unless you know\n            what you are doing. Defaults to LAT_LON_CRS which is WGS84 lat/long.\n\n    Returns:\n        gpd.GeoDataFrame: _description_\n    \"\"\"\n    if ref_nodes_df is not None:\n        shapes = update_shapes_geometry(shapes, ref_nodes_df)\n    tr_links = unique_shape_links(shapes, from_field=from_field, to_field=to_field)\n    # WranglerLogger.debug(f\"tr_links :\\n{tr_links }\")\n\n    geometry = linestring_from_lats_lons(\n        tr_links,\n        [f\"shape_pt_lat_{from_field}\", f\"shape_pt_lat_{to_field}\"],\n        [f\"shape_pt_lon_{from_field}\", f\"shape_pt_lon_{to_field}\"],\n    )\n    # WranglerLogger.debug(f\"geometry\\n{geometry}\")\n    shapes_gdf = gpd.GeoDataFrame(tr_links, geometry=geometry, crs=crs).set_crs(LAT_LON_CRS)\n    return shapes_gdf\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.geo.shapes_to_trip_shapes_gdf","title":"network_wrangler.transit.geo.shapes_to_trip_shapes_gdf","text":"<pre><code>shapes_to_trip_shapes_gdf(shapes, ref_nodes_df=None, crs=LAT_LON_CRS)\n</code></pre> <p>Geodataframe with one polyline shape per shape_id.</p> <p>TODO: add information about the route and trips.</p> <p>Parameters:</p> <ul> <li> <code>shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>WranglerShapesTable</p> </li> <li> <code>trips</code>           \u2013            <p>WranglerTripsTable</p> </li> <li> <code>ref_nodes_df</code>               (<code>Optional[DataFrame[RoadNodesTable]]</code>, default:                   <code>None</code> )           \u2013            <p>If specified, will use geometry from these nodes.  Otherwise, will use geometry in shapes file. Defaults to None.</p> </li> <li> <code>crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>int, optional, default 4326</p> </li> </ul> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def shapes_to_trip_shapes_gdf(\n    shapes: DataFrame[WranglerShapesTable],\n    # trips: WranglerTripsTable,\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    crs: int = LAT_LON_CRS,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Geodataframe with one polyline shape per shape_id.\n\n    TODO: add information about the route and trips.\n\n    Args:\n        shapes: WranglerShapesTable\n        trips: WranglerTripsTable\n        ref_nodes_df: If specified, will use geometry from these nodes.  Otherwise, will use\n            geometry in shapes file. Defaults to None.\n        crs: int, optional, default 4326\n    \"\"\"\n    if ref_nodes_df is not None:\n        shapes = update_shapes_geometry(shapes, ref_nodes_df)\n\n    shape_geom = (\n        shapes[[\"shape_id\", \"shape_pt_lat\", \"shape_pt_lon\"]]\n        .groupby(\"shape_id\")\n        .agg(list)\n        .apply(lambda x: LineString(zip(x[1], x[0])), axis=1)\n    )\n\n    route_shapes_gdf = gpd.GeoDataFrame(\n        data=shape_geom.index, geometry=shape_geom.values, crs=crs\n    ).set_crs(LAT_LON_CRS)\n\n    return route_shapes_gdf\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.geo.stop_times_to_stop_time_links_gdf","title":"network_wrangler.transit.geo.stop_times_to_stop_time_links_gdf","text":"<pre><code>stop_times_to_stop_time_links_gdf(stop_times, stops, ref_nodes_df=None, from_field='A', to_field='B')\n</code></pre> <p>Stop times geodataframe as links using geometry from stops.txt or optionally another df.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>WranglerStopTimesTable</code>)           \u2013            <p>Feed stop times table.</p> </li> <li> <code>stops</code>               (<code>WranglerStopsTable</code>)           \u2013            <p>Feed stops table.</p> </li> <li> <code>ref_nodes_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>If specified, will use geometry from these nodes. Otherwise, will use geometry in shapes file. Defaults to None.</p> </li> <li> <code>from_field</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>Field used for the link\u2019s from node <code>model_node_id</code>. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_field</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>Field used for the link\u2019s to node <code>model_node_id</code>. Defaults to \u201cB\u201d.</p> </li> </ul> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def stop_times_to_stop_time_links_gdf(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    stops: DataFrame[WranglerStopsTable],\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Stop times geodataframe as links using geometry from stops.txt or optionally another df.\n\n    Args:\n        stop_times (WranglerStopTimesTable): Feed stop times table.\n        stops (WranglerStopsTable): Feed stops table.\n        ref_nodes_df (pd.DataFrame, optional): If specified, will use geometry from these nodes.\n            Otherwise, will use geometry in shapes file. Defaults to None.\n        from_field: Field used for the link's from node `model_node_id`. Defaults to \"A\".\n        to_field: Field used for the link's to node `model_node_id`. Defaults to \"B\".\n    \"\"\"\n    from ..utils.geo import linestring_from_lats_lons  # noqa: PLC0415\n\n    if ref_nodes_df is not None:\n        stops = update_stops_geometry(stops, ref_nodes_df)\n\n    lat_fields = []\n    lon_fields = []\n    tr_links = unique_stop_time_links(stop_times, from_field=from_field, to_field=to_field)\n    for f in (from_field, to_field):\n        tr_links = tr_links.merge(\n            stops[[\"stop_id\", \"stop_lat\", \"stop_lon\"]],\n            right_on=\"stop_id\",\n            left_on=f,\n            how=\"left\",\n        )\n        lon_f = f\"{f}_X\"\n        lat_f = f\"{f}_Y\"\n        tr_links = tr_links.rename(columns={\"stop_lon\": lon_f, \"stop_lat\": lat_f})\n        lon_fields.append(lon_f)\n        lat_fields.append(lat_f)\n\n    geometry = linestring_from_lats_lons(tr_links, lat_fields, lon_fields)\n    return gpd.GeoDataFrame(tr_links, geometry=geometry).set_crs(LAT_LON_CRS)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.geo.stop_times_to_stop_time_points_gdf","title":"network_wrangler.transit.geo.stop_times_to_stop_time_points_gdf","text":"<pre><code>stop_times_to_stop_time_points_gdf(stop_times, stops, ref_nodes_df=None)\n</code></pre> <p>Stoptimes geodataframe as points using geometry from stops.txt or optionally another df.</p> <p>Parameters:</p> <ul> <li> <code>stop_times</code>               (<code>WranglerStopTimesTable</code>)           \u2013            <p>Feed stop times table.</p> </li> <li> <code>stops</code>               (<code>WranglerStopsTable</code>)           \u2013            <p>Feed stops table.</p> </li> <li> <code>ref_nodes_df</code>               (<code>DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>If specified, will use geometry from these nodes. Otherwise, will use geometry in shapes file. Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def stop_times_to_stop_time_points_gdf(\n    stop_times: DataFrame[WranglerStopTimesTable],\n    stops: DataFrame[WranglerStopsTable],\n    ref_nodes_df: Optional[DataFrame[RoadNodesTable]] = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Stoptimes geodataframe as points using geometry from stops.txt or optionally another df.\n\n    Args:\n        stop_times (WranglerStopTimesTable): Feed stop times table.\n        stops (WranglerStopsTable): Feed stops table.\n        ref_nodes_df (pd.DataFrame, optional): If specified, will use geometry from these nodes.\n            Otherwise, will use geometry in shapes file. Defaults to None.\n    \"\"\"\n    if ref_nodes_df is not None:\n        stops = update_stops_geometry(stops, ref_nodes_df)\n\n    stop_times_geo = stop_times.merge(\n        stops[[\"stop_id\", \"stop_lat\", \"stop_lon\"]],\n        right_on=\"stop_id\",\n        left_on=\"stop_id\",\n        how=\"left\",\n    )\n    return gpd.GeoDataFrame(\n        stop_times_geo,\n        geometry=gpd.points_from_xy(stop_times_geo[\"stop_lon\"], stop_times_geo[\"stop_lat\"]),\n        crs=LAT_LON_CRS,\n    )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.geo.update_shapes_geometry","title":"network_wrangler.transit.geo.update_shapes_geometry","text":"<pre><code>update_shapes_geometry(shapes, ref_nodes_df)\n</code></pre> <p>Returns shapes table with geometry updated from ref_nodes_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def update_shapes_geometry(\n    shapes: DataFrame[WranglerShapesTable], ref_nodes_df: DataFrame[RoadNodesTable]\n) -&gt; DataFrame[WranglerShapesTable]:\n    \"\"\"Returns shapes table with geometry updated from ref_nodes_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    return update_point_geometry(\n        shapes,\n        ref_nodes_df,\n        id_field=\"shape_model_node_id\",\n        lon_field=\"shape_pt_lon\",\n        lat_field=\"shape_pt_lat\",\n    )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.geo.update_stops_geometry","title":"network_wrangler.transit.geo.update_stops_geometry","text":"<pre><code>update_stops_geometry(stops, ref_nodes_df)\n</code></pre> <p>Returns stops table with geometry updated from ref_nodes_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/transit/geo.py</code> <pre><code>def update_stops_geometry(\n    stops: DataFrame[WranglerStopsTable], ref_nodes_df: DataFrame[RoadNodesTable]\n) -&gt; DataFrame[WranglerStopsTable]:\n    \"\"\"Returns stops table with geometry updated from ref_nodes_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    return update_point_geometry(\n        stops, ref_nodes_df, id_field=\"stop_id\", lon_field=\"stop_lon\", lat_field=\"stop_lat\"\n    )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.io.convert_transit_serialization","title":"network_wrangler.transit.io.convert_transit_serialization","text":"<pre><code>convert_transit_serialization(input_path, output_format, out_dir='.', input_file_format='csv', out_prefix='', overwrite=True)\n</code></pre> <p>Converts a transit network from one serialization to another.</p> <p>Parameters:</p> <ul> <li> <code>input_path</code>               (<code>Union[str, Path]</code>)           \u2013            <p>path to the input network</p> </li> <li> <code>output_format</code>               (<code>TransitFileTypes</code>)           \u2013            <p>the format of the output files. Should be txt, csv, or parquet.</p> </li> <li> <code>out_dir</code>               (<code>Union[Path, str]</code>, default:                   <code>'.'</code> )           \u2013            <p>directory to write the network to. Defaults to current directory.</p> </li> <li> <code>input_file_format</code>               (<code>TransitFileTypes</code>, default:                   <code>'csv'</code> )           \u2013            <p>the file_format of the files to read. Should be txt, csv, or parquet. Defaults to \u201ctxt\u201d</p> </li> <li> <code>out_prefix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>prefix to add to the file name. Defaults to \u201c\u201d</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True</p> </li> </ul> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def convert_transit_serialization(\n    input_path: Union[str, Path],\n    output_format: TransitFileTypes,\n    out_dir: Union[Path, str] = \".\",\n    input_file_format: TransitFileTypes = \"csv\",\n    out_prefix: str = \"\",\n    overwrite: bool = True,\n):\n    \"\"\"Converts a transit network from one serialization to another.\n\n    Args:\n        input_path: path to the input network\n        output_format: the format of the output files. Should be txt, csv, or parquet.\n        out_dir: directory to write the network to. Defaults to current directory.\n        input_file_format: the file_format of the files to read. Should be txt, csv, or parquet.\n            Defaults to \"txt\"\n        out_prefix: prefix to add to the file name. Defaults to \"\"\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n    WranglerLogger.info(\n        f\"Loading transit net from {input_path} with input type {input_file_format}\"\n    )\n    net = load_transit(input_path, file_format=input_file_format)\n    WranglerLogger.info(f\"Writing transit network to {out_dir} in {output_format} format.\")\n    write_transit(\n        net,\n        prefix=out_prefix,\n        out_dir=out_dir,\n        file_format=output_format,\n        overwrite=overwrite,\n    )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.io.load_feed_from_dfs","title":"network_wrangler.transit.io.load_feed_from_dfs","text":"<pre><code>load_feed_from_dfs(feed_dfs, wrangler_flavored=True)\n</code></pre> <p>Create a Feed or GtfsModel object from a dictionary of DataFrames representing a GTFS feed.</p> <p>Parameters:</p> <ul> <li> <code>feed_dfs</code>               (<code>dict</code>)           \u2013            <p>A dictionary containing DataFrames representing the tables of a GTFS feed.</p> </li> <li> <code>wrangler_flavored</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, creates a Wrangler-enhanced Feed] object.                If False, creates a pure GtfsModel object. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Feed, GtfsModel]</code>           \u2013            <p>Union[Feed, GtfsModel]: A Feed or GtfsModel object representing the transit network.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the feed_dfs dictionary does not contain all the required tables.</p> </li> </ul> <p>Example usage: <pre><code>feed_dfs = {\n    \"agency\": agency_df,\n    \"routes\": routes_df,\n    \"stops\": stops_df,\n    \"trips\": trips_df,\n    \"stop_times\": stop_times_df,\n}\nfeed = load_feed_from_dfs(feed_dfs)  # Creates Feed by default\ngtfs_model = load_feed_from_dfs(feed_dfs, wrangler_flavored=False)  # Creates GtfsModel\n</code></pre></p> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def load_feed_from_dfs(feed_dfs: dict, wrangler_flavored: bool = True) -&gt; Union[Feed, GtfsModel]:\n    \"\"\"Create a Feed or GtfsModel object from a dictionary of DataFrames representing a GTFS feed.\n\n    Args:\n        feed_dfs (dict): A dictionary containing DataFrames representing the tables of a GTFS feed.\n        wrangler_flavored: If True, creates a Wrangler-enhanced Feed] object.\n                           If False, creates a pure GtfsModel object. Defaults to True.\n\n    Returns:\n        Union[Feed, GtfsModel]: A Feed or GtfsModel object representing the transit network.\n\n    Raises:\n        ValueError: If the feed_dfs dictionary does not contain all the required tables.\n\n    Example usage:\n    ```python\n    feed_dfs = {\n        \"agency\": agency_df,\n        \"routes\": routes_df,\n        \"stops\": stops_df,\n        \"trips\": trips_df,\n        \"stop_times\": stop_times_df,\n    }\n    feed = load_feed_from_dfs(feed_dfs)  # Creates Feed by default\n    gtfs_model = load_feed_from_dfs(feed_dfs, wrangler_flavored=False)  # Creates GtfsModel\n    ```\n    \"\"\"\n    # Use the appropriate model class based on the parameter\n    model_class = Feed if wrangler_flavored else GtfsModel\n\n    if not all(table in feed_dfs for table in model_class.table_names):\n        model_name = \"Feed\" if wrangler_flavored else \"GtfsModel\"\n        msg = f\"feed_dfs must contain the following tables for {model_name}: {model_class.table_names}\"\n        raise ValueError(msg)\n\n    feed = model_class(**feed_dfs)\n\n    return feed\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.io.load_feed_from_path","title":"network_wrangler.transit.io.load_feed_from_path","text":"<pre><code>load_feed_from_path(feed_path, file_format='txt', wrangler_flavored=True)\n</code></pre> <p>Create a Feed or GtfsModel object from the path to a GTFS transit feed.</p> <p>Parameters:</p> <ul> <li> <code>feed_path</code>               (<code>Union[Path, str]</code>)           \u2013            <p>The path to the GTFS transit feed.</p> </li> <li> <code>file_format</code>               (<code>TransitFileTypes</code>, default:                   <code>'txt'</code> )           \u2013            <p>the format of the files to read. Defaults to \u201ctxt\u201d</p> </li> <li> <code>wrangler_flavored</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, creates a Wrangler-enhanced Feed object.               If False, creates a pure GtfsModel object. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Feed, GtfsModel]</code>           \u2013            <p>Union[Feed, GtfsModel]: The Feed or GtfsModel object created from the GTFS transit feed.</p> </li> </ul> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def load_feed_from_path(\n    feed_path: Union[Path, str],\n    file_format: TransitFileTypes = \"txt\",\n    wrangler_flavored: bool = True,\n) -&gt; Union[Feed, GtfsModel]:\n    \"\"\"Create a Feed or GtfsModel object from the path to a GTFS transit feed.\n\n    Args:\n        feed_path (Union[Path, str]): The path to the GTFS transit feed.\n        file_format: the format of the files to read. Defaults to \"txt\"\n        wrangler_flavored: If True, creates a Wrangler-enhanced Feed object.\n                          If False, creates a pure GtfsModel object. Defaults to True.\n\n    Returns:\n        Union[Feed, GtfsModel]: The Feed or GtfsModel object created from the GTFS transit feed.\n    \"\"\"\n    feed_path = _feed_path_ref(Path(feed_path))  # unzips if needs to be unzipped\n\n    if not feed_path.is_dir():\n        msg = f\"Feed path not a directory: {feed_path}\"\n        raise NotADirectoryError(msg)\n\n    WranglerLogger.info(f\"Reading GTFS feed tables from {feed_path}\")\n\n    # Use the appropriate table names based on the model type\n    model_class = Feed if wrangler_flavored else GtfsModel\n    feed_possible_files = {\n        table: list(feed_path.glob(f\"*{table}.{file_format}\")) for table in model_class.table_names\n    }\n    WranglerLogger.debug(f\"model_class={model_class}  feed_possible_files={feed_possible_files}\")\n\n    # make sure we have all the tables we need\n    _missing_files = [t for t, v in feed_possible_files.items() if not v]\n\n    if _missing_files:\n        WranglerLogger.debug(f\"!!! Missing transit files: {_missing_files}\")\n        model_name = \"Feed\" if wrangler_flavored else \"GtfsModel\"\n        msg = f\"Required GTFS {model_name} table(s) not in {feed_path}: \\n  {_missing_files}\"\n        raise RequiredTableError(msg)\n\n    # but don't want to have more than one file per search\n    _ambiguous_files = [t for t, v in feed_possible_files.items() if len(v) &gt; 1]\n    if _ambiguous_files:\n        WranglerLogger.warning(\n            f\"! More than one file matches following tables. \\\n                               Using the first on the list: {_ambiguous_files}\"\n        )\n\n    feed_files = {t: f[0] for t, f in feed_possible_files.items()}\n    feed_dfs = {table: _read_table_from_file(table, file) for table, file in feed_files.items()}\n\n    return load_feed_from_dfs(feed_dfs, wrangler_flavored=wrangler_flavored)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.io.load_transit","title":"network_wrangler.transit.io.load_transit","text":"<pre><code>load_transit(feed, file_format='txt', config=DefaultConfig)\n</code></pre> <p>Create a <code>TransitNetwork</code> object.</p> <p>This function takes in a <code>feed</code> parameter, which can be one of the following types:</p> <ul> <li><code>Feed</code>: A Feed object representing a transit feed.</li> <li><code>dict[str, pd.DataFrame]</code>: A dictionary of DataFrames representing transit data.</li> <li><code>str</code> or <code>Path</code>: A string or a Path object representing the path to a transit feed file.</li> </ul> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Union[Feed, GtfsModel, dict[str, DataFrame], str, Path]</code>)           \u2013            <p>Feed boject, dict of transit data frames, or path to transit feed data</p> </li> <li> <code>file_format</code>               (<code>TransitFileTypes</code>, default:                   <code>'txt'</code> )           \u2013            <p>the format of the files to read. Defaults to \u201ctxt\u201d</p> </li> <li> <code>config</code>               (<code>WranglerConfig</code>, default:                   <code>DefaultConfig</code> )           \u2013            <p>WranglerConfig object. Defaults to DefaultConfig.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TransitNetwork</code>           \u2013            <p>object representing the loaded transit network.</p> </li> </ul> <p>Example usage: <pre><code>transit_network_from_zip = load_transit(\"path/to/gtfs.zip\")\n\ntransit_network_from_unzipped_dir = load_transit(\"path/to/files\")\n\ntransit_network_from_parquet = load_transit(\"path/to/files\", file_format=\"parquet\")\n\ndfs_of_transit_data = {\"routes\": routes_df, \"stops\": stops_df, \"trips\": trips_df...}\ntransit_network_from_dfs = load_transit(dfs_of_transit_data)\n</code></pre></p> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def load_transit(\n    feed: Union[Feed, GtfsModel, dict[str, pd.DataFrame], str, Path],\n    file_format: TransitFileTypes = \"txt\",\n    config: WranglerConfig = DefaultConfig,\n) -&gt; TransitNetwork:\n    \"\"\"Create a [`TransitNetwork`][network_wrangler.transit.network.TransitNetwork] object.\n\n    This function takes in a `feed` parameter, which can be one of the following types:\n\n    - `Feed`: A Feed object representing a transit feed.\n    - `dict[str, pd.DataFrame]`: A dictionary of DataFrames representing transit data.\n    - `str` or `Path`: A string or a Path object representing the path to a transit feed file.\n\n    Args:\n        feed: Feed boject, dict of transit data frames, or path to transit feed data\n        file_format: the format of the files to read. Defaults to \"txt\"\n        config: WranglerConfig object. Defaults to DefaultConfig.\n\n    Returns:\n        (TransitNetwork): object representing the loaded transit network.\n\n    Raises:\n    ValueError: If the `feed` parameter is not one of the supported types.\n\n    Example usage:\n    ```python\n    transit_network_from_zip = load_transit(\"path/to/gtfs.zip\")\n\n    transit_network_from_unzipped_dir = load_transit(\"path/to/files\")\n\n    transit_network_from_parquet = load_transit(\"path/to/files\", file_format=\"parquet\")\n\n    dfs_of_transit_data = {\"routes\": routes_df, \"stops\": stops_df, \"trips\": trips_df...}\n    transit_network_from_dfs = load_transit(dfs_of_transit_data)\n    ```\n\n    \"\"\"\n    if isinstance(feed, (Path, str)):\n        feed = Path(feed)\n        feed_obj = load_feed_from_path(feed, file_format=file_format)\n        feed_obj.feed_path = feed\n    elif isinstance(feed, dict):\n        feed_obj = load_feed_from_dfs(feed)\n    elif isinstance(feed, GtfsModel):\n        feed_obj = Feed(**feed.__dict__)\n    else:\n        if not isinstance(feed, Feed):\n            msg = f\"TransitNetwork must be seeded with a Feed, dict of dfs or Path. Found {type(feed)}\"\n            raise ValueError(msg)\n        feed_obj = feed\n\n    return TransitNetwork(feed_obj, config=config)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.io.write_feed_geo","title":"network_wrangler.transit.io.write_feed_geo","text":"<pre><code>write_feed_geo(feed, ref_nodes_df, out_dir, file_format='geojson', out_prefix=None, overwrite=True)\n</code></pre> <p>Write a Feed object to a directory in a geospatial format.</p> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Feed</code>)           \u2013            <p>Feed object to write</p> </li> <li> <code>ref_nodes_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>Reference nodes dataframe to use for geometry</p> </li> <li> <code>out_dir</code>               (<code>Union[str, Path]</code>)           \u2013            <p>directory to write the network to</p> </li> <li> <code>file_format</code>               (<code>Literal['geojson', 'shp', 'parquet']</code>, default:                   <code>'geojson'</code> )           \u2013            <p>the format of the output files. Defaults to \u201cgeojson\u201d</p> </li> <li> <code>out_prefix</code>           \u2013            <p>prefix to add to the file name</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True</p> </li> </ul> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def write_feed_geo(\n    feed: Feed,\n    ref_nodes_df: gpd.GeoDataFrame,\n    out_dir: Union[str, Path],\n    file_format: Literal[\"geojson\", \"shp\", \"parquet\"] = \"geojson\",\n    out_prefix=None,\n    overwrite: bool = True,\n) -&gt; None:\n    \"\"\"Write a Feed object to a directory in a geospatial format.\n\n    Args:\n        feed: Feed object to write\n        ref_nodes_df: Reference nodes dataframe to use for geometry\n        out_dir: directory to write the network to\n        file_format: the format of the output files. Defaults to \"geojson\"\n        out_prefix: prefix to add to the file name\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n    from .geo import shapes_to_shape_links_gdf  # noqa: PLC0415\n\n    out_dir = Path(out_dir)\n    if not out_dir.is_dir():\n        if out_dir.parent.is_dir():\n            out_dir.mkdir()\n        else:\n            msg = f\"Output directory {out_dir} ands its parent path does not exist\"\n            raise FileNotFoundError(msg)\n\n    prefix = f\"{out_prefix}_\" if out_prefix else \"\"\n    shapes_outpath = out_dir / f\"{prefix}trn_shapes.{file_format}\"\n    shapes_gdf = shapes_to_shape_links_gdf(feed.shapes, ref_nodes_df=ref_nodes_df)\n    write_table(shapes_gdf, shapes_outpath, overwrite=overwrite)\n\n    stops_outpath = out_dir / f\"{prefix}trn_stops.{file_format}\"\n    stops_gdf = to_points_gdf(feed.stops, ref_nodes_df=ref_nodes_df)\n    write_table(stops_gdf, stops_outpath, overwrite=overwrite)\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.io.write_transit","title":"network_wrangler.transit.io.write_transit","text":"<pre><code>write_transit(transit_net, out_dir='.', prefix=None, file_format='txt', overwrite=True)\n</code></pre> <p>Writes a network in the transit network standard.</p> <p>Parameters:</p> <ul> <li> <code>transit_net</code>           \u2013            <p>a TransitNetwork instance</p> </li> <li> <code>out_dir</code>               (<code>Union[Path, str]</code>, default:                   <code>'.'</code> )           \u2013            <p>directory to write the network to</p> </li> <li> <code>file_format</code>               (<code>Literal['txt', 'csv', 'parquet']</code>, default:                   <code>'txt'</code> )           \u2013            <p>the format of the output files. Defaults to \u201ctxt\u201d which is csv with txt file format.</p> </li> <li> <code>prefix</code>               (<code>Optional[Union[Path, str]]</code>, default:                   <code>None</code> )           \u2013            <p>prefix to add to the file name</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will overwrite the files if they already exist. Defaults to True</p> </li> </ul> Source code in <code>network_wrangler/transit/io.py</code> <pre><code>def write_transit(\n    transit_net,\n    out_dir: Union[Path, str] = \".\",\n    prefix: Optional[Union[Path, str]] = None,\n    file_format: Literal[\"txt\", \"csv\", \"parquet\"] = \"txt\",\n    overwrite: bool = True,\n) -&gt; None:\n    \"\"\"Writes a network in the transit network standard.\n\n    Args:\n        transit_net: a TransitNetwork instance\n        out_dir: directory to write the network to\n        file_format: the format of the output files. Defaults to \"txt\" which is csv with txt\n            file format.\n        prefix: prefix to add to the file name\n        overwrite: if True, will overwrite the files if they already exist. Defaults to True\n    \"\"\"\n    out_dir = Path(out_dir)\n    prefix = f\"{prefix}_\" if prefix else \"\"\n    for table in transit_net.feed.table_names:\n        df = transit_net.feed.get_table(table)\n        outpath = out_dir / f\"{prefix}{table}.{file_format}\"\n        write_table(df, outpath, overwrite=overwrite)\n    WranglerLogger.info(f\"Wrote {len(transit_net.feed.tables)} files to {out_dir}\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.model_transit.ModelTransit","title":"network_wrangler.transit.model_transit.ModelTransit","text":"<p>ModelTransit class for managing consistency between roadway and transit networks.</p> Source code in <code>network_wrangler/transit/model_transit.py</code> <pre><code>class ModelTransit:\n    \"\"\"ModelTransit class for managing consistency between roadway and transit networks.\"\"\"\n\n    def __init__(\n        self,\n        transit_net: TransitNetwork,\n        roadway_net: RoadwayNetwork,\n        shift_transit_to_managed_lanes: bool = True,\n    ):\n        \"\"\"ModelTransit class for managing consistency between roadway and transit networks.\"\"\"\n        self.transit_net = transit_net\n        self.roadway_net = roadway_net\n        self._roadway_net_hash = None\n        self._transit_feed_hash = None\n        self._transit_shifted_to_ML = shift_transit_to_managed_lanes\n\n    @property\n    def model_roadway_net(self):\n        \"\"\"ModelRoadwayNetwork associated with this ModelTransit.\"\"\"\n        return self.roadway_net.model_net\n\n    @property\n    def consistent_nets(self) -&gt; bool:\n        \"\"\"Indicate if roadway and transit networks have changed since self.m_feed updated.\"\"\"\n        return bool(\n            self.roadway_net.network_hash == self._roadway_net_hash\n            and self.transit_net.feed_hash == self._transit_feed_hash\n        )\n\n    @property\n    def m_feed(self):\n        \"\"\"TransitNetwork.feed with updates for consistency with associated ModelRoadwayNetwork.\"\"\"\n        if self.consistent_nets:\n            return self._m_feed\n        # NOTE: look at this\n        # If netoworks have changed, updated model transit and update reference hash\n        self._roadway_net_hash = copy.deepcopy(self.roadway_net.network_hash)\n        self._transit_feed_hash = copy.deepcopy(self.transit_net.feed_hash)\n\n        if not self._transit_shifted_to_ML:\n            self._m_feed = copy.deepcopy(self.transit_net.feed)\n            return self._m_feed\n        return None\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.model_transit.ModelTransit.consistent_nets","title":"network_wrangler.transit.model_transit.ModelTransit.consistent_nets  <code>property</code>","text":"<pre><code>consistent_nets\n</code></pre> <p>Indicate if roadway and transit networks have changed since self.m_feed updated.</p>"},{"location":"api_transit/#network_wrangler.transit.model_transit.ModelTransit.m_feed","title":"network_wrangler.transit.model_transit.ModelTransit.m_feed  <code>property</code>","text":"<pre><code>m_feed\n</code></pre> <p>TransitNetwork.feed with updates for consistency with associated ModelRoadwayNetwork.</p>"},{"location":"api_transit/#network_wrangler.transit.model_transit.ModelTransit.model_roadway_net","title":"network_wrangler.transit.model_transit.ModelTransit.model_roadway_net  <code>property</code>","text":"<pre><code>model_roadway_net\n</code></pre> <p>ModelRoadwayNetwork associated with this ModelTransit.</p>"},{"location":"api_transit/#network_wrangler.transit.model_transit.ModelTransit.__init__","title":"network_wrangler.transit.model_transit.ModelTransit.__init__","text":"<pre><code>__init__(transit_net, roadway_net, shift_transit_to_managed_lanes=True)\n</code></pre> <p>ModelTransit class for managing consistency between roadway and transit networks.</p> Source code in <code>network_wrangler/transit/model_transit.py</code> <pre><code>def __init__(\n    self,\n    transit_net: TransitNetwork,\n    roadway_net: RoadwayNetwork,\n    shift_transit_to_managed_lanes: bool = True,\n):\n    \"\"\"ModelTransit class for managing consistency between roadway and transit networks.\"\"\"\n    self.transit_net = transit_net\n    self.roadway_net = roadway_net\n    self._roadway_net_hash = None\n    self._transit_feed_hash = None\n    self._transit_shifted_to_ML = shift_transit_to_managed_lanes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection","title":"network_wrangler.transit.selection.TransitSelection","text":"<p>Object to perform and store information about a selection from a project card \u201cfacility\u201d.</p> <p>Attributes:</p> <ul> <li> <code>selection_dict</code>           \u2013            </li> <li> <code>selected_trips</code>               (<code>list</code>)           \u2013            </li> <li> <code>selected_trips_df</code>               (<code>DataFrame[WranglerTripsTable]</code>)           \u2013            <p>pd.DataFrame: DataFrame of selected trips</p> </li> <li> <code>sel_key</code>           \u2013            </li> <li> <code>net</code>           \u2013            </li> </ul> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>class TransitSelection:\n    \"\"\"Object to perform and store information about a selection from a project card \"facility\".\n\n    Attributes:\n        selection_dict: dict: Dictionary of selection criteria\n        selected_trips: list: List of selected trips\n        selected_trips_df: pd.DataFrame: DataFrame of selected trips\n        sel_key: str: Hash of selection_dict\n        net: TransitNetwork: Network to select from\n    \"\"\"\n\n    def __init__(\n        self,\n        net: TransitNetwork,\n        selection_dict: Union[dict, SelectTransitTrips],\n    ):\n        \"\"\"Constructor for TransitSelection object.\n\n        Args:\n            net (TransitNetwork): Transit network object to select from.\n            selection_dict: Selection dictionary conforming to SelectTransitTrips\n        \"\"\"\n        self.net = net\n        self.selection_dict = selection_dict\n\n        # Initialize\n        self._selected_trips_df = None\n        self.sel_key = dict_to_hexkey(selection_dict)\n        self._stored_feed_hash = copy.deepcopy(self.net.feed.hash)\n\n        WranglerLogger.debug(f\"...created TransitSelection object: {selection_dict}\")\n\n    def __nonzero__(self):\n        \"\"\"Return True if there are selected trips.\"\"\"\n        return len(self.selected_trips_df) &gt; 0\n\n    @property\n    def selection_dict(self):\n        \"\"\"Getter for selection_dict.\"\"\"\n        return self._selection_dict\n\n    @selection_dict.setter\n    def selection_dict(self, value: Union[dict, SelectTransitTrips]):\n        self._selection_dict = self.validate_selection_dict(value)\n\n    def validate_selection_dict(self, selection_dict: Union[dict, SelectTransitTrips]) -&gt; dict:\n        \"\"\"Check that selection dictionary has valid and used properties consistent with network.\n\n        Checks that selection_dict is a valid TransitSelectionDict:\n            - query vars exist in respective Feed tables\n        Args:\n            selection_dict (dict): selection dictionary\n\n        Raises:\n            TransitSelectionNetworkConsistencyError: If not consistent with transit network\n            ValidationError: if format not consistent with SelectTransitTrips\n        \"\"\"\n        if not isinstance(selection_dict, SelectTransitTrips):\n            selection_dict = SelectTransitTrips(**selection_dict)\n        selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n        WranglerLogger.debug(f\"SELECT DICT - before Validation: \\n{selection_dict}\")\n        _trip_selection_fields = list((selection_dict.get(\"trip_properties\", {}) or {}).keys())\n        _missing_trip_fields = set(_trip_selection_fields) - set(self.net.feed.trips.columns)\n\n        if _missing_trip_fields:\n            msg = f\"Fields in trip selection dictionary but not trips.txt: {_missing_trip_fields}\"\n            raise TransitSelectionNetworkConsistencyError(msg)\n\n        _route_selection_fields = list((selection_dict.get(\"route_properties\", {}) or {}).keys())\n        _missing_route_fields = set(_route_selection_fields) - set(self.net.feed.routes.columns)\n\n        if _missing_route_fields:\n            msg = (\n                f\"Fields in route selection dictionary but not routes.txt: {_missing_route_fields}\"\n            )\n            raise TransitSelectionNetworkConsistencyError(msg)\n        return selection_dict\n\n    @property\n    def selected_trips(self) -&gt; list:\n        \"\"\"List of selected trip_ids.\"\"\"\n        if self.selected_trips_df is None:\n            return []\n        return self.selected_trips_df.trip_id.tolist()\n\n    @property\n    def selected_trips_df(self) -&gt; DataFrame[WranglerTripsTable]:\n        \"\"\"Lazily evaluates selection for trips or returns stored value in self._selected_trips_df.\n\n        Will re-evaluate if the current network hash is different than the stored one from the\n        last selection.\n\n        Returns:\n            DataFrame[WranglerTripsTable] of selected trips\n        \"\"\"\n        if (self._selected_trips_df is not None) and self._stored_feed_hash == self.net.feed_hash:\n            return self._selected_trips_df\n\n        self._selected_trips_df = self._select_trips()\n        self._stored_feed_hash = copy.deepcopy(self.net.feed_hash)\n        return self._selected_trips_df\n\n    @property\n    def selected_frequencies_df(self) -&gt; DataFrame[WranglerFrequenciesTable]:\n        \"\"\"DataFrame of selected frequencies.\"\"\"\n        sel_freq_df = self.net.feed.frequencies.loc[\n            self.net.feed.frequencies.trip_id.isin(self.selected_trips_df.trip_id)\n        ]\n        # if timespans are selected, filter to those that overlap\n        if self.selection_dict.get(\"timespans\"):\n            sel_freq_df = filter_df_to_overlapping_timespans(\n                sel_freq_df, self.selection_dict.get(\"timespans\")\n            )\n        return sel_freq_df\n\n    @property\n    def selected_shapes_df(self) -&gt; DataFrame[WranglerShapesTable]:\n        \"\"\"DataFrame of selected shapes.\n\n        Can visualize the selected shapes quickly using the following code:\n\n        ```python\n        all_routes = net.feed.shapes.plot(color=\"gray\")\n        selection.selected_shapes_df.plot(ax=all_routes, color=\"red\")\n        ```\n\n        \"\"\"\n        return self.net.feed.shapes.loc[\n            self.net.feed.shapes.shape_id.isin(self.selected_trips_df.shape_id)\n        ]\n\n    def _select_trips(self) -&gt; DataFrame[WranglerTripsTable]:\n        \"\"\"Selects transit trips based on selection dictionary.\n\n        Returns:\n            DataFrame[WranglerTripsTable]: trips_df DataFrame of selected trips\n        \"\"\"\n        return _filter_trips_by_selection_dict(\n            self.net.feed,\n            self.selection_dict,\n        )\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.selected_frequencies_df","title":"network_wrangler.transit.selection.TransitSelection.selected_frequencies_df  <code>property</code>","text":"<pre><code>selected_frequencies_df\n</code></pre> <p>DataFrame of selected frequencies.</p>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.selected_shapes_df","title":"network_wrangler.transit.selection.TransitSelection.selected_shapes_df  <code>property</code>","text":"<pre><code>selected_shapes_df\n</code></pre> <p>DataFrame of selected shapes.</p> <p>Can visualize the selected shapes quickly using the following code:</p> <pre><code>all_routes = net.feed.shapes.plot(color=\"gray\")\nselection.selected_shapes_df.plot(ax=all_routes, color=\"red\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.selected_trips","title":"network_wrangler.transit.selection.TransitSelection.selected_trips  <code>property</code>","text":"<pre><code>selected_trips\n</code></pre> <p>List of selected trip_ids.</p>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.selected_trips_df","title":"network_wrangler.transit.selection.TransitSelection.selected_trips_df  <code>property</code>","text":"<pre><code>selected_trips_df\n</code></pre> <p>Lazily evaluates selection for trips or returns stored value in self._selected_trips_df.</p> <p>Will re-evaluate if the current network hash is different than the stored one from the last selection.</p> <p>Returns:</p> <ul> <li> <code>DataFrame[WranglerTripsTable]</code>           \u2013            <p>DataFrame[WranglerTripsTable] of selected trips</p> </li> </ul>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.selection_dict","title":"network_wrangler.transit.selection.TransitSelection.selection_dict  <code>property</code> <code>writable</code>","text":"<pre><code>selection_dict\n</code></pre> <p>Getter for selection_dict.</p>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.__init__","title":"network_wrangler.transit.selection.TransitSelection.__init__","text":"<pre><code>__init__(net, selection_dict)\n</code></pre> <p>Constructor for TransitSelection object.</p> <p>Parameters:</p> <ul> <li> <code>net</code>               (<code>TransitNetwork</code>)           \u2013            <p>Transit network object to select from.</p> </li> <li> <code>selection_dict</code>               (<code>Union[dict, SelectTransitTrips]</code>)           \u2013            <p>Selection dictionary conforming to SelectTransitTrips</p> </li> </ul> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>def __init__(\n    self,\n    net: TransitNetwork,\n    selection_dict: Union[dict, SelectTransitTrips],\n):\n    \"\"\"Constructor for TransitSelection object.\n\n    Args:\n        net (TransitNetwork): Transit network object to select from.\n        selection_dict: Selection dictionary conforming to SelectTransitTrips\n    \"\"\"\n    self.net = net\n    self.selection_dict = selection_dict\n\n    # Initialize\n    self._selected_trips_df = None\n    self.sel_key = dict_to_hexkey(selection_dict)\n    self._stored_feed_hash = copy.deepcopy(self.net.feed.hash)\n\n    WranglerLogger.debug(f\"...created TransitSelection object: {selection_dict}\")\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.__nonzero__","title":"network_wrangler.transit.selection.TransitSelection.__nonzero__","text":"<pre><code>__nonzero__()\n</code></pre> <p>Return True if there are selected trips.</p> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>def __nonzero__(self):\n    \"\"\"Return True if there are selected trips.\"\"\"\n    return len(self.selected_trips_df) &gt; 0\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.selection.TransitSelection.validate_selection_dict","title":"network_wrangler.transit.selection.TransitSelection.validate_selection_dict","text":"<pre><code>validate_selection_dict(selection_dict)\n</code></pre> <p>Check that selection dictionary has valid and used properties consistent with network.</p> Checks that selection_dict is a valid TransitSelectionDict <ul> <li>query vars exist in respective Feed tables</li> </ul> <p>Raises:</p> <ul> <li> <code>TransitSelectionNetworkConsistencyError</code>             \u2013            <p>If not consistent with transit network</p> </li> <li> <code>ValidationError</code>             \u2013            <p>if format not consistent with SelectTransitTrips</p> </li> </ul> Source code in <code>network_wrangler/transit/selection.py</code> <pre><code>def validate_selection_dict(self, selection_dict: Union[dict, SelectTransitTrips]) -&gt; dict:\n    \"\"\"Check that selection dictionary has valid and used properties consistent with network.\n\n    Checks that selection_dict is a valid TransitSelectionDict:\n        - query vars exist in respective Feed tables\n    Args:\n        selection_dict (dict): selection dictionary\n\n    Raises:\n        TransitSelectionNetworkConsistencyError: If not consistent with transit network\n        ValidationError: if format not consistent with SelectTransitTrips\n    \"\"\"\n    if not isinstance(selection_dict, SelectTransitTrips):\n        selection_dict = SelectTransitTrips(**selection_dict)\n    selection_dict = selection_dict.model_dump(exclude_none=True, by_alias=True)\n    WranglerLogger.debug(f\"SELECT DICT - before Validation: \\n{selection_dict}\")\n    _trip_selection_fields = list((selection_dict.get(\"trip_properties\", {}) or {}).keys())\n    _missing_trip_fields = set(_trip_selection_fields) - set(self.net.feed.trips.columns)\n\n    if _missing_trip_fields:\n        msg = f\"Fields in trip selection dictionary but not trips.txt: {_missing_trip_fields}\"\n        raise TransitSelectionNetworkConsistencyError(msg)\n\n    _route_selection_fields = list((selection_dict.get(\"route_properties\", {}) or {}).keys())\n    _missing_route_fields = set(_route_selection_fields) - set(self.net.feed.routes.columns)\n\n    if _missing_route_fields:\n        msg = (\n            f\"Fields in route selection dictionary but not routes.txt: {_missing_route_fields}\"\n        )\n        raise TransitSelectionNetworkConsistencyError(msg)\n    return selection_dict\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.validate.shape_links_without_road_links","title":"network_wrangler.transit.validate.shape_links_without_road_links","text":"<pre><code>shape_links_without_road_links(tr_shapes, rd_links_df)\n</code></pre> <p>Validate that links in transit shapes exist in referenced roadway links.</p> <p>Parameters:</p> <ul> <li> <code>tr_shapes</code>               (<code>DataFrame[WranglerShapesTable]</code>)           \u2013            <p>transit shapes from shapes.txt to validate foreign key to.</p> </li> <li> <code>rd_links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>Links dataframe from roadway network to validate</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>df with shape_id and A, B</p> </li> </ul> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def shape_links_without_road_links(\n    tr_shapes: DataFrame[WranglerShapesTable],\n    rd_links_df: DataFrame[RoadLinksTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Validate that links in transit shapes exist in referenced roadway links.\n\n    Args:\n        tr_shapes: transit shapes from shapes.txt to validate foreign key to.\n        rd_links_df: Links dataframe from roadway network to validate\n\n    Returns:\n        df with shape_id and A, B\n    \"\"\"\n    tr_shape_links = unique_shape_links(tr_shapes)\n    # WranglerLogger.debug(f\"Unique shape links: \\n {tr_shape_links}\")\n    rd_links_transit_ok = rd_links_df[\n        (rd_links_df[\"drive_access\"]) | (rd_links_df[\"bus_only\"]) | (rd_links_df[\"rail_only\"])\n    ]\n\n    merged_df = tr_shape_links.merge(\n        rd_links_transit_ok[[\"A\", \"B\"]],\n        how=\"left\",\n        on=[\"A\", \"B\"],\n        indicator=True,\n    )\n\n    missing_links_df = merged_df.loc[merged_df._merge == \"left_only\", [\"shape_id\", \"A\", \"B\"]]\n    if len(missing_links_df):\n        WranglerLogger.error(\n            f\"! Transit shape links missing in roadway network: \\n {missing_links_df}\"\n        )\n    return missing_links_df[[\"shape_id\", \"A\", \"B\"]]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.validate.stop_times_without_road_links","title":"network_wrangler.transit.validate.stop_times_without_road_links","text":"<pre><code>stop_times_without_road_links(tr_stop_times, rd_links_df)\n</code></pre> <p>Validate that links in transit shapes exist in referenced roadway links.</p> <p>Parameters:</p> <ul> <li> <code>tr_stop_times</code>               (<code>DataFrame[WranglerStopTimesTable]</code>)           \u2013            <p>transit stop_times from stop_times.txt to validate foreign key to.</p> </li> <li> <code>rd_links_df</code>               (<code>DataFrame[RoadLinksTable]</code>)           \u2013            <p>Links dataframe from roadway network to validate</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>df with shape_id and A, B</p> </li> </ul> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def stop_times_without_road_links(\n    tr_stop_times: DataFrame[WranglerStopTimesTable],\n    rd_links_df: DataFrame[RoadLinksTable],\n) -&gt; pd.DataFrame:\n    \"\"\"Validate that links in transit shapes exist in referenced roadway links.\n\n    Args:\n        tr_stop_times: transit stop_times from stop_times.txt to validate foreign key to.\n        rd_links_df: Links dataframe from roadway network to validate\n\n    Returns:\n        df with shape_id and A, B\n    \"\"\"\n    tr_links = unique_stop_time_links(tr_stop_times)\n\n    rd_links_transit_ok = rd_links_df[\n        (rd_links_df[\"drive_access\"]) | (rd_links_df[\"bus_only\"]) | (rd_links_df[\"rail_only\"])\n    ]\n\n    merged_df = tr_links.merge(\n        rd_links_transit_ok[[\"A\", \"B\"]],\n        how=\"left\",\n        on=[\"A\", \"B\"],\n        indicator=True,\n    )\n\n    missing_links_df = merged_df.loc[merged_df._merge == \"left_only\", [\"trip_id\", \"A\", \"B\"]]\n    if len(missing_links_df):\n        WranglerLogger.error(\n            f\"! Transit stop_time links missing in roadway network: \\n {missing_links_df}\"\n        )\n    return missing_links_df[[\"trip_id\", \"A\", \"B\"]]\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.validate.transit_nodes_without_road_nodes","title":"network_wrangler.transit.validate.transit_nodes_without_road_nodes","text":"<pre><code>transit_nodes_without_road_nodes(feed, nodes_df, rd_field='model_node_id')\n</code></pre> <p>Validate all of a transit feeds node foreign keys exist in referenced roadway nodes.</p> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Feed</code>)           \u2013            <p>Transit Feed to query.</p> </li> <li> <code>nodes_df</code>               (<code>DataFrame</code>)           \u2013            <p>Nodes dataframe from roadway network to validate foreign key to. Defaults to self.roadway_net.nodes_df</p> </li> <li> <code>rd_field</code>               (<code>str</code>, default:                   <code>'model_node_id'</code> )           \u2013            <p>field in roadway nodes to check against. Defaults to \u201cmodel_node_id\u201d</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[int]</code>           \u2013            <p>boolean indicating if relationships are all valid</p> </li> </ul> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def transit_nodes_without_road_nodes(\n    feed: Feed,\n    nodes_df: DataFrame[RoadNodesTable],\n    rd_field: str = \"model_node_id\",\n) -&gt; list[int]:\n    \"\"\"Validate all of a transit feeds node foreign keys exist in referenced roadway nodes.\n\n    Args:\n        feed: Transit Feed to query.\n        nodes_df (pd.DataFrame, optional): Nodes dataframe from roadway network to validate\n            foreign key to. Defaults to self.roadway_net.nodes_df\n        rd_field: field in roadway nodes to check against. Defaults to \"model_node_id\"\n\n    Returns:\n        boolean indicating if relationships are all valid\n    \"\"\"\n    feed_nodes_series = [\n        feed.stops[\"stop_id\"],\n        feed.shapes[\"shape_model_node_id\"],\n        feed.stop_times[\"stop_id\"],\n    ]\n    tr_nodes = set(concat_with_attr(feed_nodes_series).unique())\n    rd_nodes = set(nodes_df[rd_field].unique().tolist())\n    # nodes in tr_nodes but not rd_nodes\n    missing_tr_nodes = list(tr_nodes - rd_nodes)\n\n    if missing_tr_nodes:\n        WranglerLogger.error(\n            f\"! Transit nodes in missing in roadway network: \\n {missing_tr_nodes}\"\n        )\n    return missing_tr_nodes\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.validate.transit_road_net_consistency","title":"network_wrangler.transit.validate.transit_road_net_consistency","text":"<pre><code>transit_road_net_consistency(feed, road_net)\n</code></pre> <p>Checks foreign key and network link relationships between transit feed and a road_net.</p> <p>Parameters:</p> <ul> <li> <code>feed</code>               (<code>Feed</code>)           \u2013            <p>Transit Feed.</p> </li> <li> <code>road_net</code>               (<code>RoadwayNetwork</code>)           \u2013            <p>Roadway network to check relationship with.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>boolean indicating if road_net is consistent with transit network.</p> </li> </ul> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def transit_road_net_consistency(feed: Feed, road_net: RoadwayNetwork) -&gt; bool:\n    \"\"\"Checks foreign key and network link relationships between transit feed and a road_net.\n\n    Args:\n        feed: Transit Feed.\n        road_net (RoadwayNetwork): Roadway network to check relationship with.\n\n    Returns:\n        bool: boolean indicating if road_net is consistent with transit network.\n    \"\"\"\n    _missing_links = shape_links_without_road_links(feed.shapes, road_net.links_df)\n    _missing_nodes = transit_nodes_without_road_nodes(feed, road_net.nodes_df)\n    _consistency = _missing_links.empty and not _missing_nodes\n    return _consistency\n</code></pre>"},{"location":"api_transit/#network_wrangler.transit.validate.validate_transit_in_dir","title":"network_wrangler.transit.validate.validate_transit_in_dir","text":"<pre><code>validate_transit_in_dir(dir, file_format='txt', road_dir=None, road_file_format='geojson')\n</code></pre> <p>Validates a roadway network in a directory to the wrangler data model specifications.</p> <p>Parameters:</p> <ul> <li> <code>dir</code>               (<code>Path</code>)           \u2013            <p>The transit network file directory.</p> </li> <li> <code>file_format</code>               (<code>str</code>, default:                   <code>'txt'</code> )           \u2013            <p>The format of roadway network file name. Defaults to \u201ctxt\u201d.</p> </li> <li> <code>road_dir</code>               (<code>Path</code>, default:                   <code>None</code> )           \u2013            <p>The roadway network file directory. Defaults to None.</p> </li> <li> <code>road_file_format</code>               (<code>str</code>, default:                   <code>'geojson'</code> )           \u2013            <p>The format of roadway network file name. Defaults to \u201cgeojson\u201d.</p> </li> <li> <code>output_dir</code>               (<code>str</code>)           \u2013            <p>The output directory for the validation report. Defaults to \u201c.\u201d.</p> </li> </ul> Source code in <code>network_wrangler/transit/validate.py</code> <pre><code>def validate_transit_in_dir(\n    dir: Path,\n    file_format: TransitFileTypes = \"txt\",\n    road_dir: Optional[Path] = None,\n    road_file_format: RoadwayFileTypes = \"geojson\",\n) -&gt; bool:\n    \"\"\"Validates a roadway network in a directory to the wrangler data model specifications.\n\n    Args:\n        dir (Path): The transit network file directory.\n        file_format (str): The format of roadway network file name. Defaults to \"txt\".\n        road_dir (Path): The roadway network file directory. Defaults to None.\n        road_file_format (str): The format of roadway network file name. Defaults to \"geojson\".\n        output_dir (str): The output directory for the validation report. Defaults to \".\".\n    \"\"\"\n    from .io import load_transit  # noqa: PLC0415\n\n    try:\n        t = load_transit(dir, file_format=file_format)\n    except SchemaErrors as e:\n        WranglerLogger.error(f\"!!! [Transit Network invalid] - Failed Loading to Feed object\\n{e}\")\n        return False\n    if road_dir is not None:\n        from ..roadway import load_roadway_from_dir  # noqa: PLC0415\n        from .network import TransitRoadwayConsistencyError  # noqa: PLC0415\n\n        try:\n            r = load_roadway_from_dir(road_dir, file_format=road_file_format)\n        except FileNotFoundError:\n            WranglerLogger.error(f\"! Roadway network not found in {road_dir}\")\n            return False\n        except Exception as e:\n            WranglerLogger.error(\n                f\"! Error loading roadway network. \\\n                                 Skipping validation of road to transit network.\\n{e}\"\n            )\n        try:\n            t.road_net = r\n        except TransitRoadwayConsistencyError as e:\n            WranglerLogger.error(\n                f\"!!! [Tranit Network inconsistent] Error in road to transit \\\n                                 network consistency.\\n{e}\"\n            )\n            return False\n\n    return True\n</code></pre>"},{"location":"api_utils/","title":"Utilities","text":"<p>Utility functions and helper classes used throughout Network Wrangler.</p>"},{"location":"api_utils/#core-utilities","title":"Core Utilities","text":"<p>General utility functions used throughout package.</p>"},{"location":"api_utils/#network_wrangler.utils.utils.DictionaryMergeError","title":"network_wrangler.utils.utils.DictionaryMergeError","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when there is a conflict in merging two dictionaries.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>class DictionaryMergeError(Exception):\n    \"\"\"Error raised when there is a conflict in merging two dictionaries.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.check_one_or_one_superset_present","title":"network_wrangler.utils.utils.check_one_or_one_superset_present","text":"<pre><code>check_one_or_one_superset_present(mixed_list, all_fields_present)\n</code></pre> <p>Checks that exactly one of the fields in mixed_list is in fields_present or one superset.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def check_one_or_one_superset_present(\n    mixed_list: list[Union[str, list[str]]], all_fields_present: list[str]\n) -&gt; bool:\n    \"\"\"Checks that exactly one of the fields in mixed_list is in fields_present or one superset.\"\"\"\n    normalized_list = normalize_to_lists(mixed_list)\n\n    list_items_present = [i for i in normalized_list if set(i).issubset(all_fields_present)]\n\n    if len(list_items_present) == 1:\n        return True\n\n    return list_elements_subset_of_single_element(list_items_present)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.combine_unique_unhashable_list","title":"network_wrangler.utils.utils.combine_unique_unhashable_list","text":"<pre><code>combine_unique_unhashable_list(list1, list2)\n</code></pre> <p>Combines lists preserving order of first and removing duplicates.</p> <p>Parameters:</p> <ul> <li> <code>list1</code>               (<code>list</code>)           \u2013            <p>The first list.</p> </li> <li> <code>list2</code>               (<code>list</code>)           \u2013            <p>The second list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>          \u2013            <p>A new list containing the elements from list1 followed by the</p> </li> <li>           \u2013            <p>unique elements from list2.</p> </li> </ul> Example <p>list1 = [1, 2, 3] list2 = [2, 3, 4, 5] combine_unique_unhashable_list(list1, list2) [1, 2, 3, 4, 5]</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def combine_unique_unhashable_list(list1: list, list2: list):\n    \"\"\"Combines lists preserving order of first and removing duplicates.\n\n    Args:\n        list1 (list): The first list.\n        list2 (list): The second list.\n\n    Returns:\n        list: A new list containing the elements from list1 followed by the\n        unique elements from list2.\n\n    Example:\n        &gt;&gt;&gt; list1 = [1, 2, 3]\n        &gt;&gt;&gt; list2 = [2, 3, 4, 5]\n        &gt;&gt;&gt; combine_unique_unhashable_list(list1, list2)\n        [1, 2, 3, 4, 5]\n    \"\"\"\n    return [item for item in list1 if item not in list2] + list2\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.delete_keys_from_dict","title":"network_wrangler.utils.utils.delete_keys_from_dict","text":"<pre><code>delete_keys_from_dict(dictionary, keys)\n</code></pre> <p>Removes list of keys from potentially nested dictionary.</p> <p>SOURCE: https://stackoverflow.com/questions/3405715/ User: @mseifert</p> <p>Parameters:</p> <ul> <li> <code>dictionary</code>               (<code>dict</code>)           \u2013            <p>dictionary to remove keys from</p> </li> <li> <code>keys</code>               (<code>list</code>)           \u2013            <p>list of keys to remove</p> </li> </ul> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def delete_keys_from_dict(dictionary: dict, keys: list) -&gt; dict:\n    \"\"\"Removes list of keys from potentially nested dictionary.\n\n    SOURCE: https://stackoverflow.com/questions/3405715/\n    User: @mseifert\n\n    Args:\n        dictionary: dictionary to remove keys from\n        keys: list of keys to remove\n\n    \"\"\"\n    keys_set = list(set(keys))  # Just an optimization for the \"if key in keys\" lookup.\n\n    modified_dict = {}\n    for key, value in dictionary.items():\n        if key not in keys_set:\n            if isinstance(value, dict):\n                modified_dict[key] = delete_keys_from_dict(value, keys_set)\n            else:\n                modified_dict[key] = (\n                    value  # or copy.deepcopy(value) if a copy is desired for non-dicts.\n                )\n    return modified_dict\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.dict_to_hexkey","title":"network_wrangler.utils.utils.dict_to_hexkey","text":"<pre><code>dict_to_hexkey(d)\n</code></pre> <p>Converts a dictionary to a hexdigest of the sha1 hash of the dictionary.</p> <p>Parameters:</p> <ul> <li> <code>d</code>               (<code>dict</code>)           \u2013            <p>dictionary to convert to string</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>hexdigest of the sha1 hash of dictionary</p> </li> </ul> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def dict_to_hexkey(d: dict) -&gt; str:\n    \"\"\"Converts a dictionary to a hexdigest of the sha1 hash of the dictionary.\n\n    Args:\n        d (dict): dictionary to convert to string\n\n    Returns:\n        str: hexdigest of the sha1 hash of dictionary\n    \"\"\"\n    return hashlib.sha1(str(d).encode()).hexdigest()\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.findkeys","title":"network_wrangler.utils.utils.findkeys","text":"<pre><code>findkeys(node, kv)\n</code></pre> <p>Returns values of all keys in various objects.</p> <p>Adapted from arainchi on Stack Overflow: https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def findkeys(node, kv):\n    \"\"\"Returns values of all keys in various objects.\n\n    Adapted from arainchi on Stack Overflow:\n    https://stackoverflow.com/questions/9807634/find-all-occurrences-of-a-key-in-nested-dictionaries-and-lists\n    \"\"\"\n    if isinstance(node, list):\n        for i in node:\n            for x in findkeys(i, kv):\n                yield x\n    elif isinstance(node, dict):\n        if kv in node:\n            yield node[kv]\n        for j in node.values():\n            for x in findkeys(j, kv):\n                yield x\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.get_overlapping_range","title":"network_wrangler.utils.utils.get_overlapping_range","text":"<pre><code>get_overlapping_range(ranges)\n</code></pre> <p>Returns the overlapping range for a list of ranges or tuples defining ranges.</p> <p>Parameters:</p> <ul> <li> <code>ranges</code>               (<code>list[Union[tuple[int], range]]</code>)           \u2013            <p>A list of ranges or tuples defining ranges.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[None, range]</code>           \u2013            <p>Union[None, range]: The overlapping range if found, otherwise None.</p> </li> </ul> Example <p>ranges = [(1, 5), (3, 7), (6, 10)] get_overlapping_range(ranges) range(3, 5)</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def get_overlapping_range(ranges: list[Union[tuple[int, int], range]]) -&gt; Union[None, range]:\n    \"\"\"Returns the overlapping range for a list of ranges or tuples defining ranges.\n\n    Args:\n        ranges (list[Union[tuple[int], range]]): A list of ranges or tuples defining ranges.\n\n    Returns:\n        Union[None, range]: The overlapping range if found, otherwise None.\n\n    Example:\n        &gt;&gt;&gt; ranges = [(1, 5), (3, 7), (6, 10)]\n        &gt;&gt;&gt; get_overlapping_range(ranges)\n        range(3, 5)\n\n    \"\"\"\n    # check that any tuples have two values\n    if any(isinstance(r, tuple) and len(r) != 2 for r in ranges):  # noqa: PLR2004\n        msg = \"Tuple ranges must have two values.\"\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n\n    _ranges = [r if isinstance(r, range) else range(r[0], r[1]) for r in ranges]\n\n    _overlap_start = max(r.start for r in _ranges)\n    _overlap_end = min(r.stop for r in _ranges)\n\n    if _overlap_start &lt; _overlap_end:\n        return range(_overlap_start, _overlap_end)\n    return None\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.list_elements_subset_of_single_element","title":"network_wrangler.utils.utils.list_elements_subset_of_single_element","text":"<pre><code>list_elements_subset_of_single_element(mixed_list)\n</code></pre> <p>Find the first list in the mixed_list.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>@validate_call\ndef list_elements_subset_of_single_element(mixed_list: list[Union[str, list[str]]]) -&gt; bool:\n    \"\"\"Find the first list in the mixed_list.\"\"\"\n    potential_supersets = []\n    for item in mixed_list:\n        if isinstance(item, list) and len(item) &gt; 0:\n            potential_supersets.append(set(item))\n\n    # If no list is found, return False\n    if not potential_supersets:\n        return False\n\n    normalized_list = normalize_to_lists(mixed_list)\n\n    valid_supersets = []\n    for ss in potential_supersets:\n        if all(ss.issuperset(i) for i in normalized_list):\n            valid_supersets.append(ss)\n\n    return len(valid_supersets) == 1\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.make_slug","title":"network_wrangler.utils.utils.make_slug","text":"<pre><code>make_slug(text, delimiter='_')\n</code></pre> <p>Makes a slug from text.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def make_slug(text: str, delimiter: str = \"_\") -&gt; str:\n    \"\"\"Makes a slug from text.\"\"\"\n    text = re.sub(\"[,.;@#?!&amp;$']+\", \"\", text.lower())\n    return re.sub(\"[\\ ]+\", delimiter, text)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.merge_dicts","title":"network_wrangler.utils.utils.merge_dicts","text":"<pre><code>merge_dicts(right, left, path=None)\n</code></pre> <p>Merges the contents of nested dict left into nested dict right.</p> <p>Raises errors in case of namespace conflicts.</p> <p>Parameters:</p> <ul> <li> <code>right</code>           \u2013            <p>dict, modified in place</p> </li> <li> <code>left</code>           \u2013            <p>dict to be merged into right</p> </li> <li> <code>path</code>           \u2013            <p>default None, sequence of keys to be reported in case of error in merging nested dictionaries</p> </li> </ul> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def merge_dicts(right, left, path=None):\n    \"\"\"Merges the contents of nested dict left into nested dict right.\n\n    Raises errors in case of namespace conflicts.\n\n    Args:\n        right: dict, modified in place\n        left: dict to be merged into right\n        path: default None, sequence of keys to be reported in case of\n            error in merging nested dictionaries\n    \"\"\"\n    if path is None:\n        path = []\n    for key in left:\n        if key in right:\n            if isinstance(right[key], dict) and isinstance(left[key], dict):\n                merge_dicts(right[key], left[key], [*path, str(key)])\n            else:\n                path = \".\".join([*path, str(key)])\n                msg = f\"duplicate keys in source dict files: {path}\"\n                WranglerLogger.error(msg)\n                raise DictionaryMergeError(msg)\n        else:\n            right[key] = left[key]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.normalize_to_lists","title":"network_wrangler.utils.utils.normalize_to_lists","text":"<pre><code>normalize_to_lists(mixed_list)\n</code></pre> <p>Turn a mixed list of scalars and lists into a list of lists.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def normalize_to_lists(mixed_list: list[Union[str, list]]) -&gt; list[list]:\n    \"\"\"Turn a mixed list of scalars and lists into a list of lists.\"\"\"\n    normalized_list = []\n    for item in mixed_list:\n        if isinstance(item, str):\n            normalized_list.append([item])\n        else:\n            normalized_list.append(item)\n    return normalized_list\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.split_string_prefix_suffix_from_num","title":"network_wrangler.utils.utils.split_string_prefix_suffix_from_num","text":"<pre><code>split_string_prefix_suffix_from_num(input_string)\n</code></pre> <p>Split a string prefix and suffix from last number.</p> <p>Parameters:</p> <ul> <li> <code>input_string</code>               (<code>str</code>)           \u2013            <p>The input string to be processed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code>          \u2013            <p>A tuple containing the prefix (including preceding numbers),    the last numeric part as an integer, and the suffix.</p> </li> </ul> Notes <p>This function uses regular expressions to split a string into three parts: the prefix, the last numeric part, and the suffix. The prefix includes any preceding numbers, the last numeric part is converted to an integer, and the suffix includes any non-digit characters after the last numeric part.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"abc123def456\")\n('abc', 123, 'def456')\n</code></pre> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"hello\")\n('hello', 0, '')\n</code></pre> <pre><code>&gt;&gt;&gt; split_string_prefix_suffix_from_num(\"123\")\n('', 123, '')\n</code></pre> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def split_string_prefix_suffix_from_num(input_string: str):\n    \"\"\"Split a string prefix and suffix from *last* number.\n\n    Args:\n        input_string (str): The input string to be processed.\n\n    Returns:\n        tuple: A tuple containing the prefix (including preceding numbers),\n               the last numeric part as an integer, and the suffix.\n\n    Notes:\n        This function uses regular expressions to split a string into three parts:\n        the prefix, the last numeric part, and the suffix. The prefix includes any\n        preceding numbers, the last numeric part is converted to an integer, and\n        the suffix includes any non-digit characters after the last numeric part.\n\n    Examples:\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"abc123def456\")\n        ('abc', 123, 'def456')\n\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"hello\")\n        ('hello', 0, '')\n\n        &gt;&gt;&gt; split_string_prefix_suffix_from_num(\"123\")\n        ('', 123, '')\n\n    \"\"\"\n    input_string = str(input_string)\n    pattern = re.compile(r\"(.*?)(\\d+)(\\D*)$\")\n    match = pattern.match(input_string)\n\n    if match:\n        # Extract the groups: prefix (including preceding numbers), last numeric part, suffix\n        prefix, numeric_part, suffix = match.groups()\n        # Convert the numeric part to an integer\n        num_variable = int(numeric_part)\n        return prefix, num_variable, suffix\n    return input_string, 0, \"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.utils.topological_sort","title":"network_wrangler.utils.utils.topological_sort","text":"<pre><code>topological_sort(adjacency_list, visited_list)\n</code></pre> <p>Topological sorting for Acyclic Directed Graph.</p> <p>Parameters: - adjacency_list (dict): A dictionary representing the adjacency list of the graph. - visited_list (list): A list representing the visited status of each vertex in the graph.</p> <p>Returns: - output_stack (list): A list containing the vertices in topological order.</p> <p>This function performs a topological sort on an acyclic directed graph. It takes an adjacency list and a visited list as input. The adjacency list represents the connections between vertices in the graph, and the visited list keeps track of the visited status of each vertex.</p> <p>The function uses a recursive helper function to perform the topological sort. It starts by iterating over each vertex in the visited list. For each unvisited vertex, it calls the helper function, which recursively visits all the neighbors of the vertex and adds them to the output stack in reverse order. Finally, it returns the output stack, which contains the vertices in topological order.</p> Source code in <code>network_wrangler/utils/utils.py</code> <pre><code>def topological_sort(adjacency_list, visited_list):\n    \"\"\"Topological sorting for Acyclic Directed Graph.\n\n    Parameters:\n    - adjacency_list (dict): A dictionary representing the adjacency list of the graph.\n    - visited_list (list): A list representing the visited status of each vertex in the graph.\n\n    Returns:\n    - output_stack (list): A list containing the vertices in topological order.\n\n    This function performs a topological sort on an acyclic directed graph. It takes an adjacency\n    list and a visited list as input. The adjacency list represents the connections between\n    vertices in the graph, and the visited list keeps track of the visited status of each vertex.\n\n    The function uses a recursive helper function to perform the topological sort. It starts by\n    iterating over each vertex in the visited list. For each unvisited vertex, it calls the helper\n    function, which recursively visits all the neighbors of the vertex and adds them to the output\n    stack in reverse order. Finally, it returns the output stack, which contains the vertices in\n    topological order.\n    \"\"\"\n    output_stack = []\n\n    def _topology_sort_util(vertex):\n        if not visited_list[vertex]:\n            visited_list[vertex] = True\n            for neighbor in adjacency_list[vertex]:\n                _topology_sort_util(neighbor)\n            output_stack.insert(0, vertex)\n\n    for vertex in visited_list:\n        _topology_sort_util(vertex)\n\n    return output_stack\n</code></pre>"},{"location":"api_utils/#package-constants","title":"Package Constants","text":"<p>Parameters for Network Wrangler which should not be changed by the user.</p> <p>Parameters that are here are used throughout the codebase and are stated here for easy reference. Additional parameters that are more narrowly scoped are defined in the appropriate modules.</p> <p>Changing these parameters may have unintended consequences and should only be done by developers who understand the codebase.</p>"},{"location":"api_utils/#network_wrangler.params.SMALL_RECS","title":"network_wrangler.params.SMALL_RECS  <code>module-attribute</code>","text":"<pre><code>SMALL_RECS = 5\n</code></pre> <p>Number of records to display in a dataframe summary.</p>"},{"location":"api_utils/#io-utilities","title":"I/O Utilities","text":"<p>Helper functions for reading and writing files to reduce boilerplate.</p> <p>Utility functions for loading dictionaries from files.</p>"},{"location":"api_utils/#network_wrangler.utils.io_table.FileReadError","title":"network_wrangler.utils.io_table.FileReadError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error reading a file.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>class FileReadError(Exception):\n    \"\"\"Raised when there is an error reading a file.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_table.FileWriteError","title":"network_wrangler.utils.io_table.FileWriteError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error writing a file.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>class FileWriteError(Exception):\n    \"\"\"Raised when there is an error writing a file.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_table.convert_file_serialization","title":"network_wrangler.utils.io_table.convert_file_serialization","text":"<pre><code>convert_file_serialization(input_file, output_file, overwrite=True, boundary_gdf=None, boundary_geocode=None, boundary_file=None, node_filter_s=None, chunk_size=None)\n</code></pre> <p>Convert a file serialization format to another and optionally filter to a boundary.</p> <p>If the input file is a JSON file that is larger than a reasonable portion of available memory, and the output file is a Parquet file the JSON file will be read in chunks.</p> <p>If the input file is a Geographic data type (shp, geojon, geoparquet) and a boundary is provided, the data will be filtered to the boundary.</p> <p>Parameters:</p> <ul> <li> <code>input_file</code>               (<code>Path</code>)           \u2013            <p>Path to the input JSON or GEOJSON file.</p> </li> <li> <code>output_file</code>               (<code>Path</code>)           \u2013            <p>Path to the output Parquet file.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, overwrite the output file if it exists.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>node_filter_s</code>               (<code>Optional[Series]</code>, default:                   <code>None</code> )           \u2013            <p>If provided, will filter links in .json file to only those that connect to nodes. Defaults to None.</p> </li> <li> <code>chunk_size</code>               (<code>Optional[int]</code>, default:                   <code>None</code> )           \u2013            <p>Number of JSON objects to process in each chunk. Only works for JSON to Parquet. If None, will determine if chunking needed and what size.</p> </li> </ul> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def convert_file_serialization(\n    input_file: Path,\n    output_file: Path,\n    overwrite: bool = True,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    node_filter_s: Optional[pd.Series] = None,\n    chunk_size: Optional[int] = None,\n):\n    \"\"\"Convert a file serialization format to another and optionally filter to a boundary.\n\n    If the input file is a JSON file that is larger than a reasonable portion of available\n    memory, *and* the output file is a Parquet file the JSON file will be read in chunks.\n\n    If the input file is a Geographic data type (shp, geojon, geoparquet) and a boundary is\n    provided, the data will be filtered to the boundary.\n\n    Args:\n        input_file: Path to the input JSON or GEOJSON file.\n        output_file: Path to the output Parquet file.\n        overwrite: If True, overwrite the output file if it exists.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        node_filter_s: If provided, will filter links in .json file to only those that connect to\n            nodes. Defaults to None.\n        chunk_size: Number of JSON objects to process in each chunk. Only works for\n            JSON to Parquet. If None, will determine if chunking needed and what size.\n    \"\"\"\n    WranglerLogger.debug(f\"Converting {input_file} to {output_file}.\")\n\n    if output_file.exists() and not overwrite:\n        msg = f\"File {output_file} already exists and overwrite is False.\"\n        raise FileExistsError(msg)\n\n    if Path(input_file).suffix == \".json\" and Path(output_file).suffix == \".parquet\":\n        if chunk_size is None:\n            chunk_size = _suggest_json_chunk_size(input_file)\n        if chunk_size is None:\n            df = read_table(input_file)\n            if node_filter_s is not None and \"A\" in df.columns and \"B\" in df.columns:\n                df = df[df[\"A\"].isin(node_filter_s) | df[\"B\"].isin(node_filter_s)]\n            write_table(df, output_file, overwrite=overwrite)\n        else:\n            _json_to_parquet_in_chunks(input_file, output_file, chunk_size)\n\n    df = read_table(\n        input_file,\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n    if node_filter_s is not None and \"A\" in df.columns and \"B\" in df.columns:\n        df = df[df[\"A\"].isin(node_filter_s) | df[\"B\"].isin(node_filter_s)]\n    write_table(df, output_file, overwrite=overwrite)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_table.prep_dir","title":"network_wrangler.utils.io_table.prep_dir","text":"<pre><code>prep_dir(outdir, overwrite=True)\n</code></pre> <p>Prepare a directory for writing files.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def prep_dir(outdir: Path, overwrite: bool = True):\n    \"\"\"Prepare a directory for writing files.\"\"\"\n    if not overwrite and outdir.exists() and len(list(outdir.iterdir())) &gt; 0:\n        msg = f\"Directory {outdir} is not empty and overwrite is False.\"\n        raise FileExistsError(msg)\n    outdir.mkdir(parents=True, exist_ok=True)\n\n    # clean out existing files\n    for f in outdir.iterdir():\n        if f.is_file():\n            f.unlink()\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_table.read_table","title":"network_wrangler.utils.io_table.read_table","text":"<pre><code>read_table(filename, sub_filename=None, boundary_gdf=None, boundary_geocode=None, boundary_file=None, read_speed=DefaultConfig.CPU.EST_PD_READ_SPEED)\n</code></pre> <p>Read file and return a dataframe or geodataframe.</p> <p>If filename is a zip file, will unzip to a temporary directory.</p> <p>If filename is a geojson or shapefile, will filter the data to the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only provide one of these boundary filters.</p> <p>If filename is a geoparquet file, will filter the data to the bounding box of the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only provide one of these boundary filters.</p> <p>NOTE:  if you are accessing multiple files from this zip file you will want to unzip it first and THEN access the table files so you don\u2019t create multiple duplicate unzipped tmp dirs.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>Path</code>)           \u2013            <p>filename to load.</p> </li> <li> <code>sub_filename</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>if the file is a zip, the sub_filename to load.</p> </li> <li> <code>boundary_gdf</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_geocode</code>               (<code>Optional[str]</code>, default:                   <code>None</code> )           \u2013            <p>Geocode to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>File to load as a boundary to filter the input data to. Only used for geographic data. Defaults to None.</p> </li> <li> <code>read_speed</code>               (<code>dict</code>, default:                   <code>EST_PD_READ_SPEED</code> )           \u2013            <p>dictionary of read speeds for different file types. Defaults to DefaultConfig.CPU.EST_PD_READ_SPEED.</p> </li> </ul> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def read_table(\n    filename: Path,\n    sub_filename: Optional[str] = None,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    boundary_geocode: Optional[str] = None,\n    boundary_file: Optional[Path] = None,\n    read_speed: dict = DefaultConfig.CPU.EST_PD_READ_SPEED,\n) -&gt; Union[pd.DataFrame, gpd.GeoDataFrame]:\n    \"\"\"Read file and return a dataframe or geodataframe.\n\n    If filename is a zip file, will unzip to a temporary directory.\n\n    If filename is a geojson or shapefile, will filter the data\n    to the boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only\n    provide one of these boundary filters.\n\n    If filename is a geoparquet file, will filter the data to the *bounding box* of the\n    boundary_gdf, boundary_geocode, or boundary_file if provided. Note that you can only\n    provide one of these boundary filters.\n\n    NOTE:  if you are accessing multiple files from this zip file you will want to unzip it first\n    and THEN access the table files so you don't create multiple duplicate unzipped tmp dirs.\n\n    Args:\n        filename (Path): filename to load.\n        sub_filename: if the file is a zip, the sub_filename to load.\n        boundary_gdf: GeoDataFrame to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_geocode: Geocode to filter the input data to. Only used for geographic data.\n            Defaults to None.\n        boundary_file: File to load as a boundary to filter the input data to. Only used for\n            geographic data. Defaults to None.\n        read_speed: dictionary of read speeds for different file types. Defaults to\n            DefaultConfig.CPU.EST_PD_READ_SPEED.\n    \"\"\"\n    filename = Path(filename)\n    if not filename.exists():\n        msg = f\"Input file {filename} does not exist.\"\n        raise FileNotFoundError(msg)\n    if filename.stat().st_size == 0:\n        msg = f\"File {filename} is empty.\"\n        raise FileExistsError(msg)\n    if filename.suffix == \".zip\":\n        if not sub_filename:\n            msg = \"sub_filename must be provided for zip files.\"\n            raise ValueError(msg)\n        filename = unzip_file(filename) / sub_filename\n    WranglerLogger.debug(\n        f\"Estimated read time: {_estimate_read_time_of_file(filename, read_speed)}.\"\n    )\n\n    # will result in None if no boundary is provided\n    mask_gdf = get_bounding_polygon(\n        boundary_gdf=boundary_gdf,\n        boundary_geocode=boundary_geocode,\n        boundary_file=boundary_file,\n    )\n\n    if any(x in filename.suffix for x in [\"geojson\", \"shp\", \"csv\"]):\n        try:\n            # masking only supported by fiona engine, which is slower.\n            if mask_gdf is None:\n                return gpd.read_file(filename, engine=\"pyogrio\")\n            return gpd.read_file(filename, mask=mask_gdf, engine=\"fiona\")\n        except Exception as err:\n            if \"csv\" in filename.suffix:\n                return pd.read_csv(filename)\n            raise FileReadError from err\n    elif \"parquet\" in filename.suffix:\n        return _read_parquet_table(filename, mask_gdf)\n    elif \"json\" in filename.suffix:\n        with filename.open() as f:\n            return pd.read_json(f, orient=\"records\")\n    msg = f\"Filetype {filename.suffix} not implemented.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_table.unzip_file","title":"network_wrangler.utils.io_table.unzip_file","text":"<pre><code>unzip_file(path)\n</code></pre> <p>Unzips a file to a temporary directory and returns the directory path.</p> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def unzip_file(path: Path) -&gt; Path:\n    \"\"\"Unzips a file to a temporary directory and returns the directory path.\"\"\"\n    tmpdir = tempfile.mkdtemp()\n    shutil.unpack_archive(path, tmpdir)\n\n    def finalize() -&gt; None:\n        shutil.rmtree(tmpdir)\n\n    # Lazy cleanup\n    weakref.finalize(tmpdir, finalize)\n\n    return Path(tmpdir)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_table.write_table","title":"network_wrangler.utils.io_table.write_table","text":"<pre><code>write_table(df, filename, overwrite=False, **kwargs)\n</code></pre> <p>Write a dataframe or geodataframe to a file.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>dataframe to write.</p> </li> <li> <code>filename</code>               (<code>Path</code>)           \u2013            <p>filename to write to.</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>whether to overwrite the file if it exists. Defaults to False.</p> </li> <li> <code>kwargs</code>           \u2013            <p>additional arguments to pass to the writer.</p> </li> </ul> Source code in <code>network_wrangler/utils/io_table.py</code> <pre><code>def write_table(\n    df: Union[pd.DataFrame, gpd.GeoDataFrame],\n    filename: Path,\n    overwrite: bool = False,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Write a dataframe or geodataframe to a file.\n\n    Args:\n        df (pd.DataFrame): dataframe to write.\n        filename (Path): filename to write to.\n        overwrite (bool): whether to overwrite the file if it exists. Defaults to False.\n        kwargs: additional arguments to pass to the writer.\n\n    \"\"\"\n    filename = Path(filename)\n    if filename.exists() and not overwrite:\n        msg = f\"File {filename} already exists and overwrite is False.\"\n        raise FileExistsError(msg)\n\n    if filename.parent.is_dir() and not filename.parent.exists():\n        filename.parent.mkdir(parents=True)\n\n    WranglerLogger.debug(f\"Writing to {filename}.\")\n\n    if \"shp\" in filename.suffix:\n        df.to_file(filename, index=False, **kwargs)\n    elif \"parquet\" in filename.suffix:\n        df.to_parquet(filename, index=False, **kwargs)\n    elif \"csv\" in filename.suffix or \"txt\" in filename.suffix:\n        df.to_csv(filename, index=False, date_format=\"%H:%M:%S\", **kwargs)\n    elif \"geojson\" in filename.suffix:\n        # required due to issues with list-like columns\n        if isinstance(df, gpd.GeoDataFrame):\n            data = df.to_json(drop_id=True)\n        else:\n            data = df.to_json(orient=\"records\", index=False)\n        with filename.open(\"w\", encoding=\"utf-8\") as file:\n            file.write(data)\n    elif \"json\" in filename.suffix:\n        with filename.open(\"w\") as f:\n            f.write(df.to_json(orient=\"records\"))\n    else:\n        msg = f\"Filetype {filename.suffix} not implemented.\"\n        raise NotImplementedError(msg)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_dict.load_dict","title":"network_wrangler.utils.io_dict.load_dict","text":"<pre><code>load_dict(path)\n</code></pre> <p>Load a dictionary from a file.</p> Source code in <code>network_wrangler/utils/io_dict.py</code> <pre><code>def load_dict(path: Path) -&gt; dict:\n    \"\"\"Load a dictionary from a file.\"\"\"\n    path = Path(path)\n    if not path.is_file():\n        msg = f\"Specified dict file {path} not found.\"\n        raise FileNotFoundError(msg)\n\n    if path.suffix.lower() == \".toml\":\n        return _load_toml(path)\n    if path.suffix.lower() == \".json\":\n        return _load_json(path)\n    if path.suffix.lower() == \".yaml\" or path.suffix.lower() == \".yml\":\n        return _load_yaml(path)\n    msg = f\"Filetype {path.suffix} not implemented.\"\n    raise NotImplementedError(msg)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.io_dict.load_merge_dict","title":"network_wrangler.utils.io_dict.load_merge_dict","text":"<pre><code>load_merge_dict(path)\n</code></pre> <p>Load and merge multiple dictionaries from files.</p> Source code in <code>network_wrangler/utils/io_dict.py</code> <pre><code>def load_merge_dict(path: Union[Path, list[Path]]) -&gt; dict:\n    \"\"\"Load and merge multiple dictionaries from files.\"\"\"\n    if not isinstance(path, list):\n        path = [path]\n    data = load_dict(path[0])\n    for path_item in path[1:]:\n        merge_dicts(data, load_dict(path_item))\n    return data\n</code></pre>"},{"location":"api_utils/#data-manipulation","title":"Data Manipulation","text":"<p>Helper functions for data models.</p> <p>Utility functions for pandas data manipulation.</p> <p>Dataframe accessors that allow functions to be called directly on the dataframe.</p>"},{"location":"api_utils/#network_wrangler.utils.models.DatamodelDataframeIncompatableError","title":"network_wrangler.utils.models.DatamodelDataframeIncompatableError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a data model and a dataframe are not compatable.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>class DatamodelDataframeIncompatableError(Exception):\n    \"\"\"Raised when a data model and a dataframe are not compatable.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.TableValidationError","title":"network_wrangler.utils.models.TableValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a table validation fails.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>class TableValidationError(Exception):\n    \"\"\"Raised when a table validation fails.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.coerce_extra_fields_to_type_in_df","title":"network_wrangler.utils.models.coerce_extra_fields_to_type_in_df","text":"<pre><code>coerce_extra_fields_to_type_in_df(data, model, df)\n</code></pre> <p>Coerce extra fields in data that aren\u2019t specified in Pydantic model to the type in the df.</p> <p>Note: will not coerce lists of submodels, etc.</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>dict</code>)           \u2013            <p>The data to coerce.</p> </li> <li> <code>model</code>               (<code>BaseModel</code>)           \u2013            <p>The Pydantic model to validate the data against.</p> </li> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>The DataFrame to coerce the data to.</p> </li> </ul> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def coerce_extra_fields_to_type_in_df(\n    data: BaseModel, model: BaseModel, df: pd.DataFrame\n) -&gt; BaseModel:\n    \"\"\"Coerce extra fields in data that aren't specified in Pydantic model to the type in the df.\n\n    Note: will not coerce lists of submodels, etc.\n\n    Args:\n        data (dict): The data to coerce.\n        model (BaseModel): The Pydantic model to validate the data against.\n        df (pd.DataFrame): The DataFrame to coerce the data to.\n    \"\"\"\n    out_data = copy.deepcopy(data)\n\n    # Coerce submodels\n    for field in submodel_fields_in_model(model, data):\n        out_data.__dict__[field] = coerce_extra_fields_to_type_in_df(\n            data.__dict__[field], model.__annotations__[field], df\n        )\n\n    for field in extra_attributes_undefined_in_model(data, model):\n        try:\n            v = coerce_val_to_df_types(field, data.model_extra[field], df)\n        except ValueError as err:\n            raise DatamodelDataframeIncompatableError() from err\n        out_data.model_extra[field] = v\n    return out_data\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.default_from_datamodel","title":"network_wrangler.utils.models.default_from_datamodel","text":"<pre><code>default_from_datamodel(data_model, field)\n</code></pre> <p>Returns default value from pandera data model for a given field name.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def default_from_datamodel(data_model: pa.DataFrameModel, field: str):\n    \"\"\"Returns default value from pandera data model for a given field name.\"\"\"\n    if field in data_model.__fields__ and hasattr(data_model.__fields__[field][1], \"default\"):\n        return data_model.__fields__[field][1].default\n    return None\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.empty_df_from_datamodel","title":"network_wrangler.utils.models.empty_df_from_datamodel","text":"<pre><code>empty_df_from_datamodel(model, crs=LAT_LON_CRS)\n</code></pre> <p>Create an empty DataFrame or GeoDataFrame with the specified columns.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>BaseModel</code>)           \u2013            <p>A pandera data model to create empty [Geo]DataFrame from.</p> </li> <li> <code>crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>if schema has geometry, will use this as the geometry\u2019s crs. Defaults to LAT_LONG_CRS</p> </li> </ul> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def empty_df_from_datamodel(\n    model: DataFrameModel, crs: int = LAT_LON_CRS\n) -&gt; Union[gpd.GeoDataFrame, pd.DataFrame]:\n    \"\"\"Create an empty DataFrame or GeoDataFrame with the specified columns.\n\n    Args:\n        model (BaseModel): A pandera data model to create empty [Geo]DataFrame from.\n        crs: if schema has geometry, will use this as the geometry's crs. Defaults to LAT_LONG_CRS\n    Returns:\n        An empty [Geo]DataFrame that validates to the specified model.\n    \"\"\"\n    schema = model.to_schema()\n    data: dict[str, list] = {col: [] for col in schema.columns}\n\n    if \"geometry\" in data:\n        return model(gpd.GeoDataFrame(data, crs=crs))\n\n    return model(pd.DataFrame(data))\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.extra_attributes_undefined_in_model","title":"network_wrangler.utils.models.extra_attributes_undefined_in_model","text":"<pre><code>extra_attributes_undefined_in_model(instance, model)\n</code></pre> <p>Find the extra attributes in a pydantic model that are not defined in the model.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def extra_attributes_undefined_in_model(instance: BaseModel, model: BaseModel) -&gt; list:\n    \"\"\"Find the extra attributes in a pydantic model that are not defined in the model.\"\"\"\n    defined_fields = model.model_fields\n    all_attributes = list(instance.model_dump(exclude_none=True, by_alias=True).keys())\n    extra_attributes = [a for a in all_attributes if a not in defined_fields]\n    return extra_attributes\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.fill_df_with_defaults_from_model","title":"network_wrangler.utils.models.fill_df_with_defaults_from_model","text":"<pre><code>fill_df_with_defaults_from_model(df, model)\n</code></pre> <p>Fill a DataFrame with default values from a Pandera DataFrameModel.</p> <p>Parameters:</p> <ul> <li> <code>df</code>           \u2013            <p>DataFrame to fill with default values.</p> </li> <li> <code>model</code>           \u2013            <p>Pandera DataFrameModel to get default values from.</p> </li> </ul> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def fill_df_with_defaults_from_model(df, model):\n    \"\"\"Fill a DataFrame with default values from a Pandera DataFrameModel.\n\n    Args:\n        df: DataFrame to fill with default values.\n        model: Pandera DataFrameModel to get default values from.\n    \"\"\"\n    for c in df.columns:\n        default_value = default_from_datamodel(model, c)\n        if default_value is None:\n            df[c] = df[c].where(pd.notna(df[c]), None)\n        else:\n            df[c] = df[c].fillna(default_value)\n    return df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.identify_model","title":"network_wrangler.utils.models.identify_model","text":"<pre><code>identify_model(data, models)\n</code></pre> <p>Identify the model that the input data conforms to.</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>Union[DataFrame, dict]</code>)           \u2013            <p>The input data to identify.</p> </li> <li> <code>models</code>               (<code>list[DataFrameModel, BaseModel]</code>)           \u2013            <p>A list of models to validate the input data against.</p> </li> </ul> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def identify_model(\n    data: Union[pd.DataFrame, dict], models: list\n) -&gt; Union[DataFrameModel, BaseModel]:\n    \"\"\"Identify the model that the input data conforms to.\n\n    Args:\n        data (Union[pd.DataFrame, dict]): The input data to identify.\n        models (list[DataFrameModel,BaseModel]): A list of models to validate the input\n          data against.\n    \"\"\"\n    for m in models:\n        try:\n            if isinstance(data, pd.DataFrame):\n                validate_df_to_model(data, m)\n            else:\n                m(**data)\n            return m\n        except ValidationError:\n            continue\n        except SchemaError:\n            continue\n\n    WranglerLogger.error(\n        f\"The input data isn't consistant with any provided data model.\\\n                         \\nInput data: {data}\\\n                         \\nData Models: {models}\"\n    )\n    msg = \"The input data isn't consistant with any provided data model.\"\n    raise TableValidationError(msg)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.order_fields_from_data_model","title":"network_wrangler.utils.models.order_fields_from_data_model","text":"<pre><code>order_fields_from_data_model(df, model)\n</code></pre> <p>Order the fields in a DataFrame to match the order in a Pandera DataFrameModel.</p> <p>Will add any fields that are not in the model to the end of the DataFrame. Will not add any fields that are in the model but not in the DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame to order.</p> </li> <li> <code>model</code>               (<code>DataFrameModel</code>)           \u2013            <p>Pandera DataFrameModel to order the DataFrame to.</p> </li> </ul> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def order_fields_from_data_model(df: pd.DataFrame, model: DataFrameModel) -&gt; pd.DataFrame:\n    \"\"\"Order the fields in a DataFrame to match the order in a Pandera DataFrameModel.\n\n    Will add any fields that are not in the model to the end of the DataFrame.\n    Will not add any fields that are in the model but not in the DataFrame.\n\n    Args:\n        df: DataFrame to order.\n        model: Pandera DataFrameModel to order the DataFrame to.\n    \"\"\"\n    model_fields = list(model.__fields__.keys())\n    df_model_fields = [f for f in model_fields if f in df.columns]\n    df_additional_fields = [f for f in df.columns if f not in model_fields]\n    return df[df_model_fields + df_additional_fields]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.submodel_fields_in_model","title":"network_wrangler.utils.models.submodel_fields_in_model","text":"<pre><code>submodel_fields_in_model(model, instance=None)\n</code></pre> <p>Find the fields in a pydantic model that are submodels.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def submodel_fields_in_model(model: type, instance: Optional[BaseModel] = None) -&gt; list:\n    \"\"\"Find the fields in a pydantic model that are submodels.\"\"\"\n    types = get_type_hints(model)\n    model_type = (ModelMetaclass, BaseModel)\n    submodels = [f for f in model.model_fields if isinstance(types.get(f), model_type)]\n    if instance is not None:\n        defined = list(instance.model_dump(exclude_none=True, by_alias=True).keys())\n        return [f for f in submodels if f in defined]\n    return submodels\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.validate_call_pyd","title":"network_wrangler.utils.models.validate_call_pyd","text":"<pre><code>validate_call_pyd(func)\n</code></pre> <p>Decorator to validate the function i/o using Pydantic models without Pandera.</p> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>def validate_call_pyd(func):\n    \"\"\"Decorator to validate the function i/o using Pydantic models without Pandera.\"\"\"\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        type_hints = get_type_hints(func)\n        # Modify the type hints to replace pandera DataFrame models with pandas DataFrames\n        modified_type_hints = {\n            key: value\n            for key, value in type_hints.items()\n            if not _is_type_from_type_hint(value, PanderaDataFrame)\n        }\n\n        new_func = func\n        new_func.__annotations__ = modified_type_hints\n        validated_func = validate_call(new_func, config={\"arbitrary_types_allowed\": True})\n\n        return validated_func(*args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.models.validate_df_to_model","title":"network_wrangler.utils.models.validate_df_to_model","text":"<pre><code>validate_df_to_model(df, model, output_file=Path('validation_failure_cases.csv'))\n</code></pre> <p>Wrapper to validate a DataFrame against a Pandera DataFrameModel with better logging.</p> <p>Also copies the attrs from the input DataFrame to the validated DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame to validate.</p> </li> <li> <code>model</code>               (<code>type</code>)           \u2013            <p>Pandera DataFrameModel to validate against.</p> </li> <li> <code>output_file</code>               (<code>Path</code>, default:                   <code>Path('validation_failure_cases.csv')</code> )           \u2013            <p>Optional file to write validation errors to. Defaults to validation_failure_cases.csv.</p> </li> </ul> Source code in <code>network_wrangler/utils/models.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef validate_df_to_model(\n    df: DataFrame, model: type, output_file: Path = Path(\"validation_failure_cases.csv\")\n) -&gt; DataFrame:\n    \"\"\"Wrapper to validate a DataFrame against a Pandera DataFrameModel with better logging.\n\n    Also copies the attrs from the input DataFrame to the validated DataFrame.\n\n    Args:\n        df: DataFrame to validate.\n        model: Pandera DataFrameModel to validate against.\n        output_file: Optional file to write validation errors to. Defaults to\n            validation_failure_cases.csv.\n    \"\"\"\n    attrs = copy.deepcopy(df.attrs)\n    err_msg = f\"Validation to {model.__name__} failed.\"\n    try:\n        model_df = model.validate(df, lazy=True)\n        model_df = fill_df_with_defaults_from_model(model_df, model)\n        model_df.attrs = attrs\n        return model_df\n    except (TypeError, ValueError) as e:\n        WranglerLogger.error(f\"Validation to {model.__name__} failed.\\n{e}\")\n        raise TableValidationError(err_msg) from e\n    except SchemaErrors as e:\n        # Log the summary of errors\n        WranglerLogger.error(\n            f\"Validation to {model.__name__} failed with {len(e.failure_cases)} \\\n            errors: \\n{e.failure_cases}\"\n        )\n\n        # If there are many errors, save them to a file\n        if len(e.failure_cases) &gt; SMALL_RECS:\n            error_file = output_file\n            e.failure_cases.to_csv(error_file)\n            WranglerLogger.info(f\"Detailed error cases written to {error_file}\")\n        else:\n            # Otherwise log the errors directly\n            WranglerLogger.error(\"Detailed failure cases:\\n%s\", e.failure_cases)\n        raise TableValidationError(err_msg) from e\n    except SchemaError as e:\n        WranglerLogger.error(f\"Validation to {model.__name__} failed with error: {e}\")\n        WranglerLogger.error(f\"Failure Cases:\\n{e.failure_cases}\")\n        raise TableValidationError(err_msg) from e\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.DataSegmentationError","title":"network_wrangler.utils.data.DataSegmentationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error segmenting data.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class DataSegmentationError(Exception):\n    \"\"\"Raised when there is an error segmenting data.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.InvalidJoinFieldError","title":"network_wrangler.utils.data.InvalidJoinFieldError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when the join field is not unique.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class InvalidJoinFieldError(Exception):\n    \"\"\"Raised when the join field is not unique.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.MissingPropertiesError","title":"network_wrangler.utils.data.MissingPropertiesError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when properties are missing from the dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>class MissingPropertiesError(Exception):\n    \"\"\"Raised when properties are missing from the dataframe.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.coerce_dict_to_df_types","title":"network_wrangler.utils.data.coerce_dict_to_df_types","text":"<pre><code>coerce_dict_to_df_types(d, df, skip_keys=None, return_skipped=False)\n</code></pre> <p>Coerce dictionary values to match the type of a dataframe columns matching dict keys.</p> <p>Will also coerce a list of values.</p> <p>Parameters:</p> <ul> <li> <code>d</code>               (<code>dict</code>)           \u2013            <p>dictionary to coerce with singleton or list values</p> </li> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>dataframe to get types from</p> </li> <li> <code>skip_keys</code>               (<code>Optional[list]</code>, default:                   <code>None</code> )           \u2013            <p>list of dict keys to skip. Defaults to []/</p> </li> <li> <code>return_skipped</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>keep the uncoerced, skipped keys/vals in the resulting dict. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict[str, CoerceTypes]</code> )          \u2013            <p>dict with coerced types</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_dict_to_df_types(\n    d: dict[str, CoerceTypes],\n    df: pd.DataFrame,\n    skip_keys: Optional[list] = None,\n    return_skipped: bool = False,\n) -&gt; dict[str, CoerceTypes]:\n    \"\"\"Coerce dictionary values to match the type of a dataframe columns matching dict keys.\n\n    Will also coerce a list of values.\n\n    Args:\n        d (dict): dictionary to coerce with singleton or list values\n        df (pd.DataFrame): dataframe to get types from\n        skip_keys: list of dict keys to skip. Defaults to []/\n        return_skipped: keep the uncoerced, skipped keys/vals in the resulting dict.\n            Defaults to False.\n\n    Returns:\n        dict: dict with coerced types\n    \"\"\"\n    if skip_keys is None:\n        skip_keys = []\n    coerced_dict: dict[str, CoerceTypes] = {}\n    for k, vals in d.items():\n        if k in skip_keys:\n            if return_skipped:\n                coerced_dict[k] = vals\n            continue\n        if k not in df.columns:\n            msg = f\"Key {k} not in dataframe columns.\"\n            raise ValueError(msg)\n        if pd.api.types.infer_dtype(df[k]) == \"integer\":\n            if isinstance(vals, list):\n                coerced_v: CoerceTypes = [int(float(v)) for v in vals]\n            else:\n                coerced_v = int(float(vals))\n        elif pd.api.types.infer_dtype(df[k]) == \"floating\":\n            coerced_v = [float(v) for v in vals] if isinstance(vals, list) else float(vals)\n        elif pd.api.types.infer_dtype(df[k]) == \"boolean\":\n            coerced_v = [bool(v) for v in vals] if isinstance(vals, list) else bool(vals)\n        elif isinstance(vals, list):\n            coerced_v = [str(v) for v in vals]\n        else:\n            coerced_v = str(vals)\n        coerced_dict[k] = coerced_v\n    return coerced_dict\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.coerce_gdf","title":"network_wrangler.utils.data.coerce_gdf","text":"<pre><code>coerce_gdf(df, geometry=None, in_crs=LAT_LON_CRS)\n</code></pre> <p>Coerce a DataFrame to a GeoDataFrame, optionally with a new geometry.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_gdf(\n    df: pd.DataFrame, geometry: GeoSeries = None, in_crs: int = LAT_LON_CRS\n) -&gt; GeoDataFrame:\n    \"\"\"Coerce a DataFrame to a GeoDataFrame, optionally with a new geometry.\"\"\"\n    if isinstance(df, GeoDataFrame):\n        if df.crs is None:\n            df.crs = in_crs\n        return df\n    p = None\n\n    if \"geometry\" not in df and geometry is None:\n        msg = \"Must give geometry argument if don't have Geometry in dataframe\"\n        raise ValueError(msg)\n\n    geometry = geometry if geometry is not None else df[\"geometry\"]\n    if not isinstance(geometry, GeoSeries):\n        try:\n            geometry = GeoSeries(geometry)\n        except Exception:\n            geometry = geometry.apply(wkt.loads)\n    df = GeoDataFrame(df, geometry=geometry, crs=in_crs)\n\n    return df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.coerce_val_to_df_types","title":"network_wrangler.utils.data.coerce_val_to_df_types","text":"<pre><code>coerce_val_to_df_types(field, val, df)\n</code></pre> <p>Coerce field value to match the type of a matching dataframe columns.</p> <p>Parameters:</p> <ul> <li> <code>field</code>               (<code>str</code>)           \u2013            <p>field to lookup</p> </li> <li> <code>val</code>               (<code>CoerceTypes</code>)           \u2013            <p>value or list of values to coerce</p> </li> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>dataframe to get types from</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_val_to_df_types(  # noqa: PLR0911\n    field: str,\n    val: CoerceTypes,\n    df: pd.DataFrame,\n) -&gt; CoerceTypes:\n    \"\"\"Coerce field value to match the type of a matching dataframe columns.\n\n    Args:\n        field: field to lookup\n        val: value or list of values to coerce\n        df (pd.DataFrame): dataframe to get types from\n\n    Returns: coerced value or list of values\n    \"\"\"\n    if field not in df.columns:\n        msg = f\"Field {field} not in dataframe columns.\"\n        raise ValueError(msg)\n    if pd.api.types.infer_dtype(df[field]) == \"integer\":\n        if isinstance(val, list):\n            return [int(float(v)) for v in val]\n        return int(float(val))\n    if pd.api.types.infer_dtype(df[field]) == \"floating\":\n        if isinstance(val, list):\n            return [float(v) for v in val]\n        return float(val)\n    if pd.api.types.infer_dtype(df[field]) == \"boolean\":\n        if isinstance(val, list):\n            return [bool(v) for v in val]\n        return bool(val)\n    if isinstance(val, list):\n        return [str(v) for v in val]\n    return str(val)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.coerce_val_to_series_type","title":"network_wrangler.utils.data.coerce_val_to_series_type","text":"<pre><code>coerce_val_to_series_type(val, s)\n</code></pre> <p>Coerces a value to match type of pandas series.</p> <p>Will try not to fail so if you give it a value that can\u2019t convert to a number, it will return a string.</p> <p>Parameters:</p> <ul> <li> <code>val</code>           \u2013            <p>Any type of singleton value</p> </li> <li> <code>s</code>               (<code>Series</code>)           \u2013            <p>series to match the type to</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def coerce_val_to_series_type(val, s: pd.Series) -&gt; Union[float, str, bool]:\n    \"\"\"Coerces a value to match type of pandas series.\n\n    Will try not to fail so if you give it a value that can't convert to a number, it will\n    return a string.\n\n    Args:\n        val: Any type of singleton value\n        s (pd.Series): series to match the type to\n    \"\"\"\n    # WranglerLogger.debug(f\"Input val: {val} of type {type(val)} to match with series type \\\n    #    {pd.api.types.infer_dtype(s)}.\")\n    if pd.api.types.infer_dtype(s) in [\"integer\", \"floating\"]:\n        try:\n            v: Union[float, str, bool] = float(val)\n        except:\n            v = str(val)\n    elif pd.api.types.infer_dtype(s) == \"boolean\":\n        v = bool(val)\n    else:\n        v = str(val)\n    # WranglerLogger.debug(f\"Return value: {v}\")\n    return v\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.compare_df_values","title":"network_wrangler.utils.data.compare_df_values","text":"<pre><code>compare_df_values(df1, df2, join_col=None, ignore=None, atol=1e-05)\n</code></pre> <p>Compare overlapping part of dataframes and returns where there are differences.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def compare_df_values(\n    df1, df2, join_col: Optional[str] = None, ignore: Optional[list[str]] = None, atol=1e-5\n):\n    \"\"\"Compare overlapping part of dataframes and returns where there are differences.\"\"\"\n    if ignore is None:\n        ignore = []\n    comp_c = [\n        c\n        for c in df1.columns\n        if c in df2.columns and c not in ignore and not isinstance(df1[c], GeoSeries)\n    ]\n    if join_col is None:\n        comp_df = df1[comp_c].merge(\n            df2[comp_c],\n            how=\"inner\",\n            right_index=True,\n            left_index=True,\n            suffixes=[\"_a\", \"_b\"],\n        )\n    else:\n        comp_df = df1[comp_c].merge(df2[comp_c], how=\"inner\", on=join_col, suffixes=[\"_a\", \"_b\"])\n\n    # Filter columns by data type\n    numeric_cols = [col for col in comp_c if np.issubdtype(df1[col].dtype, np.number)]\n    ll_cols = list(set(list_like_columns(df1) + list_like_columns(df2)))\n    other_cols = [col for col in comp_c if col not in numeric_cols and col not in ll_cols]\n\n    # For numeric columns, use np.isclose\n    if numeric_cols:\n        numeric_a = comp_df[[f\"{col}_a\" for col in numeric_cols]]\n        numeric_b = comp_df[[f\"{col}_b\" for col in numeric_cols]]\n        is_close = np.isclose(numeric_a, numeric_b, atol=atol, equal_nan=True)\n        comp_df[numeric_cols] = ~is_close\n\n    if ll_cols:\n        for ll_c in ll_cols:\n            comp_df[ll_c] = diff_list_like_series(comp_df[ll_c + \"_a\"], comp_df[ll_c + \"_b\"])\n\n    # For non-numeric columns, use direct comparison\n    if other_cols:\n        for col in other_cols:\n            comp_df[col] = (comp_df[f\"{col}_a\"] != comp_df[f\"{col}_b\"]) &amp; ~(\n                comp_df[f\"{col}_a\"].isna() &amp; comp_df[f\"{col}_b\"].isna()\n            )\n\n    # Filter columns and rows where no differences\n    cols_w_diffs = [col for col in comp_c if comp_df[col].any()]\n    out_cols = [col for subcol in cols_w_diffs for col in (f\"{subcol}_a\", f\"{subcol}_b\", subcol)]\n    comp_df = comp_df[out_cols]\n    comp_df = comp_df.loc[comp_df[cols_w_diffs].any(axis=1)]\n\n    return comp_df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.compare_lists","title":"network_wrangler.utils.data.compare_lists","text":"<pre><code>compare_lists(list1, list2)\n</code></pre> <p>Compare two lists.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def compare_lists(list1, list2) -&gt; bool:\n    \"\"\"Compare two lists.\"\"\"\n    list1 = convert_numpy_to_list(list1)\n    list2 = convert_numpy_to_list(list1)\n    return list1 != list2\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.concat_with_attr","title":"network_wrangler.utils.data.concat_with_attr","text":"<pre><code>concat_with_attr(dfs, **kwargs)\n</code></pre> <p>Concatenate a list of dataframes and retain the attributes of the first dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def concat_with_attr(dfs: list[pd.DataFrame], **kwargs) -&gt; pd.DataFrame:\n    \"\"\"Concatenate a list of dataframes and retain the attributes of the first dataframe.\"\"\"\n    import copy  # noqa: PLC0415\n\n    if not dfs:\n        msg = \"No dataframes to concatenate.\"\n        raise ValueError(msg)\n    attrs = copy.deepcopy(dfs[0].attrs)\n    df = pd.concat(dfs, **kwargs)\n    df.attrs = attrs\n    return df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.convert_numpy_to_list","title":"network_wrangler.utils.data.convert_numpy_to_list","text":"<pre><code>convert_numpy_to_list(item)\n</code></pre> <p>Function to recursively convert numpy arrays to lists.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def convert_numpy_to_list(item):\n    \"\"\"Function to recursively convert numpy arrays to lists.\"\"\"\n    if isinstance(item, np.ndarray):\n        return item.tolist()\n    if isinstance(item, list):\n        return [convert_numpy_to_list(sub_item) for sub_item in item]\n    if isinstance(item, dict):\n        return {key: convert_numpy_to_list(value) for key, value in item.items()}\n    return item\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.dict_fields_in_df","title":"network_wrangler.utils.data.dict_fields_in_df","text":"<pre><code>dict_fields_in_df(d, df)\n</code></pre> <p>Check if all fields in dict are in dataframe.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def dict_fields_in_df(d: dict, df: pd.DataFrame) -&gt; bool:\n    \"\"\"Check if all fields in dict are in dataframe.\"\"\"\n    missing_fields = [f for f in d if f not in df.columns]\n    if missing_fields:\n        msg = f\"Fields in dictionary missing from dataframe: {missing_fields}.\"\n        WranglerLogger.error(msg)\n        raise ValueError(msg)\n    return True\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.dict_to_query","title":"network_wrangler.utils.data.dict_to_query","text":"<pre><code>dict_to_query(selection_dict)\n</code></pre> <p>Generates the query of from selection_dict.</p> <p>Parameters:</p> <ul> <li> <code>selection_dict</code>               (<code>Mapping[str, Any]</code>)           \u2013            <p>selection dictionary</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>_type_</code> (              <code>str</code> )          \u2013            <p>Query value</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def dict_to_query(\n    selection_dict: Mapping[str, Any],\n) -&gt; str:\n    \"\"\"Generates the query of from selection_dict.\n\n    Args:\n        selection_dict: selection dictionary\n\n    Returns:\n        _type_: Query value\n    \"\"\"\n    WranglerLogger.debug(\"Building selection query\")\n\n    def _kv_to_query_part(k, v, _q_part=\"\"):\n        if isinstance(v, list):\n            _q_part += \"(\" + \" or \".join([_kv_to_query_part(k, i) for i in v]) + \")\"\n            return _q_part\n        if isinstance(v, str):\n            return k + '.str.contains(\"' + v + '\")'\n        return k + \"==\" + str(v)\n\n    query = \"(\" + \" and \".join([_kv_to_query_part(k, v) for k, v in selection_dict.items()]) + \")\"\n    WranglerLogger.debug(f\"Selection query: \\n{query}\")\n    return query\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.diff_dfs","title":"network_wrangler.utils.data.diff_dfs","text":"<pre><code>diff_dfs(df1, df2, ignore=None)\n</code></pre> <p>Returns True if two dataframes are different and log differences.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def diff_dfs(df1, df2, ignore: Optional[list[str]] = None) -&gt; bool:\n    \"\"\"Returns True if two dataframes are different and log differences.\"\"\"\n    if ignore is None:\n        ignore = []\n    diff = False\n    if set(df1.columns) != set(df2.columns):\n        WranglerLogger.warning(\n            f\" Columns are different 1vs2 \\n    {set(df1.columns) ^ set(df2.columns)}\"\n        )\n        common_cols = [col for col in df1.columns if col in df2.columns]\n        df1 = df1[common_cols]\n        df2 = df2[common_cols]\n        diff = True\n\n    cols_to_compare = [col for col in df1.columns if col not in ignore]\n    df1 = df1[cols_to_compare]\n    df2 = df2[cols_to_compare]\n\n    if len(df1) != len(df2):\n        WranglerLogger.warning(f\" Length is different /DF1: {len(df1)} vs /DF2: {len(df2)}\\n /\")\n        diff = True\n\n    diff_df = compare_df_values(df1, df2)\n\n    if not diff_df.empty:\n        WranglerLogger.error(f\"!!! Differences dfs: \\n{diff_df}\")\n        return True\n\n    if not diff:\n        WranglerLogger.info(\"...no differences in df found.\")\n    return diff\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.diff_list_like_series","title":"network_wrangler.utils.data.diff_list_like_series","text":"<pre><code>diff_list_like_series(s1, s2)\n</code></pre> <p>Compare two series that contain list-like items as strings.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def diff_list_like_series(s1, s2) -&gt; bool:\n    \"\"\"Compare two series that contain list-like items as strings.\"\"\"\n    diff_df = concat_with_attr([s1, s2], axis=1, keys=[\"s1\", \"s2\"])\n    # diff_df[\"diff\"] = diff_df.apply(lambda x: str(x[\"s1\"]) != str(x[\"s2\"]), axis=1)\n    diff_df[\"diff\"] = diff_df.apply(lambda x: compare_lists(x[\"s1\"], x[\"s2\"]), axis=1)\n    if diff_df[\"diff\"].any():\n        WranglerLogger.info(\"List-Like differences:\")\n        WranglerLogger.info(diff_df)\n        return True\n    return False\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.fk_in_pk","title":"network_wrangler.utils.data.fk_in_pk","text":"<pre><code>fk_in_pk(pk, fk, ignore_nan=True)\n</code></pre> <p>Check if all foreign keys are in the primary keys, optionally ignoring NaN.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def fk_in_pk(\n    pk: Union[pd.Series, list], fk: Union[pd.Series, list], ignore_nan: bool = True\n) -&gt; tuple[bool, list]:\n    \"\"\"Check if all foreign keys are in the primary keys, optionally ignoring NaN.\"\"\"\n    if isinstance(fk, list):\n        fk = pd.Series(fk)\n\n    if ignore_nan:\n        fk = fk.dropna()\n\n    missing_flag = ~fk.isin(pk)\n\n    if missing_flag.any():\n        WranglerLogger.warning(\n            f\"Following keys referenced in {fk.name} but missing in\\\n            primary key table: \\n{fk[missing_flag]} \"\n        )\n        return False, fk[missing_flag].tolist()\n\n    return True, []\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.isin_dict","title":"network_wrangler.utils.data.isin_dict","text":"<pre><code>isin_dict(df, d, ignore_missing=True, strict_str=False)\n</code></pre> <p>Filter the dataframe using a dictionary - faster than using isin.</p> <p>Uses merge to filter the dataframe by the dictionary keys and values.</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>dataframe to filter</p> </li> <li> <code>d</code>               (<code>dict</code>)           \u2013            <p>dictionary with keys as column names and values as values to filter by</p> </li> <li> <code>ignore_missing</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>if True, will ignore missing values in the selection dict.</p> </li> <li> <code>strict_str</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>if True, will not allow partial string matches and will force case-matching. Defaults to False. If False, will be overridden if key is in STRICT_MATCH_FIELDS or if ignore_missing is False.</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def isin_dict(\n    df: pd.DataFrame, d: dict, ignore_missing: bool = True, strict_str: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Filter the dataframe using a dictionary - faster than using isin.\n\n    Uses merge to filter the dataframe by the dictionary keys and values.\n\n    Args:\n        df: dataframe to filter\n        d: dictionary with keys as column names and values as values to filter by\n        ignore_missing: if True, will ignore missing values in the selection dict.\n        strict_str: if True, will not allow partial string matches and will force case-matching.\n            Defaults to False. If False, will be overridden if key is in STRICT_MATCH_FIELDS or if\n            ignore_missing is False.\n    \"\"\"\n    sel_links_mask = np.zeros(len(df), dtype=bool)\n    missing = {}\n    for col, vals in d.items():\n        if vals is None:\n            continue\n        if col not in df.columns:\n            msg = f\"Key {col} not in dataframe columns.\"\n            raise DataframeSelectionError(msg)\n        _strict_str = strict_str or col in STRICT_MATCH_FIELDS or not ignore_missing\n        vals_list = [vals] if not isinstance(vals, list) else vals\n\n        index_name = df.index.name if df.index.name is not None else \"index\"\n        _df = df[[col]].reset_index(names=index_name)\n\n        if isinstance(vals_list[0], str) and not _strict_str:\n            vals_list = [val.lower() for val in vals_list]\n            _df[col] = _df[col].str.lower()\n\n            # Use str.contains for partial matching\n            mask = np.zeros(len(_df), dtype=bool)\n            for val in vals_list:\n                mask |= _df[col].str.contains(val, case=False, na=False)\n            selected = _df[mask].set_index(index_name)\n        else:\n            vals_df = pd.DataFrame({col: vals_list}, index=range(len(vals_list)))\n            merged_df = _df.merge(vals_df, on=col, how=\"outer\", indicator=True)\n            selected = merged_df[merged_df[\"_merge\"] == \"both\"].set_index(index_name)\n            _missing_vals = merged_df[merged_df[\"_merge\"] == \"right_only\"][col].tolist()\n            if _missing_vals:\n                missing[col] = _missing_vals\n                WranglerLogger.warning(f\"Missing values in selection dict for {col}: {missing}\")\n\n        sel_links_mask |= df.index.isin(selected.index)\n\n    if not ignore_missing and any(missing):\n        msg = \"Missing values in selection dict.\"\n        raise DataframeSelectionError(msg)\n\n    return df.loc[sel_links_mask]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.list_like_columns","title":"network_wrangler.utils.data.list_like_columns","text":"<pre><code>list_like_columns(df, item_type=None)\n</code></pre> <p>Find columns in a dataframe that contain list-like items that can\u2019t be json-serialized.</p> <p>Parameters:</p> <ul> <li> <code>df</code>           \u2013            <p>dataframe to check</p> </li> <li> <code>item_type</code>               (<code>Optional[type]</code>, default:                   <code>None</code> )           \u2013            <p>if not None, will only return columns where all items are of this type by checking only the first item in the column.  Defaults to None.</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def list_like_columns(df, item_type: Optional[type] = None) -&gt; list[str]:\n    \"\"\"Find columns in a dataframe that contain list-like items that can't be json-serialized.\n\n    Args:\n        df: dataframe to check\n        item_type: if not None, will only return columns where all items are of this type by\n            checking **only** the first item in the column.  Defaults to None.\n    \"\"\"\n    list_like_columns = []\n\n    for column in df.columns:\n        if df[column].apply(lambda x: isinstance(x, (list, ndarray))).any():\n            if item_type is not None and not isinstance(df[column].iloc[0], item_type):\n                continue\n            list_like_columns.append(column)\n    return list_like_columns\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.segment_data_by_selection","title":"network_wrangler.utils.data.segment_data_by_selection","text":"<pre><code>segment_data_by_selection(item_list, data, field=None, end_val=0)\n</code></pre> <p>Segment a dataframe or series into before, middle, and end segments based on item_list.</p> <p>selected segment = everything from the first to last item in item_list inclusive of the first     and last items. Before segment = everything before After segment = everything after</p> <p>Parameters:</p> <ul> <li> <code>item_list</code>               (<code>list</code>)           \u2013            <p>List of items to segment data by. If longer than two, will only use the first and last items.</p> </li> <li> <code>data</code>               (<code>Union[Series, DataFrame]</code>)           \u2013            <p>Data to segment into before, middle, and after.</p> </li> <li> <code>field</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>If a dataframe, specifies which field to reference. Defaults to None.</p> </li> <li> <code>end_val</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Notation for util the end or from the begining. Defaults to 0.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>DataSegmentationError</code>             \u2013            <p>If item list isn\u2019t found in data in correct order.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code> (              <code>tuple[Union[Series, list, DataFrame], Union[Series, list, DataFrame], Union[Series, list, DataFrame]]</code> )          \u2013            <p>data broken out by beofore, selected segment, and after.</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def segment_data_by_selection(\n    item_list: list,\n    data: Union[list, pd.DataFrame, pd.Series],\n    field: Optional[str] = None,\n    end_val=0,\n) -&gt; tuple[\n    Union[pd.Series, list, pd.DataFrame],\n    Union[pd.Series, list, pd.DataFrame],\n    Union[pd.Series, list, pd.DataFrame],\n]:\n    \"\"\"Segment a dataframe or series into before, middle, and end segments based on item_list.\n\n    selected segment = everything from the first to last item in item_list inclusive of the first\n        and last items.\n    Before segment = everything before\n    After segment = everything after\n\n    Args:\n        item_list (list): List of items to segment data by. If longer than two, will only\n            use the first and last items.\n        data (Union[pd.Series, pd.DataFrame]): Data to segment into before, middle, and after.\n        field (str, optional): If a dataframe, specifies which field to reference.\n            Defaults to None.\n        end_val (int, optional): Notation for util the end or from the begining. Defaults to 0.\n\n    Raises:\n        DataSegmentationError: If item list isn't found in data in correct order.\n\n    Returns:\n        tuple: data broken out by beofore, selected segment, and after.\n    \"\"\"\n    ref_data = data\n    if isinstance(data, pd.DataFrame):\n        ref_data = data[field].tolist()\n    elif isinstance(data, pd.Series):\n        ref_data = data.tolist()\n\n    # ------- Replace \"to the end\" indicators with first or last value --------\n    start_item, end_item = item_list[0], item_list[-1]\n    if start_item == end_val:\n        start_item = ref_data[0]\n    if end_item == end_val:\n        end_item = ref_data[-1]\n\n    # --------Find the start and end indices -----------------------------------\n    start_idxs = list({i for i, item in enumerate(ref_data) if item == start_item})\n    if not start_idxs:\n        msg = f\"Segment start item: {start_item} not in data.\"\n        raise DataSegmentationError(msg)\n    if len(start_idxs) &gt; 1:\n        WranglerLogger.warning(\n            f\"Found multiple starting locations for data segment: {start_item}.\\\n                                Choosing first ... largest segment being selected.\"\n        )\n    start_idx = min(start_idxs)\n\n    # find the end node starting from the start index.\n    end_idxs = [i + start_idx for i, item in enumerate(ref_data[start_idx:]) if item == end_item]\n    # WranglerLogger.debug(f\"End indexes: {end_idxs}\")\n    if not end_idxs:\n        msg = f\"Segment end item: {end_item} not in data after starting idx.\"\n        raise DataSegmentationError(msg)\n    if len(end_idxs) &gt; 1:\n        WranglerLogger.warning(\n            f\"Found multiple ending locations for data segment: {end_item}.\\\n                                Choosing last ... largest segment being selected.\"\n        )\n    end_idx = max(end_idxs) + 1\n    # WranglerLogger.debug(\n    # f\"Segmenting data fr {start_item} idx:{start_idx} to {end_item} idx:{end_idx}.\\n{ref_data}\")\n    # -------- Extract the segments --------------------------------------------\n    if isinstance(data, pd.DataFrame):\n        before_segment = data.iloc[:start_idx]\n        selected_segment = data.iloc[start_idx:end_idx]\n        after_segment = data.iloc[end_idx:]\n    else:\n        before_segment = data[:start_idx]\n        selected_segment = data[start_idx:end_idx]\n        after_segment = data[end_idx:]\n\n    if isinstance(data, (pd.DataFrame, pd.Series)):\n        before_segment = before_segment.reset_index(drop=True)\n        selected_segment = selected_segment.reset_index(drop=True)\n        after_segment = after_segment.reset_index(drop=True)\n\n    # WranglerLogger.debug(f\"Segmented data into before, selected, and after.\\n \\\n    #    Before:\\n{before_segment}\\nSelected:\\n{selected_segment}\\nAfter:\\n{after_segment}\")\n\n    return before_segment, selected_segment, after_segment\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.segment_data_by_selection_min_overlap","title":"network_wrangler.utils.data.segment_data_by_selection_min_overlap","text":"<pre><code>segment_data_by_selection_min_overlap(selection_list, data, field, replacements_list, end_val=0)\n</code></pre> <p>Segments data based on item_list reducing overlap with replacement list.</p> <p>selected segment: everything from the first to last item in item_list inclusive of the first     and last items but not if first and last items overlap with replacement list. Before segment = everything before After segment = everything after</p> <p>Example: selection_list = [2,5] data = pd.DataFrame({\u201ci\u201d:[1,2,3,4,5,6]}) field = \u201ci\u201d replacements_list = [2,22,33]</p> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>[22,33]</p> </li> <li> <code>tuple[Union[Series, DataFrame], Union[Series, DataFrame], Union[Series, DataFrame]]</code>           \u2013            <p>[1], [2,3,4,5], [6]</p> </li> </ul> <p>Parameters:</p> <ul> <li> <code>selection_list</code>               (<code>list</code>)           \u2013            <p>List of items to segment data by. If longer than two, will only use the first and last items.</p> </li> <li> <code>data</code>               (<code>Union[Series, DataFrame]</code>)           \u2013            <p>Data to segment into before, middle, and after.</p> </li> <li> <code>field</code>               (<code>str</code>)           \u2013            <p>Specifies which field to reference.</p> </li> <li> <code>replacements_list</code>               (<code>list</code>)           \u2013            <p>List of items to eventually replace the selected segment with.</p> </li> <li> <code>end_val</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Notation for util the end or from the begining. Defaults to 0.</p> </li> </ul> <p>tuple containing:</p> <ul> <li> <code>list</code>           \u2013            <ul> <li>updated replacement_list</li> </ul> </li> <li> <code>tuple[Union[Series, DataFrame], Union[Series, DataFrame], Union[Series, DataFrame]]</code>           \u2013            <ul> <li>tuple of before, selected segment, and after data</li> </ul> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def segment_data_by_selection_min_overlap(\n    selection_list: list,\n    data: pd.DataFrame,\n    field: str,\n    replacements_list: list,\n    end_val=0,\n) -&gt; tuple[\n    list,\n    tuple[\n        Union[pd.Series, pd.DataFrame],\n        Union[pd.Series, pd.DataFrame],\n        Union[pd.Series, pd.DataFrame],\n    ],\n]:\n    \"\"\"Segments data based on item_list reducing overlap with replacement list.\n\n    *selected segment*: everything from the first to last item in item_list inclusive of the first\n        and last items but not if first and last items overlap with replacement list.\n    Before segment = everything before\n    After segment = everything after\n\n    Example:\n    selection_list = [2,5]\n    data = pd.DataFrame({\"i\":[1,2,3,4,5,6]})\n    field = \"i\"\n    replacements_list = [2,22,33]\n\n    Returns:\n        [22,33]\n        [1], [2,3,4,5], [6]\n\n    Args:\n        selection_list (list): List of items to segment data by. If longer than two, will only\n            use the first and last items.\n        data (Union[pd.Series, pd.DataFrame]): Data to segment into before, middle, and after.\n        field (str): Specifies which field to reference.\n        replacements_list (list): List of items to eventually replace the selected segment with.\n        end_val (int, optional): Notation for util the end or from the begining. Defaults to 0.\n\n    Returns: tuple containing:\n        - updated replacement_list\n        - tuple of before, selected segment, and after data\n    \"\"\"\n    before_segment, segment_df, after_segment = segment_data_by_selection(\n        selection_list, data, field=field, end_val=end_val\n    )\n    if not isinstance(segment_df, pd.DataFrame):\n        msg = \"segment_df should be a DataFrame - something is wrong.\"\n        raise ValueError(msg)\n\n    if replacements_list and replacements_list[0] == segment_df[field].iat[0]:\n        # move first item from selected segment to the before_segment df\n        replacements_list = replacements_list[1:]\n        before_segment = concat_with_attr(\n            [before_segment, segment_df.iloc[:1]], ignore_index=True, sort=False\n        )\n        segment_df = segment_df.iloc[1:]\n        # WranglerLogger.debug(f\"item start overlaps with replacement. Repl: {replacements_list}\")\n    if replacements_list and replacements_list[-1] == data[field].iat[-1]:\n        # move last item from selected segment to the after_segment df\n        replacements_list = replacements_list[:-1]\n        after_segment = concat_with_attr(\n            [data.iloc[-1:], after_segment], ignore_index=True, sort=False\n        )\n        segment_df = segment_df.iloc[:-1]\n        # WranglerLogger.debug(f\"item end overlaps with replacement. Repl: {replacements_list}\")\n\n    return replacements_list, (before_segment, segment_df, after_segment)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.update_df_by_col_value","title":"network_wrangler.utils.data.update_df_by_col_value","text":"<pre><code>update_df_by_col_value(destination_df, source_df, join_col, properties=None, fail_if_missing=True)\n</code></pre> <p>Updates destination_df with ALL values in source_df for specified props with same join_col.</p> <p>Source_df can contain a subset of IDs of destination_df. If fail_if_missing is true, destination_df must have all the IDS in source DF - ensuring all source_df values are contained in resulting df.</p> <pre><code>&gt;&gt; destination_df\ntrip_id  property1  property2\n1         10      100\n2         20      200\n3         30      300\n4         40      400\n\n&gt;&gt; source_df\ntrip_id  property1  property2\n2         25      250\n3         35      350\n\n&gt;&gt; updated_df\ntrip_id  property1  property2\n0        1       10      100\n1        2       25      250\n2        3       35      350\n3        4       40      400\n</code></pre> <p>Parameters:</p> <ul> <li> <code>destination_df</code>               (<code>DataFrame</code>)           \u2013            <p>Dataframe to modify.</p> </li> <li> <code>source_df</code>               (<code>DataFrame</code>)           \u2013            <p>Dataframe with updated columns</p> </li> <li> <code>join_col</code>               (<code>str</code>)           \u2013            <p>column to join on</p> </li> <li> <code>properties</code>               (<code>list[str]</code>, default:                   <code>None</code> )           \u2013            <p>List of properties to use. If None, will default to all in source_df.</p> </li> <li> <code>fail_if_missing</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, will raise an error if there are missing IDs in destination_df that exist in source_df.</p> </li> </ul> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def update_df_by_col_value(\n    destination_df: pd.DataFrame,\n    source_df: pd.DataFrame,\n    join_col: str,\n    properties: Optional[list[str]] = None,\n    fail_if_missing: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"Updates destination_df with ALL values in source_df for specified props with same join_col.\n\n    Source_df can contain a subset of IDs of destination_df.\n    If fail_if_missing is true, destination_df must have all\n    the IDS in source DF - ensuring all source_df values are contained in resulting df.\n\n    ```\n    &gt;&gt; destination_df\n    trip_id  property1  property2\n    1         10      100\n    2         20      200\n    3         30      300\n    4         40      400\n\n    &gt;&gt; source_df\n    trip_id  property1  property2\n    2         25      250\n    3         35      350\n\n    &gt;&gt; updated_df\n    trip_id  property1  property2\n    0        1       10      100\n    1        2       25      250\n    2        3       35      350\n    3        4       40      400\n    ```\n\n    Args:\n        destination_df (pd.DataFrame): Dataframe to modify.\n        source_df (pd.DataFrame): Dataframe with updated columns\n        join_col (str): column to join on\n        properties (list[str]): List of properties to use. If None, will default to all\n            in source_df.\n        fail_if_missing (bool): If True, will raise an error if there are missing IDs in\n            destination_df that exist in source_df.\n    \"\"\"\n    # 1. Identify which properties should be updated; and if they exist in both DFs.\n    if properties is None:\n        properties = [\n            c for c in source_df.columns if c in destination_df.columns and c != join_col\n        ]\n    else:\n        _dest_miss = _df_missing_cols(destination_df, [*properties, join_col])\n        if _dest_miss:\n            msg = f\"Properties missing from destination_df: {_dest_miss}\"\n            raise MissingPropertiesError(msg)\n        _source_miss = _df_missing_cols(source_df, [*properties, join_col])\n        if _source_miss:\n            msg = f\"Properties missing from source_df: {_source_miss}\"\n            raise MissingPropertiesError(msg)\n\n    # 2. Identify if there are IDs missing from destination_df that exist in source_df\n    if fail_if_missing:\n        missing_ids = set(source_df[join_col]) - set(destination_df[join_col])\n        if missing_ids:\n            msg = f\"IDs missing from source_df: \\n{missing_ids}\"\n            raise InvalidJoinFieldError(msg)\n\n    WranglerLogger.debug(f\"Updating properties for {len(source_df)} records: {properties}.\")\n\n    if not source_df[join_col].is_unique:\n        msg = f\"Can't join from source_df when join_col: {join_col} is not unique.\"\n        raise InvalidJoinFieldError(msg)\n\n    if not destination_df[join_col].is_unique:\n        return _update_props_from_one_to_many(destination_df, source_df, join_col, properties)\n\n    return _update_props_for_common_idx(destination_df, source_df, join_col, properties)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.data.validate_existing_value_in_df","title":"network_wrangler.utils.data.validate_existing_value_in_df","text":"<pre><code>validate_existing_value_in_df(df, idx, field, expected_value)\n</code></pre> <p>Validate if df[field]==expected_value for all indices in idx.</p> Source code in <code>network_wrangler/utils/data.py</code> <pre><code>def validate_existing_value_in_df(df: pd.DataFrame, idx: list[int], field: str, expected_value):\n    \"\"\"Validate if df[field]==expected_value for all indices in idx.\"\"\"\n    if field not in df.columns:\n        WranglerLogger.warning(f\"!! {field} Not an existing field.\")\n        return False\n    if not df.loc[idx, field].eq(expected_value).all():\n        WranglerLogger.warning(\n            f\"Existing value defined for {field} in project card \\\n            does not match the value in the selection links. \\n\\\n            Specified Existing: {expected_value}\\n\\\n            Actual Existing: \\n {df.loc[idx, field]}.\"\n        )\n        return False\n    return True\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.DictQueryAccessor","title":"network_wrangler.utils.df_accessors.DictQueryAccessor","text":"<p>Query link, node and shape dataframes using project selection dictionary.</p> <p>Will overlook any keys which are not columns in the dataframe.</p> <p>Usage:</p> <pre><code>selection_dict = {\n    \"lanes\": [1, 2, 3],\n    \"name\": [\"6th\", \"Sixth\", \"sixth\"],\n    \"drive_access\": 1,\n}\nselected_links_df = links_df.dict_query(selection_dict)\n</code></pre> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"dict_query\")\nclass DictQueryAccessor:\n    \"\"\"Query link, node and shape dataframes using project selection dictionary.\n\n    Will overlook any keys which are not columns in the dataframe.\n\n    Usage:\n\n    ```\n    selection_dict = {\n        \"lanes\": [1, 2, 3],\n        \"name\": [\"6th\", \"Sixth\", \"sixth\"],\n        \"drive_access\": 1,\n    }\n    selected_links_df = links_df.dict_query(selection_dict)\n    ```\n\n    \"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dictionary query accessor.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self, selection_dict: dict, return_all_if_none: bool = False):\n        \"\"\"Queries the dataframe using the selection dictionary.\n\n        Args:\n            selection_dict (dict): _description_\n            return_all_if_none (bool, optional): If True, will return entire df if dict has\n                 no values. Defaults to False.\n        \"\"\"\n        _not_selection_keys = [\"modes\", \"all\", \"ignore_missing\"]\n        _selection_dict = {\n            k: v\n            for k, v in selection_dict.items()\n            if k not in _not_selection_keys and v is not None\n        }\n        missing_columns = [k for k in _selection_dict if k not in self._obj.columns]\n        if missing_columns:\n            msg = f\"Selection fields not found in dataframe: {missing_columns}\"\n            raise SelectionError(msg)\n\n        if not _selection_dict:\n            if return_all_if_none:\n                return self._obj\n            msg = f\"Relevant part of selection dictionary is empty: {selection_dict}\"\n            raise SelectionError(msg)\n\n        _sel_query = dict_to_query(_selection_dict)\n        # WranglerLogger.debug(f\"_sel_query: \\n   {_sel_query}\")\n        _df = self._obj.query(_sel_query, engine=\"python\")\n\n        if len(_df) == 0:\n            WranglerLogger.warning(\n                f\"No records found in df \\\n                  using selection: {selection_dict}\"\n            )\n        return _df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.DictQueryAccessor.__call__","title":"network_wrangler.utils.df_accessors.DictQueryAccessor.__call__","text":"<pre><code>__call__(selection_dict, return_all_if_none=False)\n</code></pre> <p>Queries the dataframe using the selection dictionary.</p> <p>Parameters:</p> <ul> <li> <code>selection_dict</code>               (<code>dict</code>)           \u2013            <p>description</p> </li> <li> <code>return_all_if_none</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, will return entire df if dict has  no values. Defaults to False.</p> </li> </ul> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self, selection_dict: dict, return_all_if_none: bool = False):\n    \"\"\"Queries the dataframe using the selection dictionary.\n\n    Args:\n        selection_dict (dict): _description_\n        return_all_if_none (bool, optional): If True, will return entire df if dict has\n             no values. Defaults to False.\n    \"\"\"\n    _not_selection_keys = [\"modes\", \"all\", \"ignore_missing\"]\n    _selection_dict = {\n        k: v\n        for k, v in selection_dict.items()\n        if k not in _not_selection_keys and v is not None\n    }\n    missing_columns = [k for k in _selection_dict if k not in self._obj.columns]\n    if missing_columns:\n        msg = f\"Selection fields not found in dataframe: {missing_columns}\"\n        raise SelectionError(msg)\n\n    if not _selection_dict:\n        if return_all_if_none:\n            return self._obj\n        msg = f\"Relevant part of selection dictionary is empty: {selection_dict}\"\n        raise SelectionError(msg)\n\n    _sel_query = dict_to_query(_selection_dict)\n    # WranglerLogger.debug(f\"_sel_query: \\n   {_sel_query}\")\n    _df = self._obj.query(_sel_query, engine=\"python\")\n\n    if len(_df) == 0:\n        WranglerLogger.warning(\n            f\"No records found in df \\\n              using selection: {selection_dict}\"\n        )\n    return _df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.DictQueryAccessor.__init__","title":"network_wrangler.utils.df_accessors.DictQueryAccessor.__init__","text":"<pre><code>__init__(pandas_obj)\n</code></pre> <p>Initialization function for the dictionary query accessor.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dictionary query accessor.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.Isin_dict","title":"network_wrangler.utils.df_accessors.Isin_dict","text":"<p>Faster implimentation of isin for querying dataframes with dictionary.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"isin_dict\")\nclass Isin_dict:\n    \"\"\"Faster implimentation of isin for querying dataframes with dictionary.\"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dataframe hash.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self, d: dict, **kwargs) -&gt; pd.DataFrame:\n        \"\"\"Function to perform the faster dictionary isin().\"\"\"\n        return isin_dict(self._obj, d, **kwargs)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.Isin_dict.__call__","title":"network_wrangler.utils.df_accessors.Isin_dict.__call__","text":"<pre><code>__call__(d, **kwargs)\n</code></pre> <p>Function to perform the faster dictionary isin().</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self, d: dict, **kwargs) -&gt; pd.DataFrame:\n    \"\"\"Function to perform the faster dictionary isin().\"\"\"\n    return isin_dict(self._obj, d, **kwargs)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.Isin_dict.__init__","title":"network_wrangler.utils.df_accessors.Isin_dict.__init__","text":"<pre><code>__init__(pandas_obj)\n</code></pre> <p>Initialization function for the dataframe hash.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dataframe hash.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.dfHash","title":"network_wrangler.utils.df_accessors.dfHash","text":"<p>Creates a dataframe hash that is compatable with geopandas and various metadata.</p> <p>Definitely not the fastest, but she seems to work where others have failed.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>@pd.api.extensions.register_dataframe_accessor(\"df_hash\")\nclass dfHash:\n    \"\"\"Creates a dataframe hash that is compatable with geopandas and various metadata.\n\n    Definitely not the fastest, but she seems to work where others have failed.\n    \"\"\"\n\n    def __init__(self, pandas_obj):\n        \"\"\"Initialization function for the dataframe hash.\"\"\"\n        self._obj = pandas_obj\n\n    def __call__(self):\n        \"\"\"Function to hash the dataframe with version-robust computation.\"\"\"\n        # Convert to a more stable representation that's less sensitive to version differences\n        # Sort the dataframe to ensure consistent ordering regardless of how it was loaded\n        df_sorted = self._obj.sort_index(axis=0).sort_index(axis=1)\n\n        # Use a more stable string representation that's less sensitive to version differences\n        # Convert to numpy array and then to string, which is more consistent across versions\n        _value = str(df_sorted.values.tolist()).encode()\n        hash = hashlib.sha1(_value).hexdigest()\n        return hash\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.dfHash.__call__","title":"network_wrangler.utils.df_accessors.dfHash.__call__","text":"<pre><code>__call__()\n</code></pre> <p>Function to hash the dataframe with version-robust computation.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __call__(self):\n    \"\"\"Function to hash the dataframe with version-robust computation.\"\"\"\n    # Convert to a more stable representation that's less sensitive to version differences\n    # Sort the dataframe to ensure consistent ordering regardless of how it was loaded\n    df_sorted = self._obj.sort_index(axis=0).sort_index(axis=1)\n\n    # Use a more stable string representation that's less sensitive to version differences\n    # Convert to numpy array and then to string, which is more consistent across versions\n    _value = str(df_sorted.values.tolist()).encode()\n    hash = hashlib.sha1(_value).hexdigest()\n    return hash\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.df_accessors.dfHash.__init__","title":"network_wrangler.utils.df_accessors.dfHash.__init__","text":"<pre><code>__init__(pandas_obj)\n</code></pre> <p>Initialization function for the dataframe hash.</p> Source code in <code>network_wrangler/utils/df_accessors.py</code> <pre><code>def __init__(self, pandas_obj):\n    \"\"\"Initialization function for the dataframe hash.\"\"\"\n    self._obj = pandas_obj\n</code></pre>"},{"location":"api_utils/#network-and-geographic-utilities","title":"Network and Geographic Utilities","text":"<p>Functions to help with network manipulations in dataframes.</p> <p>Helper geographic manipulation functions.</p>"},{"location":"api_utils/#network_wrangler.utils.net.point_seq_to_links","title":"network_wrangler.utils.net.point_seq_to_links","text":"<pre><code>point_seq_to_links(point_seq_df, id_field, seq_field, node_id_field, from_field='A', to_field='B')\n</code></pre> <p>Translates a df with tidy data representing a sequence of points into links.</p> <p>Parameters:</p> <ul> <li> <code>point_seq_df</code>               (<code>DataFrame</code>)           \u2013            <p>Dataframe with source breadcrumbs</p> </li> <li> <code>id_field</code>               (<code>str</code>)           \u2013            <p>Trace ID</p> </li> <li> <code>seq_field</code>               (<code>str</code>)           \u2013            <p>Order of breadcrumbs within ID_field</p> </li> <li> <code>node_id_field</code>               (<code>str</code>)           \u2013            <p>field denoting the node ID</p> </li> <li> <code>from_field</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>Field to export from_field to. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_field</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>Field to export to_field to. Defaults to \u201cB\u201d.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Link records with id_field, from_field, to_field</p> </li> </ul> Source code in <code>network_wrangler/utils/net.py</code> <pre><code>def point_seq_to_links(\n    point_seq_df: DataFrame,\n    id_field: str,\n    seq_field: str,\n    node_id_field: str,\n    from_field: str = \"A\",\n    to_field: str = \"B\",\n) -&gt; DataFrame:\n    \"\"\"Translates a df with tidy data representing a sequence of points into links.\n\n    Args:\n        point_seq_df (pd.DataFrame): Dataframe with source breadcrumbs\n        id_field (str): Trace ID\n        seq_field (str): Order of breadcrumbs within ID_field\n        node_id_field (str): field denoting the node ID\n        from_field (str, optional): Field to export from_field to. Defaults to \"A\".\n        to_field (str, optional): Field to export to_field to. Defaults to \"B\".\n\n    Returns:\n        pd.DataFrame: Link records with id_field, from_field, to_field\n    \"\"\"\n    point_seq_df = point_seq_df.sort_values(by=[id_field, seq_field])\n\n    links = point_seq_df.add_suffix(f\"_{from_field}\").join(\n        point_seq_df.shift(-1).add_suffix(f\"_{to_field}\")\n    )\n\n    links = links[links[f\"{id_field}_{to_field}\"] == links[f\"{id_field}_{from_field}\"]]\n\n    links = links.drop(columns=[f\"{id_field}_{to_field}\"])\n    links = links.rename(\n        columns={\n            f\"{id_field}_{from_field}\": id_field,\n            f\"{node_id_field}_{from_field}\": from_field,\n            f\"{node_id_field}_{to_field}\": to_field,\n        }\n    )\n\n    links = links.dropna(subset=[from_field, to_field])\n    # Since join with a shift() has some NAs, we need to recast the columns to int\n    _int_cols = [to_field, f\"{seq_field}_{to_field}\"]\n    links[_int_cols] = links[_int_cols].astype(int)\n    return links\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.InvalidCRSError","title":"network_wrangler.utils.geo.InvalidCRSError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a point is not valid for a given coordinate reference system.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>class InvalidCRSError(Exception):\n    \"\"\"Raised when a point is not valid for a given coordinate reference system.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.check_point_valid_for_crs","title":"network_wrangler.utils.geo.check_point_valid_for_crs","text":"<pre><code>check_point_valid_for_crs(point, crs)\n</code></pre> <p>Check if a point is valid for a given coordinate reference system.</p> <p>Parameters:</p> <ul> <li> <code>point</code>               (<code>Point</code>)           \u2013            <p>Shapely Point</p> </li> <li> <code>crs</code>               (<code>int</code>)           \u2013            <p>coordinate reference system in ESPG code</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def check_point_valid_for_crs(point: Point, crs: int):\n    \"\"\"Check if a point is valid for a given coordinate reference system.\n\n    Args:\n        point: Shapely Point\n        crs: coordinate reference system in ESPG code\n\n    raises: InvalidCRSError if point is not valid for the given crs\n    \"\"\"\n    crs = CRS.from_user_input(crs)\n    minx, miny, maxx, maxy = crs.area_of_use.bounds\n    ok_bounds = True\n    if not minx &lt;= point.x &lt;= maxx:\n        WranglerLogger.error(f\"Invalid X coordinate for CRS {crs}: {point.x}\")\n        ok_bounds = False\n    if not miny &lt;= point.y &lt;= maxy:\n        WranglerLogger.error(f\"Invalid Y coordinate for CRS {crs}: {point.y}\")\n        ok_bounds = False\n\n    if not ok_bounds:\n        msg = f\"Invalid coordinate for CRS {crs}: {point.x}, {point.y}\"\n        raise InvalidCRSError(msg)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.get_bearing","title":"network_wrangler.utils.geo.get_bearing","text":"<pre><code>get_bearing(lat1, lon1, lat2, lon2)\n</code></pre> <p>Calculate the bearing (forward azimuth) b/w the two points.</p> <p>returns: bearing in radians</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_bearing(lat1, lon1, lat2, lon2):\n    \"\"\"Calculate the bearing (forward azimuth) b/w the two points.\n\n    returns: bearing in radians\n    \"\"\"\n    # bearing in degrees\n    brng = Geodesic.WGS84.Inverse(lat1, lon1, lat2, lon2)[\"azi1\"]\n\n    # convert bearing to radians\n    brng = math.radians(brng)\n\n    return brng\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.get_bounding_polygon","title":"network_wrangler.utils.geo.get_bounding_polygon","text":"<pre><code>get_bounding_polygon(boundary_geocode=None, boundary_file=None, boundary_gdf=None, crs=LAT_LON_CRS)\n</code></pre> <p>Get the bounding polygon for a given boundary.</p> <p>Will return None if no arguments given. Will raise a ValueError if more than one given.</p> <p>This function retrieves the bounding polygon for a given boundary. The boundary can be provided as a GeoDataFrame, a geocode string or dictionary, or a boundary file. The resulting polygon geometry is returned as a GeoSeries.</p> <p>Parameters:</p> <ul> <li> <code>boundary_geocode</code>               (<code>Union[str, dict]</code>, default:                   <code>None</code> )           \u2013            <p>A geocode string or dictionary representing the boundary. Defaults to None.</p> </li> <li> <code>boundary_file</code>               (<code>Union[str, Path]</code>, default:                   <code>None</code> )           \u2013            <p>A path to the boundary file. Only used if boundary_geocode is None. Defaults to None.</p> </li> <li> <code>boundary_gdf</code>               (<code>GeoDataFrame</code>, default:                   <code>None</code> )           \u2013            <p>A GeoDataFrame representing the boundary. Only used if boundary_geocode and boundary_file are None. Defaults to None.</p> </li> <li> <code>crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>The coordinate reference system (CRS) code. Defaults to 4326 (WGS84).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GeoSeries</code>           \u2013            <p>gpd.GeoSeries: The polygon geometry representing the bounding polygon.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_bounding_polygon(\n    boundary_geocode: Optional[Union[str, dict]] = None,\n    boundary_file: Optional[Union[str, Path]] = None,\n    boundary_gdf: Optional[gpd.GeoDataFrame] = None,\n    crs: int = LAT_LON_CRS,  # WGS84\n) -&gt; gpd.GeoSeries:\n    \"\"\"Get the bounding polygon for a given boundary.\n\n    Will return None if no arguments given. Will raise a ValueError if more than one given.\n\n    This function retrieves the bounding polygon for a given boundary. The boundary can be provided\n    as a GeoDataFrame, a geocode string or dictionary, or a boundary file. The resulting polygon\n    geometry is returned as a GeoSeries.\n\n    Args:\n        boundary_geocode (Union[str, dict], optional): A geocode string or dictionary\n            representing the boundary. Defaults to None.\n        boundary_file (Union[str, Path], optional): A path to the boundary file. Only used if\n            boundary_geocode is None. Defaults to None.\n        boundary_gdf (gpd.GeoDataFrame, optional): A GeoDataFrame representing the boundary.\n            Only used if boundary_geocode and boundary_file are None. Defaults to None.\n        crs (int, optional): The coordinate reference system (CRS) code. Defaults to 4326 (WGS84).\n\n    Returns:\n        gpd.GeoSeries: The polygon geometry representing the bounding polygon.\n    \"\"\"\n    import osmnx as ox  # noqa: PLC0415\n\n    nargs = sum(x is not None for x in [boundary_gdf, boundary_geocode, boundary_file])\n    if nargs == 0:\n        return None\n    if nargs != 1:\n        msg = \"Exactly one of boundary_gdf, boundary_geocode, or boundary_file must be provided.\"\n        raise ValueError(msg)\n\n    OK_BOUNDARY_SUFF = [\".shp\", \".geojson\", \".parquet\"]\n\n    if boundary_geocode is not None:\n        boundary_gdf = ox.geocode_to_gdf(boundary_geocode)\n    elif boundary_file is not None:\n        boundary_file = Path(boundary_file)\n        if boundary_file.suffix not in OK_BOUNDARY_SUFF:\n            msg = \"Boundary file must have one of the following suffixes: {OK_BOUNDARY_SUFF}\"\n            raise ValueError(msg)\n        if not boundary_file.exists():\n            msg = f\"Boundary file {boundary_file} does not exist\"\n            raise FileNotFoundError(msg)\n        if boundary_file.suffix == \".parquet\":\n            boundary_gdf = gpd.read_parquet(boundary_file)\n        else:\n            boundary_gdf = gpd.read_file(boundary_file)\n            if boundary_file.suffix == \".geojson\":  # geojson standard is WGS84\n                boundary_gdf.crs = crs\n\n    if boundary_gdf is None:\n        msg = \"One of boundary_gdf, boundary_geocode or boundary_file must be provided.\"\n        raise ValueError(msg)\n\n    if boundary_gdf.crs is not None:\n        boundary_gdf = boundary_gdf.to_crs(crs)\n    # make sure boundary_gdf is a polygon\n    if len(boundary_gdf.geom_type[boundary_gdf.geom_type != \"Polygon\"]) &gt; 0:\n        msg = \"boundary_gdf must all be Polygons\"\n        raise ValueError(msg)\n    # get the boundary as a single polygon\n    boundary_gs = gpd.GeoSeries([boundary_gdf.geometry.union_all()], crs=crs)\n\n    return boundary_gs\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.get_point_geometry_from_linestring","title":"network_wrangler.utils.geo.get_point_geometry_from_linestring","text":"<pre><code>get_point_geometry_from_linestring(polyline_geometry, pos=0)\n</code></pre> <p>Get a point geometry from a linestring geometry.</p> <p>Parameters:</p> <ul> <li> <code>polyline_geometry</code>           \u2013            <p>shapely LineString instance</p> </li> <li> <code>pos</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>position in the linestring to get the point from. Defaults to 0.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def get_point_geometry_from_linestring(polyline_geometry, pos: int = 0):\n    \"\"\"Get a point geometry from a linestring geometry.\n\n    Args:\n        polyline_geometry: shapely LineString instance\n        pos: position in the linestring to get the point from. Defaults to 0.\n    \"\"\"\n    # WranglerLogger.debug(\n    #    f\"get_point_geometry_from_linestring.polyline_geometry.coords[0]: \\\n    #    {polyline_geometry.coords[0]}.\"\n    # )\n\n    # Note: when upgrading to shapely 2.0, will need to use following command\n    # _point_coords = get_coordinates(polyline_geometry).tolist()[pos]\n    return point_from_xy(*polyline_geometry.coords[pos])\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.length_of_linestring_miles","title":"network_wrangler.utils.geo.length_of_linestring_miles","text":"<pre><code>length_of_linestring_miles(gdf)\n</code></pre> <p>Returns a Series with the linestring length in miles.</p> <p>Parameters:</p> <ul> <li> <code>gdf</code>               (<code>Union[GeoSeries, GeoDataFrame]</code>)           \u2013            <p>GeoDataFrame with linestring geometry.  If given a GeoSeries will attempt to convert to a GeoDataFrame.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def length_of_linestring_miles(gdf: Union[gpd.GeoSeries, gpd.GeoDataFrame]) -&gt; pd.Series:\n    \"\"\"Returns a Series with the linestring length in miles.\n\n    Args:\n        gdf: GeoDataFrame with linestring geometry.  If given a GeoSeries will attempt to convert\n            to a GeoDataFrame.\n    \"\"\"\n    # WranglerLogger.debug(f\"length_of_linestring_miles.gdf input:\\n{gdf}.\")\n    if isinstance(gdf, gpd.GeoSeries):\n        gdf = gpd.GeoDataFrame(geometry=gdf)\n\n    p_crs = gdf.estimate_utm_crs()\n    gdf = gdf.to_crs(p_crs)\n    METERS_IN_MILES = 1609.34\n    length_miles = gdf.geometry.length / METERS_IN_MILES\n    length_s = pd.Series(length_miles, index=gdf.index)\n\n    return length_s\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.linestring_from_lats_lons","title":"network_wrangler.utils.geo.linestring_from_lats_lons","text":"<pre><code>linestring_from_lats_lons(df, lat_fields, lon_fields)\n</code></pre> <p>Create a LineString geometry from a DataFrame with lon/lat fields.</p> <p>Parameters:</p> <ul> <li> <code>df</code>           \u2013            <p>DataFrame with columns for lon/lat fields.</p> </li> <li> <code>lat_fields</code>           \u2013            <p>list of column names for the lat fields.</p> </li> <li> <code>lon_fields</code>           \u2013            <p>list of column names for the lon fields.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def linestring_from_lats_lons(df, lat_fields, lon_fields) -&gt; gpd.GeoSeries:\n    \"\"\"Create a LineString geometry from a DataFrame with lon/lat fields.\n\n    Args:\n        df: DataFrame with columns for lon/lat fields.\n        lat_fields: list of column names for the lat fields.\n        lon_fields: list of column names for the lon fields.\n    \"\"\"\n    if len(lon_fields) != len(lat_fields):\n        msg = \"lon_fields and lat_fields lists must have the same length\"\n        raise ValueError(msg)\n\n    line_geometries = gpd.GeoSeries(\n        [\n            LineString([(row[lon], row[lat]) for lon, lat in zip(lon_fields, lat_fields)])\n            for _, row in df.iterrows()\n        ]\n    )\n\n    return gpd.GeoSeries(line_geometries)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.linestring_from_nodes","title":"network_wrangler.utils.geo.linestring_from_nodes","text":"<pre><code>linestring_from_nodes(links_df, nodes_df, from_node='A', to_node='B', node_pk='model_node_id')\n</code></pre> <p>Creates a LineString geometry GeoSeries from a DataFrame of links and a DataFrame of nodes.</p> <p>Parameters:</p> <ul> <li> <code>links_df</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame with columns for from_node and to_node.</p> </li> <li> <code>nodes_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>GeoDataFrame with geometry column.</p> </li> <li> <code>from_node</code>               (<code>str</code>, default:                   <code>'A'</code> )           \u2013            <p>column name in links_df for the from node. Defaults to \u201cA\u201d.</p> </li> <li> <code>to_node</code>               (<code>str</code>, default:                   <code>'B'</code> )           \u2013            <p>column name in links_df for the to node. Defaults to \u201cB\u201d.</p> </li> <li> <code>node_pk</code>               (<code>str</code>, default:                   <code>'model_node_id'</code> )           \u2013            <p>primary key column name in nodes_df. Defaults to \u201cmodel_node_id\u201d.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def linestring_from_nodes(\n    links_df: pd.DataFrame,\n    nodes_df: gpd.GeoDataFrame,\n    from_node: str = \"A\",\n    to_node: str = \"B\",\n    node_pk: str = \"model_node_id\",\n) -&gt; gpd.GeoSeries:\n    \"\"\"Creates a LineString geometry GeoSeries from a DataFrame of links and a DataFrame of nodes.\n\n    Args:\n        links_df: DataFrame with columns for from_node and to_node.\n        nodes_df: GeoDataFrame with geometry column.\n        from_node: column name in links_df for the from node. Defaults to \"A\".\n        to_node: column name in links_df for the to node. Defaults to \"B\".\n        node_pk: primary key column name in nodes_df. Defaults to \"model_node_id\".\n    \"\"\"\n    assert \"geometry\" in nodes_df.columns, \"nodes_df must have a 'geometry' column\"\n\n    idx_name = \"index\" if links_df.index.name is None else links_df.index.name\n    # WranglerLogger.debug(f\"Index name: {idx_name}\")\n    required_link_cols = [from_node, to_node]\n\n    if not all(col in links_df.columns for col in required_link_cols):\n        WranglerLogger.error(\n            f\"links_df.columns missing required columns.\\n\\\n                            links_df.columns: {links_df.columns}\\n\\\n                            required_link_cols: {required_link_cols}\"\n        )\n        msg = \"links_df must have columns {required_link_cols} to create linestring from nodes\"\n        raise ValueError(msg)\n\n    links_geo_df = copy.deepcopy(links_df[required_link_cols])\n    # need to continuously reset the index to make sure the index is the same as the link index\n    links_geo_df = (\n        links_geo_df.reset_index()\n        .merge(\n            nodes_df[[node_pk, \"geometry\"]],\n            left_on=from_node,\n            right_on=node_pk,\n            how=\"left\",\n        )\n        .set_index(idx_name)\n    )\n\n    links_geo_df = links_geo_df.rename(columns={\"geometry\": \"geometry_A\"})\n\n    links_geo_df = (\n        links_geo_df.reset_index()\n        .merge(\n            nodes_df[[node_pk, \"geometry\"]],\n            left_on=to_node,\n            right_on=node_pk,\n            how=\"left\",\n        )\n        .set_index(idx_name)\n    )\n\n    links_geo_df = links_geo_df.rename(columns={\"geometry\": \"geometry_B\"})\n\n    # makes sure all nodes exist\n    _missing_geo_links_df = links_geo_df[\n        links_geo_df[\"geometry_A\"].isnull() | links_geo_df[\"geometry_B\"].isnull()\n    ]\n    if not _missing_geo_links_df.empty:\n        missing_nodes = _missing_geo_links_df[[from_node, to_node]].values\n        WranglerLogger.error(\n            f\"Cannot create link geometry from nodes because the nodes are\\\n                             missing from the network. Missing nodes: {missing_nodes}\"\n        )\n        msg = \"Cannot create link geometry from nodes because the nodes are missing from the network.\"\n        raise MissingNodesError(msg)\n\n    # create geometry from points\n    links_geo_df[\"geometry\"] = links_geo_df.apply(\n        lambda row: LineString([row[\"geometry_A\"], row[\"geometry_B\"]]), axis=1\n    )\n\n    # convert to GeoDataFrame\n    links_gdf = gpd.GeoDataFrame(links_geo_df[\"geometry\"], geometry=links_geo_df[\"geometry\"])\n    return links_gdf[\"geometry\"]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.location_ref_from_point","title":"network_wrangler.utils.geo.location_ref_from_point","text":"<pre><code>location_ref_from_point(geometry, sequence=1, bearing=None, distance_to_next_ref=None)\n</code></pre> <p>Generates a shared street point location reference.</p> <p>Parameters:</p> <ul> <li> <code>geometry</code>               (<code>Point</code>)           \u2013            <p>Point shapely geometry</p> </li> <li> <code>sequence</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Sequence if part of polyline. Defaults to None.</p> </li> <li> <code>bearing</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>Direction of line if part of polyline. Defaults to None.</p> </li> <li> <code>distance_to_next_ref</code>               (<code>float</code>, default:                   <code>None</code> )           \u2013            <p>Distnce to next point if part of polyline. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LocationReference</code> (              <code>LocationReference</code> )          \u2013            <p>As defined by sharedStreets.io schema</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_ref_from_point(\n    geometry: Point,\n    sequence: int = 1,\n    bearing: Optional[float] = None,\n    distance_to_next_ref: Optional[float] = None,\n) -&gt; LocationReference:\n    \"\"\"Generates a shared street point location reference.\n\n    Args:\n        geometry (Point): Point shapely geometry\n        sequence (int, optional): Sequence if part of polyline. Defaults to None.\n        bearing (float, optional): Direction of line if part of polyline. Defaults to None.\n        distance_to_next_ref (float, optional): Distnce to next point if part of polyline.\n            Defaults to None.\n\n    Returns:\n        LocationReference: As defined by sharedStreets.io schema\n    \"\"\"\n    lr = {\n        \"point\": LatLongCoordinates(geometry.coords[0]),\n    }\n\n    for arg in [\"sequence\", \"bearing\", \"distance_to_next_ref\"]:\n        if locals()[arg] is not None:\n            lr[arg] = locals()[arg]\n\n    return LocationReference(**lr)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.location_refs_from_linestring","title":"network_wrangler.utils.geo.location_refs_from_linestring","text":"<pre><code>location_refs_from_linestring(geometry)\n</code></pre> <p>Generates a shared street location reference from linestring.</p> <p>Parameters:</p> <ul> <li> <code>geometry</code>               (<code>LineString</code>)           \u2013            <p>Shapely LineString instance</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>LocationReferences</code> (              <code>list[LocationReference]</code> )          \u2013            <p>As defined by sharedStreets.io schema</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def location_refs_from_linestring(geometry: LineString) -&gt; list[LocationReference]:\n    \"\"\"Generates a shared street location reference from linestring.\n\n    Args:\n        geometry (LineString): Shapely LineString instance\n\n    Returns:\n        LocationReferences: As defined by sharedStreets.io schema\n    \"\"\"\n    return [\n        location_ref_from_point(\n            point,\n            sequence=i + 1,\n            distance_to_next_ref=point.distance(geometry.coords[i + 1]),\n            bearing=get_bearing(*point.coords[0], *geometry.coords[i + 1]),\n        )\n        for i, point in enumerate(geometry.coords[:-1])\n    ]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.offset_geometry_meters","title":"network_wrangler.utils.geo.offset_geometry_meters","text":"<pre><code>offset_geometry_meters(geo_s, offset_distance_meters)\n</code></pre> <p>Offset a GeoSeries of LineStrings by a given distance in meters.</p> <p>Parameters:</p> <ul> <li> <code>geo_s</code>               (<code>GeoSeries</code>)           \u2013            <p>GeoSeries of LineStrings to offset.</p> </li> <li> <code>offset_distance_meters</code>               (<code>float</code>)           \u2013            <p>distance in meters to offset the LineStrings.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_geometry_meters(geo_s: gpd.GeoSeries, offset_distance_meters: float) -&gt; gpd.GeoSeries:\n    \"\"\"Offset a GeoSeries of LineStrings by a given distance in meters.\n\n    Args:\n        geo_s: GeoSeries of LineStrings to offset.\n        offset_distance_meters: distance in meters to offset the LineStrings.\n    \"\"\"\n    if geo_s.empty:\n        return geo_s\n    og_crs = geo_s.crs\n    meters_crs = _id_utm_crs(geo_s)\n    geo_s = geo_s.to_crs(meters_crs)\n    offset_geo = geo_s.apply(lambda x: x.offset_curve(offset_distance_meters))\n    offset_geo = gpd.GeoSeries(offset_geo)\n    return offset_geo.to_crs(og_crs)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.offset_point_with_distance_and_bearing","title":"network_wrangler.utils.geo.offset_point_with_distance_and_bearing","text":"<pre><code>offset_point_with_distance_and_bearing(lon, lat, distance, bearing)\n</code></pre> <p>Get the new lon-lat (in degrees) given current point (lon-lat), distance and bearing.</p> <p>Parameters:</p> <ul> <li> <code>lon</code>               (<code>float</code>)           \u2013            <p>longitude of original point</p> </li> <li> <code>lat</code>               (<code>float</code>)           \u2013            <p>latitude of original point</p> </li> <li> <code>distance</code>               (<code>float</code>)           \u2013            <p>distance in meters to offset point by</p> </li> <li> <code>bearing</code>               (<code>float</code>)           \u2013            <p>direction to offset point to in radians</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def offset_point_with_distance_and_bearing(\n    lon: float, lat: float, distance: float, bearing: float\n) -&gt; list[float]:\n    \"\"\"Get the new lon-lat (in degrees) given current point (lon-lat), distance and bearing.\n\n    Args:\n        lon: longitude of original point\n        lat: latitude of original point\n        distance: distance in meters to offset point by\n        bearing: direction to offset point to in radians\n\n    returns: list of new offset lon-lat\n    \"\"\"\n    # Earth's radius in meters\n    radius = 6378137\n\n    # convert the lat long from degree to radians\n    lat_radians = math.radians(lat)\n    lon_radians = math.radians(lon)\n\n    # calculate the new lat long in radians\n    out_lat_radians = math.asin(\n        math.sin(lat_radians) * math.cos(distance / radius)\n        + math.cos(lat_radians) * math.sin(distance / radius) * math.cos(bearing)\n    )\n\n    out_lon_radians = lon_radians + math.atan2(\n        math.sin(bearing) * math.sin(distance / radius) * math.cos(lat_radians),\n        math.cos(distance / radius) - math.sin(lat_radians) * math.sin(lat_radians),\n    )\n    # convert the new lat long back to degree\n    out_lat = math.degrees(out_lat_radians)\n    out_lon = math.degrees(out_lon_radians)\n\n    return [out_lon, out_lat]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.point_from_xy","title":"network_wrangler.utils.geo.point_from_xy","text":"<pre><code>point_from_xy(x, y, xy_crs=LAT_LON_CRS, point_crs=LAT_LON_CRS)\n</code></pre> <p>Creates point geometry from x and y coordinates.</p> <p>Parameters:</p> <ul> <li> <code>x</code>           \u2013            <p>x coordinate, in xy_crs</p> </li> <li> <code>y</code>           \u2013            <p>y coordinate, in xy_crs</p> </li> <li> <code>xy_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)</p> </li> <li> <code>point_crs</code>               (<code>int</code>, default:                   <code>LAT_LON_CRS</code> )           \u2013            <p>coordinate reference system in ESPG code for point output. Defaults to 4326 (WGS84)</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def point_from_xy(x, y, xy_crs: int = LAT_LON_CRS, point_crs: int = LAT_LON_CRS):\n    \"\"\"Creates point geometry from x and y coordinates.\n\n    Args:\n        x: x coordinate, in xy_crs\n        y: y coordinate, in xy_crs\n        xy_crs: coordinate reference system in ESPG code for x/y inputs. Defaults to 4326 (WGS84)\n        point_crs: coordinate reference system in ESPG code for point output.\n            Defaults to 4326 (WGS84)\n\n    Returns: Shapely Point in point_crs\n    \"\"\"\n    point = Point(x, y)\n\n    if xy_crs == point_crs:\n        check_point_valid_for_crs(point, point_crs)\n        return point\n\n    if (xy_crs, point_crs) not in transformers:\n        # store transformers in dictionary because they are an \"expensive\" operation\n        transformers[(xy_crs, point_crs)] = Transformer.from_proj(\n            Proj(init=\"epsg:\" + str(xy_crs)),\n            Proj(init=\"epsg:\" + str(point_crs)),\n            always_xy=True,  # required b/c Proj v6+ uses lon/lat instead of x/y\n        )\n\n    return transform(transformers[(xy_crs, point_crs)].transform, point)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.to_points_gdf","title":"network_wrangler.utils.geo.to_points_gdf","text":"<pre><code>to_points_gdf(table, ref_nodes_df=None, ref_road_net=None)\n</code></pre> <p>Convert a table to a GeoDataFrame.</p> <p>If the table is already a GeoDataFrame, return it as is. Otherwise, attempt to convert the table to a GeoDataFrame using the following methods: 1. If the table has a \u2018geometry\u2019 column, return a GeoDataFrame using that column. 2. If the table has \u2018lat\u2019 and \u2018lon\u2019 columns, return a GeoDataFrame using those columns. 3. If the table has a \u2018*model_node_id\u2019 or \u2018stop_id\u2019 column, return a GeoDataFrame using that column and the      nodes_df provided. If none of the above, raise a ValueError.</p> <p>Parameters:</p> <ul> <li> <code>table</code>               (<code>DataFrame</code>)           \u2013            <p>DataFrame to convert to GeoDataFrame.</p> </li> <li> <code>ref_nodes_df</code>               (<code>Optional[GeoDataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>GeoDataFrame of nodes to use to convert model_node_id to geometry.</p> </li> <li> <code>ref_road_net</code>               (<code>Optional[RoadwayNetwork]</code>, default:                   <code>None</code> )           \u2013            <p>RoadwayNetwork object to use to convert model_node_id to geometry.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GeoDataFrame</code> (              <code>GeoDataFrame</code> )          \u2013            <p>GeoDataFrame representation of the table.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def to_points_gdf(\n    table: pd.DataFrame,\n    ref_nodes_df: Optional[gpd.GeoDataFrame] = None,\n    ref_road_net: Optional[RoadwayNetwork] = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Convert a table to a GeoDataFrame.\n\n    If the table is already a GeoDataFrame, return it as is. Otherwise, attempt to convert the\n    table to a GeoDataFrame using the following methods:\n    1. If the table has a 'geometry' column, return a GeoDataFrame using that column.\n    2. If the table has 'lat' and 'lon' columns, return a GeoDataFrame using those columns.\n    3. If the table has a '*model_node_id' or 'stop_id' column, return a GeoDataFrame using that column and the\n         nodes_df provided.\n    If none of the above, raise a ValueError.\n\n    Args:\n        table: DataFrame to convert to GeoDataFrame.\n        ref_nodes_df: GeoDataFrame of nodes to use to convert model_node_id to geometry.\n        ref_road_net: RoadwayNetwork object to use to convert model_node_id to geometry.\n\n    Returns:\n        GeoDataFrame: GeoDataFrame representation of the table.\n    \"\"\"\n    if table is gpd.GeoDataFrame:\n        return table\n\n    WranglerLogger.debug(\"Converting GTFS table to GeoDataFrame\")\n    if \"geometry\" in table.columns:\n        return gpd.GeoDataFrame(table, geometry=\"geometry\")\n\n    lat_cols = list(filter(lambda col: \"lat\" in col, table.columns))\n    lon_cols = list(filter(lambda col: \"lon\" in col, table.columns))\n    model_node_id_cols = [\n        c for c in [\"model_node_id\", \"stop_id\", \"shape_model_node_id\"] if c in table.columns\n    ]\n\n    if not (lat_cols and lon_cols) or not model_node_id_cols:\n        WranglerLogger.error(\n            \"Needed either lat/long or *model_node_id columns to convert \\\n            to GeoDataFrame. Columns found: {table.columns}\"\n        )\n        if not (lat_cols and lon_cols):\n            WranglerLogger.error(\"No lat/long cols found.\")\n        if not model_node_id_cols:\n            WranglerLogger.error(\"No *model_node_id cols found.\")\n        msg = \"Could not find lat/long, geometry columns or *model_node_id column in \\\n                         table necessary to convert to GeoDataFrame\"\n        raise ValueError(msg)\n\n    if lat_cols and lon_cols:\n        # using first found lat and lon columns\n        return gpd.GeoDataFrame(\n            table,\n            geometry=gpd.points_from_xy(table[lon_cols[0]], table[lat_cols[0]]),\n            crs=\"EPSG:4326\",\n        )\n\n    if model_node_id_cols:\n        node_id_col = model_node_id_cols[0]\n\n        if ref_nodes_df is None:\n            if ref_road_net is None:\n                msg = \"Must provide either nodes_df or road_net to convert \\\n                                 model_node_id to geometry\"\n                raise ValueError(msg)\n            ref_nodes_df = ref_road_net.nodes_df\n\n        WranglerLogger.debug(\"Converting table to GeoDataFrame using model_node_id\")\n\n        _table = table.merge(\n            ref_nodes_df[[\"model_node_id\", \"geometry\"]],\n            left_on=node_id_col,\n            right_on=\"model_node_id\",\n        )\n        return gpd.GeoDataFrame(_table, geometry=\"geometry\")\n    msg = \"Could not find lat/long, geometry columns or *model_node_id column in table \\\n                        necessary to convert to GeoDataFrame\"\n    raise ValueError(msg)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.update_nodes_in_linestring_geometry","title":"network_wrangler.utils.geo.update_nodes_in_linestring_geometry","text":"<pre><code>update_nodes_in_linestring_geometry(original_df, updated_nodes_df, position)\n</code></pre> <p>Updates the nodes in a linestring geometry and returns updated geometry.</p> <p>Parameters:</p> <ul> <li> <code>original_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>GeoDataFrame with the <code>model_node_id</code> and linestring geometry</p> </li> <li> <code>updated_nodes_df</code>               (<code>GeoDataFrame</code>)           \u2013            <p>GeoDataFrame with updated node geometries.</p> </li> <li> <code>position</code>               (<code>int</code>)           \u2013            <p>position in the linestring to update with the node.</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_nodes_in_linestring_geometry(\n    original_df: gpd.GeoDataFrame,\n    updated_nodes_df: gpd.GeoDataFrame,\n    position: int,\n) -&gt; gpd.GeoSeries:\n    \"\"\"Updates the nodes in a linestring geometry and returns updated geometry.\n\n    Args:\n        original_df: GeoDataFrame with the `model_node_id` and linestring geometry\n        updated_nodes_df: GeoDataFrame with updated node geometries.\n        position: position in the linestring to update with the node.\n    \"\"\"\n    LINK_FK_NODE = [\"A\", \"B\"]\n    original_index = original_df.index\n\n    updated_df = original_df.reset_index().merge(\n        updated_nodes_df[[\"model_node_id\", \"geometry\"]],\n        left_on=LINK_FK_NODE[position],\n        right_on=\"model_node_id\",\n        suffixes=(\"\", \"_node\"),\n    )\n\n    updated_df[\"geometry\"] = updated_df.apply(\n        lambda row: update_points_in_linestring(\n            row[\"geometry\"], row[\"geometry_node\"].coords[0], position\n        ),\n        axis=1,\n    )\n\n    updated_df = updated_df.reset_index().set_index(original_index.names)\n\n    WranglerLogger.debug(f\"updated_df - AFTER: \\n {updated_df.geometry}\")\n    return updated_df[\"geometry\"]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.update_point_geometry","title":"network_wrangler.utils.geo.update_point_geometry","text":"<pre><code>update_point_geometry(df, ref_point_df, lon_field='X', lat_field='Y', id_field='model_node_id', ref_lon_field='X', ref_lat_field='Y', ref_id_field='model_node_id')\n</code></pre> <p>Returns copy of df with lat and long fields updated with geometry from ref_point_df.</p> <p>NOTE: does not update \u201cgeometry\u201d field if it exists.</p> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_point_geometry(\n    df: pd.DataFrame,\n    ref_point_df: pd.DataFrame,\n    lon_field: str = \"X\",\n    lat_field: str = \"Y\",\n    id_field: str = \"model_node_id\",\n    ref_lon_field: str = \"X\",\n    ref_lat_field: str = \"Y\",\n    ref_id_field: str = \"model_node_id\",\n) -&gt; pd.DataFrame:\n    \"\"\"Returns copy of df with lat and long fields updated with geometry from ref_point_df.\n\n    NOTE: does not update \"geometry\" field if it exists.\n    \"\"\"\n    df = copy.deepcopy(df)\n\n    ref_df = ref_point_df.rename(\n        columns={\n            ref_lon_field: lon_field,\n            ref_lat_field: lat_field,\n            ref_id_field: id_field,\n        }\n    )\n\n    updated_df = update_df_by_col_value(\n        df,\n        ref_df[[id_field, lon_field, lat_field]],\n        id_field,\n        properties=[lat_field, lon_field],\n        fail_if_missing=False,\n    )\n    return updated_df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.geo.update_points_in_linestring","title":"network_wrangler.utils.geo.update_points_in_linestring","text":"<pre><code>update_points_in_linestring(linestring, updated_coords, position)\n</code></pre> <p>Replaces a point in a linestring with a new point.</p> <p>Parameters:</p> <ul> <li> <code>linestring</code>               (<code>LineString</code>)           \u2013            <p>original_linestring</p> </li> <li> <code>updated_coords</code>               (<code>List[float]</code>)           \u2013            <p>updated poimt coordinates</p> </li> <li> <code>position</code>               (<code>int</code>)           \u2013            <p>position in the linestring to update</p> </li> </ul> Source code in <code>network_wrangler/utils/geo.py</code> <pre><code>def update_points_in_linestring(\n    linestring: LineString, updated_coords: list[float], position: int\n):\n    \"\"\"Replaces a point in a linestring with a new point.\n\n    Args:\n        linestring (LineString): original_linestring\n        updated_coords (List[float]): updated poimt coordinates\n        position (int): position in the linestring to update\n    \"\"\"\n    coords = [c for c in linestring.coords]\n    coords[position] = updated_coords\n    return LineString(coords)\n</code></pre>"},{"location":"api_utils/#time-utilities","title":"Time Utilities","text":"<p>Functions related to parsing and comparing time objects and series.</p> <p>Internal function terminology for timespan scopes:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given timespan combination.     This includes the default timespan as well as scopes wholely contained within.</li> <li><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan.     This includes the default timespan, all <code>matching</code> timespans and all timespans where     at least one minute overlap.</li> <li><code>conflicting</code>: a timespan that is overlapping but not matching. By definition default      scope values are not conflicting.</li> <li><code>independent</code> a timespan that is not overlapping.</li> </ul> <p>Module for time and timespan objects.</p>"},{"location":"api_utils/#network_wrangler.utils.time.TimespanDfQueryError","title":"network_wrangler.utils.time.TimespanDfQueryError","text":"<p>               Bases: <code>Exception</code></p> <p>Error for timespan query errors.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>class TimespanDfQueryError(Exception):\n    \"\"\"Error for timespan query errors.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.calc_overlap_duration_with_query","title":"network_wrangler.utils.time.calc_overlap_duration_with_query","text":"<pre><code>calc_overlap_duration_with_query(start_time_s, end_time_s, start_time_q, end_time_q)\n</code></pre> <p>Calculate the overlap series of start and end times and a query start and end times.</p> <p>Parameters:</p> <ul> <li> <code>start_time_s</code>               (<code>Series[datetime]</code>)           \u2013            <p>Series of start times to calculate overlap with.</p> </li> <li> <code>end_time_s</code>               (<code>Series[datetime]</code>)           \u2013            <p>Series of end times to calculate overlap with.</p> </li> <li> <code>start_time_q</code>               (<code>datetime</code>)           \u2013            <p>Query start time to calculate overlap with.</p> </li> <li> <code>end_time_q</code>               (<code>datetime</code>)           \u2013            <p>Query end time to calculate overlap with.</p> </li> </ul> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def calc_overlap_duration_with_query(\n    start_time_s: pd.Series[datetime],\n    end_time_s: pd.Series[datetime],\n    start_time_q: datetime,\n    end_time_q: datetime,\n) -&gt; pd.Series[timedelta]:\n    \"\"\"Calculate the overlap series of start and end times and a query start and end times.\n\n    Args:\n        start_time_s: Series of start times to calculate overlap with.\n        end_time_s: Series of end times to calculate overlap with.\n        start_time_q: Query start time to calculate overlap with.\n        end_time_q: Query end time to calculate overlap with.\n    \"\"\"\n    overlap_start = start_time_s.combine(start_time_q, max)\n    overlap_end = end_time_s.combine(end_time_q, min)\n    overlap_duration_s = (overlap_end - overlap_start).dt.total_seconds() / 60\n\n    return overlap_duration_s\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.convert_timespan_to_start_end_dt","title":"network_wrangler.utils.time.convert_timespan_to_start_end_dt","text":"<pre><code>convert_timespan_to_start_end_dt(timespan_s)\n</code></pre> <p>Convert a timespan string [\u201812:00\u2019,\u201814:00] to start_time &amp; end_time datetime cols in df.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def convert_timespan_to_start_end_dt(timespan_s: pd.Serie[str]) -&gt; pd.DataFrame:\n    \"\"\"Convert a timespan string ['12:00','14:00] to start_time &amp; end_time datetime cols in df.\"\"\"\n    start_time = timespan_s.apply(lambda x: str_to_time(x[0]))\n    end_time = timespan_s.apply(lambda x: str_to_time(x[1]))\n    return pd.DataFrame({\"start_time\": start_time, \"end_time\": end_time})\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.dt_contains","title":"network_wrangler.utils.time.dt_contains","text":"<pre><code>dt_contains(timespan1, timespan2)\n</code></pre> <p>Check timespan1 inclusively contains timespan2.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p>Parameters:</p> <ul> <li> <code>timespan1</code>               (<code>list[time]</code>)           \u2013            <p>The first timespan represented as a list containing the start time and end time.</p> </li> <li> <code>timespan2</code>               (<code>list[time]</code>)           \u2013            <p>The second timespan represented as a list containing the start time and end time.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the first timespan contains the second timespan, False otherwise.</p> </li> </ul> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef dt_contains(timespan1: list[datetime], timespan2: list[datetime]) -&gt; bool:\n    \"\"\"Check timespan1 inclusively contains timespan2.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    Args:\n        timespan1 (list[time]): The first timespan represented as a list containing the start\n            time and end time.\n        timespan2 (list[time]): The second timespan represented as a list containing the start\n            time and end time.\n\n    Returns:\n        bool: True if the first timespan contains the second timespan, False otherwise.\n    \"\"\"\n    start_time_dt, end_time_dt = timespan1\n\n    if end_time_dt &lt; start_time_dt:\n        end_time_dt = end_time_dt + timedelta(days=1)\n\n    start_time_dt2, end_time_dt2 = timespan2\n\n    if end_time_dt2 &lt; start_time_dt2:\n        end_time_dt2 = end_time_dt2 + timedelta(days=1)\n\n    return (start_time_dt &lt;= start_time_dt2) and (end_time_dt &gt;= end_time_dt2)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.dt_list_overlaps","title":"network_wrangler.utils.time.dt_list_overlaps","text":"<pre><code>dt_list_overlaps(timespans)\n</code></pre> <p>Check if any of the timespans overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def dt_list_overlaps(timespans: list[list[datetime]]) -&gt; bool:\n    \"\"\"Check if any of the timespans overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    return bool(filter_dt_list_to_overlaps(timespans))\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.dt_overlap_duration","title":"network_wrangler.utils.time.dt_overlap_duration","text":"<pre><code>dt_overlap_duration(timedelta1, timedelta2)\n</code></pre> <p>Check if two timespans overlap and return the amount of overlap.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef dt_overlap_duration(timedelta1: timedelta, timedelta2: timedelta) -&gt; timedelta:\n    \"\"\"Check if two timespans overlap and return the amount of overlap.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n    \"\"\"\n    if timedelta1.end_time &lt; timedelta1.start_time:\n        timedelta1 = timedelta1 + timedelta(days=1)\n    if timedelta2.end_time &lt; timedelta2.start_time:\n        timedelta2 = timedelta2 + timedelta(days=1)\n    overlap_start = max(timedelta1.start_time, timedelta2.start_time)\n    overlap_end = min(timedelta1.end_time, timedelta2.end_time)\n    overlap_duration = max(overlap_end - overlap_start, timedelta(0))\n    return overlap_duration\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.dt_overlaps","title":"network_wrangler.utils.time.dt_overlaps","text":"<pre><code>dt_overlaps(timespan1, timespan2)\n</code></pre> <p>Check if two timespans overlap.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef dt_overlaps(timespan1: list[datetime], timespan2: list[datetime]) -&gt; bool:\n    \"\"\"Check if two timespans overlap.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    time1_start, time1_end = timespan1\n    time2_start, time2_end = timespan2\n\n    if time1_end &lt; time1_start:\n        time1_end += timedelta(days=1)\n    if time2_end &lt; time2_start:\n        time2_end += timedelta(days=1)\n\n    return (time1_start &lt; time2_end) and (time2_start &lt; time1_end)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.dt_to_seconds_from_midnight","title":"network_wrangler.utils.time.dt_to_seconds_from_midnight","text":"<pre><code>dt_to_seconds_from_midnight(dt)\n</code></pre> <p>Convert a datetime object to the number of seconds since midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef dt_to_seconds_from_midnight(dt: datetime) -&gt; int:\n    \"\"\"Convert a datetime object to the number of seconds since midnight.\"\"\"\n    return round((dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds())\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.duration_dt","title":"network_wrangler.utils.time.duration_dt","text":"<pre><code>duration_dt(start_time_dt, end_time_dt)\n</code></pre> <p>Returns a datetime.timedelta object representing the duration of the timespan.</p> <p>If end_time is less than start_time, the duration will assume that it crosses over midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def duration_dt(start_time_dt: datetime, end_time_dt: datetime) -&gt; timedelta:\n    \"\"\"Returns a datetime.timedelta object representing the duration of the timespan.\n\n    If end_time is less than start_time, the duration will assume that it crosses over\n    midnight.\n    \"\"\"\n    if end_time_dt &lt; start_time_dt:\n        return timedelta(\n            hours=24 - start_time_dt.hour + end_time_dt.hour,\n            minutes=end_time_dt.minute - start_time_dt.minute,\n            seconds=end_time_dt.second - start_time_dt.second,\n        )\n    return end_time_dt - start_time_dt\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.filter_df_to_max_overlapping_timespans","title":"network_wrangler.utils.time.filter_df_to_max_overlapping_timespans","text":"<pre><code>filter_df_to_max_overlapping_timespans(orig_df, query_timespan, strict_match=False, min_overlap_minutes=1, keep_max_of_cols=None)\n</code></pre> <p>Filters dataframe for entries that have maximum overlap with the given query timespan.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p>Parameters:</p> <ul> <li> <code>orig_df</code>               (<code>DataFrame</code>)           \u2013            <p>dataframe to query timespans for with <code>start_time</code> and <code>end_time</code> fields.</p> </li> <li> <code>query_timespan</code>               (<code>list[TimeString]</code>)           \u2013            <p>TimespanString of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> </li> <li> <code>strict_match</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>boolean indicating if the returned df should only contain records that fully contain the query timespan. If set to True, min_overlap_minutes does not apply. Defaults to False.</p> </li> <li> <code>min_overlap_minutes</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>minimum number of minutes the timespans need to overlap to keep. Defaults to 1.</p> </li> <li> <code>keep_max_of_cols</code>               (<code>Optional[list[str]]</code>, default:                   <code>None</code> )           \u2013            <p>list of fields to return the maximum value of overlap for.  If None, will return all overlapping time periods. Defaults to <code>['model_link_id']</code></p> </li> </ul> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef filter_df_to_max_overlapping_timespans(\n    orig_df: pd.DataFrame,\n    query_timespan: list[TimeString],\n    strict_match: bool = False,\n    min_overlap_minutes: int = 1,\n    keep_max_of_cols: Optional[list[str]] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Filters dataframe for entries that have maximum overlap with the given query timespan.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    Args:\n        orig_df: dataframe to query timespans for with `start_time` and `end_time` fields.\n        query_timespan: TimespanString of format ['HH:MM','HH:MM'] to query orig_df for overlapping\n            records.\n        strict_match: boolean indicating if the returned df should only contain\n            records that fully contain the query timespan. If set to True, min_overlap_minutes\n            does not apply. Defaults to False.\n        min_overlap_minutes: minimum number of minutes the timespans need to overlap to keep.\n            Defaults to 1.\n        keep_max_of_cols: list of fields to return the maximum value of overlap for.  If None,\n            will return all overlapping time periods. Defaults to `['model_link_id']`\n    \"\"\"\n    if keep_max_of_cols is None:\n        keep_max_of_cols = [\"model_link_id\"]\n    if \"start_time\" not in orig_df.columns or \"end_time\" not in orig_df.columns:\n        msg = \"DataFrame must have 'start_time' and 'end_time' columns\"\n        WranglerLogger.error(msg)\n        raise TimespanDfQueryError(msg)\n    q_start, q_end = str_to_time_list(query_timespan)\n\n    real_end = orig_df[\"end_time\"]\n    real_end.loc[orig_df[\"end_time\"] &lt; orig_df[\"start_time\"]] += pd.Timedelta(days=1)\n\n    orig_df[\"overlap_duration\"] = calc_overlap_duration_with_query(\n        orig_df[\"start_time\"],\n        real_end,\n        q_start,\n        q_end,\n    )\n    if strict_match:\n        overlap_df = orig_df.loc[(orig_df.start_time &lt;= q_start) &amp; (real_end &gt;= q_end)]\n    else:\n        overlap_df = orig_df.loc[orig_df.overlap_duration &gt; min_overlap_minutes]\n    WranglerLogger.debug(f\"overlap_df: \\n{overlap_df}\")\n    if keep_max_of_cols:\n        # keep only the maximum overlap\n        idx = overlap_df.groupby(keep_max_of_cols)[\"overlap_duration\"].idxmax()\n        overlap_df = overlap_df.loc[idx]\n    return overlap_df\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.filter_df_to_overlapping_timespans","title":"network_wrangler.utils.time.filter_df_to_overlapping_timespans","text":"<pre><code>filter_df_to_overlapping_timespans(orig_df, query_timespans)\n</code></pre> <p>Filters dataframe for entries that have any overlap with ANY of the given query timespans.</p> <p>If the end time is less than the start time, it is assumed to be the next day.</p> <p>Parameters:</p> <ul> <li> <code>orig_df</code>               (<code>DataFrame</code>)           \u2013            <p>dataframe to query timespans for with <code>start_time</code> and <code>end_time</code> fields.</p> </li> <li> <code>query_timespans</code>               (<code>list[TimespanString]</code>)           \u2013            <p>List of a list of TimespanStr of format [\u2018HH:MM\u2019,\u2019HH:MM\u2019] to query orig_df for overlapping records.</p> </li> </ul> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef filter_df_to_overlapping_timespans(\n    orig_df: pd.DataFrame,\n    query_timespans: list[TimespanString],\n) -&gt; pd.DataFrame:\n    \"\"\"Filters dataframe for entries that have any overlap with ANY of the given query timespans.\n\n    If the end time is less than the start time, it is assumed to be the next day.\n\n    Args:\n        orig_df: dataframe to query timespans for with `start_time` and `end_time` fields.\n        query_timespans: List of a list of TimespanStr of format ['HH:MM','HH:MM'] to query orig_df\n            for overlapping records.\n    \"\"\"\n    if \"start_time\" not in orig_df.columns or \"end_time\" not in orig_df.columns:\n        msg = \"DataFrame must have 'start_time' and 'end_time' columns\"\n        WranglerLogger.error(msg)\n        raise TimespanDfQueryError(msg)\n\n    mask = pd.Series([False] * len(orig_df), index=orig_df.index)\n    for query_timespan in query_timespans:\n        q_start_time, q_end_time = str_to_time_list(query_timespan)\n        end_time_s = orig_df[\"end_time\"]\n        end_time_s.loc[orig_df[\"end_time\"] &lt; orig_df[\"start_time\"]] += pd.Timedelta(days=1)\n        this_ts_mask = (orig_df[\"start_time\"] &lt; q_end_time) &amp; (q_start_time &lt; end_time_s)\n        mask |= this_ts_mask\n    return orig_df.loc[mask]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.filter_dt_list_to_overlaps","title":"network_wrangler.utils.time.filter_dt_list_to_overlaps","text":"<pre><code>filter_dt_list_to_overlaps(timespans)\n</code></pre> <p>Filter a list of timespans to only include those that overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call\ndef filter_dt_list_to_overlaps(timespans: list[list[datetime]]) -&gt; list[list[datetime]]:\n    \"\"\"Filter a list of timespans to only include those that overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    overlaps = []\n    for i in range(len(timespans)):\n        for j in range(i + 1, len(timespans)):\n            if dt_overlaps(timespans[i], timespans[j]):\n                overlaps += [timespans[i], timespans[j]]\n\n    # remove dupes\n    return list(map(list, set(map(tuple, overlaps))))\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.format_seconds_to_legible_str","title":"network_wrangler.utils.time.format_seconds_to_legible_str","text":"<pre><code>format_seconds_to_legible_str(seconds)\n</code></pre> <p>Formats seconds into a human-friendly string for log files.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def format_seconds_to_legible_str(seconds: int) -&gt; str:\n    \"\"\"Formats seconds into a human-friendly string for log files.\"\"\"\n    if seconds &lt; 60:  # noqa: PLR2004\n        return f\"{int(seconds)} seconds\"\n    if seconds &lt; 3600:  # noqa: PLR2004\n        return f\"{int(seconds // 60)} minutes\"\n    hours = int(seconds // 3600)\n    minutes = int((seconds % 3600) // 60)\n    return f\"{hours} hours and {minutes} minutes\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.is_increasing","title":"network_wrangler.utils.time.is_increasing","text":"<pre><code>is_increasing(datetimes)\n</code></pre> <p>Check if a list of datetime objects is increasing in time.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def is_increasing(datetimes: list[datetime]) -&gt; bool:\n    \"\"\"Check if a list of datetime objects is increasing in time.\"\"\"\n    return all(datetimes[i] &lt;= datetimes[i + 1] for i in range(len(datetimes) - 1))\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.seconds_from_midnight_to_str","title":"network_wrangler.utils.time.seconds_from_midnight_to_str","text":"<pre><code>seconds_from_midnight_to_str(seconds)\n</code></pre> <p>Convert the number of seconds since midnight to a TimeString (HH:MM).</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef seconds_from_midnight_to_str(seconds: int) -&gt; TimeString:\n    \"\"\"Convert the number of seconds since midnight to a TimeString (HH:MM).\"\"\"\n    return str(timedelta(seconds=seconds))\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.str_to_seconds_from_midnight","title":"network_wrangler.utils.time.str_to_seconds_from_midnight","text":"<pre><code>str_to_seconds_from_midnight(time_str)\n</code></pre> <p>Convert a TimeString (HH:MM&lt;:SS&gt;) to the number of seconds since midnight.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef str_to_seconds_from_midnight(time_str: TimeString) -&gt; int:\n    \"\"\"Convert a TimeString (HH:MM&lt;:SS&gt;) to the number of seconds since midnight.\"\"\"\n    dt = str_to_time(time_str)\n    return dt_to_seconds_from_midnight(dt)\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.str_to_time","title":"network_wrangler.utils.time.str_to_time","text":"<pre><code>str_to_time(time_str, base_date=None)\n</code></pre> <p>Convert TimeString (HH:MM&lt;:SS&gt;) to datetime object.</p> <p>If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.</p> <p>Parameters:</p> <ul> <li> <code>time_str</code>               (<code>TimeString</code>)           \u2013            <p>TimeString in HH:MM:SS or HH:MM format.</p> </li> <li> <code>base_date</code>               (<code>Optional[date]</code>, default:                   <code>None</code> )           \u2013            <p>optional date to base the datetime on. Defaults to None. If not provided, will use today.</p> </li> </ul> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef str_to_time(time_str: TimeString, base_date: Optional[date] = None) -&gt; datetime:\n    \"\"\"Convert TimeString (HH:MM&lt;:SS&gt;) to datetime object.\n\n    If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.\n\n    Args:\n        time_str: TimeString in HH:MM:SS or HH:MM format.\n        base_date: optional date to base the datetime on. Defaults to None.\n            If not provided, will use today.\n    \"\"\"\n    # Set the base date to today if not provided\n    if base_date is None:\n        base_date = date.today()\n\n    # Split the time string to extract hours, minutes, and seconds\n    parts = time_str.split(\":\")\n    hours = int(parts[0])\n    minutes = int(parts[1])\n    seconds = int(parts[2]) if len(parts) == 3 else 0  # noqa: PLR2004\n\n    if hours &gt;= 24:  # noqa: PLR2004\n        add_days = hours // 24\n        base_date += timedelta(days=add_days)\n        hours -= 24 * add_days\n\n    # Create a time object with the adjusted hours, minutes, and seconds\n    adjusted_time = datetime.strptime(f\"{hours:02}:{minutes:02}:{seconds:02}\", \"%H:%M:%S\").time()\n\n    # Combine the base date with the adjusted time and add the extra days if needed\n    combined_datetime = datetime.combine(base_date, adjusted_time)\n\n    return combined_datetime\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.str_to_time_list","title":"network_wrangler.utils.time.str_to_time_list","text":"<pre><code>str_to_time_list(timespan)\n</code></pre> <p>Convert list of TimeStrings (HH:MM&lt;:SS&gt;) to list of datetime.time objects.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef str_to_time_list(timespan: list[TimeString]) -&gt; list[datetime]:\n    \"\"\"Convert list of TimeStrings (HH:MM&lt;:SS&gt;) to list of datetime.time objects.\"\"\"\n    timespan_dt: list[datetime] = list(map(str_to_time, timespan))\n    if not is_increasing(timespan_dt):\n        timespan_dt = [timespan_dt[0], timespan_dt[1] + timedelta(days=1)]\n        WranglerLogger.warning(\n            f\"Timespan is not in increasing order: {timespan}.\\\n            End time will be treated as next day.\"\n        )\n    return timespan_dt\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.str_to_time_series","title":"network_wrangler.utils.time.str_to_time_series","text":"<pre><code>str_to_time_series(time_str_s, base_date=None)\n</code></pre> <p>Convert mixed panda series datetime and TimeString (HH:MM&lt;:SS&gt;) to datetime object.</p> <p>If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.</p> <p>Parameters:</p> <ul> <li> <code>time_str_s</code>               (<code>Series</code>)           \u2013            <p>Pandas Series of TimeStrings in HH:MM:SS or HH:MM format.</p> </li> <li> <code>base_date</code>               (<code>Optional[Union[Series, date]]</code>, default:                   <code>None</code> )           \u2013            <p>optional date to base the datetime on. Defaults to None. If not provided, will use today. Can be either a single instance or a series of same length as time_str_s</p> </li> </ul> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def str_to_time_series(\n    time_str_s: pd.Series, base_date: Optional[Union[pd.Series, date]] = None\n) -&gt; pd.Series:\n    \"\"\"Convert mixed panda series datetime and TimeString (HH:MM&lt;:SS&gt;) to datetime object.\n\n    If HH &gt; 24, will subtract 24 to be within 24 hours. Timespans will be treated as the next day.\n\n    Args:\n        time_str_s: Pandas Series of TimeStrings in HH:MM:SS or HH:MM format.\n        base_date: optional date to base the datetime on. Defaults to None.\n            If not provided, will use today. Can be either a single instance or a series of\n            same length as time_str_s\n    \"\"\"\n    # check strings are in the correct format, leave existing date times alone\n    is_string = time_str_s.apply(lambda x: isinstance(x, str))\n    time_strings = time_str_s[is_string]\n    result = time_str_s.copy()\n    if is_string.any():\n        result[is_string] = _all_str_to_time_series(time_strings, base_date)\n    result = result.astype(\"datetime64[ns]\")\n    return result\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.timespan_str_list_to_dt","title":"network_wrangler.utils.time.timespan_str_list_to_dt","text":"<pre><code>timespan_str_list_to_dt(timespans)\n</code></pre> <p>Convert list of TimespanStrings to list of datetime.time objects.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>@validate_call(config={\"arbitrary_types_allowed\": True})\ndef timespan_str_list_to_dt(timespans: list[TimespanString]) -&gt; list[list[datetime]]:\n    \"\"\"Convert list of TimespanStrings to list of datetime.time objects.\"\"\"\n    return [str_to_time_list(ts) for ts in timespans]\n</code></pre>"},{"location":"api_utils/#network_wrangler.utils.time.timespans_overlap","title":"network_wrangler.utils.time.timespans_overlap","text":"<pre><code>timespans_overlap(timespan1, timespan2)\n</code></pre> <p>Check if two timespan strings overlap.</p> <p><code>overlapping</code>: a timespan that fully or partially overlaps a given timespan. This includes and all timespans where at least one minute overlap.</p> Source code in <code>network_wrangler/utils/time.py</code> <pre><code>def timespans_overlap(timespan1: list[TimespanString], timespan2: list[TimespanString]) -&gt; bool:\n    \"\"\"Check if two timespan strings overlap.\n\n    `overlapping`: a timespan that fully or partially overlaps a given timespan.\n    This includes and all timespans where at least one minute overlap.\n    \"\"\"\n    timespan1 = str_to_time_list(timespan1)\n    timespan2 = str_to_time_list(timespan2)\n    return dt_overlaps(timespan1, timespan2)\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Time","title":"network_wrangler.time.Time","text":"<p>Represents a time object.</p> <p>This class provides methods to initialize and manipulate time objects.</p> <p>Attributes:</p> <ul> <li> <code>datetime</code>               (<code>datetime</code>)           \u2013            <p>The underlying datetime object representing the time.</p> </li> <li> <code>time_str</code>               (<code>str</code>)           \u2013            <p>The time string representation in HH:MM:SS format.</p> </li> <li> <code>time_sec</code>               (<code>int</code>)           \u2013            <p>The time in seconds since midnight.</p> </li> <li> <code>_raw_time_in</code>               (<code>TimeType</code>)           \u2013            <p>The raw input value used to initialize the Time object.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>class Time:\n    \"\"\"Represents a time object.\n\n    This class provides methods to initialize and manipulate time objects.\n\n    Attributes:\n        datetime (datetime): The underlying datetime object representing the time.\n        time_str (str): The time string representation in HH:MM:SS format.\n        time_sec (int): The time in seconds since midnight.\n\n        _raw_time_in (TimeType): The raw input value used to initialize the Time object.\n\n    \"\"\"\n\n    def __init__(self, value: TimeType):\n        \"\"\"Initializes a Time object.\n\n        Args:\n            value (TimeType): A time object, string in HH:MM[:SS] format, or seconds since\n                midnight.\n\n        Raises:\n            TimeFormatError: If the value is not a valid time format.\n\n        \"\"\"\n        if isinstance(value, datetime):\n            self.datetime: datetime = value\n        elif isinstance(value, time):\n            self.datetime = datetime.combine(datetime.today(), value)\n        elif isinstance(value, str):\n            self.datetime = str_to_time(value)\n        elif isinstance(value, int):\n            self.datetime = datetime.datetime.fromtimestamp(value).time()\n        else:\n            msg = \"time must be a string, int, or time object\"\n            raise TimeFormatError(msg)\n\n        self._raw_time_in = value\n\n    def __getitem__(self, item: Any) -&gt; str:\n        \"\"\"Get the time string representation.\n\n        Args:\n            item (Any): Not used.\n\n        Returns:\n            str: The time string representation in HH:MM:SS format.\n        \"\"\"\n        return self.time_str\n\n    @property\n    def time_str(self):\n        \"\"\"Get the time string representation.\n\n        Returns:\n            str: The time string representation in HH:MM:SS format.\n        \"\"\"\n        return self.datetime.strftime(\"%H:%M:%S\")\n\n    @property\n    def time_sec(self):\n        \"\"\"Get the time in seconds since midnight.\n\n        Returns:\n            int: The time in seconds since midnight.\n        \"\"\"\n        return self.datetime.hour * 3600 + self.datetime.minute * 60 + self.datetime.second\n\n    def __str__(self) -&gt; str:\n        \"\"\"Get the string representation of the Time object.\n\n        Returns:\n            str: The time string representation in HH:MM:SS format.\n        \"\"\"\n        return self.time_str\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Get the hash value of the Time object.\n\n        Returns:\n            int: The hash value of the Time object.\n        \"\"\"\n        return hash(str(self))\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Time.time_sec","title":"network_wrangler.time.Time.time_sec  <code>property</code>","text":"<pre><code>time_sec\n</code></pre> <p>Get the time in seconds since midnight.</p> <p>Returns:</p> <ul> <li> <code>int</code>          \u2013            <p>The time in seconds since midnight.</p> </li> </ul>"},{"location":"api_utils/#network_wrangler.time.Time.time_str","title":"network_wrangler.time.Time.time_str  <code>property</code>","text":"<pre><code>time_str\n</code></pre> <p>Get the time string representation.</p> <p>Returns:</p> <ul> <li> <code>str</code>          \u2013            <p>The time string representation in HH:MM:SS format.</p> </li> </ul>"},{"location":"api_utils/#network_wrangler.time.Time.__getitem__","title":"network_wrangler.time.Time.__getitem__","text":"<pre><code>__getitem__(item)\n</code></pre> <p>Get the time string representation.</p> <p>Parameters:</p> <ul> <li> <code>item</code>               (<code>Any</code>)           \u2013            <p>Not used.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The time string representation in HH:MM:SS format.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>def __getitem__(self, item: Any) -&gt; str:\n    \"\"\"Get the time string representation.\n\n    Args:\n        item (Any): Not used.\n\n    Returns:\n        str: The time string representation in HH:MM:SS format.\n    \"\"\"\n    return self.time_str\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Time.__hash__","title":"network_wrangler.time.Time.__hash__","text":"<pre><code>__hash__()\n</code></pre> <p>Get the hash value of the Time object.</p> <p>Returns:</p> <ul> <li> <code>int</code> (              <code>int</code> )          \u2013            <p>The hash value of the Time object.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Get the hash value of the Time object.\n\n    Returns:\n        int: The hash value of the Time object.\n    \"\"\"\n    return hash(str(self))\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Time.__init__","title":"network_wrangler.time.Time.__init__","text":"<pre><code>__init__(value)\n</code></pre> <p>Initializes a Time object.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>TimeType</code>)           \u2013            <p>A time object, string in HH:MM[:SS] format, or seconds since midnight.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TimeFormatError</code>             \u2013            <p>If the value is not a valid time format.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>def __init__(self, value: TimeType):\n    \"\"\"Initializes a Time object.\n\n    Args:\n        value (TimeType): A time object, string in HH:MM[:SS] format, or seconds since\n            midnight.\n\n    Raises:\n        TimeFormatError: If the value is not a valid time format.\n\n    \"\"\"\n    if isinstance(value, datetime):\n        self.datetime: datetime = value\n    elif isinstance(value, time):\n        self.datetime = datetime.combine(datetime.today(), value)\n    elif isinstance(value, str):\n        self.datetime = str_to_time(value)\n    elif isinstance(value, int):\n        self.datetime = datetime.datetime.fromtimestamp(value).time()\n    else:\n        msg = \"time must be a string, int, or time object\"\n        raise TimeFormatError(msg)\n\n    self._raw_time_in = value\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Time.__str__","title":"network_wrangler.time.Time.__str__","text":"<pre><code>__str__()\n</code></pre> <p>Get the string representation of the Time object.</p> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The time string representation in HH:MM:SS format.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Get the string representation of the Time object.\n\n    Returns:\n        str: The time string representation in HH:MM:SS format.\n    \"\"\"\n    return self.time_str\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Timespan","title":"network_wrangler.time.Timespan","text":"<p>Timespan object.</p> <p>This class provides methods to initialize and manipulate time objects.</p> <p>If the end_time is less than the start_time, the duration will assume that it crosses     over midnight.</p> <p>Attributes:</p> <ul> <li> <code>start_time</code>               (<code>time</code>)           \u2013            <p>The start time of the timespan.</p> </li> <li> <code>end_time</code>               (<code>time</code>)           \u2013            <p>The end time of the timespan.</p> </li> <li> <code>timespan_str_list</code>               (<code>str</code>)           \u2013            <p>A list of start time and end time in HH:MM:SS format.</p> </li> <li> <code>start_time_sec</code>               (<code>int</code>)           \u2013            <p>The start time in seconds since midnight.</p> </li> <li> <code>end_time_sec</code>               (<code>int</code>)           \u2013            <p>The end time in seconds since midnight.</p> </li> <li> <code>duration</code>               (<code>timedelta</code>)           \u2013            <p>The duration of the timespan.</p> </li> <li> <code>duration_sec</code>               (<code>int</code>)           \u2013            <p>The duration of the timespan in seconds.</p> </li> <li> <code>_raw_timespan_in</code>               (<code>Any</code>)           \u2013            <p>The raw input value used to initialize the Timespan object.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>class Timespan:\n    \"\"\"Timespan object.\n\n    This class provides methods to initialize and manipulate time objects.\n\n    If the end_time is less than the start_time, the duration will assume that it crosses\n        over midnight.\n\n    Attributes:\n        start_time (datetime.time): The start time of the timespan.\n        end_time (datetime.time): The end time of the timespan.\n        timespan_str_list (str): A list of start time and end time in HH:MM:SS format.\n        start_time_sec (int): The start time in seconds since midnight.\n        end_time_sec (int): The end time in seconds since midnight.\n        duration (datetime.timedelta): The duration of the timespan.\n        duration_sec (int): The duration of the timespan in seconds.\n\n        _raw_timespan_in (Any): The raw input value used to initialize the Timespan object.\n\n    \"\"\"\n\n    def __init__(self, value: list[TimeType]):\n        \"\"\"Constructor for the Timespan object.\n\n        If the value is a list of two time strings, datetime objects, Time, or seconds from\n        midnight, the start_time and end_time attributes will be set accordingly.\n\n        Args:\n            value (time): a list of two time strings, datetime objects, Time, or seconds from\n              midnight.\n        \"\"\"\n        if len(value) != 2:  # noqa: PLR2004\n            msg = \"timespan must be a list of 2 time strings, datetime objs, Time, or sec from midnight.\"\n            raise TimespanFormatError(msg)\n\n        self.start_time, self.end_time = (Time(t) for t in value)\n        self._raw_timespan_in = value\n\n    @property\n    def timespan_str_list(self):\n        \"\"\"Get the timespan string representation.\"\"\"\n        return [self.start_time.time_str, self.end_time.time_str]\n\n    @property\n    def start_time_sec(self):\n        \"\"\"Start time in seconds since midnight.\"\"\"\n        return self.start_time.time_sec\n\n    @property\n    def end_time_sec(self):\n        \"\"\"End time in seconds since midnight.\"\"\"\n        return self.end_time.time_sec\n\n    @property\n    def duration(self):\n        \"\"\"Duration of timespan as a timedelta object.\"\"\"\n        return duration_dt(self.start_time, self.end_time)\n\n    @property\n    def duration_sec(self):\n        \"\"\"Duration of timespan in seconds.\n\n        If end_time is less than start_time, the duration will assume that it crosses over\n        midnight.\n        \"\"\"\n        if self.end_time_sec &lt; self.start_time_sec:\n            return (24 * 3600) - self.start_time_sec + self.end_time_sec\n        return self.end_time_sec - self.start_time_sec\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the Timespan object.\"\"\"\n        return str(self.timespan_str)\n\n    def __hash__(self) -&gt; int:\n        \"\"\"Hash value of the Timespan object.\"\"\"\n        return hash(str(self))\n\n    def overlaps(self, other: Timespan) -&gt; bool:\n        \"\"\"Check if two timespans overlap.\n\n        If the start time is greater than the end time, the timespan is assumed to cross over\n        midnight.\n\n        Args:\n            other (Timespan): The other timespan to compare.\n\n        Returns:\n            bool: True if the two timespans overlap, False otherwise.\n        \"\"\"\n        real_end_time = self.end_time.datetime\n        if self.end_time.datetime &gt; self.start_time.datetime:\n            real_end_time = self.end_time.datetime + datetime.timedelta(days=1)\n\n        real_other_end_time = other.end_time.datetime\n        if other.end_time.datetime &gt; other.start_time.datetime:\n            real_other_end_time = other.end_time.datetime + datetime.timedelta(days=1)\n        return (\n            self.start_time.datetime &lt;= real_other_end_time\n            and real_end_time &gt;= other.start_time.datetime\n        )\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Timespan.duration","title":"network_wrangler.time.Timespan.duration  <code>property</code>","text":"<pre><code>duration\n</code></pre> <p>Duration of timespan as a timedelta object.</p>"},{"location":"api_utils/#network_wrangler.time.Timespan.duration_sec","title":"network_wrangler.time.Timespan.duration_sec  <code>property</code>","text":"<pre><code>duration_sec\n</code></pre> <p>Duration of timespan in seconds.</p> <p>If end_time is less than start_time, the duration will assume that it crosses over midnight.</p>"},{"location":"api_utils/#network_wrangler.time.Timespan.end_time_sec","title":"network_wrangler.time.Timespan.end_time_sec  <code>property</code>","text":"<pre><code>end_time_sec\n</code></pre> <p>End time in seconds since midnight.</p>"},{"location":"api_utils/#network_wrangler.time.Timespan.start_time_sec","title":"network_wrangler.time.Timespan.start_time_sec  <code>property</code>","text":"<pre><code>start_time_sec\n</code></pre> <p>Start time in seconds since midnight.</p>"},{"location":"api_utils/#network_wrangler.time.Timespan.timespan_str_list","title":"network_wrangler.time.Timespan.timespan_str_list  <code>property</code>","text":"<pre><code>timespan_str_list\n</code></pre> <p>Get the timespan string representation.</p>"},{"location":"api_utils/#network_wrangler.time.Timespan.__hash__","title":"network_wrangler.time.Timespan.__hash__","text":"<pre><code>__hash__()\n</code></pre> <p>Hash value of the Timespan object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"Hash value of the Timespan object.\"\"\"\n    return hash(str(self))\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Timespan.__init__","title":"network_wrangler.time.Timespan.__init__","text":"<pre><code>__init__(value)\n</code></pre> <p>Constructor for the Timespan object.</p> <p>If the value is a list of two time strings, datetime objects, Time, or seconds from midnight, the start_time and end_time attributes will be set accordingly.</p> <p>Parameters:</p> <ul> <li> <code>value</code>               (<code>time</code>)           \u2013            <p>a list of two time strings, datetime objects, Time, or seconds from midnight.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>def __init__(self, value: list[TimeType]):\n    \"\"\"Constructor for the Timespan object.\n\n    If the value is a list of two time strings, datetime objects, Time, or seconds from\n    midnight, the start_time and end_time attributes will be set accordingly.\n\n    Args:\n        value (time): a list of two time strings, datetime objects, Time, or seconds from\n          midnight.\n    \"\"\"\n    if len(value) != 2:  # noqa: PLR2004\n        msg = \"timespan must be a list of 2 time strings, datetime objs, Time, or sec from midnight.\"\n        raise TimespanFormatError(msg)\n\n    self.start_time, self.end_time = (Time(t) for t in value)\n    self._raw_timespan_in = value\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Timespan.__str__","title":"network_wrangler.time.Timespan.__str__","text":"<pre><code>__str__()\n</code></pre> <p>String representation of the Timespan object.</p> Source code in <code>network_wrangler/time.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the Timespan object.\"\"\"\n    return str(self.timespan_str)\n</code></pre>"},{"location":"api_utils/#network_wrangler.time.Timespan.overlaps","title":"network_wrangler.time.Timespan.overlaps","text":"<pre><code>overlaps(other)\n</code></pre> <p>Check if two timespans overlap.</p> <p>If the start time is greater than the end time, the timespan is assumed to cross over midnight.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>Timespan</code>)           \u2013            <p>The other timespan to compare.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the two timespans overlap, False otherwise.</p> </li> </ul> Source code in <code>network_wrangler/time.py</code> <pre><code>def overlaps(self, other: Timespan) -&gt; bool:\n    \"\"\"Check if two timespans overlap.\n\n    If the start time is greater than the end time, the timespan is assumed to cross over\n    midnight.\n\n    Args:\n        other (Timespan): The other timespan to compare.\n\n    Returns:\n        bool: True if the two timespans overlap, False otherwise.\n    \"\"\"\n    real_end_time = self.end_time.datetime\n    if self.end_time.datetime &gt; self.start_time.datetime:\n        real_end_time = self.end_time.datetime + datetime.timedelta(days=1)\n\n    real_other_end_time = other.end_time.datetime\n    if other.end_time.datetime &gt; other.start_time.datetime:\n        real_other_end_time = other.end_time.datetime + datetime.timedelta(days=1)\n    return (\n        self.start_time.datetime &lt;= real_other_end_time\n        and real_end_time &gt;= other.start_time.datetime\n    )\n</code></pre>"},{"location":"api_utils/#logging-and-visualization","title":"Logging and Visualization","text":"<p>Logging utilities for Network Wrangler.</p> <p>Module for visualizing roadway and transit networks using Mapbox tiles.</p> <p>This module provides a function <code>net_to_mapbox</code> that creates and serves Mapbox tiles on a local web server based on roadway and transit networks.</p> Example usage <p>net_to_mapbox(roadway, transit)</p>"},{"location":"api_utils/#network_wrangler.logger.setup_logging","title":"network_wrangler.logger.setup_logging","text":"<pre><code>setup_logging(info_log_filename=None, debug_log_filename=None, std_out_level='info')\n</code></pre> <p>Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.</p> <p>Called by the test_logging fixture in conftest.py and can be called by the user to setup logging for their session. If called multiple times, the logger will be reset.</p> <p>Parameters:</p> <ul> <li> <code>info_log_filename</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>the location of the log file that will get created to add the INFO log. The INFO Log is terse, just gives the bare minimum of details. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> </li> <li> <code>debug_log_filename</code>               (<code>Optional[Path]</code>, default:                   <code>None</code> )           \u2013            <p>the location of the log file that will get created to add the DEBUG log The DEBUG log is very noisy, for debugging. Defaults to file in cwd() <code>wrangler_[datetime].log</code>. To turn off logging to a file, use log_filename = None.</p> </li> <li> <code>std_out_level</code>               (<code>str</code>, default:                   <code>'info'</code> )           \u2013            <p>the level of logging to the console. One of \u201cinfo\u201d, \u201cwarning\u201d, \u201cdebug\u201d. Defaults to \u201cinfo\u201d but will be set to ERROR if nothing provided matches.</p> </li> </ul> Source code in <code>network_wrangler/logger.py</code> <pre><code>def setup_logging(\n    info_log_filename: Optional[Path] = None,\n    debug_log_filename: Optional[Path] = None,\n    std_out_level: str = \"info\",\n):\n    \"\"\"Sets up the WranglerLogger w.r.t. the debug file location and if logging to console.\n\n    Called by the test_logging fixture in conftest.py and can be called by the user to setup\n    logging for their session. If called multiple times, the logger will be reset.\n\n    Args:\n        info_log_filename: the location of the log file that will get created to add the INFO log.\n            The INFO Log is terse, just gives the bare minimum of details.\n            Defaults to file in cwd() `wrangler_[datetime].log`. To turn off logging to a file,\n            use log_filename = None.\n        debug_log_filename: the location of the log file that will get created to add the DEBUG log\n            The DEBUG log is very noisy, for debugging. Defaults to file in cwd()\n            `wrangler_[datetime].log`. To turn off logging to a file, use log_filename = None.\n        std_out_level: the level of logging to the console. One of \"info\", \"warning\", \"debug\".\n            Defaults to \"info\" but will be set to ERROR if nothing provided matches.\n    \"\"\"\n    # add function variable so that we know if logging has been called\n    setup_logging.called = True\n\n    DEFAULT_LOG_PATH = Path(f\"wrangler_{datetime.now().strftime('%Y_%m_%d__%H_%M_%S')}.debug.log\")\n    debug_log_filename = debug_log_filename if debug_log_filename else DEFAULT_LOG_PATH\n\n    # Clear handles if any exist already\n    WranglerLogger.handlers = []\n\n    WranglerLogger.setLevel(logging.DEBUG)\n\n    FORMAT = logging.Formatter(\n        \"%(asctime)-15s %(levelname)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S,\"\n    )\n    default_info_f = f\"network_wrangler_{datetime.now().strftime('%Y_%m_%d__%H_%M_%S')}.info.log\"\n    info_log_filename = info_log_filename or Path.cwd() / default_info_f\n\n    info_file_handler = logging.FileHandler(Path(info_log_filename))\n    info_file_handler.setLevel(logging.INFO)\n    info_file_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(info_file_handler)\n\n    # create debug file only when debug_log_filename is provided\n    if debug_log_filename:\n        debug_log_handler = logging.FileHandler(Path(debug_log_filename))\n        debug_log_handler.setLevel(logging.DEBUG)\n        debug_log_handler.setFormatter(FORMAT)\n        WranglerLogger.addHandler(debug_log_handler)\n\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.DEBUG)\n    console_handler.setFormatter(FORMAT)\n    WranglerLogger.addHandler(console_handler)\n    if std_out_level == \"debug\":\n        console_handler.setLevel(logging.DEBUG)\n    elif std_out_level == \"info\":\n        console_handler.setLevel(logging.INFO)\n    elif std_out_level == \"warning\":\n        console_handler.setLevel(logging.WARNING)\n    else:\n        console_handler.setLevel(logging.ERROR)\n</code></pre>"},{"location":"api_utils/#network_wrangler.viz.MissingMapboxTokenError","title":"network_wrangler.viz.MissingMapboxTokenError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when MAPBOX_ACCESS_TOKEN is not found in environment variables.</p> Source code in <code>network_wrangler/viz.py</code> <pre><code>class MissingMapboxTokenError(Exception):\n    \"\"\"Raised when MAPBOX_ACCESS_TOKEN is not found in environment variables.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.viz.net_to_mapbox","title":"network_wrangler.viz.net_to_mapbox","text":"<pre><code>net_to_mapbox(roadway=None, transit=None, roadway_geojson_out=Path('roadway_shapes.geojson'), transit_geojson_out=Path('transit_shapes.geojson'), mbtiles_out=Path('network.mbtiles'), overwrite=True, port='9000')\n</code></pre> <p>Creates and serves mapbox tiles on local web server based on roadway and transit networks.</p> <p>Parameters:</p> <ul> <li> <code>roadway</code>               (<code>Optional[Union[RoadwayNetwork, GeoDataFrame, str, Path]]</code>, default:                   <code>None</code> )           \u2013            <p>a RoadwayNetwork instance, geodataframe with roadway linetrings, or path to a geojson file. Defaults to empty GeoDataFrame.</p> </li> <li> <code>transit</code>               (<code>Optional[Union[TransitNetwork, GeoDataFrame]]</code>, default:                   <code>None</code> )           \u2013            <p>a TransitNetwork instance or a geodataframe with roadway linetrings, or path to a geojson file. Defaults to empty GeoDataFrame.</p> </li> <li> <code>roadway_geojson_out</code>               (<code>Path</code>, default:                   <code>Path('roadway_shapes.geojson')</code> )           \u2013            <p>file path for roadway geojson which gets created if roadway is not a path to a geojson file. Defaults to roadway_shapes.geojson.</p> </li> <li> <code>transit_geojson_out</code>               (<code>Path</code>, default:                   <code>Path('transit_shapes.geojson')</code> )           \u2013            <p>file path for transit geojson which gets created if transit is not a path to a geojson file. Defaults to transit_shapes.geojson.</p> </li> <li> <code>mbtiles_out</code>               (<code>Path</code>, default:                   <code>Path('network.mbtiles')</code> )           \u2013            <p>path to output mapbox tiles. Defaults to network.mbtiles</p> </li> <li> <code>overwrite</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>boolean indicating if can overwrite mbtiles_out and roadway_geojson_out and transit_geojson_out. Defaults to True.</p> </li> <li> <code>port</code>               (<code>str</code>, default:                   <code>'9000'</code> )           \u2013            <p>port to serve resulting tiles on. Defaults to 9000.</p> </li> </ul> Source code in <code>network_wrangler/viz.py</code> <pre><code>def net_to_mapbox(\n    roadway: Optional[Union[RoadwayNetwork, gpd.GeoDataFrame, str, Path]] = None,\n    transit: Optional[Union[TransitNetwork, gpd.GeoDataFrame]] = None,\n    roadway_geojson_out: Path = Path(\"roadway_shapes.geojson\"),\n    transit_geojson_out: Path = Path(\"transit_shapes.geojson\"),\n    mbtiles_out: Path = Path(\"network.mbtiles\"),\n    overwrite: bool = True,\n    port: str = \"9000\",\n):\n    \"\"\"Creates and serves mapbox tiles on local web server based on roadway and transit networks.\n\n    Args:\n        roadway: a RoadwayNetwork instance, geodataframe with roadway linetrings, or path to a\n            geojson file. Defaults to empty GeoDataFrame.\n        transit: a TransitNetwork instance or a geodataframe with roadway linetrings, or path to a\n            geojson file. Defaults to empty GeoDataFrame.\n        roadway_geojson_out: file path for roadway geojson which gets created if roadway is not\n            a path to a geojson file. Defaults to roadway_shapes.geojson.\n        transit_geojson_out: file path for transit geojson which gets created if transit is not\n            a path to a geojson file. Defaults to transit_shapes.geojson.\n        mbtiles_out: path to output mapbox tiles. Defaults to network.mbtiles\n        overwrite: boolean indicating if can overwrite mbtiles_out and roadway_geojson_out and\n            transit_geojson_out. Defaults to True.\n        port: port to serve resulting tiles on. Defaults to 9000.\n    \"\"\"\n    if roadway is None:\n        roadway = gpd.GeoDataFrame()\n    if transit is None:\n        transit = gpd.GeoDataFrame()\n    # test for mapbox token\n    try:\n        os.getenv(\"MAPBOX_ACCESS_TOKEN\")\n    except Exception as err:\n        WranglerLogger.error(\n            \"NEED TO SET MAPBOX ACCESS TOKEN IN ENVIRONMENT VARIABLES/n \\\n                In command line: &gt;&gt;export MAPBOX_ACCESS_TOKEN='pk.0000.1111' # \\\n                replace value with your mapbox public access token\"\n        )\n        raise MissingMapboxTokenError() from err\n\n    if isinstance(transit, TransitNetwork):\n        transit = transit.shape_links_gdf\n        transit.to_file(transit_geojson_out, driver=\"GeoJSON\")\n    elif Path(transit).exists():\n        transit_geojson_out = transit\n    else:\n        msg = f\"Don't understand transit input: {transit}\"\n        raise ValueError(msg)\n\n    if isinstance(roadway, RoadwayNetwork):\n        roadway = roadway.link_shapes_df\n        roadway.to_file(roadway_geojson_out, driver=\"GeoJSON\")\n    elif Path(roadway).exists():\n        roadway_geojson_out = Path(roadway)\n    else:\n        msg = \"Don't understand roadway input: {roadway}\"\n        raise ValueError(msg)\n\n    tippe_options_list: list[str] = [\"-zg\", \"-o\", str(mbtiles_out)]\n    if overwrite:\n        tippe_options_list.append(\"--force\")\n    # tippe_options_list.append(\"--drop-densest-as-needed\")\n    tippe_options_list.append(str(roadway_geojson_out))\n    tippe_options_list.append(str(transit_geojson_out))\n\n    try:\n        WranglerLogger.info(\n            f\"Running tippecanoe with following options: {' '.join(tippe_options_list)}\"\n        )\n        subprocess.run([\"tippecanoe\", *tippe_options_list], check=False)\n    except Exception as err:\n        WranglerLogger.error(\n            \"If tippecanoe isn't installed, try `brew install tippecanoe` or \\\n                visit https://github.com/mapbox/tippecanoe\"\n        )\n        raise ImportError() from err\n\n    try:\n        WranglerLogger.info(\n            \"Running mbview with following options: {}\".format(\" \".join(tippe_options_list))\n        )\n        subprocess.run([\"mbview\", \"--port\", port, f\", /{mbtiles_out}\"], check=False)\n    except Exception as err:\n        WranglerLogger.error(\n            \"If mbview isn't installed, try `npm install -g @mapbox/mbview` or \\\n                visit https://github.com/mapbox/mbview\"\n        )\n        raise ImportError(msg) from err\n</code></pre>"},{"location":"api_utils/#error-handling","title":"Error Handling","text":"<p>All network wrangler errors.</p>"},{"location":"api_utils/#network_wrangler.errors.DataframeSelectionError","title":"network_wrangler.errors.DataframeSelectionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with a selection from a dataframe.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class DataframeSelectionError(Exception):\n    \"\"\"Raised when there is an issue with a selection from a dataframe.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.FeedReadError","title":"network_wrangler.errors.FeedReadError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error reading a transit feed.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class FeedReadError(Exception):\n    \"\"\"Raised when there is an error reading a transit feed.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.FeedValidationError","title":"network_wrangler.errors.FeedValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with the validation of the GTFS data.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class FeedValidationError(Exception):\n    \"\"\"Raised when there is an issue with the validation of the GTFS data.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.InvalidScopedLinkValue","title":"network_wrangler.errors.InvalidScopedLinkValue","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with a scoped link value.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class InvalidScopedLinkValue(Exception):\n    \"\"\"Raised when there is an issue with a scoped link value.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.LinkAddError","title":"network_wrangler.errors.LinkAddError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with adding links.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkAddError(Exception):\n    \"\"\"Raised when there is an issue with adding links.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.LinkChangeError","title":"network_wrangler.errors.LinkChangeError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error in changing a link property.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkChangeError(Exception):\n    \"\"\"Raised when there is an error in changing a link property.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.LinkCreationError","title":"network_wrangler.errors.LinkCreationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with creating links.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkCreationError(Exception):\n    \"\"\"Raised when there is an issue with creating links.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.LinkDeletionError","title":"network_wrangler.errors.LinkDeletionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with deleting links.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkDeletionError(Exception):\n    \"\"\"Raised when there is an issue with deleting links.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.LinkNotFoundError","title":"network_wrangler.errors.LinkNotFoundError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a link is not found in the links table.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class LinkNotFoundError(Exception):\n    \"\"\"Raised when a link is not found in the links table.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ManagedLaneAccessEgressError","title":"network_wrangler.errors.ManagedLaneAccessEgressError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with access/egress points to managed lanes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ManagedLaneAccessEgressError(Exception):\n    \"\"\"Raised when there is an issue with access/egress points to managed lanes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.MissingNodesError","title":"network_wrangler.errors.MissingNodesError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when referenced nodes are missing from the network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class MissingNodesError(Exception):\n    \"\"\"Raised when referenced nodes are missing from the network.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NewRoadwayError","title":"network_wrangler.errors.NewRoadwayError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a new roadway.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NewRoadwayError(Exception):\n    \"\"\"Raised when there is an issue with applying a new roadway.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NodeAddError","title":"network_wrangler.errors.NodeAddError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with adding nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeAddError(Exception):\n    \"\"\"Raised when there is an issue with adding nodes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NodeChangeError","title":"network_wrangler.errors.NodeChangeError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a node change.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeChangeError(Exception):\n    \"\"\"Raised when there is an issue with applying a node change.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NodeDeletionError","title":"network_wrangler.errors.NodeDeletionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with deleting nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeDeletionError(Exception):\n    \"\"\"Raised when there is an issue with deleting nodes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NodeNotFoundError","title":"network_wrangler.errors.NodeNotFoundError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a node is not found in the nodes table.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodeNotFoundError(Exception):\n    \"\"\"Raised when a node is not found in the nodes table.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NodesInLinksMissingError","title":"network_wrangler.errors.NodesInLinksMissingError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with validating links and nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NodesInLinksMissingError(Exception):\n    \"\"\"Raised when there is an issue with validating links and nodes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NotLinksError","title":"network_wrangler.errors.NotLinksError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a dataframe is not a RoadLinksTable.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NotLinksError(Exception):\n    \"\"\"Raised when a dataframe is not a RoadLinksTable.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.NotNodesError","title":"network_wrangler.errors.NotNodesError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a dataframe is not a RoadNodesTable.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class NotNodesError(Exception):\n    \"\"\"Raised when a dataframe is not a RoadNodesTable.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ProjectCardError","title":"network_wrangler.errors.ProjectCardError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a project card is not valid.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ProjectCardError(Exception):\n    \"\"\"Raised when a project card is not valid.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.RoadwayDeletionError","title":"network_wrangler.errors.RoadwayDeletionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a roadway deletion.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class RoadwayDeletionError(Exception):\n    \"\"\"Raised when there is an issue with applying a roadway deletion.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.RoadwayPropertyChangeError","title":"network_wrangler.errors.RoadwayPropertyChangeError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with applying a roadway property change.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class RoadwayPropertyChangeError(Exception):\n    \"\"\"Raised when there is an issue with applying a roadway property change.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ScenarioConflictError","title":"network_wrangler.errors.ScenarioConflictError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a conflict is detected.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScenarioConflictError(Exception):\n    \"\"\"Raised when a conflict is detected.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ScenarioCorequisiteError","title":"network_wrangler.errors.ScenarioCorequisiteError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a co-requisite is not satisfied.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScenarioCorequisiteError(Exception):\n    \"\"\"Raised when a co-requisite is not satisfied.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ScenarioPrerequisiteError","title":"network_wrangler.errors.ScenarioPrerequisiteError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a pre-requisite is not satisfied.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScenarioPrerequisiteError(Exception):\n    \"\"\"Raised when a pre-requisite is not satisfied.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ScopeConflictError","title":"network_wrangler.errors.ScopeConflictError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is a scope conflict in a list of ScopedPropertySetItems.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScopeConflictError(Exception):\n    \"\"\"Raised when there is a scope conflict in a list of ScopedPropertySetItems.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ScopeLinkValueError","title":"network_wrangler.errors.ScopeLinkValueError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with ScopedLinkValueList.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ScopeLinkValueError(Exception):\n    \"\"\"Raised when there is an issue with ScopedLinkValueList.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.SegmentFormatError","title":"network_wrangler.errors.SegmentFormatError","text":"<p>               Bases: <code>Exception</code></p> <p>Error in segment format.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SegmentFormatError(Exception):\n    \"\"\"Error in segment format.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.SegmentSelectionError","title":"network_wrangler.errors.SegmentSelectionError","text":"<p>               Bases: <code>Exception</code></p> <p>Error in segment selection.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SegmentSelectionError(Exception):\n    \"\"\"Error in segment selection.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.SelectionError","title":"network_wrangler.errors.SelectionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with a selection.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SelectionError(Exception):\n    \"\"\"Raised when there is an issue with a selection.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ShapeAddError","title":"network_wrangler.errors.ShapeAddError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with adding shapes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ShapeAddError(Exception):\n    \"\"\"Raised when there is an issue with adding shapes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.ShapeDeletionError","title":"network_wrangler.errors.ShapeDeletionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an issue with deleting shapes from a network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class ShapeDeletionError(Exception):\n    \"\"\"Raised when there is an issue with deleting shapes from a network.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.SubnetCreationError","title":"network_wrangler.errors.SubnetCreationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a subnet can\u2019t be created.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SubnetCreationError(Exception):\n    \"\"\"Raised when a subnet can't be created.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.SubnetExpansionError","title":"network_wrangler.errors.SubnetExpansionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a subnet can\u2019t be expanded to include a node or set of nodes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class SubnetExpansionError(Exception):\n    \"\"\"Raised when a subnet can't be expanded to include a node or set of nodes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TimeFormatError","title":"network_wrangler.errors.TimeFormatError","text":"<p>               Bases: <code>Exception</code></p> <p>Time format error exception.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TimeFormatError(Exception):\n    \"\"\"Time format error exception.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TimespanFormatError","title":"network_wrangler.errors.TimespanFormatError","text":"<p>               Bases: <code>Exception</code></p> <p>Timespan format error exception.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TimespanFormatError(Exception):\n    \"\"\"Timespan format error exception.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitPropertyChangeError","title":"network_wrangler.errors.TransitPropertyChangeError","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when applying transit property changes.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitPropertyChangeError(Exception):\n    \"\"\"Error raised when applying transit property changes.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitRoadwayConsistencyError","title":"network_wrangler.errors.TransitRoadwayConsistencyError","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when transit network is inconsistent with roadway network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitRoadwayConsistencyError(Exception):\n    \"\"\"Error raised when transit network is inconsistent with roadway network.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitRouteAddError","title":"network_wrangler.errors.TransitRouteAddError","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when applying add transit route.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitRouteAddError(Exception):\n    \"\"\"Error raised when applying add transit route.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitRoutingChangeError","title":"network_wrangler.errors.TransitRoutingChangeError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when there is an error in the transit routing change.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitRoutingChangeError(Exception):\n    \"\"\"Raised when there is an error in the transit routing change.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitSelectionEmptyError","title":"network_wrangler.errors.TransitSelectionEmptyError","text":"<p>               Bases: <code>Exception</code></p> <p>Error for when no transit trips are selected.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitSelectionEmptyError(Exception):\n    \"\"\"Error for when no transit trips are selected.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitSelectionError","title":"network_wrangler.errors.TransitSelectionError","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for transit selection errors.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitSelectionError(Exception):\n    \"\"\"Base error for transit selection errors.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitSelectionNetworkConsistencyError","title":"network_wrangler.errors.TransitSelectionNetworkConsistencyError","text":"<p>               Bases: <code>TransitSelectionError</code></p> <p>Error for when transit selection dictionary is not consistent with transit network.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitSelectionNetworkConsistencyError(TransitSelectionError):\n    \"\"\"Error for when transit selection dictionary is not consistent with transit network.\"\"\"\n</code></pre>"},{"location":"api_utils/#network_wrangler.errors.TransitValidationError","title":"network_wrangler.errors.TransitValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Error raised when transit network doesn\u2019t have expected values.</p> Source code in <code>network_wrangler/errors.py</code> <pre><code>class TransitValidationError(Exception):\n    \"\"\"Error raised when transit network doesn't have expected values.\"\"\"\n</code></pre>"},{"location":"data_models/","title":"Data Models","text":"<p>Network Wrangler uses pandera\u2019s DataFrameModel as the base class for all data validation models. The following diagrams show how the core network classes contain these data models and their inheritance relationships:</p>"},{"location":"data_models/#network-containment-diagram","title":"Network Containment Diagram","text":"%%{init: {'theme':'base', 'themeVariables': {'fontSize': '12px'}}}%% graph TD     S[Scenario]      S --&gt; RN      subgraph \"RoadwayNetwork\"         RN[RoadwayNetwork]         RL[nodes_df: RoadNodesTable]         RK[links_df: RoadLinksTable]         RS[shapes_df: RoadShapesTable]         RN -.-&gt; RL         RN -.-&gt; RK         RN -.-&gt; RS     end      %% Force vertical spacing     SPACER1[\" \"]     SPACER2[\" \"]      RN --&gt; SPACER1     SPACER1 --&gt; SPACER2     SPACER2 --&gt; TN      subgraph \"TransitNetwork\"         TN[TransitNetwork]         F[Feed]         TS[stops: WranglerStopsTable]         TR[routes: RoutesTable]         TT[trips: WranglerTripsTable]         TST[stop_times: WranglerStopTimesTable]         TSH[shapes: WranglerShapesTable]         TF[frequencies: WranglerFrequenciesTable]         TA[agencies: AgenciesTable]         TN -.-&gt; F         F -.-&gt; TS         F -.-&gt; TR         F -.-&gt; TT         F -.-&gt; TST         F -.-&gt; TSH         F -.-&gt; TF         F -.-&gt; TA     end      %% Hide spacers     style SPACER1 fill:transparent,stroke:transparent     style SPACER2 fill:transparent,stroke:transparent      click S \"../api/#network_wrangler.scenario\"     click RN \"../api/#network_wrangler.roadway.network\"     click TN \"../api/#network_wrangler.transit.network\"     click F \"../api_transit/#network_wrangler.transit.feed.feed.Feed\"     click RL \"../api_roadway/#network_wrangler.models.roadway.tables.RoadNodesTable\"     click RK \"../api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable\"     click RS \"../api_roadway/#network_wrangler.models.roadway.tables.RoadShapesTable\"     click TS \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerStopsTable\"     click TR \"../api_transit/#network_wrangler.models.gtfs.tables.RoutesTable\"     click TT \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerTripsTable\"     click TST \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerStopTimesTable\"     click TSH \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerShapesTable\"     click TF \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerFrequenciesTable\"     click TA \"../api_transit/#network_wrangler.models.gtfs.tables.AgenciesTable\"      classDef core fill:#e3f2fd,stroke:#1976d2,stroke-width:3px     classDef container fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px     classDef roadway fill:#e8f5e8,stroke:#388e3c,stroke-width:2px     classDef transit fill:#fff3e0,stroke:#f57c00,stroke-width:2px      class S,RN,TN,F core     class RL,RK,RS roadway     class TS,TR,TT,TST,TSH,TF,TA transit"},{"location":"data_models/#roadway-inheritance-diagrams","title":"Roadway Inheritance Diagrams","text":"%%{init: {'theme':'base', 'themeVariables': {'fontSize': '12px'}}}%% graph TD     A[\"DataFrameModel\"]     A --&gt; B[\"RoadLinksTable\"]     A --&gt; C[\"RoadNodesTable\"]     A --&gt; D[\"RoadShapesTable\"]     A --&gt; E[\"ExplodedScopedLinkPropertyTable\"]     A --&gt; F[\"NodeGeometryChangeTable\"]      click A \"https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.pandas.model.DataFrameModel.html\"     click B \"../api_roadway/#network_wrangler.models.roadway.tables.RoadLinksTable\"     click C \"../api_roadway/#network_wrangler.models.roadway.tables.RoadNodesTable\"     click D \"../api_roadway/#network_wrangler.models.roadway.tables.RoadShapesTable\"     click E \"../api_roadway/#network_wrangler.models.roadway.tables.ExplodedScopedLinkPropertyTable\"     click F \"../api_roadway/#network_wrangler.roadway.nodes.edit.NodeGeometryChangeTable\"      classDef pandera fill:#e1f5fe,stroke:#01579b,stroke-width:3px     classDef roadway fill:#f3e5f5,stroke:#4a148c,stroke-width:2px      class A pandera     class B,C,D,E,F roadway"},{"location":"data_models/#transitgtfs-inheritance-diagrams","title":"Transit/GTFS Inheritance Diagrams","text":"%%{init: {'theme':'base', 'themeVariables': {'fontSize': '12px'}}}%% graph TD     A[\"DataFrameModel\"]     A --&gt; B[\"AgenciesTable\"]     A --&gt; C[\"StopsTable\"]     A --&gt; D[\"RoutesTable\"]     A --&gt; E[\"ShapesTable\"]     A --&gt; F[\"TripsTable\"]     A --&gt; G[\"FrequenciesTable\"]     A --&gt; H[\"StopTimesTable\"]      C --&gt; I[\"WranglerStopsTable\"]     E --&gt; J[\"WranglerShapesTable\"]     F --&gt; K[\"WranglerTripsTable\"]     G --&gt; L[\"WranglerFrequenciesTable\"]     H --&gt; M[\"WranglerStopTimesTable\"]      click A \"https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.pandas.model.DataFrameModel.html\"     click B \"../api_transit/#network_wrangler.models.gtfs.tables.AgenciesTable\"     click C \"../api_transit/#network_wrangler.models.gtfs.tables.StopsTable\"     click D \"../api_transit/#network_wrangler.models.gtfs.tables.RoutesTable\"     click E \"../api_transit/#network_wrangler.models.gtfs.tables.ShapesTable\"     click F \"../api_transit/#network_wrangler.models.gtfs.tables.TripsTable\"     click G \"../api_transit/#network_wrangler.models.gtfs.tables.FrequenciesTable\"     click H \"../api_transit/#network_wrangler.models.gtfs.tables.StopTimesTable\"     click I \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerStopsTable\"     click J \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerShapesTable\"     click K \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerTripsTable\"     click L \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerFrequenciesTable\"     click M \"../api_transit/#network_wrangler.models.gtfs.tables.WranglerStopTimesTable\"      classDef pandera fill:#e1f5fe,stroke:#01579b,stroke-width:3px     classDef gtfs fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px     classDef wrangler fill:#fff3e0,stroke:#e65100,stroke-width:2px      class A pandera     class B,C,D,E,F,G,H gtfs     class I,J,K,L,M wrangler <p>Legend:</p> <ul> <li>\ud83d\udd17 DataFrameModel - External pandera base class (links to pandera docs)</li> <li>\ud83d\udfe3 Purple - Roadway network data models  </li> <li>\ud83d\udfe2 Green - Standard GTFS transit data models</li> <li>\ud83d\udfe0 Orange - Wrangler-enhanced GTFS models with additional fields</li> </ul>"},{"location":"data_models/#dbmodelmixin-inheritance-diagrams","title":"DBModelMixin Inheritance Diagrams","text":"%%{init: {'theme':'base', 'themeVariables': {'fontSize': '12px'}}}%% graph TD     A[\"DBModelMixin\"]     A --&gt; B[\"GtfsModel\"]     A --&gt; C[\"Feed\"]     A --&gt; D[\"MockDBModel\"]      click A \"../api/#network_wrangler.models._base.db.DBModelMixin\"     click B \"../api_transit/#network_wrangler.models.gtfs.gtfs.GtfsModel\"     click C \"../api_transit/#network_wrangler.transit.feed.feed.Feed\"      classDef mixin fill:#fff3e0,stroke:#e65100,stroke-width:3px     classDef gtfs fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px     classDef wrangler fill:#e1f5fe,stroke:#01579b,stroke-width:2px     classDef test fill:#f3e5f5,stroke:#4a148c,stroke-width:2px      class A mixin     class B gtfs     class C wrangler     class D test <p>Legend:</p> <ul> <li>\ud83d\udfe0 DBModelMixin - Base mixin for managing interrelated DataFrameModel tables</li> <li>\ud83d\udfe2 GtfsModel - Pure GTFS feed data wrapper</li> <li>\ud83d\udd35 Feed - Wrangler-enhanced GTFS feed with additional functionality</li> <li>\ud83d\udfe3 MockDBModel - Test implementation (not shown in API docs)</li> </ul> <p>\ud83d\udca1 Tip: Click on any box in the diagrams to jump directly to that class\u2019s documentation!</p>"},{"location":"design/","title":"Design","text":""},{"location":"design/#atomic-parts","title":"Atomic Parts","text":"flowchart TD     subgraph BaseScenario         base_road_net[\"road_net(RoadwayNetwork)\"]         base_transit_net[\"transit_net(TransitNetwork)\"]         applied_projects[\"applied_projects(list)\"]         conflicts[\"conflicts(dict)\"]     end     BaseScenario --&gt; base_scenario     subgraph Scenario     base_scenario[\"base_scenario(dict)\"]     projects[\"projects(ProjectCard`\"]     road_net[\"road_net(RoadwayNetwork)\"]     transit_net[\"transit_net(TransitNetwork)\"]     config[\"config(WranglerConfig)\"]     end <p>NetworkWrangler deals with four primary atomic parts:</p> <p>1. <code>Scenario</code> objects describe a Roadway Network, Transit Network, and collection of Projects. Scenarios manage the addition and construction of projects on the network via projct cards including required pre-requisites, co-requisites, and conflicts. Scenarios can be based on or tiered from other scenarios but must at the very least be based on an existing roadway and/or transit network defined in <code>base_scenario</code>.</p> <p>2. <code>RoadwayNetwork</code> objects stores information about roadway nodes, directed links between nodes, and the shapes of links (note that the same shape can be shared between two or more links). Network Wrangler reads/writes roadway network objects from/to three files: <code>links</code>, <code>shape</code>, and <code>nodes</code>. Their data is stored as GeoDataFrames in the object.</p> <p>3. <code>TransitNetwork</code> objects contain information about the service (represented by the GTFS-compatable <code>Feed</code> object with stops, routes, trips, shapes, stoptimes, and frequencies tables), and how it maps to a <code>RoadwayNetwork</code>, stored as <code>road_net</code> attribute.  Network Wrangler reads/writes transit network information from/to gtfs-like files and stores them as DataFrames within.</p> <p>4.<code>ProjectCard</code> objects store information (including  metadata) about changes to the network.  Network Wrangler uses the <code>projectcard</code> package to read project cards from .yaml-like files and validate them.</p>"},{"location":"design/#applying-projects","title":"Applying Projects","text":"<p>The basic functionality of NetworkWrangler is to apply a set of projects to a scenario.</p> <pre><code>from project_card import read_cards\ncards = read_cards([\n    \"projects/project_a.yml\",\n    \"projects/project_b.yml\",\n    \"projects/project_c.yml\",\n])\nmy_scenario.add_project_cards(cards.values())\nmy_scenario.queued_projects\n&gt;&gt;  [\"project_a\", \"project_b\", \"project_c\"]\nmy_scenario.apply_projects([\"project_a\"])\nmy_scenario.applied_projects\n&gt;&gt; [\"project_a\"]\nmy_scenario.queued_projects\n&gt;&gt;  [\"project_b\", \"project_c\"]\nmy_scenario.apply_all_projects()\nmy_scenario.applied_projects\n&gt;&gt; [\"project_a\", \"project_b\", \"project_c\"]\n</code></pre>"},{"location":"design/#project-dependencies","title":"Project Dependencies","text":"<p>Each project can specify any number of other projects (by project name) as a:</p> <ul> <li><code>prerequisite</code>: list of projects that must be applied before this one.</li> <li><code>corequisite</code>: list of projects that must be applied alongside this one (but not necessarily first).</li> <li><code>conflicts</code>: list of projects that must not be applied to the same scenario as this one.</li> </ul> <p>The Scenario object keeps track of the applied projects to make sure that these dependencies are enforced.</p> <p>Base Scenarios with applied projects</p> <p>Make sure your base scenario contains your applied projects and their conflicts.  This can be easily enforced by either loading a scenario from its .yml file or if you are seeding the base_scenario with an actual Scenario object instead of a dictionary.</p>"},{"location":"design/#order-of-project-application","title":"Order of project application","text":"<p>The order projects are applied defaults to the order they are specified in <code>my_scenario.projects</code>.  If a project card lists another project as a <code>prerequisite</code>, then NetworkWrangler will re-arrange the queued projects to make sure that is applied first.</p> <p>This order can always be reviewed in <code>my_scenario.queued_projects</code>.</p>"},{"location":"design/#existing-values","title":"Existing Values","text":"<p>You can control the behavior of Network Wrangler if existing value is not equal to the <code>existing</code> attribute in a ProjectCard as follows:</p> <ul> <li><code>error</code>: Raise an error.</li> <li><code>skip</code>: Skips applying the project.</li> <li><code>warn</code>: Writes a warning about conflicting values. This is the global default.</li> </ul> <p>These options can be set at the global configuration level by using WranglerConfig.</p> <pre><code>EDITS:\n    EXISTING_VALUE_CONFLICT: warn\n</code></pre> <p>This behavior can be overridden within a project card for a <code>roadway_property_change</code> or <code>transit_property_change</code> project for any individual <code>property_changes</code> item.</p> <pre><code>transit_property_change:\n    property_changes:\n        headway_secs:\n            existing: 360\n            change: -180\n            existing_value_conflict: error # this overrides the setting in WranglerConfig to error if the existing value is not 360.\n</code></pre>"},{"location":"design/#scoped-roadway-property-changes","title":"Scoped Roadway Property Changes","text":"<p>In some cases, properties of a roadway network may apply only during certain times of the day or for certain categories of users (e.g. trucks, HOV2, etc).  The Network Wrangler data model provides the ability to scope each property using the syntax described in the network documentation.</p> <p>The value for a scoped property for a given link record is a list of ScopedLinkValueItem objects.</p> <p>Define the value of a link property for a particular timespan or category.</p> <p>Attributes:</p> <ul> <li> <code>`category`</code>               (<code>str</code>)           \u2013            <p>Category or link user that this scoped value applies to, ex: <code>HOV2</code>, <code>truck</code>, etc.  Categories are user-defined with the exception of <code>any</code> which is reserved as the default category. Default is <code>DEFAULT_CATEGORY</code>, which is <code>all</code>.</p> </li> <li> <code>`timespan`</code>               (<code>list[TimeString]</code>)           \u2013            <p>timespan of the link property as defined as a list of two HH:MM(:SS) strings. Default is <code>DEFAULT_TIMESPAN</code>, which is <code>[\"00:00\", \"24:00\"]</code>.</p> </li> <li> <code>`value`</code>               (<code>Union[float, int, str]</code>)           \u2013            <p>Value of the link property for the given category and timespan.</p> </li> </ul> <p>Conflicting or matching scopes are not allowed in a list of ScopedLinkValueItems:</p> <ul> <li><code>matching</code>: a scope that could be applied for a given category/timespan combination. This includes the default scopes as well as scopes that are contained within the given category AND timespan combination.</li> <li><code>overlapping</code>: a scope that fully or partially overlaps a given category OR timespan combination.  This includes the default scopes, all <code>matching</code> scopes and all scopes where at least one minute of timespan or one category overlap.</li> <li><code>conflicting</code>: a scope that is overlapping but not matching for a given category/timespan.</li> </ul> <p>NOTE: Default scope values of <code>category: any</code> and <code>timespan:[\"00:00\", \"24:00\"]</code> are not considered conflicting, but are applied to residual scopes.</p> <p>There are a few ways that network wrangler can treat conflicts:</p> <ul> <li><code>conflicting</code> (default behavior):  overwrite any conflicting scoped properties for that property/link with what is given in the project card.</li> <li><code>all</code>: overwrite all scoped properties for that property/link with what is given in the project card.</li> <li><code>error</code>: raise an error when a conflict is detected.</li> </ul> <p>These options can be set at the global configuration level by using WranglerConfig.</p> <pre><code>EDITS:\n    OVERWRITE_SCOPED: error # will default to raising an error if any scoped value in this specific property change conflicts with this scope.\n</code></pre> <p>This behavior can be overridden within a project card for a <code>roadway_property_change</code> project for any individual <code>property_changes</code> item.</p> <pre><code>roadway_property_change:\n    property_changes:\n        sc_myproperty:\n            set: 1\n            scoped:\n                timespan: [[12:00, 15:00]]\n                set: 2\n            overwrite_scoped: all # will overwrite all scopes in a link/property. Useful if you are completely defining something rather than amending.\n</code></pre>"},{"location":"design/#selections","title":"Selections","text":""},{"location":"design/#roadway","title":"Roadway","text":""},{"location":"design/#segment","title":"Segment","text":"<p>Example Segment Facility Searches</p> <pre><code>facility:\n    links:\n        name: [\"6th\", \"Sixth\", \"sixth\"] # find streets that have one of the various forms of 6th\n    from:\n        osm_node_id: \"187899923\"  # start searching for segments at this ID\n    to:\n        osm_node_id\": \"187865924\" # end at this ID\n</code></pre> <pre><code>facility:\n    links:\n        name: [\"6th\", \"Sixth\", \"sixth\"]\n        lanes: [2, 3]  # from the initial connected segment search, only return links that are either 2 OR 3 lanes\n    from:\n        osm_node_id: \"187899923\"\n    to:\n        osm_node_id\": \"187942339\"\n</code></pre> <p>When Network Wrangler conducts a search for a facility, it tries to navigate from the <code>from</code> node to the <code>to</code> node based on a network created from the initial selection values of: <code>name</code>, <code>ref</code>, <code>osm_link_id</code> and <code>model_link_id</code>.</p> <p>If it cannot do so initially, it will expand its search graph several times until it achieves a navigable route \u2013\u00a0or reaches the maximum number of expansions which defaults to <code>roadway.segment.DEFAULT_MAX_SEARCH_BREADTH = 10</code> but can be set higher by running <code>...selection.create_segment(max_search_breadth=BIGGER_NUMBER</code> before returning the values form the selection. In production, you will want to set the search breadth as low as possible while also being successful so that you don\u2019t get strange routes.</p> <p>Pertinent relationships:</p> <ul> <li><code>RoadwayNetwork.selections</code> is a dictionary of stored  <code>RoadwayLinkSelection</code> or <code>RoadwayNodeSelection</code> objects mapped to a hash of the stringified roadway selection dictionary.</li> <li>A <code>RoadwayLinkSelection</code> object which is a <code>segment</code> type of selection will have a single associated <code>Segment</code> object accessed from <code>RoadwayLinkSelection.segment</code> to store relevant functionality.</li> <li><code>Segment.subnet</code> is a single associated <code>Subnet</code> representing the subset of nodes and links that Network Wrangler will search to find a connected graph.  This is because creating a connected graph can be very memory and computationally intensive and we want to limit the size of them substantially.</li> <li><code>Subnet.graph</code> is the associated <code>networkx.MultiDiGraph</code> connected graph object which is used to conduct the shortest path search.</li> </ul> <p>For an interactive demonstration of what this means: <code>notebooks.Roadway Network Search.ipynb</code></p>"},{"location":"design/#organization","title":"Organization","text":"<code>../network_wrangler</code> <code>__init__.py</code> Things that must get done every time <code>network_wrangler</code> is used. <code>bin</code> Executable scripts. <code>configs</code> Structure and default values for user-settable configuration. <code>errors.py</code> User-facing errors. <code>logger.py</code> Logging utilities and the WranglerLogger class. <code>models</code> Pydantic and pandera data models and helper functions for them. <code>params.py</code> Package-wide constants. <code>roadway</code> Classes and functions pertaining to read, write, analyzing and editing roadway networks. <code>scenario.py</code> Scenario object class and helper functions. <code>time.py</code> Time helper functions. <code>transit</code> Classes and functions pertaining to read, write, analyzing and editing transit networks. <code>utils</code> Utility functions. <code>viz.py</code> Visualization helper functions. <code>network_wrangler/roadway</code> <code>links</code> Module for managing roadway links. <code>nodes</code> Module for managing roadway nodes. <code>projects</code> Module with functions to apply various types of roadway projects. <code>shapes</code> Module for managing roadway shapes. <code>clip.py</code> Functions to clip a RoadwayNetwork object to a boundary. <code>graph.py</code> Functions to convert RoadwayNetwork to osmnx graph and perform graph operations. <code>io.py</code> Functions for reading and writing roadway networks. <code>model_roadway.py</code> Functions to create a model roadway network from a roadway network. <code>network.py</code> RoadwayNetwork class and functions for Network Wrangler. <code>segment.py</code> Segment class and related functions for working with segments of a RoadwayNetwork. <code>selection.py</code> Roadway selection classes for selecting links and nodes from a roadway network. <code>subnet.py</code> Subnet class for RoadwayNetwork object. <code>utils.py</code> Utility functions for RoadwayNetwork and ModelRoadwayNetwork classes. <code>validate.py</code> Validates a roadway network to the wrangler data model specifications. <code>viz.py</code> Visualization functions for RoadwayNetwork and RoadwayLinkSelection. <code>network_wrangler/transit</code> <code>feed</code> Relational tables representing transit service. <code>projects</code> Module with functions to apply various types of transit projects. <code>clip.py</code> Functions to clip a TransitNetwork object to a boundary. <code>geo.py</code> Geographic functions for GTFS tables. <code>io.py</code> Functions for reading and writing transit feeds and networks. <code>model_transit.py</code> ModelTransit class and functions for managing consistency between roadway and transit networks. <code>network.py</code> TransitNetwork class for representing a transit network consisting of a schedule <code>Feed</code> mapped to a <code>RoadwayNetwork</code>. <code>selection.py</code> Classes and functions for selecting transit trips from a transit network. <code>validate.py</code> Functions to check for transit network validity and consistency with roadway network."},{"location":"development/","title":"Development","text":""},{"location":"development/#contributing-to-network-wrangler","title":"Contributing to Network Wrangler","text":""},{"location":"development/#setup","title":"Setup","text":""},{"location":"development/#recommended-tools","title":"Recommended Tools","text":"<ul> <li>GitHub desktop to manage access to the main repository.</li> <li>Git to conduct required version control.</li> <li>MiniConda to manage your Python environments.</li> <li>VSCode to edit and test code.</li> <li>Some type of terminal application (note, this comes with Mac/Ubuntu).</li> </ul>"},{"location":"development/#setup-virtual-environment","title":"Setup Virtual Environment","text":"<p>Create and/or activate the virtual environment where you want to install Network Wrangler.</p> <p>Creating and activating a virtual environment using conda</p> <pre><code>conda config --add channels conda-forge\nconda create python=3.11 -n wrangler-dev #if you don't already have a virtual environment\nconda activate wrangler-dev\n</code></pre>"},{"location":"development/#clone","title":"Clone","text":"<p>To effectively work on Network Wrangler locally, install it from a clone by either:</p> <ol> <li>Use the GitHub user interface by clicking on the green button \u201cclone or download\u201d in the main network wrangler repository page.</li> <li>Use the command prompt in a terminal to navigate to the directory that you would like to store your network wrangler clone and then using a git command to clone it.</li> </ol> <p>Clone network wrangler</p> <pre><code>cd path to where you want to put wrangler\ngit clone https://github.com/wsp-sag/network_wrangler\n</code></pre>"},{"location":"development/#install-in-develop-mode","title":"Install in Develop Mode","text":"<p>Install Network Wrangler in \u201cdevelop\u201d mode using the <code>-e</code> flag so that changes to your code will be reflected when you are using and testing network wrangler:</p> <p>Install Network Wrangler from Clone</p> <pre><code>cd network_wrangler\npip install -e .\n</code></pre> <p>Install development dependencies</p> <pre><code>pip install -r requirements.tests.txt\npip install -r requirements.docs.txt\n</code></pre>"},{"location":"development/#ide-settings","title":"IDE Settings","text":""},{"location":"development/#vscode","title":"VSCode","text":"<p>Select conda env as Python interpreter:</p> <pre><code>- `cmd-shift-P`: Python: Select Interpreter\n</code></pre> <p>If you are using VS Code, here are some recommended extensions and settings to leverage the IDE capabilities:</p> Extension Purpose Microsoft Python Pytest integration, code-completion Astral Ruff Linting and formatting Microsoft Jupyter Edit and run python notebooks Microsoft Data Wrangler Review and edit data in pandas dataframes David Anson markdownlint Lint markdown Github Pull Requests Manage github issues and PRs Dvir Yitzchaki parquet-viewer Review parquet data as json Random Fractals Inc. Geo Data Viewer Render geojson data <p>Leveraging these extensions to their full potential may take some configuration. Here are some examples. YMMV.</p> <p><code>settings.json</code> for VS Code</p> <pre><code>{\n    \"[python]\": {\n    \"editor.formatOnSave\": true,\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\",\n    \"editor.codeActionsOnSave\": {\n    \"source.fixAll\": \"explicit\",\n    \"source.organizeImports\": \"explicit\"\n    }\n},\n    \"python.testing.pytestArgs\": [\n        \"tests\"\n    ],\n    \"python.testing.unittestEnabled\": false,\n    \"python.testing.pytestEnabled\": true,\n    \"python.testing.cwd\": \"\",\n    \"python.testing.autoTestDiscoverOnSaveEnabled\": true,\n    \"python.defaultInterpreterPath\": \"/usr/bin/env python\",\n    \"python.testing.pytestPath\": \"/opt/miniconda3/envs/wrangler-dev/bin/pytest\",\n}\n</code></pre> <p>Code &gt; Settings &gt; Settings</p> <p>For tests to run in conda environment, add path to it. To find it, you can run <code>conda info --envs</code></p> <p><code>@id:python.condaPath</code>: <code>opt/miniconda3/envs/wrangler-dev</code></p>"},{"location":"development/#development-workflow","title":"Development Workflow","text":"<ol> <li>Create an issue for any features/bugs that you are working on.</li> <li>Create a branch to work on a new issue (or checkout an existing one where the issue is being worked on).  </li> <li>Develop comprehensive tests in the <code>/tests</code> folder.</li> <li>Modify code including inline documentation such that it passes all  tests (not just your new ones)</li> <li>Lint code using <code>pre-commit run --all-files</code></li> <li>Fill out information in the pull request template</li> <li>Submit all pull requests to the <code>develop</code> branch.</li> <li>Core developer will review your pull request and suggest changes.</li> <li>After requested changes are complete, core developer will sign off on pull-request merge.</li> </ol> <p>Tip</p> <p>Keep pull requests small and focused. One issue is best.</p> <p>Tip</p> <p>Don\u2019t forget to update any associated documentation as well!</p>"},{"location":"development/#documentation","title":"Documentation","text":"<p>Documentation is stored in the <code>/docs</code> folder and created by <code>mkdocs</code> using the <code>material-for-mkdocs</code> theme.</p> <p>Build and locally serve documentation</p> <pre><code>mkdocs serve\n</code></pre> <p>Documentation is deployed using the <code>mike</code> package and Github Actions configured in <code>.github/workflows/</code> for each \u201cref\u201d (i.e. branch) in the network_wrangler repository.</p>"},{"location":"development/#references","title":"References","text":"<ul> <li>MkDocs User Guide: Configuration</li> <li>mkdocstrings-python</li> <li>Material for MkDocs Setup</li> <li>Admonitions</li> </ul>"},{"location":"development/#making-sure-your-code-works","title":"Making sure your code works","text":""},{"location":"development/#linting-and-type-checking","title":"Linting and Type Checking","text":"<p>Before even running the tests, its a good idea to lint and check the types of the code using pre-commit:</p> <p>Example</p> <pre><code>pre-commit run --all-files\n</code></pre> <p>Your code must pass the pre-commit tests as a part of continuous integration, so you might as well fix anything now if it arises.</p>"},{"location":"development/#adding-tests","title":"Adding Tests","text":"<p>..to come</p>"},{"location":"development/#running-tests","title":"Running Tests","text":"<p>Tests and test data reside in the <code>/tests</code> directory:</p> <p>Example</p> <pre><code>pytest\n</code></pre> <p>Your code must pass the these tests as a part of continuous integration, so you might as well fix anything now if it arises.</p>"},{"location":"development/#profiling-performance","title":"Profiling Performance","text":"<p>When you run the tests, their performance is profiled using <code>pytest-profiling</code> and profiles for tests are stored in <code>.prof</code> directory. If you want to explore what is taking time in a particular test, you can do so using products like <code>snakviz</code></p> <p>Explore performance of a test</p> <pre><code>snakeviz .prof/&lt;test_name&gt;.prof\n</code></pre> <p>We also benchmark some specific tests (<code>test_benchmarks.py</code>) that we want to compare when reviewing pull requests. If you want to review how you are doing on these benchmarks you can save the benchmarks when you run pytestand compare these numbers to another branch.</p> <p>Compare benchmarks between branches</p> <pre><code>pytest --benchmark-save=branch_1\ngit checkout branch_2\npytest --benchmark-save=branch_2\npytest-benchmark compare branch_1 branch_2\n</code></pre>"},{"location":"development/#evaluate-code-maintainability","title":"Evaluate Code Maintainability","text":"<p>Using Radon</p> <p>Maintainability Index is a software metric which measures how maintainable (easy to support and change) the source code is. The maintainability index is calculated as a factored formula consisting of SLOC (Source Lines Of Code), Cyclomatic Complexity and Halstead volume.</p> <pre><code>radon mi ../network_wrangler -s\n</code></pre> <p>Cyclomatic Complexity corresponds to the number of decisions a block of code contains plus 1. This number (also called McCabe number) is equal to the number of linearly independent paths through the code. This number can be used as a guide when testing conditional logic in blocks.</p> <pre><code>radon cc ../network_wrangler --average\n</code></pre>"},{"location":"development/#continuous-integration","title":"Continuous Integration","text":"<p>Continuous Integration is managed by Github Actions in <code>.github/workflows</code>. All tests other than those with the decorator <code>@pytest.mark.skipci</code> will be run.</p>"},{"location":"development/#project-governance","title":"Project Governance","text":"<p>The project is currently governed by representatives of its two major organizational contributors:</p> <ul> <li>Metropolitan Council (MN)</li> <li>Metropolitan Transportation Commission (California)</li> </ul>"},{"location":"development/#code-of-conduct","title":"Code of Conduct","text":"<p>Contributors to the Network Wrangler Project are expected to read and follow the CODE_OF_CONDUCT for the project.</p>"},{"location":"development/#contributors","title":"Contributors","text":"<ol> <li>Lisa Z. - initial Network Wrangler implementation at SFCTA</li> <li>Billy C. - initial Network Wrangler implementation at SFCTA</li> <li>Elizabeth S.</li> <li>Sijia W.</li> <li>David O.</li> <li>Ashish K.</li> <li>Yue S.</li> </ol> <p>Note</p> <p>There are likely more contributors - feel free to add your name if we missed it!</p>"},{"location":"development/#release-history","title":"Release History","text":""},{"location":"development/#changelog","title":"Changelog","text":"<p>Notable changes and version history.</p> Version Date Comment v1.0-beta-2 20204-10-15 Bug fixes in scenario loading, projectcard API and compatibility of transit net with roadway deletions. Some additional performance improvements. v1.0-beta-1 20204-10-9 Feature-complete for 1.0 v1.0-alpha-2 2024-10-8 Testing for Met Council v1.0-alpha-1 2024-07-17 Full refactor v0.2.0-alpha 2020-09-16 - v0.1.0-alpha 2020-09-09 - 0.0.2 2020-02-05 -"},{"location":"how_to/","title":"How To","text":""},{"location":"how_to/#build-a-scenario-using-api","title":"Build a Scenario using API","text":"<p>Scenario objects manage how a collection of projects is applied to the networks.</p> <p>Scenarios are built from a base scenario and a list of project cards.</p> <p>A project card is a YAML file (or similar) that describes a change to the network. The project card can contain multiple changes, each of which is applied to the network in sequence.</p> <p>additional examples</p> <p>You can see additional scenario creating capabilities in the example jupyter notebook <code>Scenario Building Example.ipynb</code>.</p>"},{"location":"how_to/#network_wrangler.scenario--create-a-scenario","title":"Create a Scenario","text":"<p>Instantiate a scenario by seeding it with a base scenario and optionally some project cards.</p> <pre><code>from network_wrangler import create_scenario\n\nmy_scenario = create_scenario(\n    base_scenario=my_base_year_scenario,\n    card_search_dir=project_card_directory,\n    filter_tags=[\"baseline2050\"],\n)\n</code></pre> <p>A <code>base_year_scenario</code> is a dictionary representation of key components of a scenario:</p> <ul> <li><code>road_net</code>: RoadwayNetwork instance</li> <li><code>transit_net</code>: TransitNetwork instance</li> <li><code>applied_projects</code>: list of projects that have been applied to the base scenario so that the     scenario knows if there will be conflicts with future projects or if a future project\u2019s     pre-requisite is satisfied.</li> <li><code>conflicts</code>: dictionary of conflicts for project that have been applied to the base scenario so     that the scenario knows if there will be conflicts with future projects.</li> </ul> <pre><code>my_base_year_scenario = {\n    \"road_net\": load_from_roadway_dir(STPAUL_DIR),\n    \"transit_net\": load_transit(STPAUL_DIR),\n    \"applied_projects\": [],\n    \"conflicts\": {},\n}\n</code></pre>"},{"location":"how_to/#network_wrangler.scenario--add-projects-to-a-scenario","title":"Add Projects to a Scenario","text":"<p>In addition to adding projects when you create the scenario, project cards can be added to a scenario using the <code>add_project_cards</code> method.</p> <pre><code>from projectcard import read_cards\n\nproject_card_dict = read_cards(card_location, filter_tags=[\"Baseline2030\"], recursive=True)\nmy_scenario.add_project_cards(project_card_dict.values())\n</code></pre> <p>Where <code>card_location</code> can be a single path, list of paths, a directory, or a glob pattern.</p>"},{"location":"how_to/#network_wrangler.scenario--apply-projects-to-a-scenario","title":"Apply Projects to a Scenario","text":"<p>Projects can be applied to a scenario using the <code>apply_all_projects</code> method. Before applying projects, the scenario will check that all pre-requisites are satisfied, that there are no conflicts, and that the projects are in the planned projects list.</p> <p>If you want to check the order of projects before applying them, you can use the <code>queued_projects</code> prooperty.</p> <pre><code>my_scenario.queued_projects\nmy_scenario.apply_all_projects()\n</code></pre> <p>You can review the resulting scenario, roadway network, and transit networks.</p> <pre><code>my_scenario.applied_projects\nmy_scenario.road_net.links_gdf.explore()\nmy_scenario.transit_net.feed.shapes_gdf.explore()\n</code></pre>"},{"location":"how_to/#network_wrangler.scenario--write-a-scenario-to-disk","title":"Write a Scenario to Disk","text":"<p>Scenarios (and their networks) can be written to disk using the <code>write</code> method which in addition to writing out roadway and transit networks, will serialize the scenario to a yaml-like file and can also write out the project cards that have been applied.</p> <pre><code>my_scenario.write(\n    \"output_dir\",\n    \"scenario_name_to_use\",\n    overwrite=True,\n    projects_write=True,\n    file_format=\"parquet\",\n)\n</code></pre> Example Serialized Scenario File<pre><code>applied_projects: &amp;id001\n- project a\n- project b\nbase_scenario:\napplied_projects: *id001\nroadway:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\n    file_format: geojson\ntransit:\n    dir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/examples/small\nconfig:\nCPU:\n    EST_PD_READ_SPEED:\n    csv: 0.03\n    geojson: 0.03\n    json: 0.15\n    parquet: 0.005\n    txt: 0.04\nIDS:\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: &amp;id002 !!python/tuple\n    - 950000\n    - 999999\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: *id002\n    ML_NODE_ID_SCALAR: 15000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\nMODEL_ROADWAY:\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\n    ML_OFFSET_METERS: -10\nconflicts: {}\ncorequisites: {}\nname: first_scenario\nprerequisites: {}\nroadway:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/roadway\nfile_format: parquet\ntransit:\ndir: /Users/elizabeth/Documents/urbanlabs/MetCouncil/NetworkWrangler/working/network_wrangler/tests/out/first_scenario/transit\nfile_format: txt\n</code></pre>"},{"location":"how_to/#network_wrangler.scenario--load-a-scenario-from-disk","title":"Load a scenario from disk","text":"<p>And if you want to reload scenario that you \u201cwrote\u201d, you can use the <code>load_scenario</code> function.</p> <pre><code>from network_wrangler import load_scenario\n\nmy_scenario = load_scenario(\"output_dir/scenario_name_to_use_scenario.yml\")\n</code></pre>"},{"location":"how_to/#build-a-scenario-from-a-scenario-configuration-file","title":"Build a Scenario from a Scenario Configuration File","text":"<p>Scenario configuration for Network Wrangler.</p> <p>You can build a scenario and write out the output from a scenario configuration file using the code below.  This is very useful when you are running a specific scenario with minor variations over again because you can enter your config file into version control.  In addition to the completed roadway and transit files, the output will provide a record of how the scenario was run.</p> Usage <pre><code>    from scenario import build_scenario_from_config\n    my_scenario = build_scenario_from_config(my_scenario_config)\n</code></pre> <p>Where <code>my_scenario_config</code> can be a:</p> <ul> <li>Path to a scenario config file in yaml/toml/json (recommended),</li> <li>Dictionary which is in the same structure of a scenario config file, or</li> <li>A <code>ScenarioConfig()</code>  instance.</li> </ul> <p>Notes on relative paths in scenario configs</p> <ul> <li>Relative paths are recognized by a preceeding \u201c.\u201d.</li> <li>Relative paths within <code>output_scenario</code> for <code>roadway</code>, <code>transit</code>, and <code>project_cards</code> are interpreted to be relative to <code>output_scenario.path</code>.</li> <li>All other relative paths are interpreted to be relative to directory of the scenario config file. (Or if scenario config is provided as a dictionary, relative paths will be interpreted as relative to the current working directory.)</li> </ul> Example Scenario Config<pre><code>name: \"my_scenario\"\nbase_scenario:\n    roadway:\n        dir: \"path/to/roadway_network\"\n        file_format: \"geojson\"\n        read_in_shapes: True\n    transit:\n        dir: \"path/to/transit_network\"\n        file_format: \"txt\"\n    applied_projects:\n        - \"project1\"\n        - \"project2\"\n    conflicts:\n        \"project3\": [\"project1\", \"project2\"]\n        \"project4\": [\"project1\"]\nprojects:\n    project_card_filepath:\n        - \"path/to/projectA.yaml\"\n        - \"path/to/projectB.yaml\"\n    filter_tags:\n        - \"tag1\"\noutput_scenario:\n    overwrite: True\n    roadway:\n        out_dir: \"path/to/output/roadway\"\n        prefix: \"my_scenario\"\n        file_format: \"geojson\"\n        true_shape: False\n    transit:\n        out_dir: \"path/to/output/transit\"\n        prefix: \"my_scenario\"\n        file_format: \"txt\"\n    project_cards:\n        out_dir: \"path/to/output/project_cards\"\n\nwrangler_config: \"path/to/wrangler_config.yaml\"\n</code></pre> Extended Usage <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_scenario_config\n\nmy_scenario_config = load_scenario_config(\"path/to/config.yaml\")\n</code></pre> <p>Access the configuration:</p> <pre><code>my_scenario_config.base_transit_network.path\n&gt;&gt; path/to/transit_network\n</code></pre> <p>show_source: false \u00a0\u00a0\u00a0\u00a0\u00a0     show_submodules: false \u00a0\u00a0\u00a0\u00a0\u00a0     show_classes: false \u00a0\u00a0\u00a0\u00a0\u00a0     show_functions: false</p>"},{"location":"how_to/#change-wrangler-configuration","title":"Change Wrangler Configuration","text":"<p>Configuration for parameters for Network Wrangler.</p> <p>Users can change a handful of parameters which control the way Wrangler runs.  These parameters can be saved as a wrangler config file which can be read in repeatedly to make sure the same parameters are used each time.</p> Usage <p>At runtime, you can specify configurable parameters at the scenario level which will then also be assigned and accessible to the roadway and transit networks.</p> <pre><code>create_scenario(...config = myconfig)\n</code></pre> <p>Or if you are not using Scenario functionality, you can specify the config when you read in a RoadwayNetwork.</p> <pre><code>load_roadway_from_dir(**roadway, config=myconfig)\nload_transit(**transit, config=myconfig)\n</code></pre> <p><code>my_config</code> can be a:</p> <ul> <li>Path to a config file in yaml/toml/json (recommended),</li> <li>List of paths to config files (in case you want to split up various sub-configurations)</li> <li>Dictionary which is in the same structure of a config file, or</li> <li>A <code>WranglerConfig()</code>  instance.</li> </ul> <p>If not provided, Wrangler will use reasonable defaults.</p> <p>Default Wrangler Configuration Values</p> <p>If not explicitly provided, the following default values are used:</p> <pre><code>IDS:\n    TRANSIT_SHAPE_ID_METHOD: scalar\n    TRANSIT_SHAPE_ID_SCALAR: 1000000\n    ROAD_SHAPE_ID_METHOD: scalar\n    ROAD_SHAPE_ID_SCALAR: 1000\n    ML_LINK_ID_METHOD: range\n    ML_LINK_ID_RANGE: (950000, 999999)\n    ML_LINK_ID_SCALAR: 15000\n    ML_NODE_ID_METHOD: range\n    ML_NODE_ID_RANGE: (950000, 999999)\n    ML_NODE_ID_SCALAR: 15000\nEDITS:\n    EXISTING_VALUE_CONFLIC: warn\n    OVERWRITE_SCOPED: conflicting\nMODEL_ROADWAY:\n    ML_OFFSET_METERS: int = -10\n    ADDITIONAL_COPY_FROM_GP_TO_ML: []\n    ADDITIONAL_COPY_TO_ACCESS_EGRESS: []\nCPU:\n    EST_PD_READ_SPEED:\n        csv: 0.03\n        parquet: 0.005\n        geojson: 0.03\n        json: 0.15\n        txt: 0.04\n</code></pre> Extended usage <p>Load the default configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n</code></pre> <p>Access the configuration:</p> <pre><code>from network_wrangler.configs import DefaultConfig\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS\n&gt;&gt; -10\n</code></pre> <p>Modify the default configuration in-line:</p> <pre><code>from network_wrangler.configs import DefaultConfig\n\nDefaultConfig.MODEL_ROADWAY.ML_OFFSET_METERS = 20\n</code></pre> <p>Load a configuration from a file:</p> <pre><code>from network_wrangler.configs import load_wrangler_config\n\nconfig = load_wrangler_config(\"path/to/config.yaml\")\n</code></pre> <p>Set a configuration value:</p> <pre><code>config.MODEL_ROADWAY.ML_OFFSET_METERS = 10\n</code></pre> <p>show_source: false \u00a0\u00a0\u00a0\u00a0\u00a0     show_submodules: false \u00a0\u00a0\u00a0\u00a0\u00a0     show_classes: false \u00a0\u00a0\u00a0\u00a0\u00a0     show_functions: false</p>"},{"location":"how_to/#review-changes-beetween-networks","title":"Review changes beetween networks","text":"<p>Review Added Managed Lanes</p> <pre><code>from network_wrangler import load_roadway_from_dir\nfrom projectcard import read_card\nfrom pathlib import Path\n\nEXAMPLE_DIR = Path.cwd().parent / \"examples\"\nSTPAUL = EXAMPLE_DIR / \"stpaul\"\nSTPAUL_ROAD = load_roadway_from_dir(STPAUL)\n\ncard_path = STPAUL / \"project_cards\" / \"road.prop_change.managed_lanes.yml\"\ncard = read_card(card_path)\nstpaul_build = STPAUL_ROAD.apply(card)\n\nml_map = STPAUL_ROAD.links_df[STPAUL_ROAD.links_df.managed &gt; 0].explore(\n    color=\"blue\",\n    tiles=\"CartoDB positron\",\n    name=\"Managed Lanes\",\n    style_kwds={\"opacity\": 0.6, \"weight\": 20}\n)\n\nadded_managed_lanes = stpaul_build.links_df[(stpaul_build.links_df.managed &gt; 0) &amp; (STPAUL_ROAD.links_df.managed == 0)]\n\nadded_managed_lanes.explore(\n    m=ml_map,\n    color=\"red\",\n    name=\"Added Managed Lanes\",\n    style_kwds={\"opacity\": 0.6, \"weight\": 20}\n)\n</code></pre> <p>additional examples</p> <p>You can see additional scenario review capabilities in the example jupyter notebook <code>Visual Checks.ipynb</code>.</p>"},{"location":"how_to/#review-selected-facilities","title":"Review selected facilities","text":"<p>Review selected links</p> <pre><code>from network_wrangler import load_roadway_from_dir\nfrom pathlib import Path\n\nEXAMPLE_DIR = Path.cwd().parent / \"examples\"\nSTPAUL = EXAMPLE_DIR / \"stpaul\"\n\nSTPAUL_ROAD = load_roadway_from_dir(STPAUL)\nsel_dict = {\n  \"links\": {\n      \"modes\": [\"walk\"],\n      \"name\": [\"Valley Street\"],\n  },\n  \"from\": {\"model_node_id\": 174762},\n  \"to\": {\"model_node_id\": 43041},\n}\nSTPAUL_ROAD.get_selection(sel_dict).selected_links_df.explore(\n  color=\"red\", style_kwds={\"opacity\": 0.6, \"weight\": 20}\n)\n</code></pre> <p>additional examples</p> <p>You can see additional interactive exploration of how selections work and how to review them in the Jupyter notebook <code>Roadway Network Search.ipynb</code>.</p>"},{"location":"how_to/#create-your-own-example-data-from-open-street-map","title":"Create your own example data from Open Street Map","text":"<p>This script builds a basic OpenStreetMap (OSM) road network for a specified place.</p> <p>This script uses the network_wrangler library to build a roadway network from OSM data. It allows you to specify the place name, network type, output path, and file format for the resulting network.</p> Usage <p><code>python build_basic_osm_roadnet.py &lt;place_name&gt; [--type &lt;type&gt;] [--path &lt;path&gt;] [--file_format &lt;file_format&gt;]</code></p> <p>Parameters:</p> <ul> <li> <code>place_name</code>               (<code>str</code>)           \u2013            <p>Name of the place to build the road network for.</p> </li> <li> <code>--type</code>               (<code>Optional[str]</code>)           \u2013            <p>Type of network to build Defaults to <code>drive</code>.</p> </li> <li> <code>--path</code>               (<code>Optional[str]</code>)           \u2013            <p>Path to write the network. Defaults to current working directory.</p> </li> <li> <code>--file_format</code>               (<code>Optional[str]</code>)           \u2013            <p>File format for writing the network. Defaults to <code>geojson</code>.</p> </li> </ul> Example <pre><code>python build_basic_osm_roadnet.py \"San Francisco, California\" --type \"drive\" --path \"/path/to/output\" --file_format \"geojson\"\n</code></pre> <p>additional examples</p> <p>You can review the process in this script step-wise and interactively create your own networks from OSM with variation in the underlying assumptions in the Jupyter notebook <code>Create Network from OSM.ipynb</code>.</p>"},{"location":"how_to/#review-separated-model-network-managed-lanes","title":"Review separated model network managed lanes","text":"<p>Review model network</p> <pre><code>m_net = stpaul_build.model_net\nmodel_net_map = m_net.gp_links_df.explore(\n    tiles=\"CartoDB positron\",\n    color=\"blue\",\n    style_kwds={\"opacity\": 0.6, \"weight\": 10}\n)\nm_net.ml_links_df.explore(m=model_net_map, color=\"red\", style_kwds={\"opacity\": 0.6, \"weight\": 10})\nm_net.dummy_links_df.explore(m=model_net_map, color=\"green\", style_kwds={\"opacity\": 0.6, \"weight\": 10})\n</code></pre> <p>additional examples</p> <p>You can learn more about visualization of networks in the Jupyter notebook <code>Network Viewer.ipynb</code>.</p> <p>{!   include-markdown(\u201chttps://raw.githubusercontent.com/network-wrangler/projectcard/refs/heads/main/docs/how-to.md\u201d) !}</p>"},{"location":"networks/","title":"Networks","text":""},{"location":"networks/#roadway-network-format","title":"Roadway Network Format","text":"<p>RoadwayNetworks must be defined in the following format, which leverages Open Street Map which uses a tag-based format (e.g. json, xml).  This may be changed in the future to align with the tabular-based General Modeling Network Specification.</p> <p>A network is defined by a set of nodes and links which connect them.  Shapes may be optionally specified for each link in a separate file.</p> <p>file serialization formats</p> <p>While the default serialiation for roadway networks is <code>json</code>/<code>geojson</code> and for transit data is <code>csv</code>, networks can also be stored \u2013 more efficiently \u2013\u00a0in parquet files with a similar structure. Other workable file serializations include shapefiles, csvs, and anything that can be read by pandas or geopandas. This can be noted in most I/O procedures by including the keyword argument <code>file_format = &lt;format&gt;</code>.</p>"},{"location":"networks/#roadway-validation","title":"Roadway Validation","text":"<p>RoadwayNetworks can be validated using the following tools:</p> CLIPython API <p><pre><code>python validate_roadway.py &lt;network_directory&gt; &lt;file_format&gt; [-s] [--output_dir &lt;output_dir&gt;]\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>file_format</code>: The suffices of roadway network file name.</li> <li><code>-s</code>, <code>--strict</code>: Validate the roadway network strictly without parsing and filling in data.</li> <li><code>--output_dir</code>: The output directory for the validation report.</li> </ul> <p><pre><code>from network_wrangler.roadway.validate import validate_roadway_in_dir\nvalidate_roadway_in_dir(\n    directory=&lt;network_directory&gt;,\n    file_format=&lt;file_format&gt;,\n    strict=&lt;strict_bool&gt;&gt;,\n    output_dir=&lt;output_dir&gt;\n)\n</code></pre> Where:</p> <ul> <li><code>network_directory</code>: The roadway network file directory.</li> <li><code>file_format</code>: The suffices of roadway network file name.</li> <li><code>strict</code>: Validate the roadway network strictly without parsing and filling in data.</li> <li><code>output_dir</code>: The output directory for the validation report.</li> </ul>"},{"location":"networks/#examples","title":"Examples","text":"<p>Network Wrangler is packaged with two examples located in the <code>/examples</code> directory:</p> <ul> <li>St Paul, MN</li> <li>Small which is a several block exerpt of St Paul and is infinitely easier to trouble-shoot quickly.</li> </ul>"},{"location":"networks/#road-nodes-links","title":"Road Nodes &amp; Links","text":"<p>These are valid <code>geojson</code>, <code>shp</code>, or <code>parquet</code> file.</p> <p>See:</p> <ul> <li><code>RoadNodesTable</code></li> <li><code>RoadLinksTable</code></li> <li><code>RoadShapesTable</code></li> </ul>"},{"location":"networks/#transit-network-format","title":"Transit Network Format","text":"<p>Transit Networks must use the the GTFS Schedule format with the following additional constraints:</p> <ol> <li>At this time, only frequency-based schedules are supported.</li> <li>Each <code>stop_id</code> must be a node in the RoadwayNetwork.</li> <li><code>shapes.txt</code> is required (it is optional in GTFS) and must have the added field <code>model_node_id</code> associating a specific location with a node on the <code>RoadwayNetwork</code>.</li> </ol> <p>See:</p> <ul> <li><code>WranglerStopsTable</code></li> <li><code>RoutesTable</code></li> <li><code>WranglerTripsTable</code></li> <li><code>WranglerStopTimesTable</code></li> <li><code>WranglerShapesTable</code></li> <li><code>WranglerFrequenciesTable</code></li> <li><code>AgenciesTable</code></li> </ul>"},{"location":"networks/#transit-validation","title":"Transit Validation","text":"<p>TransitNetworks can be validated using the following tools:</p> CLIPython API <p><pre><code>python validate_transit.py &lt;network_dir&gt; &lt;file_format&gt; [-s] [--output_dir &lt;output_dir&gt;] [--road_dir &lt;road_dir&gt;] [--road_file_format &lt;road_file_format]\n</code></pre> Where:</p> <ul> <li><code>network_dir</code>: The transit network file directory.</li> <li><code>file_format</code>: The suffices of transit network .</li> <li><code>--output_dir</code>: The output directory for the validation report.</li> <li><code>--road_dir</code>: The directory roadway network. if want to validate the transit network to it.</li> <li><code>--road_file_format</code>: The file format for roadway network. Defaults to \u2018geojson\u2019.</li> </ul> <p><pre><code>from network_wrangler.transit.validate import validate_transit_in_dir\nvalidate_transit_in_dir(\n    dir=&lt;network_dir&gt;,\n    file_format=&lt;network_file_format&gt;,\n    road_dir=&lt;road_dir&gt;,\n    road_file_format=&lt;road_file_format,\n)\n</code></pre> Where:</p> <ul> <li><code>network_dir</code>: The roadway network file directory.</li> <li><code>network_file_format</code>: The file format of the transit files.</li> <li><code>road_dir</code>: The directory roadway network. if want to validate the transit network to it.</li> <li><code>road_file_format</code>: The file format for roadway network. Defaults to \u2018geojson\u2019.</li> </ul>"},{"location":"networks/#project-cards","title":"Project Cards","text":"<p>Project Cards, which define changes to the roadway and transit networks must use the ProjectCard standard.</p>"},{"location":"networks/#model-roadway-network-export-format","title":"Model Roadway Network Export Format","text":"<p>In order to separately calculate the delay when the networks are assigned in static roadway network assignment the roadway network must be exported with separate managed lane links.</p> <p>To acheive this, RoadwayNetwork objects have the option to be exported in the ModelRoadwayNetwork format, which separates a link into two: set of managed lanes and a set of general purpose lanes which are connected by a set of dummy connector links.  </p>"},{"location":"networks/#managed-lane-links","title":"Managed Lane Links","text":"<p>All properties preceded by <code>ML_</code> will be copied, without that prefix, to the managed lane links.</p> <p>The following are controlled by parameters which can be set using WranglerConfig:</p> <p>Geometry of managed lanes will be defined as a shape offset by the parameter <code>ML_OFFSET_METERS</code>. Properties defined in the parameter <code>ADDITIONAL_COPY_FROM_GP_TO_ML</code> are also copied from the parent link.</p> <p>New <code>model_node_id</code> s and <code>model_link_ids</code> are generated based either on ranges or using a scalar from the GP link based on: <code>ML_LINK_ID_METHOD</code>, <code>ML_NODE_ID_METHOD</code>, <code>ML_LINK_ID_RANGE</code>, <code>ML_NODE_ID_RANGE</code>, <code>ML_LINK_ID_SCALAR</code>, <code>ML_NODE_ID_SCALAR</code></p> <p><code>name</code> is created as \u201cmanaged lane of <code>name of GP link</code>\u201c</p> <p>Relationship to the general purpose lanes is retained using the fields <code>GP_A</code>, <code>GP_B</code>, <code>GP_model_link_id</code>.</p> <p>Managed-lane link-ids are generated as multiples of 10.</p>"},{"location":"networks/#dummy-connector-links","title":"Dummy Connector Links","text":"<p>Dummy connector links are generated between the general purpose lane links and managed lane links at points defined by the variable <code>ML_access_point</code> and <code>ML_egress_point</code>.  If a managed lane is created without explictly setting these values, network wrangler will assume that the managed lanes can be accessed at any node.</p> <p>The parameter <code>ADDITIONAL_COPY_TO_ACCESS_EGRESS</code> defines what additional attributes are copied from the general purpose lane to the access and egress links.</p> <p><code>name</code> is created as \u201c dummy link\u201d <p><code>model_link_id</code> is created as follows, noting that <code>model_link_id</code> s for managed lanes will be multiples of 10:</p> <ul> <li>1 + managed lane\u2019s <code>model_link_id</code> for access links</li> <li>2 + managed lane\u2019s <code>model_link_id</code> for access links</li> </ul> <p>See:</p> <ul> <li><code>ModelRoadwayConfig</code></li> <li><code>IdGenerationConfig</code></li> </ul>"},{"location":"networks/#network-management","title":"Network Management","text":"<p>Several functions assist in managing networks themselves including converting serialization formats and clipping to various geographic bounds.</p>"},{"location":"networks/#viewing","title":"Viewing","text":"<p>Because the roadway network is already in GeoDataFrames, they can be easily viewed in Jupyter Notebooks using commands such as:</p> <pre><code>my_small_net = SMALL_ROAD.links_df).explore(tiles=\"CartoDB positron\")\nSMALL_ROAD.nodes_df.explore(m=my_small_net, color=\"grey\")\nmy_small_net\n</code></pre> <p>For larger networks, you might want to sample objects if you are just trying to get the general picture in order to save memory.</p> <pre><code>stpaul_net = STPAUL_ROAD.links_df.sample(300).explore(tiles=\"CartoDB positron\")\nSTPAUL_ROAD.nodes_df.sample(300).explore(m=stpaul_net, color=\"grey\")\nstpaul_net\n</code></pre> <p>For transit, you have access to GeoDataFrames for both shapes and stops:</p> <pre><code>STPAUL_TRANSIT.shapes_gdf.explore(m=stpaul_net, color=\"limegreen\")\nSTPAUL_TRANSIT.stops_gdf.explore(m=stpaul_net, color=\"limegreen\")\nstpaul_net\n</code></pre>"},{"location":"networks/#clipping","title":"Clipping","text":"<p>There are two options for getting networks that are subsets of the larger one:</p> <ol> <li>clipping networks already loaded from files. Useful when you are already manipulating the objects.</li> <li>filtering the network when it is read in.</li> </ol> <p>In both instances, you have the option to filter based on one of three methods:</p> <ol> <li><code>boundary_file</code> which is a geojson or shapefile that you want to filter to.</li> <li><code>boundary_gdf</code> passing a geodataframe with a single polygon record that you want to filter to.</li> <li><code>boundary_geocode</code> which queries open streetmap for a jurisdiction matching the provided name, e.g. \u201cSt Paul, MN, USA\u201d.</li> </ol> <p>Transit additionally has the option to be filtered to a roadway network.</p>"},{"location":"networks/#clipping-loaded-networks","title":"Clipping loaded networks","text":"<p>If your network is already loaded from disk into a RoadwayNetwork or TransitNetwork, you can clip it using <code>clip_roadway()</code> or <code>clip_transit()</code>:</p> <pre><code>from network_wrangler.roadway import clip_roadway\nclipped_road_eco = clip_roadway(STPAUL_ROAD, boundary_file=TEST_DATA / \"ecolab.geojson\")\nclipped_road_eco.links_df.explore(m= color=\"hotpink\")\n</code></pre> <pre><code>from network_wrangler.transit.clip import clip_transit\nclipped_transit_eco = clip_transit(STPAUL_TRANSIT, roadway_net=clipped_road_eco)\n</code></pre>"},{"location":"networks/#filtering-on-being-read-from-disk","title":"Filtering on being read from disk","text":"<p>To filter roadway networks on being read-in, you can use the same parameters (<code>boundary_gdf</code>, <code>boundary_geocode</code> or <code>boundary_file</code>, available in <code>load_roadway_from_dir</code>, and all associated methods.  </p> <pre><code>downtown_net = load_roadway_from_dir(STPAUL_DIR, boundary_geocode=\"Downtown, St Paul, MN, USA\")\n</code></pre> <p>This feature is not yet implemented in transit.</p>"},{"location":"networks/#converting-serialization","title":"Converting Serialization","text":"<p>To convert file serialization without reading it into objects, you can use the method <code>convert_roadway_file_serialization()</code>:</p> <pre><code>from roadway.io import convert_roadway_file_serialization\n\nconvert_roadway_file_serialization(\n    my_dir, # the path to the input directory.\n    \"geojson\", # the file format of the input files. Defaults to \"geojson\".\n    my_new_dir, # the path were the output will be saved.\n    \"parquet\", # the format of the output files. Defaults to \"parquet\".\n    \"new\", # the name prefix of the roadway files that will be generated. Defaults to \"\".\n    overwrite = True, # if True, will overwrite the files if they already exist. Defaults to True.\n)\n</code></pre> <p>clip to</p> <p>Note you can also pass one of <code>boundary_geocode</code>, <code>boundary_gdf</code> or <code>boundary_file</code> to clip while you are converting the file serialization.</p>"}]}